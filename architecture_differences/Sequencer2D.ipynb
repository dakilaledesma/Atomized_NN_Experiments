{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakilaledesma/Atomized_NN_Experiments/blob/main/architecture_differences/Sequencer2D.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RBv2CGN3gJv",
        "outputId": "9c2ed204-f6df-4d3c-b97f-0ec74fc14c78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 121 ms, sys: 28.3 ms, total: 149 ms\n",
            "Wall time: 19.6 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "! unzip -q drive/MyDrive/UNC/H2022/orchidaceae_train.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXOHMDgapMby",
        "outputId": "614534c1-fdea-4650-ae7a-5fcca46fb25f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-image-models'...\n",
            "remote: Enumerating objects: 10686, done.\u001b[K\n",
            "remote: Counting objects: 100% (217/217), done.\u001b[K\n",
            "remote: Compressing objects: 100% (129/129), done.\u001b[K\n",
            "remote: Total 10686 (delta 105), reused 158 (delta 83), pack-reused 10469\u001b[K\n",
            "Receiving objects: 100% (10686/10686), 20.36 MiB | 24.04 MiB/s, done.\n",
            "Resolving deltas: 100% (7818/7818), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/rwightman/pytorch-image-models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "slckThLBilky"
      },
      "outputs": [],
      "source": [
        "import fileinput\n",
        "import sys\n",
        "\n",
        "def replacement(file, previousw, nextw):\n",
        "   for line in fileinput.input(file, inplace=1):\n",
        "       line = line.replace(previousw, nextw)\n",
        "       sys.stdout.write(line)\n",
        "\n",
        "file = \"/content/pytorch-image-models/timm/utils/checkpoint_saver.py\"\n",
        "replacement(file, \"if os.path.exists(last_save_path):\", \"# if os.path.exists(last_save_path):\")\n",
        "replacement(file, \"os.unlink(last_save_path)  # required for Windows support.\", \"# os.unlink(last_save_path)  # required for Windows support.\")\n",
        "replacement(file, \"os.link(last_save_path, save_path)\", \"# os.link(last_save_path, save_path)\")\n",
        "replacement(file, \"os.unlink(best_save_path)\", \"# os.unlink(best_save_path)\")\n",
        "replacement(file, \"os.link(last_save_path, best_save_path)\", \"# os.link(last_save_path, best_save_path)\")\n",
        "replacement(file, \"if os.path.exists(best_save_path):\", \"# if os.path.exists(best_save_path):\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kIBgHy6pSFD",
        "outputId": "fd4b376b-c168-4153-ddeb-497069f92131"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Train: 12 [2350/2354 (100%)]  Loss: 3.218 (2.66)  Time: 0.457s,   17.51/s  (0.467s,   17.12/s)  LR: 9.460e-05  Data: 0.005 (0.008)\n",
            "Train: 12 [2353/2354 (100%)]  Loss: 1.767 (2.66)  Time: 0.451s,   17.73/s  (0.467s,   17.12/s)  LR: 9.460e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.618 (0.618)  Loss:  1.5049 (1.5049)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.162 (0.147)  Loss:  3.4004 (1.1788)  Acc@1: 25.0000 (77.9412)  Acc@5: 25.0000 (93.1373)\n",
            "Test: [ 100/2354]  Time: 0.132 (0.140)  Loss:  2.6074 (1.3764)  Acc@1: 25.0000 (71.2871)  Acc@5: 75.0000 (92.0792)\n",
            "Test: [ 150/2354]  Time: 0.113 (0.138)  Loss:  0.2126 (1.2058)  Acc@1: 100.0000 (73.5099)  Acc@5: 100.0000 (94.3709)\n",
            "Test: [ 200/2354]  Time: 0.104 (0.137)  Loss:  2.7656 (1.1242)  Acc@1:  0.0000 (75.6219)  Acc@5: 75.0000 (94.9005)\n",
            "Test: [ 250/2354]  Time: 0.195 (0.137)  Loss:  0.2137 (1.1865)  Acc@1: 100.0000 (74.1036)  Acc@5: 100.0000 (94.7211)\n",
            "Test: [ 300/2354]  Time: 0.125 (0.137)  Loss:  1.0254 (1.1252)  Acc@1: 100.0000 (76.1628)  Acc@5: 100.0000 (94.9336)\n",
            "Test: [ 350/2354]  Time: 0.088 (0.136)  Loss:  1.4180 (1.1271)  Acc@1: 75.0000 (75.2137)  Acc@5: 100.0000 (95.2991)\n",
            "Test: [ 400/2354]  Time: 0.115 (0.136)  Loss:  0.6299 (1.1203)  Acc@1: 100.0000 (75.3117)  Acc@5: 100.0000 (95.0748)\n",
            "Test: [ 450/2354]  Time: 0.134 (0.136)  Loss:  0.3123 (1.0853)  Acc@1: 100.0000 (76.2749)  Acc@5: 100.0000 (95.3991)\n",
            "Test: [ 500/2354]  Time: 0.115 (0.136)  Loss:  1.0400 (1.0537)  Acc@1: 100.0000 (77.2455)  Acc@5: 100.0000 (95.6088)\n",
            "Test: [ 550/2354]  Time: 0.118 (0.136)  Loss:  2.0410 (1.0416)  Acc@1: 75.0000 (77.2686)  Acc@5: 75.0000 (95.8258)\n",
            "Test: [ 600/2354]  Time: 0.278 (0.136)  Loss:  0.5073 (1.0363)  Acc@1: 100.0000 (78.0366)  Acc@5: 100.0000 (95.9651)\n",
            "Test: [ 650/2354]  Time: 0.154 (0.138)  Loss:  0.3420 (1.0143)  Acc@1: 100.0000 (78.3026)  Acc@5: 100.0000 (96.0829)\n",
            "Test: [ 700/2354]  Time: 0.143 (0.138)  Loss:  0.5562 (1.0042)  Acc@1: 100.0000 (78.8160)  Acc@5: 100.0000 (96.0414)\n",
            "Test: [ 750/2354]  Time: 0.129 (0.138)  Loss:  0.7783 (1.0063)  Acc@1: 75.0000 (78.5619)  Acc@5: 100.0000 (96.0053)\n",
            "Test: [ 800/2354]  Time: 0.137 (0.138)  Loss:  0.4626 (1.0301)  Acc@1: 100.0000 (77.7154)  Acc@5: 100.0000 (95.8801)\n",
            "Test: [ 850/2354]  Time: 0.198 (0.138)  Loss:  0.1938 (1.0251)  Acc@1: 100.0000 (77.7615)  Acc@5: 100.0000 (95.8578)\n",
            "Test: [ 900/2354]  Time: 0.206 (0.138)  Loss:  0.8813 (1.0080)  Acc@1: 75.0000 (78.2464)  Acc@5: 75.0000 (96.0322)\n",
            "Test: [ 950/2354]  Time: 0.161 (0.138)  Loss:  0.4250 (0.9867)  Acc@1: 100.0000 (79.0484)  Acc@5: 100.0000 (96.1882)\n",
            "Test: [1000/2354]  Time: 0.162 (0.137)  Loss:  0.4565 (0.9868)  Acc@1: 100.0000 (79.3207)  Acc@5: 100.0000 (96.2787)\n",
            "Test: [1050/2354]  Time: 0.129 (0.137)  Loss:  1.2256 (0.9906)  Acc@1: 50.0000 (79.1865)  Acc@5: 100.0000 (96.2179)\n",
            "Test: [1100/2354]  Time: 0.128 (0.137)  Loss:  1.4619 (0.9915)  Acc@1: 75.0000 (79.1099)  Acc@5: 100.0000 (96.3442)\n",
            "Test: [1150/2354]  Time: 0.086 (0.137)  Loss:  2.1758 (0.9839)  Acc@1: 100.0000 (79.3440)  Acc@5: 100.0000 (96.3076)\n",
            "Test: [1200/2354]  Time: 0.153 (0.137)  Loss:  1.0977 (0.9864)  Acc@1: 75.0000 (79.3505)  Acc@5: 75.0000 (96.2739)\n",
            "Test: [1250/2354]  Time: 0.120 (0.137)  Loss:  0.2472 (0.9720)  Acc@1: 100.0000 (79.8161)  Acc@5: 100.0000 (96.2830)\n",
            "Test: [1300/2354]  Time: 0.083 (0.137)  Loss:  0.7783 (0.9756)  Acc@1: 100.0000 (79.4581)  Acc@5: 100.0000 (96.2913)\n",
            "Test: [1350/2354]  Time: 0.278 (0.138)  Loss:  0.1721 (0.9759)  Acc@1: 100.0000 (79.5522)  Acc@5: 100.0000 (96.2620)\n",
            "Test: [1400/2354]  Time: 0.167 (0.138)  Loss:  0.4548 (0.9782)  Acc@1: 100.0000 (79.5503)  Acc@5: 100.0000 (96.2170)\n",
            "Test: [1450/2354]  Time: 0.092 (0.138)  Loss:  1.0664 (0.9686)  Acc@1: 75.0000 (79.6692)  Acc@5: 100.0000 (96.2957)\n",
            "Test: [1500/2354]  Time: 0.156 (0.138)  Loss:  1.5176 (0.9755)  Acc@1: 50.0000 (79.4137)  Acc@5: 100.0000 (96.2358)\n",
            "Test: [1550/2354]  Time: 0.166 (0.138)  Loss:  0.5425 (1.0002)  Acc@1: 100.0000 (78.6267)  Acc@5: 100.0000 (96.0187)\n",
            "Test: [1600/2354]  Time: 0.091 (0.137)  Loss:  0.3821 (1.0099)  Acc@1: 100.0000 (78.2636)  Acc@5: 100.0000 (95.9869)\n",
            "Test: [1650/2354]  Time: 0.162 (0.137)  Loss:  0.3384 (1.0162)  Acc@1: 100.0000 (77.8619)  Acc@5: 100.0000 (95.9570)\n",
            "Test: [1700/2354]  Time: 0.159 (0.137)  Loss:  0.0492 (1.0077)  Acc@1: 100.0000 (78.1893)  Acc@5: 100.0000 (96.0024)\n",
            "Test: [1750/2354]  Time: 0.118 (0.137)  Loss:  1.3594 (1.0219)  Acc@1: 75.0000 (77.2844)  Acc@5: 100.0000 (96.0594)\n",
            "Test: [1800/2354]  Time: 0.109 (0.137)  Loss:  1.3486 (1.0275)  Acc@1: 75.0000 (77.2765)  Acc@5: 100.0000 (95.9883)\n",
            "Test: [1850/2354]  Time: 0.186 (0.137)  Loss:  0.5454 (1.0229)  Acc@1: 100.0000 (77.3906)  Acc@5: 100.0000 (96.0562)\n",
            "Test: [1900/2354]  Time: 0.172 (0.137)  Loss:  1.5322 (1.0275)  Acc@1: 75.0000 (77.3935)  Acc@5: 75.0000 (95.9890)\n",
            "Test: [1950/2354]  Time: 0.145 (0.137)  Loss:  1.3848 (1.0315)  Acc@1: 100.0000 (77.4218)  Acc@5: 100.0000 (95.9380)\n",
            "Test: [2000/2354]  Time: 0.125 (0.137)  Loss:  0.4216 (1.0303)  Acc@1: 100.0000 (77.5362)  Acc@5: 100.0000 (95.9770)\n",
            "Test: [2050/2354]  Time: 0.158 (0.137)  Loss:  2.3848 (1.0467)  Acc@1: 25.0000 (76.8771)  Acc@5: 75.0000 (95.7582)\n",
            "Test: [2100/2354]  Time: 0.112 (0.138)  Loss:  1.5957 (1.0453)  Acc@1: 75.0000 (76.8801)  Acc@5: 100.0000 (95.7996)\n",
            "Test: [2150/2354]  Time: 0.114 (0.137)  Loss:  2.6250 (1.0633)  Acc@1:  0.0000 (76.1971)  Acc@5: 75.0000 (95.6299)\n",
            "Test: [2200/2354]  Time: 0.124 (0.137)  Loss:  1.9248 (1.0656)  Acc@1: 75.0000 (76.1699)  Acc@5: 100.0000 (95.6383)\n",
            "Test: [2250/2354]  Time: 0.126 (0.137)  Loss:  0.2974 (1.0655)  Acc@1: 100.0000 (76.3327)  Acc@5: 100.0000 (95.6464)\n",
            "Test: [2300/2354]  Time: 0.128 (0.137)  Loss:  0.2375 (1.0631)  Acc@1: 100.0000 (76.4668)  Acc@5: 100.0000 (95.6432)\n",
            "Test: [2350/2354]  Time: 0.075 (0.137)  Loss:  1.4121 (1.0631)  Acc@1: 75.0000 (76.3930)  Acc@5: 100.0000 (95.6614)\n",
            "Test: [2354/2354]  Time: 0.068 (0.137)  Loss:  1.5195 (1.0642)  Acc@1: 66.6667 (76.3882)  Acc@5: 100.0000 (95.6471)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-2.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar', 70.64444208514705)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-9.pth.tar', 68.34058817284213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-8.pth.tar', 64.23187174859326)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-7.pth.tar', 58.424461196265995)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-6.pth.tar', 53.67873447368398)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-5.pth.tar', 44.633188236543155)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-4.pth.tar', 39.08058180273915)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-3.pth.tar', 23.29334324238242)\n",
            "\n",
            "Train: 13 [   0/2354 (  0%)]  Loss: 2.245 (2.25)  Time: 1.207s,    6.63/s  (1.207s,    6.63/s)  LR: 9.369e-05  Data: 0.488 (0.488)\n",
            "Train: 13 [  50/2354 (  2%)]  Loss: 3.509 (2.57)  Time: 0.478s,   16.75/s  (0.499s,   16.04/s)  LR: 9.369e-05  Data: 0.010 (0.018)\n",
            "Train: 13 [ 100/2354 (  4%)]  Loss: 1.543 (2.66)  Time: 0.466s,   17.17/s  (0.483s,   16.58/s)  LR: 9.369e-05  Data: 0.008 (0.013)\n",
            "Train: 13 [ 150/2354 (  6%)]  Loss: 3.461 (2.60)  Time: 0.459s,   17.42/s  (0.482s,   16.60/s)  LR: 9.369e-05  Data: 0.006 (0.011)\n",
            "Train: 13 [ 200/2354 (  8%)]  Loss: 3.597 (2.62)  Time: 0.465s,   17.20/s  (0.478s,   16.74/s)  LR: 9.369e-05  Data: 0.006 (0.010)\n",
            "Train: 13 [ 250/2354 ( 11%)]  Loss: 1.700 (2.61)  Time: 0.460s,   17.40/s  (0.475s,   16.84/s)  LR: 9.369e-05  Data: 0.007 (0.010)\n",
            "Train: 13 [ 300/2354 ( 13%)]  Loss: 1.960 (2.61)  Time: 0.463s,   17.29/s  (0.473s,   16.90/s)  LR: 9.369e-05  Data: 0.009 (0.009)\n",
            "Train: 13 [ 350/2354 ( 15%)]  Loss: 2.072 (2.58)  Time: 0.472s,   16.94/s  (0.475s,   16.86/s)  LR: 9.369e-05  Data: 0.008 (0.009)\n",
            "Train: 13 [ 400/2354 ( 17%)]  Loss: 2.929 (2.57)  Time: 0.475s,   16.83/s  (0.474s,   16.89/s)  LR: 9.369e-05  Data: 0.006 (0.009)\n",
            "Train: 13 [ 450/2354 ( 19%)]  Loss: 2.934 (2.57)  Time: 0.467s,   17.14/s  (0.473s,   16.92/s)  LR: 9.369e-05  Data: 0.009 (0.009)\n",
            "Train: 13 [ 500/2354 ( 21%)]  Loss: 2.680 (2.56)  Time: 0.460s,   17.39/s  (0.472s,   16.95/s)  LR: 9.369e-05  Data: 0.006 (0.009)\n",
            "Train: 13 [ 550/2354 ( 23%)]  Loss: 2.778 (2.58)  Time: 0.670s,   11.94/s  (0.472s,   16.94/s)  LR: 9.369e-05  Data: 0.013 (0.009)\n",
            "Train: 13 [ 600/2354 ( 25%)]  Loss: 2.347 (2.58)  Time: 0.467s,   17.12/s  (0.472s,   16.94/s)  LR: 9.369e-05  Data: 0.010 (0.009)\n",
            "Train: 13 [ 650/2354 ( 28%)]  Loss: 3.762 (2.59)  Time: 0.463s,   17.28/s  (0.472s,   16.96/s)  LR: 9.369e-05  Data: 0.006 (0.009)\n",
            "Train: 13 [ 700/2354 ( 30%)]  Loss: 1.979 (2.59)  Time: 0.469s,   17.05/s  (0.471s,   16.97/s)  LR: 9.369e-05  Data: 0.010 (0.009)\n",
            "Train: 13 [ 750/2354 ( 32%)]  Loss: 1.595 (2.58)  Time: 0.467s,   17.12/s  (0.471s,   16.99/s)  LR: 9.369e-05  Data: 0.010 (0.008)\n",
            "Train: 13 [ 800/2354 ( 34%)]  Loss: 3.495 (2.59)  Time: 0.467s,   17.13/s  (0.472s,   16.96/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [ 850/2354 ( 36%)]  Loss: 2.274 (2.57)  Time: 0.460s,   17.38/s  (0.471s,   16.97/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [ 900/2354 ( 38%)]  Loss: 2.611 (2.56)  Time: 0.462s,   17.30/s  (0.471s,   16.98/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [ 950/2354 ( 40%)]  Loss: 3.910 (2.57)  Time: 0.469s,   17.05/s  (0.471s,   16.99/s)  LR: 9.369e-05  Data: 0.008 (0.008)\n",
            "Train: 13 [1000/2354 ( 42%)]  Loss: 2.117 (2.58)  Time: 0.473s,   16.93/s  (0.471s,   16.97/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [1050/2354 ( 45%)]  Loss: 2.511 (2.58)  Time: 0.465s,   17.19/s  (0.471s,   16.98/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [1100/2354 ( 47%)]  Loss: 1.742 (2.59)  Time: 0.475s,   16.84/s  (0.471s,   16.99/s)  LR: 9.369e-05  Data: 0.009 (0.008)\n",
            "Train: 13 [1150/2354 ( 49%)]  Loss: 1.771 (2.59)  Time: 0.467s,   17.12/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.006 (0.008)\n",
            "Train: 13 [1200/2354 ( 51%)]  Loss: 2.077 (2.60)  Time: 0.479s,   16.68/s  (0.471s,   16.97/s)  LR: 9.369e-05  Data: 0.018 (0.008)\n",
            "Train: 13 [1250/2354 ( 53%)]  Loss: 2.625 (2.59)  Time: 0.462s,   17.32/s  (0.471s,   16.98/s)  LR: 9.369e-05  Data: 0.008 (0.008)\n",
            "Train: 13 [1300/2354 ( 55%)]  Loss: 2.337 (2.59)  Time: 0.465s,   17.20/s  (0.471s,   16.98/s)  LR: 9.369e-05  Data: 0.010 (0.008)\n",
            "Train: 13 [1350/2354 ( 57%)]  Loss: 2.027 (2.59)  Time: 0.464s,   17.23/s  (0.471s,   16.99/s)  LR: 9.369e-05  Data: 0.009 (0.008)\n",
            "Train: 13 [1400/2354 ( 59%)]  Loss: 1.988 (2.59)  Time: 0.464s,   17.23/s  (0.471s,   16.98/s)  LR: 9.369e-05  Data: 0.006 (0.008)\n",
            "Train: 13 [1450/2354 ( 62%)]  Loss: 2.455 (2.58)  Time: 0.467s,   17.12/s  (0.471s,   16.99/s)  LR: 9.369e-05  Data: 0.010 (0.008)\n",
            "Train: 13 [1500/2354 ( 64%)]  Loss: 2.371 (2.58)  Time: 0.469s,   17.07/s  (0.471s,   16.99/s)  LR: 9.369e-05  Data: 0.009 (0.008)\n",
            "Train: 13 [1550/2354 ( 66%)]  Loss: 3.545 (2.58)  Time: 0.460s,   17.38/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [1600/2354 ( 68%)]  Loss: 2.465 (2.59)  Time: 0.609s,   13.13/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.019 (0.008)\n",
            "Train: 13 [1650/2354 ( 70%)]  Loss: 1.625 (2.59)  Time: 0.461s,   17.35/s  (0.471s,   16.99/s)  LR: 9.369e-05  Data: 0.009 (0.008)\n",
            "Train: 13 [1700/2354 ( 72%)]  Loss: 2.854 (2.59)  Time: 0.462s,   17.32/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.008 (0.008)\n",
            "Train: 13 [1750/2354 ( 74%)]  Loss: 2.964 (2.59)  Time: 0.467s,   17.14/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [1800/2354 ( 76%)]  Loss: 2.793 (2.59)  Time: 0.463s,   17.27/s  (0.470s,   17.01/s)  LR: 9.369e-05  Data: 0.006 (0.008)\n",
            "Train: 13 [1850/2354 ( 79%)]  Loss: 2.792 (2.59)  Time: 0.471s,   16.98/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.008 (0.008)\n",
            "Train: 13 [1900/2354 ( 81%)]  Loss: 3.007 (2.59)  Time: 0.465s,   17.20/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.010 (0.008)\n",
            "Train: 13 [1950/2354 ( 83%)]  Loss: 3.337 (2.59)  Time: 0.466s,   17.18/s  (0.470s,   17.00/s)  LR: 9.369e-05  Data: 0.010 (0.008)\n",
            "Train: 13 [2000/2354 ( 85%)]  Loss: 2.236 (2.60)  Time: 0.464s,   17.25/s  (0.470s,   17.01/s)  LR: 9.369e-05  Data: 0.009 (0.008)\n",
            "Train: 13 [2050/2354 ( 87%)]  Loss: 2.299 (2.59)  Time: 0.462s,   17.30/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [2100/2354 ( 89%)]  Loss: 4.490 (2.59)  Time: 0.465s,   17.20/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [2150/2354 ( 91%)]  Loss: 1.602 (2.60)  Time: 0.474s,   16.89/s  (0.470s,   17.00/s)  LR: 9.369e-05  Data: 0.010 (0.008)\n",
            "Train: 13 [2200/2354 ( 93%)]  Loss: 2.393 (2.59)  Time: 0.484s,   16.54/s  (0.470s,   17.01/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [2250/2354 ( 96%)]  Loss: 2.639 (2.59)  Time: 0.461s,   17.35/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [2300/2354 ( 98%)]  Loss: 3.888 (2.59)  Time: 0.462s,   17.32/s  (0.471s,   17.00/s)  LR: 9.369e-05  Data: 0.007 (0.008)\n",
            "Train: 13 [2350/2354 (100%)]  Loss: 3.836 (2.60)  Time: 0.465s,   17.21/s  (0.470s,   17.00/s)  LR: 9.369e-05  Data: 0.005 (0.008)\n",
            "Train: 13 [2353/2354 (100%)]  Loss: 2.137 (2.60)  Time: 0.453s,   17.65/s  (0.470s,   17.00/s)  LR: 9.369e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.666 (0.666)  Loss:  0.2932 (0.2932)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.137 (0.154)  Loss:  2.6836 (0.8809)  Acc@1: 25.0000 (82.8431)  Acc@5: 50.0000 (95.5882)\n",
            "Test: [ 100/2354]  Time: 0.088 (0.145)  Loss:  1.9424 (1.1149)  Acc@1: 25.0000 (74.7525)  Acc@5: 100.0000 (95.7921)\n",
            "Test: [ 150/2354]  Time: 0.143 (0.142)  Loss:  1.5146 (0.9666)  Acc@1: 25.0000 (77.4834)  Acc@5: 100.0000 (97.1854)\n",
            "Test: [ 200/2354]  Time: 0.127 (0.140)  Loss:  2.3887 (0.9402)  Acc@1: 25.0000 (75.4975)  Acc@5: 100.0000 (97.1393)\n",
            "Test: [ 250/2354]  Time: 0.101 (0.139)  Loss:  0.5288 (1.0265)  Acc@1: 100.0000 (73.8048)  Acc@5: 100.0000 (96.8127)\n",
            "Test: [ 300/2354]  Time: 0.168 (0.145)  Loss:  0.8491 (1.0019)  Acc@1: 100.0000 (75.4983)  Acc@5: 100.0000 (96.7608)\n",
            "Test: [ 350/2354]  Time: 0.163 (0.144)  Loss:  1.8506 (1.0099)  Acc@1: 25.0000 (74.9288)  Acc@5: 100.0000 (96.9373)\n",
            "Test: [ 400/2354]  Time: 0.120 (0.143)  Loss:  0.3115 (1.0196)  Acc@1: 100.0000 (74.6883)  Acc@5: 100.0000 (96.5087)\n",
            "Test: [ 450/2354]  Time: 0.177 (0.142)  Loss:  0.2986 (0.9736)  Acc@1: 100.0000 (76.2195)  Acc@5: 100.0000 (96.7295)\n",
            "Test: [ 500/2354]  Time: 0.077 (0.141)  Loss:  0.4326 (0.9271)  Acc@1: 100.0000 (77.4950)  Acc@5: 100.0000 (96.9062)\n",
            "Test: [ 550/2354]  Time: 0.144 (0.141)  Loss:  2.2949 (0.9297)  Acc@1: 50.0000 (76.7241)  Acc@5: 75.0000 (96.8240)\n",
            "Test: [ 600/2354]  Time: 0.117 (0.141)  Loss:  1.3418 (0.9225)  Acc@1: 75.0000 (77.1631)  Acc@5: 75.0000 (96.8386)\n",
            "Test: [ 650/2354]  Time: 0.101 (0.140)  Loss:  0.5840 (0.9068)  Acc@1: 75.0000 (77.6882)  Acc@5: 100.0000 (96.8510)\n",
            "Test: [ 700/2354]  Time: 0.086 (0.140)  Loss:  0.6982 (0.8896)  Acc@1: 100.0000 (78.6733)  Acc@5: 100.0000 (96.9330)\n",
            "Test: [ 750/2354]  Time: 0.124 (0.140)  Loss:  1.0605 (0.8964)  Acc@1: 75.0000 (78.8615)  Acc@5: 100.0000 (96.8708)\n",
            "Test: [ 800/2354]  Time: 0.153 (0.140)  Loss:  0.3037 (0.9207)  Acc@1: 100.0000 (77.8714)  Acc@5: 100.0000 (96.7228)\n",
            "Test: [ 850/2354]  Time: 0.153 (0.140)  Loss:  0.2173 (0.9104)  Acc@1: 100.0000 (78.4665)  Acc@5: 100.0000 (96.7098)\n",
            "Test: [ 900/2354]  Time: 0.125 (0.139)  Loss:  1.2900 (0.8884)  Acc@1: 75.0000 (79.2730)  Acc@5: 75.0000 (96.8646)\n",
            "Test: [ 950/2354]  Time: 0.186 (0.139)  Loss:  0.3879 (0.8730)  Acc@1: 100.0000 (79.9159)  Acc@5: 100.0000 (96.9506)\n",
            "Test: [1000/2354]  Time: 0.190 (0.139)  Loss:  0.9556 (0.8795)  Acc@1: 75.0000 (79.8202)  Acc@5: 100.0000 (96.9031)\n",
            "Test: [1050/2354]  Time: 0.117 (0.139)  Loss:  1.0273 (0.8835)  Acc@1: 75.0000 (79.8525)  Acc@5: 100.0000 (96.8839)\n",
            "Test: [1100/2354]  Time: 0.087 (0.139)  Loss:  0.5435 (0.8914)  Acc@1: 100.0000 (79.6322)  Acc@5: 100.0000 (96.9119)\n",
            "Test: [1150/2354]  Time: 0.089 (0.139)  Loss:  1.4951 (0.8788)  Acc@1: 100.0000 (79.9957)  Acc@5: 100.0000 (96.8723)\n",
            "Test: [1200/2354]  Time: 0.151 (0.139)  Loss:  0.8887 (0.8756)  Acc@1: 75.0000 (80.2040)  Acc@5: 100.0000 (96.8360)\n",
            "Test: [1250/2354]  Time: 0.090 (0.139)  Loss:  0.1847 (0.8664)  Acc@1: 100.0000 (80.6155)  Acc@5: 100.0000 (96.8425)\n",
            "Test: [1300/2354]  Time: 0.099 (0.139)  Loss:  0.2727 (0.8601)  Acc@1: 100.0000 (80.5342)  Acc@5: 100.0000 (96.8486)\n",
            "Test: [1350/2354]  Time: 0.178 (0.138)  Loss:  0.1197 (0.8615)  Acc@1: 100.0000 (80.6070)  Acc@5: 100.0000 (96.8542)\n",
            "Test: [1400/2354]  Time: 0.155 (0.140)  Loss:  0.6006 (0.8589)  Acc@1: 100.0000 (80.7994)  Acc@5: 100.0000 (96.8059)\n",
            "Test: [1450/2354]  Time: 0.097 (0.139)  Loss:  0.8818 (0.8554)  Acc@1: 100.0000 (80.9442)  Acc@5: 100.0000 (96.8815)\n",
            "Test: [1500/2354]  Time: 0.095 (0.139)  Loss:  1.6875 (0.8568)  Acc@1: 50.0000 (80.9127)  Acc@5: 100.0000 (96.8854)\n",
            "Test: [1550/2354]  Time: 0.172 (0.139)  Loss:  0.3013 (0.8758)  Acc@1: 100.0000 (80.2063)  Acc@5: 100.0000 (96.8085)\n",
            "Test: [1600/2354]  Time: 0.162 (0.139)  Loss:  0.3501 (0.8819)  Acc@1: 100.0000 (79.8407)  Acc@5: 100.0000 (96.8145)\n",
            "Test: [1650/2354]  Time: 0.182 (0.139)  Loss:  1.2607 (0.8920)  Acc@1: 75.0000 (79.5730)  Acc@5: 100.0000 (96.7747)\n",
            "Test: [1700/2354]  Time: 0.116 (0.139)  Loss:  0.0521 (0.8883)  Acc@1: 100.0000 (79.7325)  Acc@5: 100.0000 (96.7519)\n",
            "Test: [1750/2354]  Time: 0.168 (0.139)  Loss:  1.6445 (0.8941)  Acc@1: 25.0000 (79.4118)  Acc@5: 100.0000 (96.8018)\n",
            "Test: [1800/2354]  Time: 0.141 (0.139)  Loss:  0.4077 (0.8915)  Acc@1: 100.0000 (79.6224)  Acc@5: 100.0000 (96.8629)\n",
            "Test: [1850/2354]  Time: 0.123 (0.139)  Loss:  0.7544 (0.8865)  Acc@1: 100.0000 (79.7002)  Acc@5: 100.0000 (96.9206)\n",
            "Test: [1900/2354]  Time: 0.184 (0.139)  Loss:  1.5889 (0.8849)  Acc@1: 50.0000 (79.8001)  Acc@5: 75.0000 (96.9095)\n",
            "Test: [1950/2354]  Time: 0.216 (0.139)  Loss:  0.6660 (0.8848)  Acc@1: 75.0000 (79.7924)  Acc@5: 100.0000 (96.8478)\n",
            "Test: [2000/2354]  Time: 0.135 (0.139)  Loss:  0.8135 (0.8837)  Acc@1: 75.0000 (79.7726)  Acc@5: 100.0000 (96.8266)\n",
            "Test: [2050/2354]  Time: 0.248 (0.139)  Loss:  2.5410 (0.8960)  Acc@1: 25.0000 (79.4856)  Acc@5: 75.0000 (96.6602)\n",
            "Test: [2100/2354]  Time: 0.148 (0.140)  Loss:  1.2344 (0.8980)  Acc@1: 100.0000 (79.4265)  Acc@5: 100.0000 (96.7040)\n",
            "Test: [2150/2354]  Time: 0.176 (0.140)  Loss:  0.9028 (0.9127)  Acc@1: 100.0000 (79.0795)  Acc@5: 100.0000 (96.6062)\n",
            "Test: [2200/2354]  Time: 0.125 (0.140)  Loss:  1.1777 (0.9267)  Acc@1: 100.0000 (78.4871)  Acc@5: 100.0000 (96.6152)\n",
            "Test: [2250/2354]  Time: 0.138 (0.140)  Loss:  0.2773 (0.9275)  Acc@1: 100.0000 (78.4429)  Acc@5: 100.0000 (96.6459)\n",
            "Test: [2300/2354]  Time: 0.188 (0.139)  Loss:  0.1750 (0.9269)  Acc@1: 100.0000 (78.4876)  Acc@5: 100.0000 (96.6754)\n",
            "Test: [2350/2354]  Time: 0.075 (0.139)  Loss:  1.4482 (0.9285)  Acc@1: 50.0000 (78.2858)  Acc@5: 100.0000 (96.7035)\n",
            "Test: [2354/2354]  Time: 0.065 (0.139)  Loss:  0.6553 (0.9285)  Acc@1: 100.0000 (78.2992)  Acc@5: 100.0000 (96.7088)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-3.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar', 70.64444208514705)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-9.pth.tar', 68.34058817284213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-8.pth.tar', 64.23187174859326)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-7.pth.tar', 58.424461196265995)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-6.pth.tar', 53.67873447368398)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-5.pth.tar', 44.633188236543155)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-4.pth.tar', 39.08058180273915)\n",
            "\n",
            "Train: 14 [   0/2354 (  0%)]  Loss: 2.351 (2.35)  Time: 1.226s,    6.53/s  (1.226s,    6.53/s)  LR: 9.271e-05  Data: 0.496 (0.496)\n",
            "Train: 14 [  50/2354 (  2%)]  Loss: 2.705 (2.39)  Time: 0.465s,   17.19/s  (0.497s,   16.09/s)  LR: 9.271e-05  Data: 0.010 (0.017)\n",
            "Train: 14 [ 100/2354 (  4%)]  Loss: 2.905 (2.37)  Time: 0.467s,   17.13/s  (0.482s,   16.60/s)  LR: 9.271e-05  Data: 0.007 (0.013)\n",
            "Train: 14 [ 150/2354 (  6%)]  Loss: 2.398 (2.39)  Time: 0.470s,   17.01/s  (0.481s,   16.63/s)  LR: 9.271e-05  Data: 0.006 (0.011)\n",
            "Train: 14 [ 200/2354 (  8%)]  Loss: 2.872 (2.40)  Time: 0.459s,   17.44/s  (0.477s,   16.78/s)  LR: 9.271e-05  Data: 0.006 (0.010)\n",
            "Train: 14 [ 250/2354 ( 11%)]  Loss: 3.713 (2.43)  Time: 0.465s,   17.19/s  (0.475s,   16.86/s)  LR: 9.271e-05  Data: 0.007 (0.010)\n",
            "Train: 14 [ 300/2354 ( 13%)]  Loss: 2.498 (2.42)  Time: 0.466s,   17.18/s  (0.473s,   16.91/s)  LR: 9.271e-05  Data: 0.009 (0.009)\n",
            "Train: 14 [ 350/2354 ( 15%)]  Loss: 2.175 (2.43)  Time: 0.476s,   16.80/s  (0.474s,   16.86/s)  LR: 9.271e-05  Data: 0.007 (0.009)\n",
            "Train: 14 [ 400/2354 ( 17%)]  Loss: 2.812 (2.43)  Time: 0.462s,   17.31/s  (0.474s,   16.89/s)  LR: 9.271e-05  Data: 0.007 (0.009)\n",
            "Train: 14 [ 450/2354 ( 19%)]  Loss: 2.319 (2.42)  Time: 0.464s,   17.26/s  (0.473s,   16.93/s)  LR: 9.271e-05  Data: 0.007 (0.009)\n",
            "Train: 14 [ 500/2354 ( 21%)]  Loss: 2.458 (2.43)  Time: 0.459s,   17.42/s  (0.472s,   16.95/s)  LR: 9.271e-05  Data: 0.006 (0.009)\n",
            "Train: 14 [ 550/2354 ( 23%)]  Loss: 4.076 (2.44)  Time: 0.462s,   17.32/s  (0.473s,   16.92/s)  LR: 9.271e-05  Data: 0.007 (0.009)\n",
            "Train: 14 [ 600/2354 ( 25%)]  Loss: 1.871 (2.44)  Time: 0.465s,   17.22/s  (0.472s,   16.94/s)  LR: 9.271e-05  Data: 0.007 (0.009)\n",
            "Train: 14 [ 650/2354 ( 28%)]  Loss: 1.846 (2.45)  Time: 0.473s,   16.92/s  (0.472s,   16.96/s)  LR: 9.271e-05  Data: 0.008 (0.009)\n",
            "Train: 14 [ 700/2354 ( 30%)]  Loss: 2.091 (2.46)  Time: 0.464s,   17.23/s  (0.471s,   16.98/s)  LR: 9.271e-05  Data: 0.006 (0.008)\n",
            "Train: 14 [ 750/2354 ( 32%)]  Loss: 2.306 (2.47)  Time: 0.467s,   17.15/s  (0.472s,   16.95/s)  LR: 9.271e-05  Data: 0.010 (0.008)\n",
            "Train: 14 [ 800/2354 ( 34%)]  Loss: 2.645 (2.46)  Time: 0.459s,   17.43/s  (0.472s,   16.97/s)  LR: 9.271e-05  Data: 0.006 (0.008)\n",
            "Train: 14 [ 850/2354 ( 36%)]  Loss: 1.763 (2.47)  Time: 0.460s,   17.39/s  (0.471s,   16.98/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [ 900/2354 ( 38%)]  Loss: 2.900 (2.47)  Time: 0.463s,   17.29/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [ 950/2354 ( 40%)]  Loss: 2.574 (2.48)  Time: 0.471s,   16.98/s  (0.471s,   16.97/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1000/2354 ( 42%)]  Loss: 1.912 (2.48)  Time: 0.464s,   17.25/s  (0.471s,   16.98/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1050/2354 ( 45%)]  Loss: 3.046 (2.48)  Time: 0.467s,   17.12/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1100/2354 ( 47%)]  Loss: 1.892 (2.48)  Time: 0.464s,   17.24/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.009 (0.008)\n",
            "Train: 14 [1150/2354 ( 49%)]  Loss: 2.015 (2.48)  Time: 0.456s,   17.53/s  (0.471s,   16.98/s)  LR: 9.271e-05  Data: 0.006 (0.008)\n",
            "Train: 14 [1200/2354 ( 51%)]  Loss: 2.004 (2.49)  Time: 0.464s,   17.26/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.009 (0.008)\n",
            "Train: 14 [1250/2354 ( 53%)]  Loss: 1.896 (2.49)  Time: 0.463s,   17.28/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1300/2354 ( 55%)]  Loss: 2.877 (2.50)  Time: 0.465s,   17.20/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1350/2354 ( 57%)]  Loss: 2.460 (2.50)  Time: 0.463s,   17.29/s  (0.471s,   16.98/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1400/2354 ( 59%)]  Loss: 2.603 (2.49)  Time: 0.469s,   17.06/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.011 (0.008)\n",
            "Train: 14 [1450/2354 ( 62%)]  Loss: 1.860 (2.49)  Time: 0.467s,   17.12/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.010 (0.008)\n",
            "Train: 14 [1500/2354 ( 64%)]  Loss: 2.957 (2.49)  Time: 0.477s,   16.76/s  (0.470s,   17.00/s)  LR: 9.271e-05  Data: 0.010 (0.008)\n",
            "Train: 14 [1550/2354 ( 66%)]  Loss: 2.417 (2.48)  Time: 0.461s,   17.35/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1600/2354 ( 68%)]  Loss: 2.096 (2.49)  Time: 0.465s,   17.20/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.009 (0.008)\n",
            "Train: 14 [1650/2354 ( 70%)]  Loss: 2.019 (2.49)  Time: 0.469s,   17.07/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1700/2354 ( 72%)]  Loss: 1.588 (2.49)  Time: 0.472s,   16.96/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.009 (0.008)\n",
            "Train: 14 [1750/2354 ( 74%)]  Loss: 1.780 (2.49)  Time: 0.465s,   17.20/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1800/2354 ( 76%)]  Loss: 2.414 (2.49)  Time: 0.470s,   17.02/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1850/2354 ( 79%)]  Loss: 2.827 (2.50)  Time: 0.460s,   17.41/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1900/2354 ( 81%)]  Loss: 1.525 (2.50)  Time: 0.465s,   17.21/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [1950/2354 ( 83%)]  Loss: 2.927 (2.51)  Time: 0.462s,   17.33/s  (0.471s,   16.99/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [2000/2354 ( 85%)]  Loss: 2.384 (2.51)  Time: 0.473s,   16.90/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [2050/2354 ( 87%)]  Loss: 2.941 (2.51)  Time: 0.475s,   16.85/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.009 (0.008)\n",
            "Train: 14 [2100/2354 ( 89%)]  Loss: 2.234 (2.51)  Time: 0.468s,   17.10/s  (0.470s,   17.01/s)  LR: 9.271e-05  Data: 0.010 (0.008)\n",
            "Train: 14 [2150/2354 ( 91%)]  Loss: 2.220 (2.51)  Time: 0.467s,   17.12/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.009 (0.008)\n",
            "Train: 14 [2200/2354 ( 93%)]  Loss: 2.845 (2.51)  Time: 0.467s,   17.14/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.008 (0.008)\n",
            "Train: 14 [2250/2354 ( 96%)]  Loss: 2.938 (2.51)  Time: 0.464s,   17.25/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.007 (0.008)\n",
            "Train: 14 [2300/2354 ( 98%)]  Loss: 1.575 (2.51)  Time: 0.463s,   17.29/s  (0.470s,   17.01/s)  LR: 9.271e-05  Data: 0.009 (0.008)\n",
            "Train: 14 [2350/2354 (100%)]  Loss: 1.255 (2.51)  Time: 0.459s,   17.44/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.005 (0.008)\n",
            "Train: 14 [2353/2354 (100%)]  Loss: 1.762 (2.50)  Time: 0.458s,   17.47/s  (0.471s,   17.00/s)  LR: 9.271e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.899 (0.899)  Loss:  1.8154 (1.8154)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.150 (0.152)  Loss:  3.3555 (0.9277)  Acc@1: 25.0000 (83.3333)  Acc@5: 25.0000 (94.6078)\n",
            "Test: [ 100/2354]  Time: 0.140 (0.145)  Loss:  2.4551 (1.0863)  Acc@1: 25.0000 (77.7228)  Acc@5: 75.0000 (96.2871)\n",
            "Test: [ 150/2354]  Time: 0.146 (0.143)  Loss:  0.6841 (0.9647)  Acc@1: 100.0000 (81.2914)  Acc@5: 100.0000 (96.6887)\n",
            "Test: [ 200/2354]  Time: 0.081 (0.142)  Loss:  2.0703 (0.9226)  Acc@1:  0.0000 (81.0945)  Acc@5: 100.0000 (97.0149)\n",
            "Test: [ 250/2354]  Time: 0.102 (0.141)  Loss:  0.5674 (0.9680)  Acc@1: 100.0000 (80.3785)  Acc@5: 100.0000 (96.8127)\n",
            "Test: [ 300/2354]  Time: 0.142 (0.140)  Loss:  1.3516 (0.9431)  Acc@1: 100.0000 (81.0631)  Acc@5: 100.0000 (96.8439)\n",
            "Test: [ 350/2354]  Time: 0.125 (0.139)  Loss:  1.1338 (0.9717)  Acc@1: 100.0000 (80.4131)  Acc@5: 100.0000 (97.1510)\n",
            "Test: [ 400/2354]  Time: 0.110 (0.139)  Loss:  0.9258 (0.9567)  Acc@1: 75.0000 (80.6733)  Acc@5: 100.0000 (97.1322)\n",
            "Test: [ 450/2354]  Time: 0.126 (0.138)  Loss:  0.1125 (0.9306)  Acc@1: 100.0000 (80.7650)  Acc@5: 100.0000 (97.1175)\n",
            "Test: [ 500/2354]  Time: 0.108 (0.138)  Loss:  0.9561 (0.8948)  Acc@1: 75.0000 (81.7365)  Acc@5: 100.0000 (97.1557)\n",
            "Test: [ 550/2354]  Time: 0.097 (0.138)  Loss:  2.2891 (0.9038)  Acc@1: 50.0000 (81.3067)  Acc@5: 75.0000 (97.2323)\n",
            "Test: [ 600/2354]  Time: 0.163 (0.138)  Loss:  1.4258 (0.9045)  Acc@1: 50.0000 (81.2812)  Acc@5: 100.0000 (97.2962)\n",
            "Test: [ 650/2354]  Time: 0.192 (0.141)  Loss:  0.4312 (0.8838)  Acc@1: 100.0000 (81.9124)  Acc@5: 100.0000 (97.3502)\n",
            "Test: [ 700/2354]  Time: 0.157 (0.141)  Loss:  0.3767 (0.8760)  Acc@1: 100.0000 (82.3466)  Acc@5: 100.0000 (97.2896)\n",
            "Test: [ 750/2354]  Time: 0.165 (0.140)  Loss:  1.4473 (0.8759)  Acc@1: 75.0000 (82.2903)  Acc@5: 75.0000 (97.2037)\n",
            "Test: [ 800/2354]  Time: 0.129 (0.140)  Loss:  0.5557 (0.8893)  Acc@1: 100.0000 (81.5231)  Acc@5: 100.0000 (97.1598)\n",
            "Test: [ 850/2354]  Time: 0.132 (0.140)  Loss:  0.3008 (0.8790)  Acc@1: 100.0000 (81.9624)  Acc@5: 100.0000 (97.0623)\n",
            "Test: [ 900/2354]  Time: 0.169 (0.140)  Loss:  0.8315 (0.8554)  Acc@1: 75.0000 (82.5472)  Acc@5: 75.0000 (97.1143)\n",
            "Test: [ 950/2354]  Time: 0.108 (0.139)  Loss:  0.5337 (0.8335)  Acc@1: 75.0000 (83.0967)  Acc@5: 100.0000 (97.1609)\n",
            "Test: [1000/2354]  Time: 0.159 (0.139)  Loss:  0.1230 (0.8317)  Acc@1: 100.0000 (83.2168)  Acc@5: 100.0000 (97.2028)\n",
            "Test: [1050/2354]  Time: 0.137 (0.139)  Loss:  1.2598 (0.8361)  Acc@1: 75.0000 (83.2303)  Acc@5: 100.0000 (97.1456)\n",
            "Test: [1100/2354]  Time: 0.180 (0.139)  Loss:  0.4028 (0.8499)  Acc@1: 100.0000 (82.7430)  Acc@5: 100.0000 (97.1390)\n",
            "Test: [1150/2354]  Time: 0.144 (0.139)  Loss:  1.6445 (0.8382)  Acc@1: 100.0000 (83.0148)  Acc@5: 100.0000 (97.1764)\n",
            "Test: [1200/2354]  Time: 0.103 (0.139)  Loss:  0.9756 (0.8375)  Acc@1: 75.0000 (82.9725)  Acc@5: 75.0000 (97.1690)\n",
            "Test: [1250/2354]  Time: 0.140 (0.139)  Loss:  0.1943 (0.8273)  Acc@1: 100.0000 (83.3133)  Acc@5: 100.0000 (97.1823)\n",
            "Test: [1300/2354]  Time: 0.080 (0.140)  Loss:  0.5049 (0.8243)  Acc@1: 100.0000 (83.3782)  Acc@5: 100.0000 (97.2137)\n",
            "Test: [1350/2354]  Time: 0.148 (0.140)  Loss:  0.3337 (0.8289)  Acc@1: 100.0000 (83.1976)  Acc@5: 100.0000 (97.2058)\n",
            "Test: [1400/2354]  Time: 0.167 (0.140)  Loss:  0.1932 (0.8286)  Acc@1: 100.0000 (83.2620)  Acc@5: 100.0000 (97.1984)\n",
            "Test: [1450/2354]  Time: 0.076 (0.140)  Loss:  0.7295 (0.8222)  Acc@1: 50.0000 (83.1668)  Acc@5: 100.0000 (97.2605)\n",
            "Test: [1500/2354]  Time: 0.142 (0.140)  Loss:  0.1833 (0.8274)  Acc@1: 100.0000 (83.0280)  Acc@5: 100.0000 (97.2185)\n",
            "Test: [1550/2354]  Time: 0.117 (0.139)  Loss:  0.2195 (0.8345)  Acc@1: 100.0000 (82.8014)  Acc@5: 100.0000 (97.2437)\n",
            "Test: [1600/2354]  Time: 0.120 (0.139)  Loss:  0.4563 (0.8365)  Acc@1: 100.0000 (82.8076)  Acc@5: 100.0000 (97.2986)\n",
            "Test: [1650/2354]  Time: 0.152 (0.139)  Loss:  0.5474 (0.8513)  Acc@1: 100.0000 (82.2078)  Acc@5: 100.0000 (97.2138)\n",
            "Test: [1700/2354]  Time: 0.103 (0.139)  Loss:  0.1432 (0.8435)  Acc@1: 100.0000 (82.5397)  Acc@5: 100.0000 (97.2222)\n",
            "Test: [1750/2354]  Time: 0.100 (0.139)  Loss:  0.7593 (0.8604)  Acc@1: 100.0000 (81.7818)  Acc@5: 100.0000 (97.1730)\n",
            "Test: [1800/2354]  Time: 0.080 (0.139)  Loss:  1.1855 (0.8616)  Acc@1: 75.0000 (81.8712)  Acc@5: 100.0000 (97.1544)\n",
            "Test: [1850/2354]  Time: 0.162 (0.139)  Loss:  0.3818 (0.8542)  Acc@1: 100.0000 (81.9557)  Acc@5: 100.0000 (97.2042)\n",
            "Test: [1900/2354]  Time: 0.186 (0.139)  Loss:  1.2373 (0.8557)  Acc@1: 75.0000 (81.9569)  Acc@5: 75.0000 (97.1725)\n",
            "Test: [1950/2354]  Time: 0.273 (0.139)  Loss:  1.2188 (0.8625)  Acc@1: 50.0000 (81.8298)  Acc@5: 100.0000 (97.1169)\n",
            "Test: [2000/2354]  Time: 0.152 (0.140)  Loss:  0.1340 (0.8576)  Acc@1: 100.0000 (81.9465)  Acc@5: 100.0000 (97.1389)\n",
            "Test: [2050/2354]  Time: 0.152 (0.140)  Loss:  3.0586 (0.8701)  Acc@1:  0.0000 (81.4968)  Acc@5: 50.0000 (97.0380)\n",
            "Test: [2100/2354]  Time: 0.139 (0.140)  Loss:  0.5933 (0.8709)  Acc@1: 100.0000 (81.4731)  Acc@5: 100.0000 (97.0371)\n",
            "Test: [2150/2354]  Time: 0.150 (0.140)  Loss:  2.0684 (0.8845)  Acc@1: 25.0000 (81.0437)  Acc@5: 100.0000 (96.9898)\n",
            "Test: [2200/2354]  Time: 0.152 (0.140)  Loss:  0.7080 (0.8901)  Acc@1: 100.0000 (80.8383)  Acc@5: 100.0000 (96.9900)\n",
            "Test: [2250/2354]  Time: 0.133 (0.140)  Loss:  0.2440 (0.8895)  Acc@1: 100.0000 (80.9085)  Acc@5: 100.0000 (96.9680)\n",
            "Test: [2300/2354]  Time: 0.197 (0.140)  Loss:  0.1809 (0.8879)  Acc@1: 100.0000 (80.9539)  Acc@5: 100.0000 (96.9904)\n",
            "Test: [2350/2354]  Time: 0.075 (0.140)  Loss:  0.4297 (0.8873)  Acc@1: 100.0000 (80.8592)  Acc@5: 100.0000 (97.0013)\n",
            "Test: [2354/2354]  Time: 0.067 (0.139)  Loss:  0.4536 (0.8870)  Acc@1: 100.0000 (80.8791)  Acc@5: 100.0000 (97.0061)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-4.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar', 70.64444208514705)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-9.pth.tar', 68.34058817284213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-8.pth.tar', 64.23187174859326)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-7.pth.tar', 58.424461196265995)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-6.pth.tar', 53.67873447368398)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-5.pth.tar', 44.633188236543155)\n",
            "\n",
            "Train: 15 [   0/2354 (  0%)]  Loss: 1.736 (1.74)  Time: 1.367s,    5.85/s  (1.367s,    5.85/s)  LR: 9.166e-05  Data: 0.592 (0.592)\n",
            "Train: 15 [  50/2354 (  2%)]  Loss: 2.054 (2.20)  Time: 0.465s,   17.21/s  (0.497s,   16.11/s)  LR: 9.166e-05  Data: 0.007 (0.019)\n",
            "Train: 15 [ 100/2354 (  4%)]  Loss: 1.556 (2.24)  Time: 0.473s,   16.90/s  (0.490s,   16.33/s)  LR: 9.166e-05  Data: 0.012 (0.014)\n",
            "Train: 15 [ 150/2354 (  6%)]  Loss: 1.251 (2.21)  Time: 0.465s,   17.21/s  (0.482s,   16.60/s)  LR: 9.166e-05  Data: 0.007 (0.012)\n",
            "Train: 15 [ 200/2354 (  8%)]  Loss: 2.170 (2.20)  Time: 0.471s,   16.98/s  (0.478s,   16.74/s)  LR: 9.166e-05  Data: 0.008 (0.011)\n",
            "Train: 15 [ 250/2354 ( 11%)]  Loss: 1.630 (2.24)  Time: 0.473s,   16.93/s  (0.475s,   16.84/s)  LR: 9.166e-05  Data: 0.010 (0.010)\n",
            "Train: 15 [ 300/2354 ( 13%)]  Loss: 3.716 (2.29)  Time: 0.469s,   17.07/s  (0.477s,   16.78/s)  LR: 9.166e-05  Data: 0.006 (0.010)\n",
            "Train: 15 [ 350/2354 ( 15%)]  Loss: 2.040 (2.31)  Time: 0.461s,   17.35/s  (0.475s,   16.84/s)  LR: 9.166e-05  Data: 0.009 (0.010)\n",
            "Train: 15 [ 400/2354 ( 17%)]  Loss: 1.568 (2.32)  Time: 0.466s,   17.18/s  (0.474s,   16.88/s)  LR: 9.166e-05  Data: 0.009 (0.009)\n",
            "Train: 15 [ 450/2354 ( 19%)]  Loss: 2.005 (2.31)  Time: 0.466s,   17.18/s  (0.473s,   16.92/s)  LR: 9.166e-05  Data: 0.009 (0.009)\n",
            "Train: 15 [ 500/2354 ( 21%)]  Loss: 2.394 (2.32)  Time: 0.466s,   17.15/s  (0.474s,   16.89/s)  LR: 9.166e-05  Data: 0.010 (0.009)\n",
            "Train: 15 [ 550/2354 ( 23%)]  Loss: 2.640 (2.34)  Time: 0.462s,   17.31/s  (0.473s,   16.92/s)  LR: 9.166e-05  Data: 0.006 (0.009)\n",
            "Train: 15 [ 600/2354 ( 25%)]  Loss: 2.401 (2.34)  Time: 0.464s,   17.23/s  (0.472s,   16.94/s)  LR: 9.166e-05  Data: 0.007 (0.009)\n",
            "Train: 15 [ 650/2354 ( 28%)]  Loss: 2.363 (2.36)  Time: 0.462s,   17.33/s  (0.472s,   16.95/s)  LR: 9.166e-05  Data: 0.007 (0.009)\n",
            "Train: 15 [ 700/2354 ( 30%)]  Loss: 1.569 (2.36)  Time: 0.461s,   17.36/s  (0.473s,   16.92/s)  LR: 9.166e-05  Data: 0.010 (0.009)\n",
            "Train: 15 [ 750/2354 ( 32%)]  Loss: 3.094 (2.37)  Time: 0.468s,   17.08/s  (0.472s,   16.94/s)  LR: 9.166e-05  Data: 0.008 (0.009)\n",
            "Train: 15 [ 800/2354 ( 34%)]  Loss: 2.526 (2.37)  Time: 0.469s,   17.04/s  (0.472s,   16.95/s)  LR: 9.166e-05  Data: 0.006 (0.009)\n",
            "Train: 15 [ 850/2354 ( 36%)]  Loss: 3.381 (2.38)  Time: 0.461s,   17.34/s  (0.472s,   16.96/s)  LR: 9.166e-05  Data: 0.007 (0.009)\n",
            "Train: 15 [ 900/2354 ( 38%)]  Loss: 3.319 (2.39)  Time: 0.461s,   17.35/s  (0.472s,   16.95/s)  LR: 9.166e-05  Data: 0.006 (0.009)\n",
            "Train: 15 [ 950/2354 ( 40%)]  Loss: 3.466 (2.39)  Time: 0.469s,   17.07/s  (0.472s,   16.96/s)  LR: 9.166e-05  Data: 0.011 (0.009)\n",
            "Train: 15 [1000/2354 ( 42%)]  Loss: 3.536 (2.39)  Time: 0.467s,   17.12/s  (0.471s,   16.97/s)  LR: 9.166e-05  Data: 0.009 (0.008)\n",
            "Train: 15 [1050/2354 ( 45%)]  Loss: 2.927 (2.40)  Time: 0.602s,   13.30/s  (0.472s,   16.95/s)  LR: 9.166e-05  Data: 0.018 (0.008)\n",
            "Train: 15 [1100/2354 ( 47%)]  Loss: 2.232 (2.40)  Time: 0.466s,   17.15/s  (0.472s,   16.96/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [1150/2354 ( 49%)]  Loss: 2.811 (2.41)  Time: 0.466s,   17.16/s  (0.471s,   16.97/s)  LR: 9.166e-05  Data: 0.009 (0.008)\n",
            "Train: 15 [1200/2354 ( 51%)]  Loss: 1.875 (2.41)  Time: 0.462s,   17.32/s  (0.471s,   16.98/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [1250/2354 ( 53%)]  Loss: 2.907 (2.42)  Time: 0.471s,   16.97/s  (0.472s,   16.96/s)  LR: 9.166e-05  Data: 0.006 (0.008)\n",
            "Train: 15 [1300/2354 ( 55%)]  Loss: 2.832 (2.42)  Time: 0.466s,   17.16/s  (0.471s,   16.97/s)  LR: 9.166e-05  Data: 0.006 (0.008)\n",
            "Train: 15 [1350/2354 ( 57%)]  Loss: 1.790 (2.42)  Time: 0.469s,   17.04/s  (0.471s,   16.98/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [1400/2354 ( 59%)]  Loss: 2.563 (2.43)  Time: 0.462s,   17.33/s  (0.471s,   16.98/s)  LR: 9.166e-05  Data: 0.009 (0.008)\n",
            "Train: 15 [1450/2354 ( 62%)]  Loss: 3.820 (2.43)  Time: 0.466s,   17.18/s  (0.471s,   16.97/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [1500/2354 ( 64%)]  Loss: 2.260 (2.43)  Time: 0.463s,   17.29/s  (0.471s,   16.98/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [1550/2354 ( 66%)]  Loss: 3.240 (2.43)  Time: 0.464s,   17.26/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [1600/2354 ( 68%)]  Loss: 3.220 (2.43)  Time: 0.463s,   17.28/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.009 (0.008)\n",
            "Train: 15 [1650/2354 ( 70%)]  Loss: 1.905 (2.43)  Time: 0.464s,   17.23/s  (0.471s,   16.98/s)  LR: 9.166e-05  Data: 0.009 (0.008)\n",
            "Train: 15 [1700/2354 ( 72%)]  Loss: 2.071 (2.43)  Time: 0.463s,   17.29/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.008 (0.008)\n",
            "Train: 15 [1750/2354 ( 74%)]  Loss: 2.307 (2.43)  Time: 0.458s,   17.47/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [1800/2354 ( 76%)]  Loss: 2.110 (2.43)  Time: 0.467s,   17.13/s  (0.471s,   17.00/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [1850/2354 ( 79%)]  Loss: 3.051 (2.43)  Time: 0.465s,   17.22/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.008 (0.008)\n",
            "Train: 15 [1900/2354 ( 81%)]  Loss: 1.299 (2.43)  Time: 0.465s,   17.20/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.006 (0.008)\n",
            "Train: 15 [1950/2354 ( 83%)]  Loss: 1.915 (2.43)  Time: 0.462s,   17.33/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [2000/2354 ( 85%)]  Loss: 2.691 (2.43)  Time: 0.591s,   13.53/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.008 (0.008)\n",
            "Train: 15 [2050/2354 ( 87%)]  Loss: 2.174 (2.43)  Time: 0.475s,   16.83/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.006 (0.008)\n",
            "Train: 15 [2100/2354 ( 89%)]  Loss: 2.525 (2.43)  Time: 0.461s,   17.36/s  (0.471s,   17.00/s)  LR: 9.166e-05  Data: 0.007 (0.008)\n",
            "Train: 15 [2150/2354 ( 91%)]  Loss: 3.447 (2.43)  Time: 0.471s,   16.99/s  (0.471s,   17.00/s)  LR: 9.166e-05  Data: 0.009 (0.008)\n",
            "Train: 15 [2200/2354 ( 93%)]  Loss: 2.917 (2.43)  Time: 0.467s,   17.14/s  (0.471s,   16.99/s)  LR: 9.166e-05  Data: 0.010 (0.008)\n",
            "Train: 15 [2250/2354 ( 96%)]  Loss: 2.525 (2.42)  Time: 0.464s,   17.24/s  (0.471s,   17.00/s)  LR: 9.166e-05  Data: 0.009 (0.008)\n",
            "Train: 15 [2300/2354 ( 98%)]  Loss: 2.703 (2.42)  Time: 0.466s,   17.15/s  (0.471s,   17.00/s)  LR: 9.166e-05  Data: 0.009 (0.008)\n",
            "Train: 15 [2350/2354 (100%)]  Loss: 2.448 (2.42)  Time: 0.456s,   17.54/s  (0.470s,   17.01/s)  LR: 9.166e-05  Data: 0.005 (0.008)\n",
            "Train: 15 [2353/2354 (100%)]  Loss: 2.754 (2.43)  Time: 0.452s,   17.70/s  (0.470s,   17.01/s)  LR: 9.166e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.662 (0.662)  Loss:  1.2363 (1.2363)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.182 (0.156)  Loss:  1.7969 (0.6093)  Acc@1: 50.0000 (89.7059)  Acc@5: 100.0000 (98.0392)\n",
            "Test: [ 100/2354]  Time: 0.136 (0.164)  Loss:  1.4902 (0.7786)  Acc@1: 75.0000 (84.6535)  Acc@5: 100.0000 (98.2673)\n",
            "Test: [ 150/2354]  Time: 0.154 (0.155)  Loss:  0.3770 (0.7299)  Acc@1: 100.0000 (86.0927)  Acc@5: 100.0000 (98.6755)\n",
            "Test: [ 200/2354]  Time: 0.111 (0.151)  Loss:  0.7461 (0.6989)  Acc@1: 100.0000 (87.3134)  Acc@5: 100.0000 (98.2587)\n",
            "Test: [ 250/2354]  Time: 0.157 (0.149)  Loss:  0.1882 (0.7794)  Acc@1: 100.0000 (84.4622)  Acc@5: 100.0000 (98.1076)\n",
            "Test: [ 300/2354]  Time: 0.093 (0.148)  Loss:  1.6689 (0.7735)  Acc@1: 25.0000 (84.2193)  Acc@5: 100.0000 (97.8405)\n",
            "Test: [ 350/2354]  Time: 0.115 (0.146)  Loss:  1.1123 (0.7791)  Acc@1: 75.0000 (82.4074)  Acc@5: 100.0000 (97.9345)\n",
            "Test: [ 400/2354]  Time: 0.097 (0.145)  Loss:  0.2085 (0.7884)  Acc@1: 100.0000 (81.7955)  Acc@5: 100.0000 (97.9426)\n",
            "Test: [ 450/2354]  Time: 0.084 (0.144)  Loss:  0.2971 (0.7552)  Acc@1: 100.0000 (82.8714)  Acc@5: 100.0000 (98.1707)\n",
            "Test: [ 500/2354]  Time: 0.189 (0.144)  Loss:  0.9102 (0.7397)  Acc@1: 50.0000 (83.1836)  Acc@5: 100.0000 (98.1038)\n",
            "Test: [ 550/2354]  Time: 0.083 (0.143)  Loss:  1.7451 (0.7458)  Acc@1: 75.0000 (83.1216)  Acc@5: 75.0000 (98.1397)\n",
            "Test: [ 600/2354]  Time: 0.144 (0.143)  Loss:  1.1670 (0.7386)  Acc@1: 75.0000 (83.8602)  Acc@5: 100.0000 (98.1281)\n",
            "Test: [ 650/2354]  Time: 0.179 (0.143)  Loss:  0.5327 (0.7271)  Acc@1: 75.0000 (84.1398)  Acc@5: 100.0000 (98.0799)\n",
            "Test: [ 700/2354]  Time: 0.168 (0.144)  Loss:  0.0818 (0.7147)  Acc@1: 100.0000 (84.7004)  Acc@5: 100.0000 (98.1455)\n",
            "Test: [ 750/2354]  Time: 0.080 (0.145)  Loss:  1.0430 (0.7195)  Acc@1: 75.0000 (84.7870)  Acc@5: 100.0000 (98.0692)\n",
            "Test: [ 800/2354]  Time: 0.106 (0.144)  Loss:  0.0884 (0.7262)  Acc@1: 100.0000 (84.4881)  Acc@5: 100.0000 (98.0649)\n",
            "Test: [ 850/2354]  Time: 0.169 (0.144)  Loss:  0.0718 (0.7327)  Acc@1: 100.0000 (84.2538)  Acc@5: 100.0000 (97.9730)\n",
            "Test: [ 900/2354]  Time: 0.158 (0.144)  Loss:  1.0723 (0.7205)  Acc@1: 75.0000 (84.7669)  Acc@5: 75.0000 (98.0577)\n",
            "Test: [ 950/2354]  Time: 0.106 (0.143)  Loss:  0.3784 (0.7040)  Acc@1: 100.0000 (85.2261)  Acc@5: 100.0000 (98.1073)\n",
            "Test: [1000/2354]  Time: 0.076 (0.143)  Loss:  0.2991 (0.7040)  Acc@1: 100.0000 (85.1149)  Acc@5: 100.0000 (98.1269)\n",
            "Test: [1050/2354]  Time: 0.107 (0.143)  Loss:  0.9077 (0.7135)  Acc@1: 75.0000 (84.8478)  Acc@5: 100.0000 (98.1208)\n",
            "Test: [1100/2354]  Time: 0.160 (0.142)  Loss:  1.5176 (0.7226)  Acc@1: 100.0000 (84.8547)  Acc@5: 100.0000 (98.1153)\n",
            "Test: [1150/2354]  Time: 0.172 (0.142)  Loss:  1.7061 (0.7181)  Acc@1: 100.0000 (85.1216)  Acc@5: 100.0000 (98.0669)\n",
            "Test: [1200/2354]  Time: 0.166 (0.142)  Loss:  0.8633 (0.7134)  Acc@1: 75.0000 (85.1582)  Acc@5: 100.0000 (98.1057)\n",
            "Test: [1250/2354]  Time: 0.120 (0.142)  Loss:  0.1890 (0.7070)  Acc@1: 100.0000 (85.4516)  Acc@5: 100.0000 (98.0815)\n",
            "Test: [1300/2354]  Time: 0.189 (0.142)  Loss:  0.2429 (0.7102)  Acc@1: 100.0000 (84.9154)  Acc@5: 100.0000 (98.0592)\n",
            "Test: [1350/2354]  Time: 0.157 (0.143)  Loss:  0.0866 (0.7089)  Acc@1: 100.0000 (84.9926)  Acc@5: 100.0000 (98.0200)\n",
            "Test: [1400/2354]  Time: 0.096 (0.142)  Loss:  0.3728 (0.7079)  Acc@1: 100.0000 (85.0642)  Acc@5: 100.0000 (98.0014)\n",
            "Test: [1450/2354]  Time: 0.107 (0.142)  Loss:  0.2415 (0.7030)  Acc@1: 100.0000 (85.3377)  Acc@5: 100.0000 (98.0186)\n",
            "Test: [1500/2354]  Time: 0.116 (0.142)  Loss:  0.8433 (0.7069)  Acc@1: 100.0000 (85.1432)  Acc@5: 100.0000 (98.0180)\n",
            "Test: [1550/2354]  Time: 0.162 (0.142)  Loss:  0.1488 (0.7192)  Acc@1: 100.0000 (84.6228)  Acc@5: 100.0000 (97.9691)\n",
            "Test: [1600/2354]  Time: 0.166 (0.142)  Loss:  0.5020 (0.7248)  Acc@1: 100.0000 (84.4004)  Acc@5: 100.0000 (97.9388)\n",
            "Test: [1650/2354]  Time: 0.167 (0.142)  Loss:  0.5835 (0.7277)  Acc@1: 100.0000 (84.4185)  Acc@5: 100.0000 (97.8952)\n",
            "Test: [1700/2354]  Time: 0.162 (0.142)  Loss:  0.1234 (0.7259)  Acc@1: 100.0000 (84.5973)  Acc@5: 100.0000 (97.9130)\n",
            "Test: [1750/2354]  Time: 0.156 (0.142)  Loss:  1.1631 (0.7322)  Acc@1: 75.0000 (84.4803)  Acc@5: 100.0000 (97.9012)\n",
            "Test: [1800/2354]  Time: 0.091 (0.141)  Loss:  0.8301 (0.7380)  Acc@1: 100.0000 (84.3420)  Acc@5: 100.0000 (97.8901)\n",
            "Test: [1850/2354]  Time: 0.110 (0.141)  Loss:  0.2888 (0.7303)  Acc@1: 100.0000 (84.5489)  Acc@5: 100.0000 (97.9335)\n",
            "Test: [1900/2354]  Time: 0.248 (0.141)  Loss:  1.3701 (0.7314)  Acc@1: 75.0000 (84.5871)  Acc@5: 75.0000 (97.8958)\n",
            "Test: [1950/2354]  Time: 0.213 (0.141)  Loss:  0.6880 (0.7280)  Acc@1: 75.0000 (84.7258)  Acc@5: 100.0000 (97.8985)\n",
            "Test: [2000/2354]  Time: 0.125 (0.142)  Loss:  0.3081 (0.7257)  Acc@1: 100.0000 (84.7951)  Acc@5: 100.0000 (97.9010)\n",
            "Test: [2050/2354]  Time: 0.143 (0.142)  Loss:  1.7900 (0.7338)  Acc@1: 50.0000 (84.4710)  Acc@5: 75.0000 (97.8669)\n",
            "Test: [2100/2354]  Time: 0.155 (0.142)  Loss:  0.5532 (0.7345)  Acc@1: 100.0000 (84.5074)  Acc@5: 100.0000 (97.8701)\n",
            "Test: [2150/2354]  Time: 0.177 (0.141)  Loss:  1.8730 (0.7463)  Acc@1: 25.0000 (84.0888)  Acc@5: 75.0000 (97.7917)\n",
            "Test: [2200/2354]  Time: 0.130 (0.141)  Loss:  1.4004 (0.7564)  Acc@1: 100.0000 (83.7119)  Acc@5: 100.0000 (97.7397)\n",
            "Test: [2250/2354]  Time: 0.129 (0.141)  Loss:  0.1368 (0.7553)  Acc@1: 100.0000 (83.7961)  Acc@5: 100.0000 (97.7454)\n",
            "Test: [2300/2354]  Time: 0.147 (0.141)  Loss:  0.2974 (0.7529)  Acc@1: 100.0000 (83.8766)  Acc@5: 100.0000 (97.7618)\n",
            "Test: [2350/2354]  Time: 0.075 (0.141)  Loss:  0.9316 (0.7524)  Acc@1: 100.0000 (83.8686)  Acc@5: 100.0000 (97.7775)\n",
            "Test: [2354/2354]  Time: 0.064 (0.141)  Loss:  0.7544 (0.7531)  Acc@1: 100.0000 (83.8730)  Acc@5: 100.0000 (97.7811)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-5.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar', 70.64444208514705)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-9.pth.tar', 68.34058817284213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-8.pth.tar', 64.23187174859326)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-7.pth.tar', 58.424461196265995)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-6.pth.tar', 53.67873447368398)\n",
            "\n",
            "Train: 16 [   0/2354 (  0%)]  Loss: 2.236 (2.24)  Time: 1.387s,    5.77/s  (1.387s,    5.77/s)  LR: 9.055e-05  Data: 0.641 (0.641)\n",
            "Train: 16 [  50/2354 (  2%)]  Loss: 3.510 (2.31)  Time: 0.460s,   17.41/s  (0.501s,   15.97/s)  LR: 9.055e-05  Data: 0.007 (0.020)\n",
            "Train: 16 [ 100/2354 (  4%)]  Loss: 1.765 (2.34)  Time: 0.471s,   16.99/s  (0.492s,   16.26/s)  LR: 9.055e-05  Data: 0.007 (0.014)\n",
            "Train: 16 [ 150/2354 (  6%)]  Loss: 2.105 (2.39)  Time: 0.467s,   17.14/s  (0.483s,   16.55/s)  LR: 9.055e-05  Data: 0.009 (0.012)\n",
            "Train: 16 [ 200/2354 (  8%)]  Loss: 2.989 (2.43)  Time: 0.465s,   17.20/s  (0.479s,   16.72/s)  LR: 9.055e-05  Data: 0.006 (0.011)\n",
            "Train: 16 [ 250/2354 ( 11%)]  Loss: 2.128 (2.39)  Time: 0.550s,   14.54/s  (0.478s,   16.72/s)  LR: 9.055e-05  Data: 0.007 (0.010)\n",
            "Train: 16 [ 300/2354 ( 13%)]  Loss: 3.271 (2.37)  Time: 0.466s,   17.16/s  (0.477s,   16.78/s)  LR: 9.055e-05  Data: 0.007 (0.010)\n",
            "Train: 16 [ 350/2354 ( 15%)]  Loss: 2.133 (2.38)  Time: 0.463s,   17.27/s  (0.475s,   16.83/s)  LR: 9.055e-05  Data: 0.006 (0.010)\n",
            "Train: 16 [ 400/2354 ( 17%)]  Loss: 2.910 (2.38)  Time: 0.459s,   17.41/s  (0.476s,   16.80/s)  LR: 9.055e-05  Data: 0.007 (0.010)\n",
            "Train: 16 [ 450/2354 ( 19%)]  Loss: 1.892 (2.38)  Time: 0.467s,   17.14/s  (0.475s,   16.84/s)  LR: 9.055e-05  Data: 0.006 (0.009)\n",
            "Train: 16 [ 500/2354 ( 21%)]  Loss: 3.021 (2.39)  Time: 0.461s,   17.36/s  (0.474s,   16.87/s)  LR: 9.055e-05  Data: 0.009 (0.009)\n",
            "Train: 16 [ 550/2354 ( 23%)]  Loss: 2.517 (2.37)  Time: 0.620s,   12.91/s  (0.474s,   16.89/s)  LR: 9.055e-05  Data: 0.017 (0.009)\n",
            "Train: 16 [ 600/2354 ( 25%)]  Loss: 2.850 (2.36)  Time: 0.465s,   17.20/s  (0.474s,   16.88/s)  LR: 9.055e-05  Data: 0.009 (0.009)\n",
            "Train: 16 [ 650/2354 ( 28%)]  Loss: 2.829 (2.36)  Time: 0.477s,   16.76/s  (0.473s,   16.90/s)  LR: 9.055e-05  Data: 0.010 (0.009)\n",
            "Train: 16 [ 700/2354 ( 30%)]  Loss: 2.014 (2.36)  Time: 0.463s,   17.27/s  (0.473s,   16.92/s)  LR: 9.055e-05  Data: 0.006 (0.009)\n",
            "Train: 16 [ 750/2354 ( 32%)]  Loss: 3.126 (2.37)  Time: 0.462s,   17.32/s  (0.473s,   16.90/s)  LR: 9.055e-05  Data: 0.008 (0.009)\n",
            "Train: 16 [ 800/2354 ( 34%)]  Loss: 2.604 (2.38)  Time: 0.470s,   17.01/s  (0.473s,   16.91/s)  LR: 9.055e-05  Data: 0.006 (0.009)\n",
            "Train: 16 [ 850/2354 ( 36%)]  Loss: 2.302 (2.38)  Time: 0.460s,   17.41/s  (0.473s,   16.93/s)  LR: 9.055e-05  Data: 0.007 (0.009)\n",
            "Train: 16 [ 900/2354 ( 38%)]  Loss: 2.811 (2.39)  Time: 0.461s,   17.36/s  (0.472s,   16.94/s)  LR: 9.055e-05  Data: 0.006 (0.009)\n",
            "Train: 16 [ 950/2354 ( 40%)]  Loss: 2.143 (2.38)  Time: 0.460s,   17.40/s  (0.473s,   16.93/s)  LR: 9.055e-05  Data: 0.007 (0.009)\n",
            "Train: 16 [1000/2354 ( 42%)]  Loss: 1.604 (2.38)  Time: 0.465s,   17.22/s  (0.472s,   16.94/s)  LR: 9.055e-05  Data: 0.007 (0.009)\n",
            "Train: 16 [1050/2354 ( 45%)]  Loss: 2.210 (2.38)  Time: 0.478s,   16.75/s  (0.472s,   16.95/s)  LR: 9.055e-05  Data: 0.007 (0.009)\n",
            "Train: 16 [1100/2354 ( 47%)]  Loss: 1.853 (2.38)  Time: 0.476s,   16.81/s  (0.472s,   16.96/s)  LR: 9.055e-05  Data: 0.008 (0.009)\n",
            "Train: 16 [1150/2354 ( 49%)]  Loss: 2.307 (2.39)  Time: 0.478s,   16.75/s  (0.472s,   16.95/s)  LR: 9.055e-05  Data: 0.007 (0.009)\n",
            "Train: 16 [1200/2354 ( 51%)]  Loss: 2.524 (2.39)  Time: 0.463s,   17.29/s  (0.472s,   16.96/s)  LR: 9.055e-05  Data: 0.008 (0.009)\n",
            "Train: 16 [1250/2354 ( 53%)]  Loss: 1.930 (2.38)  Time: 0.467s,   17.15/s  (0.472s,   16.96/s)  LR: 9.055e-05  Data: 0.009 (0.008)\n",
            "Train: 16 [1300/2354 ( 55%)]  Loss: 2.307 (2.38)  Time: 0.463s,   17.28/s  (0.472s,   16.95/s)  LR: 9.055e-05  Data: 0.009 (0.008)\n",
            "Train: 16 [1350/2354 ( 57%)]  Loss: 2.174 (2.39)  Time: 0.464s,   17.23/s  (0.472s,   16.96/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [1400/2354 ( 59%)]  Loss: 2.323 (2.38)  Time: 0.465s,   17.22/s  (0.471s,   16.97/s)  LR: 9.055e-05  Data: 0.006 (0.008)\n",
            "Train: 16 [1450/2354 ( 62%)]  Loss: 2.200 (2.38)  Time: 0.459s,   17.41/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [1500/2354 ( 64%)]  Loss: 3.395 (2.38)  Time: 0.467s,   17.15/s  (0.472s,   16.96/s)  LR: 9.055e-05  Data: 0.009 (0.008)\n",
            "Train: 16 [1550/2354 ( 66%)]  Loss: 1.832 (2.39)  Time: 0.462s,   17.30/s  (0.471s,   16.97/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [1600/2354 ( 68%)]  Loss: 2.709 (2.39)  Time: 0.465s,   17.22/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.006 (0.008)\n",
            "Train: 16 [1650/2354 ( 70%)]  Loss: 2.343 (2.38)  Time: 0.463s,   17.29/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.008 (0.008)\n",
            "Train: 16 [1700/2354 ( 72%)]  Loss: 2.647 (2.38)  Time: 0.468s,   17.08/s  (0.471s,   16.97/s)  LR: 9.055e-05  Data: 0.006 (0.008)\n",
            "Train: 16 [1750/2354 ( 74%)]  Loss: 2.229 (2.38)  Time: 0.462s,   17.30/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.006 (0.008)\n",
            "Train: 16 [1800/2354 ( 76%)]  Loss: 3.379 (2.38)  Time: 0.469s,   17.05/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [1850/2354 ( 79%)]  Loss: 1.850 (2.38)  Time: 0.466s,   17.18/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [1900/2354 ( 81%)]  Loss: 2.435 (2.38)  Time: 0.470s,   17.03/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [1950/2354 ( 83%)]  Loss: 3.199 (2.38)  Time: 0.460s,   17.39/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [2000/2354 ( 85%)]  Loss: 2.486 (2.39)  Time: 0.470s,   17.03/s  (0.471s,   16.99/s)  LR: 9.055e-05  Data: 0.006 (0.008)\n",
            "Train: 16 [2050/2354 ( 87%)]  Loss: 2.353 (2.39)  Time: 0.478s,   16.73/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [2100/2354 ( 89%)]  Loss: 4.710 (2.39)  Time: 0.467s,   17.14/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [2150/2354 ( 91%)]  Loss: 3.063 (2.39)  Time: 0.464s,   17.24/s  (0.471s,   16.99/s)  LR: 9.055e-05  Data: 0.007 (0.008)\n",
            "Train: 16 [2200/2354 ( 93%)]  Loss: 2.373 (2.39)  Time: 0.467s,   17.14/s  (0.471s,   16.99/s)  LR: 9.055e-05  Data: 0.006 (0.008)\n",
            "Train: 16 [2250/2354 ( 96%)]  Loss: 2.589 (2.40)  Time: 0.463s,   17.28/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.009 (0.008)\n",
            "Train: 16 [2300/2354 ( 98%)]  Loss: 1.709 (2.39)  Time: 0.460s,   17.40/s  (0.471s,   16.98/s)  LR: 9.055e-05  Data: 0.006 (0.008)\n",
            "Train: 16 [2350/2354 (100%)]  Loss: 1.790 (2.39)  Time: 0.462s,   17.30/s  (0.471s,   16.99/s)  LR: 9.055e-05  Data: 0.005 (0.008)\n",
            "Train: 16 [2353/2354 (100%)]  Loss: 1.573 (2.39)  Time: 0.455s,   17.59/s  (0.471s,   16.99/s)  LR: 9.055e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.668 (0.668)  Loss:  0.6274 (0.6274)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.161 (0.156)  Loss:  2.2148 (0.7738)  Acc@1: 25.0000 (87.2549)  Acc@5: 50.0000 (97.5490)\n",
            "Test: [ 100/2354]  Time: 0.265 (0.149)  Loss:  1.8379 (0.8342)  Acc@1: 50.0000 (83.4158)  Acc@5: 75.0000 (97.7723)\n",
            "Test: [ 150/2354]  Time: 0.172 (0.157)  Loss:  0.2749 (0.8245)  Acc@1: 100.0000 (82.4503)  Acc@5: 100.0000 (97.6821)\n",
            "Test: [ 200/2354]  Time: 0.085 (0.151)  Loss:  1.3389 (0.7888)  Acc@1: 75.0000 (84.0796)  Acc@5: 100.0000 (98.0100)\n",
            "Test: [ 250/2354]  Time: 0.180 (0.149)  Loss:  0.4070 (0.8301)  Acc@1: 100.0000 (83.5657)  Acc@5: 100.0000 (98.0080)\n",
            "Test: [ 300/2354]  Time: 0.153 (0.147)  Loss:  1.3867 (0.8206)  Acc@1: 75.0000 (84.2193)  Acc@5: 100.0000 (97.8405)\n",
            "Test: [ 350/2354]  Time: 0.190 (0.146)  Loss:  0.2886 (0.8473)  Acc@1: 100.0000 (81.9801)  Acc@5: 100.0000 (98.0057)\n",
            "Test: [ 400/2354]  Time: 0.132 (0.145)  Loss:  0.1648 (0.8517)  Acc@1: 100.0000 (81.6708)  Acc@5: 100.0000 (97.8180)\n",
            "Test: [ 450/2354]  Time: 0.108 (0.144)  Loss:  0.2668 (0.8186)  Acc@1: 100.0000 (82.8714)  Acc@5: 100.0000 (97.9490)\n",
            "Test: [ 500/2354]  Time: 0.170 (0.144)  Loss:  0.9868 (0.8103)  Acc@1: 75.0000 (82.7844)  Acc@5: 100.0000 (98.0040)\n",
            "Test: [ 550/2354]  Time: 0.104 (0.143)  Loss:  1.6973 (0.8155)  Acc@1: 75.0000 (82.2595)  Acc@5: 75.0000 (98.0944)\n",
            "Test: [ 600/2354]  Time: 0.086 (0.143)  Loss:  0.6602 (0.8067)  Acc@1: 100.0000 (82.7787)  Acc@5: 100.0000 (98.0865)\n",
            "Test: [ 650/2354]  Time: 0.124 (0.143)  Loss:  0.4592 (0.7886)  Acc@1: 100.0000 (83.3333)  Acc@5: 100.0000 (98.1951)\n",
            "Test: [ 700/2354]  Time: 0.154 (0.142)  Loss:  0.2527 (0.7751)  Acc@1: 100.0000 (83.9872)  Acc@5: 100.0000 (98.2525)\n",
            "Test: [ 750/2354]  Time: 0.117 (0.145)  Loss:  0.8584 (0.7680)  Acc@1: 100.0000 (84.4874)  Acc@5: 100.0000 (98.2690)\n",
            "Test: [ 800/2354]  Time: 0.123 (0.144)  Loss:  0.1992 (0.7762)  Acc@1: 100.0000 (84.3633)  Acc@5: 100.0000 (98.3770)\n",
            "Test: [ 850/2354]  Time: 0.129 (0.144)  Loss:  0.2644 (0.7678)  Acc@1: 100.0000 (84.6063)  Acc@5: 100.0000 (98.3549)\n",
            "Test: [ 900/2354]  Time: 0.141 (0.144)  Loss:  1.4932 (0.7614)  Acc@1: 75.0000 (84.6282)  Acc@5: 75.0000 (98.4184)\n",
            "Test: [ 950/2354]  Time: 0.103 (0.143)  Loss:  0.2925 (0.7623)  Acc@1: 100.0000 (84.2797)  Acc@5: 100.0000 (98.3964)\n",
            "Test: [1000/2354]  Time: 0.132 (0.143)  Loss:  0.5234 (0.7605)  Acc@1: 100.0000 (84.4905)  Acc@5: 100.0000 (98.3766)\n",
            "Test: [1050/2354]  Time: 0.104 (0.143)  Loss:  0.7622 (0.7570)  Acc@1: 100.0000 (84.8716)  Acc@5: 100.0000 (98.4063)\n",
            "Test: [1100/2354]  Time: 0.156 (0.143)  Loss:  1.0010 (0.7602)  Acc@1: 100.0000 (84.8093)  Acc@5: 100.0000 (98.4332)\n",
            "Test: [1150/2354]  Time: 0.116 (0.143)  Loss:  1.8926 (0.7606)  Acc@1: 50.0000 (84.6872)  Acc@5: 100.0000 (98.4144)\n",
            "Test: [1200/2354]  Time: 0.162 (0.142)  Loss:  0.9937 (0.7597)  Acc@1: 75.0000 (84.6170)  Acc@5: 100.0000 (98.4180)\n",
            "Test: [1250/2354]  Time: 0.094 (0.142)  Loss:  0.2637 (0.7516)  Acc@1: 100.0000 (84.9520)  Acc@5: 100.0000 (98.4412)\n",
            "Test: [1300/2354]  Time: 0.182 (0.142)  Loss:  0.0698 (0.7489)  Acc@1: 100.0000 (84.8386)  Acc@5: 100.0000 (98.4435)\n",
            "Test: [1350/2354]  Time: 0.163 (0.143)  Loss:  0.0961 (0.7460)  Acc@1: 100.0000 (84.9741)  Acc@5: 100.0000 (98.4456)\n",
            "Test: [1400/2354]  Time: 0.207 (0.143)  Loss:  0.2832 (0.7399)  Acc@1: 100.0000 (85.0999)  Acc@5: 100.0000 (98.4654)\n",
            "Test: [1450/2354]  Time: 0.078 (0.143)  Loss:  0.3931 (0.7358)  Acc@1: 100.0000 (85.1999)  Acc@5: 100.0000 (98.5010)\n",
            "Test: [1500/2354]  Time: 0.192 (0.143)  Loss:  0.5596 (0.7391)  Acc@1: 100.0000 (85.0266)  Acc@5: 100.0000 (98.5010)\n",
            "Test: [1550/2354]  Time: 0.130 (0.142)  Loss:  0.3511 (0.7519)  Acc@1: 100.0000 (84.4616)  Acc@5: 100.0000 (98.4204)\n",
            "Test: [1600/2354]  Time: 0.142 (0.142)  Loss:  0.2908 (0.7596)  Acc@1: 100.0000 (84.0725)  Acc@5: 100.0000 (98.3604)\n",
            "Test: [1650/2354]  Time: 0.077 (0.142)  Loss:  0.4524 (0.7640)  Acc@1: 75.0000 (83.7523)  Acc@5: 100.0000 (98.3343)\n",
            "Test: [1700/2354]  Time: 0.114 (0.142)  Loss:  0.0948 (0.7584)  Acc@1: 100.0000 (83.9506)  Acc@5: 100.0000 (98.3245)\n",
            "Test: [1750/2354]  Time: 0.123 (0.142)  Loss:  0.8306 (0.7673)  Acc@1: 75.0000 (83.5094)  Acc@5: 100.0000 (98.3152)\n",
            "Test: [1800/2354]  Time: 0.129 (0.142)  Loss:  0.9600 (0.7652)  Acc@1: 75.0000 (83.6619)  Acc@5: 100.0000 (98.3343)\n",
            "Test: [1850/2354]  Time: 0.179 (0.142)  Loss:  0.5352 (0.7617)  Acc@1: 100.0000 (83.7925)  Acc@5: 100.0000 (98.3522)\n",
            "Test: [1900/2354]  Time: 0.115 (0.142)  Loss:  0.9854 (0.7616)  Acc@1: 75.0000 (83.8638)  Acc@5: 100.0000 (98.3430)\n",
            "Test: [1950/2354]  Time: 0.161 (0.143)  Loss:  1.0625 (0.7634)  Acc@1: 75.0000 (83.9185)  Acc@5: 100.0000 (98.3086)\n",
            "Test: [2000/2354]  Time: 0.121 (0.142)  Loss:  0.0900 (0.7578)  Acc@1: 100.0000 (84.1704)  Acc@5: 100.0000 (98.3133)\n",
            "Test: [2050/2354]  Time: 0.180 (0.142)  Loss:  0.7866 (0.7617)  Acc@1: 100.0000 (83.9956)  Acc@5: 100.0000 (98.2569)\n",
            "Test: [2100/2354]  Time: 0.207 (0.142)  Loss:  0.9668 (0.7616)  Acc@1: 75.0000 (83.9719)  Acc@5: 100.0000 (98.2389)\n",
            "Test: [2150/2354]  Time: 0.178 (0.142)  Loss:  1.6074 (0.7784)  Acc@1: 25.0000 (83.3450)  Acc@5: 100.0000 (98.1520)\n",
            "Test: [2200/2354]  Time: 0.109 (0.142)  Loss:  0.6987 (0.7824)  Acc@1: 100.0000 (83.2463)  Acc@5: 100.0000 (98.1259)\n",
            "Test: [2250/2354]  Time: 0.165 (0.142)  Loss:  0.1978 (0.7798)  Acc@1: 100.0000 (83.4296)  Acc@5: 100.0000 (98.1453)\n",
            "Test: [2300/2354]  Time: 0.162 (0.142)  Loss:  0.3625 (0.7757)  Acc@1: 100.0000 (83.5941)  Acc@5: 100.0000 (98.1638)\n",
            "Test: [2350/2354]  Time: 0.075 (0.142)  Loss:  0.6504 (0.7751)  Acc@1: 100.0000 (83.5921)  Acc@5: 100.0000 (98.1710)\n",
            "Test: [2354/2354]  Time: 0.064 (0.142)  Loss:  0.4873 (0.7755)  Acc@1: 100.0000 (83.5864)  Acc@5: 100.0000 (98.1739)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-6.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar', 70.64444208514705)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-9.pth.tar', 68.34058817284213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-8.pth.tar', 64.23187174859326)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-7.pth.tar', 58.424461196265995)\n",
            "\n",
            "Train: 17 [   0/2354 (  0%)]  Loss: 1.503 (1.50)  Time: 1.260s,    6.35/s  (1.260s,    6.35/s)  LR: 8.937e-05  Data: 0.542 (0.542)\n",
            "Train: 17 [  50/2354 (  2%)]  Loss: 1.985 (2.11)  Time: 0.383s,   20.91/s  (0.515s,   15.53/s)  LR: 8.937e-05  Data: 0.009 (0.019)\n",
            "Train: 17 [ 100/2354 (  4%)]  Loss: 2.376 (2.25)  Time: 0.470s,   17.02/s  (0.491s,   16.29/s)  LR: 8.937e-05  Data: 0.009 (0.013)\n",
            "Train: 17 [ 150/2354 (  6%)]  Loss: 2.822 (2.23)  Time: 0.470s,   17.02/s  (0.483s,   16.57/s)  LR: 8.937e-05  Data: 0.007 (0.011)\n",
            "Train: 17 [ 200/2354 (  8%)]  Loss: 3.125 (2.20)  Time: 0.468s,   17.09/s  (0.479s,   16.70/s)  LR: 8.937e-05  Data: 0.010 (0.010)\n",
            "Train: 17 [ 250/2354 ( 11%)]  Loss: 2.532 (2.23)  Time: 0.466s,   17.15/s  (0.481s,   16.65/s)  LR: 8.937e-05  Data: 0.006 (0.010)\n",
            "Train: 17 [ 300/2354 ( 13%)]  Loss: 2.352 (2.24)  Time: 0.462s,   17.32/s  (0.478s,   16.73/s)  LR: 8.937e-05  Data: 0.008 (0.010)\n",
            "Train: 17 [ 350/2354 ( 15%)]  Loss: 1.462 (2.23)  Time: 0.471s,   16.99/s  (0.476s,   16.79/s)  LR: 8.937e-05  Data: 0.008 (0.009)\n",
            "Train: 17 [ 400/2354 ( 17%)]  Loss: 3.250 (2.25)  Time: 0.672s,   11.90/s  (0.477s,   16.77/s)  LR: 8.937e-05  Data: 0.022 (0.009)\n",
            "Train: 17 [ 450/2354 ( 19%)]  Loss: 4.127 (2.26)  Time: 0.463s,   17.29/s  (0.476s,   16.81/s)  LR: 8.937e-05  Data: 0.007 (0.009)\n",
            "Train: 17 [ 500/2354 ( 21%)]  Loss: 1.247 (2.26)  Time: 0.460s,   17.38/s  (0.475s,   16.84/s)  LR: 8.937e-05  Data: 0.006 (0.009)\n",
            "Train: 17 [ 550/2354 ( 23%)]  Loss: 2.404 (2.25)  Time: 0.463s,   17.26/s  (0.474s,   16.87/s)  LR: 8.937e-05  Data: 0.009 (0.009)\n",
            "Train: 17 [ 600/2354 ( 25%)]  Loss: 1.610 (2.26)  Time: 0.472s,   16.94/s  (0.475s,   16.84/s)  LR: 8.937e-05  Data: 0.009 (0.009)\n",
            "Train: 17 [ 650/2354 ( 28%)]  Loss: 3.290 (2.28)  Time: 0.463s,   17.29/s  (0.474s,   16.86/s)  LR: 8.937e-05  Data: 0.008 (0.009)\n",
            "Train: 17 [ 700/2354 ( 30%)]  Loss: 2.535 (2.27)  Time: 0.467s,   17.12/s  (0.474s,   16.88/s)  LR: 8.937e-05  Data: 0.007 (0.009)\n",
            "Train: 17 [ 750/2354 ( 32%)]  Loss: 2.097 (2.27)  Time: 0.468s,   17.11/s  (0.473s,   16.90/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [ 800/2354 ( 34%)]  Loss: 2.306 (2.27)  Time: 0.471s,   16.99/s  (0.474s,   16.88/s)  LR: 8.937e-05  Data: 0.010 (0.008)\n",
            "Train: 17 [ 850/2354 ( 36%)]  Loss: 2.884 (2.28)  Time: 0.469s,   17.07/s  (0.474s,   16.89/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [ 900/2354 ( 38%)]  Loss: 3.220 (2.29)  Time: 0.471s,   16.97/s  (0.473s,   16.90/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [ 950/2354 ( 40%)]  Loss: 2.471 (2.29)  Time: 0.472s,   16.96/s  (0.474s,   16.88/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1000/2354 ( 42%)]  Loss: 1.996 (2.29)  Time: 0.461s,   17.34/s  (0.474s,   16.89/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1050/2354 ( 45%)]  Loss: 2.378 (2.29)  Time: 0.473s,   16.93/s  (0.473s,   16.91/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [1100/2354 ( 47%)]  Loss: 1.348 (2.30)  Time: 0.464s,   17.25/s  (0.473s,   16.92/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [1150/2354 ( 49%)]  Loss: 1.908 (2.29)  Time: 0.463s,   17.29/s  (0.473s,   16.90/s)  LR: 8.937e-05  Data: 0.009 (0.008)\n",
            "Train: 17 [1200/2354 ( 51%)]  Loss: 2.299 (2.29)  Time: 0.459s,   17.41/s  (0.473s,   16.91/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [1250/2354 ( 53%)]  Loss: 1.955 (2.29)  Time: 0.462s,   17.32/s  (0.473s,   16.92/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1300/2354 ( 55%)]  Loss: 2.133 (2.29)  Time: 0.467s,   17.14/s  (0.473s,   16.91/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [1350/2354 ( 57%)]  Loss: 2.268 (2.29)  Time: 0.464s,   17.23/s  (0.473s,   16.92/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1400/2354 ( 59%)]  Loss: 2.603 (2.29)  Time: 0.480s,   16.65/s  (0.473s,   16.93/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1450/2354 ( 62%)]  Loss: 2.184 (2.29)  Time: 0.466s,   17.16/s  (0.472s,   16.93/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1500/2354 ( 64%)]  Loss: 2.387 (2.30)  Time: 0.474s,   16.88/s  (0.473s,   16.91/s)  LR: 8.937e-05  Data: 0.010 (0.008)\n",
            "Train: 17 [1550/2354 ( 66%)]  Loss: 2.364 (2.30)  Time: 0.460s,   17.38/s  (0.473s,   16.92/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1600/2354 ( 68%)]  Loss: 2.381 (2.30)  Time: 0.466s,   17.18/s  (0.473s,   16.93/s)  LR: 8.937e-05  Data: 0.010 (0.008)\n",
            "Train: 17 [1650/2354 ( 70%)]  Loss: 2.270 (2.30)  Time: 0.471s,   16.98/s  (0.473s,   16.92/s)  LR: 8.937e-05  Data: 0.014 (0.008)\n",
            "Train: 17 [1700/2354 ( 72%)]  Loss: 2.089 (2.30)  Time: 0.463s,   17.26/s  (0.473s,   16.92/s)  LR: 8.937e-05  Data: 0.009 (0.008)\n",
            "Train: 17 [1750/2354 ( 74%)]  Loss: 2.897 (2.30)  Time: 0.470s,   17.04/s  (0.473s,   16.93/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1800/2354 ( 76%)]  Loss: 2.650 (2.30)  Time: 0.465s,   17.19/s  (0.472s,   16.93/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1850/2354 ( 79%)]  Loss: 2.960 (2.30)  Time: 0.460s,   17.38/s  (0.473s,   16.92/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [1900/2354 ( 81%)]  Loss: 1.635 (2.30)  Time: 0.461s,   17.35/s  (0.473s,   16.93/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [1950/2354 ( 83%)]  Loss: 1.268 (2.30)  Time: 0.470s,   17.02/s  (0.472s,   16.94/s)  LR: 8.937e-05  Data: 0.008 (0.008)\n",
            "Train: 17 [2000/2354 ( 85%)]  Loss: 3.497 (2.30)  Time: 0.468s,   17.10/s  (0.473s,   16.93/s)  LR: 8.937e-05  Data: 0.009 (0.008)\n",
            "Train: 17 [2050/2354 ( 87%)]  Loss: 2.781 (2.30)  Time: 0.464s,   17.25/s  (0.472s,   16.93/s)  LR: 8.937e-05  Data: 0.010 (0.008)\n",
            "Train: 17 [2100/2354 ( 89%)]  Loss: 1.866 (2.30)  Time: 0.483s,   16.57/s  (0.472s,   16.94/s)  LR: 8.937e-05  Data: 0.008 (0.008)\n",
            "Train: 17 [2150/2354 ( 91%)]  Loss: 1.936 (2.30)  Time: 0.464s,   17.25/s  (0.472s,   16.94/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [2200/2354 ( 93%)]  Loss: 1.828 (2.30)  Time: 0.464s,   17.25/s  (0.472s,   16.93/s)  LR: 8.937e-05  Data: 0.009 (0.008)\n",
            "Train: 17 [2250/2354 ( 96%)]  Loss: 2.033 (2.30)  Time: 0.459s,   17.44/s  (0.472s,   16.94/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [2300/2354 ( 98%)]  Loss: 2.331 (2.30)  Time: 0.461s,   17.37/s  (0.472s,   16.94/s)  LR: 8.937e-05  Data: 0.007 (0.008)\n",
            "Train: 17 [2350/2354 (100%)]  Loss: 3.240 (2.30)  Time: 0.481s,   16.63/s  (0.472s,   16.94/s)  LR: 8.937e-05  Data: 0.006 (0.008)\n",
            "Train: 17 [2353/2354 (100%)]  Loss: 3.265 (2.30)  Time: 0.455s,   17.57/s  (0.472s,   16.94/s)  LR: 8.937e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.591 (0.591)  Loss:  0.6650 (0.6650)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.125 (0.153)  Loss:  1.7207 (0.5566)  Acc@1: 75.0000 (93.1373)  Acc@5: 100.0000 (98.5294)\n",
            "Test: [ 100/2354]  Time: 0.167 (0.146)  Loss:  1.2373 (0.8248)  Acc@1: 75.0000 (85.3960)  Acc@5: 75.0000 (98.5149)\n",
            "Test: [ 150/2354]  Time: 0.080 (0.143)  Loss:  0.3992 (0.8136)  Acc@1: 100.0000 (84.7682)  Acc@5: 100.0000 (98.5099)\n",
            "Test: [ 200/2354]  Time: 0.116 (0.141)  Loss:  1.8828 (0.7549)  Acc@1: 25.0000 (85.5721)  Acc@5: 100.0000 (98.7562)\n",
            "Test: [ 250/2354]  Time: 0.082 (0.141)  Loss:  0.3328 (0.7946)  Acc@1: 100.0000 (85.1594)  Acc@5: 100.0000 (99.0040)\n",
            "Test: [ 300/2354]  Time: 0.152 (0.140)  Loss:  1.2812 (0.7729)  Acc@1: 50.0000 (85.9635)  Acc@5: 100.0000 (98.7542)\n",
            "Test: [ 350/2354]  Time: 0.166 (0.140)  Loss:  1.1729 (0.7833)  Acc@1: 50.0000 (84.3305)  Acc@5: 100.0000 (98.8604)\n",
            "Test: [ 400/2354]  Time: 0.187 (0.140)  Loss:  0.1626 (0.7823)  Acc@1: 100.0000 (84.1646)  Acc@5: 100.0000 (98.8155)\n",
            "Test: [ 450/2354]  Time: 0.159 (0.140)  Loss:  0.4451 (0.7511)  Acc@1: 100.0000 (85.0887)  Acc@5: 100.0000 (98.8914)\n",
            "Test: [ 500/2354]  Time: 0.084 (0.139)  Loss:  0.6519 (0.7287)  Acc@1: 100.0000 (85.6786)  Acc@5: 100.0000 (98.9022)\n",
            "Test: [ 550/2354]  Time: 0.110 (0.139)  Loss:  1.4004 (0.7361)  Acc@1: 75.0000 (85.3448)  Acc@5: 75.0000 (98.8657)\n",
            "Test: [ 600/2354]  Time: 0.135 (0.142)  Loss:  0.3906 (0.7187)  Acc@1: 100.0000 (86.1897)  Acc@5: 100.0000 (98.8769)\n",
            "Test: [ 650/2354]  Time: 0.080 (0.142)  Loss:  0.5801 (0.7046)  Acc@1: 75.0000 (86.6743)  Acc@5: 100.0000 (98.8479)\n",
            "Test: [ 700/2354]  Time: 0.144 (0.142)  Loss:  0.0900 (0.6843)  Acc@1: 100.0000 (87.3395)  Acc@5: 100.0000 (98.8588)\n",
            "Test: [ 750/2354]  Time: 0.198 (0.141)  Loss:  1.0283 (0.6759)  Acc@1: 50.0000 (87.4834)  Acc@5: 100.0000 (98.8682)\n",
            "Test: [ 800/2354]  Time: 0.142 (0.141)  Loss:  0.2666 (0.6769)  Acc@1: 100.0000 (87.1411)  Acc@5: 100.0000 (98.9076)\n",
            "Test: [ 850/2354]  Time: 0.082 (0.141)  Loss:  0.0714 (0.6747)  Acc@1: 100.0000 (87.1915)  Acc@5: 100.0000 (98.7955)\n",
            "Test: [ 900/2354]  Time: 0.145 (0.141)  Loss:  1.1445 (0.6571)  Acc@1: 75.0000 (87.6804)  Acc@5: 75.0000 (98.8346)\n",
            "Test: [ 950/2354]  Time: 0.127 (0.141)  Loss:  0.5894 (0.6503)  Acc@1: 100.0000 (87.9075)  Acc@5: 100.0000 (98.8433)\n",
            "Test: [1000/2354]  Time: 0.087 (0.141)  Loss:  0.8408 (0.6526)  Acc@1: 100.0000 (88.0619)  Acc@5: 100.0000 (98.8761)\n",
            "Test: [1050/2354]  Time: 0.094 (0.141)  Loss:  0.3059 (0.6543)  Acc@1: 100.0000 (88.2017)  Acc@5: 100.0000 (98.8582)\n",
            "Test: [1100/2354]  Time: 0.130 (0.141)  Loss:  0.7393 (0.6627)  Acc@1: 100.0000 (88.0563)  Acc@5: 100.0000 (98.8420)\n",
            "Test: [1150/2354]  Time: 0.124 (0.142)  Loss:  1.5645 (0.6577)  Acc@1: 100.0000 (88.3362)  Acc@5: 100.0000 (98.8271)\n",
            "Test: [1200/2354]  Time: 0.130 (0.142)  Loss:  0.8345 (0.6595)  Acc@1: 75.0000 (88.2390)  Acc@5: 100.0000 (98.7719)\n",
            "Test: [1250/2354]  Time: 0.154 (0.142)  Loss:  0.0640 (0.6548)  Acc@1: 100.0000 (88.4692)  Acc@5: 100.0000 (98.8209)\n",
            "Test: [1300/2354]  Time: 0.125 (0.141)  Loss:  0.3369 (0.6606)  Acc@1: 100.0000 (88.0284)  Acc@5: 100.0000 (98.8086)\n",
            "Test: [1350/2354]  Time: 0.141 (0.141)  Loss:  0.1813 (0.6538)  Acc@1: 100.0000 (88.2124)  Acc@5: 100.0000 (98.8527)\n",
            "Test: [1400/2354]  Time: 0.138 (0.141)  Loss:  0.5127 (0.6628)  Acc@1: 75.0000 (87.7766)  Acc@5: 100.0000 (98.7866)\n",
            "Test: [1450/2354]  Time: 0.170 (0.141)  Loss:  0.5396 (0.6547)  Acc@1: 75.0000 (87.8532)  Acc@5: 100.0000 (98.8284)\n",
            "Test: [1500/2354]  Time: 0.177 (0.141)  Loss:  0.7109 (0.6557)  Acc@1: 100.0000 (87.9247)  Acc@5: 100.0000 (98.8008)\n",
            "Test: [1550/2354]  Time: 0.106 (0.141)  Loss:  0.2029 (0.6668)  Acc@1: 100.0000 (87.6209)  Acc@5: 100.0000 (98.7589)\n",
            "Test: [1600/2354]  Time: 0.115 (0.141)  Loss:  0.6367 (0.6786)  Acc@1: 100.0000 (87.1643)  Acc@5: 100.0000 (98.7196)\n",
            "Test: [1650/2354]  Time: 0.094 (0.141)  Loss:  0.4087 (0.6879)  Acc@1: 100.0000 (86.9170)  Acc@5: 100.0000 (98.7129)\n",
            "Test: [1700/2354]  Time: 0.195 (0.140)  Loss:  0.0536 (0.6858)  Acc@1: 100.0000 (86.9636)  Acc@5: 100.0000 (98.7213)\n",
            "Test: [1750/2354]  Time: 0.129 (0.141)  Loss:  1.0664 (0.6881)  Acc@1: 75.0000 (86.8646)  Acc@5: 100.0000 (98.7293)\n",
            "Test: [1800/2354]  Time: 0.148 (0.141)  Loss:  1.3428 (0.6920)  Acc@1: 75.0000 (86.8962)  Acc@5: 75.0000 (98.6813)\n",
            "Test: [1850/2354]  Time: 0.160 (0.141)  Loss:  0.7354 (0.6907)  Acc@1: 100.0000 (86.9665)  Acc@5: 100.0000 (98.7034)\n",
            "Test: [1900/2354]  Time: 0.147 (0.141)  Loss:  1.0771 (0.6882)  Acc@1: 75.0000 (87.0068)  Acc@5: 100.0000 (98.7375)\n",
            "Test: [1950/2354]  Time: 0.156 (0.141)  Loss:  1.0654 (0.6871)  Acc@1: 75.0000 (87.0835)  Acc@5: 100.0000 (98.7186)\n",
            "Test: [2000/2354]  Time: 0.082 (0.141)  Loss:  0.1525 (0.6853)  Acc@1: 100.0000 (87.1064)  Acc@5: 100.0000 (98.7256)\n",
            "Test: [2050/2354]  Time: 0.078 (0.141)  Loss:  2.1230 (0.6968)  Acc@1: 75.0000 (86.7138)  Acc@5: 75.0000 (98.7201)\n",
            "Test: [2100/2354]  Time: 0.150 (0.141)  Loss:  1.1064 (0.6990)  Acc@1: 100.0000 (86.6968)  Acc@5: 100.0000 (98.7268)\n",
            "Test: [2150/2354]  Time: 0.116 (0.141)  Loss:  1.2871 (0.7081)  Acc@1: 50.0000 (86.6109)  Acc@5: 100.0000 (98.7215)\n",
            "Test: [2200/2354]  Time: 0.116 (0.141)  Loss:  1.1230 (0.7183)  Acc@1: 75.0000 (86.3017)  Acc@5: 100.0000 (98.7165)\n",
            "Test: [2250/2354]  Time: 0.170 (0.141)  Loss:  0.3569 (0.7175)  Acc@1: 100.0000 (86.3616)  Acc@5: 100.0000 (98.7006)\n",
            "Test: [2300/2354]  Time: 0.124 (0.140)  Loss:  0.3408 (0.7150)  Acc@1: 100.0000 (86.4624)  Acc@5: 100.0000 (98.7071)\n",
            "Test: [2350/2354]  Time: 0.076 (0.141)  Loss:  1.2295 (0.7150)  Acc@1: 50.0000 (86.4207)  Acc@5: 100.0000 (98.7133)\n",
            "Test: [2354/2354]  Time: 0.067 (0.141)  Loss:  0.2178 (0.7152)  Acc@1: 100.0000 (86.4211)  Acc@5: 100.0000 (98.7154)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-7.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar', 70.64444208514705)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-9.pth.tar', 68.34058817284213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-8.pth.tar', 64.23187174859326)\n",
            "\n",
            "Train: 18 [   0/2354 (  0%)]  Loss: 2.196 (2.20)  Time: 1.195s,    6.69/s  (1.195s,    6.69/s)  LR: 8.814e-05  Data: 0.399 (0.399)\n",
            "Train: 18 [  50/2354 (  2%)]  Loss: 3.604 (2.14)  Time: 0.457s,   17.49/s  (0.499s,   16.04/s)  LR: 8.814e-05  Data: 0.006 (0.015)\n",
            "Train: 18 [ 100/2354 (  4%)]  Loss: 2.807 (2.22)  Time: 0.462s,   17.33/s  (0.482s,   16.60/s)  LR: 8.814e-05  Data: 0.009 (0.011)\n",
            "Train: 18 [ 150/2354 (  6%)]  Loss: 1.340 (2.21)  Time: 0.617s,   12.96/s  (0.478s,   16.74/s)  LR: 8.814e-05  Data: 0.007 (0.010)\n",
            "Train: 18 [ 200/2354 (  8%)]  Loss: 1.488 (2.20)  Time: 0.477s,   16.78/s  (0.478s,   16.73/s)  LR: 8.814e-05  Data: 0.010 (0.010)\n",
            "Train: 18 [ 250/2354 ( 11%)]  Loss: 2.343 (2.20)  Time: 0.469s,   17.06/s  (0.476s,   16.82/s)  LR: 8.814e-05  Data: 0.010 (0.009)\n",
            "Train: 18 [ 300/2354 ( 13%)]  Loss: 1.725 (2.20)  Time: 0.470s,   17.04/s  (0.474s,   16.88/s)  LR: 8.814e-05  Data: 0.010 (0.009)\n",
            "Train: 18 [ 350/2354 ( 15%)]  Loss: 3.380 (2.22)  Time: 0.463s,   17.29/s  (0.475s,   16.84/s)  LR: 8.814e-05  Data: 0.007 (0.009)\n",
            "Train: 18 [ 400/2354 ( 17%)]  Loss: 2.667 (2.23)  Time: 0.457s,   17.52/s  (0.474s,   16.88/s)  LR: 8.814e-05  Data: 0.007 (0.009)\n",
            "Train: 18 [ 450/2354 ( 19%)]  Loss: 2.202 (2.24)  Time: 0.470s,   17.04/s  (0.473s,   16.91/s)  LR: 8.814e-05  Data: 0.009 (0.009)\n",
            "Train: 18 [ 500/2354 ( 21%)]  Loss: 2.197 (2.26)  Time: 0.620s,   12.90/s  (0.473s,   16.92/s)  LR: 8.814e-05  Data: 0.019 (0.009)\n",
            "Train: 18 [ 550/2354 ( 23%)]  Loss: 1.420 (2.25)  Time: 0.460s,   17.39/s  (0.473s,   16.90/s)  LR: 8.814e-05  Data: 0.007 (0.009)\n",
            "Train: 18 [ 600/2354 ( 25%)]  Loss: 1.436 (2.25)  Time: 0.463s,   17.26/s  (0.473s,   16.93/s)  LR: 8.814e-05  Data: 0.007 (0.009)\n",
            "Train: 18 [ 650/2354 ( 28%)]  Loss: 2.710 (2.26)  Time: 0.466s,   17.17/s  (0.472s,   16.95/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [ 700/2354 ( 30%)]  Loss: 2.959 (2.26)  Time: 0.466s,   17.18/s  (0.473s,   16.92/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [ 750/2354 ( 32%)]  Loss: 3.113 (2.27)  Time: 0.457s,   17.50/s  (0.472s,   16.94/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [ 800/2354 ( 34%)]  Loss: 1.554 (2.28)  Time: 0.465s,   17.20/s  (0.472s,   16.96/s)  LR: 8.814e-05  Data: 0.010 (0.008)\n",
            "Train: 18 [ 850/2354 ( 36%)]  Loss: 2.357 (2.27)  Time: 0.631s,   12.67/s  (0.472s,   16.95/s)  LR: 8.814e-05  Data: 0.019 (0.008)\n",
            "Train: 18 [ 900/2354 ( 38%)]  Loss: 2.151 (2.27)  Time: 0.462s,   17.33/s  (0.472s,   16.95/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [ 950/2354 ( 40%)]  Loss: 1.430 (2.27)  Time: 0.466s,   17.17/s  (0.472s,   16.96/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1000/2354 ( 42%)]  Loss: 2.390 (2.26)  Time: 0.464s,   17.23/s  (0.471s,   16.97/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1050/2354 ( 45%)]  Loss: 1.447 (2.25)  Time: 0.461s,   17.37/s  (0.472s,   16.95/s)  LR: 8.814e-05  Data: 0.008 (0.008)\n",
            "Train: 18 [1100/2354 ( 47%)]  Loss: 1.915 (2.26)  Time: 0.459s,   17.43/s  (0.472s,   16.96/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1150/2354 ( 49%)]  Loss: 1.481 (2.25)  Time: 0.458s,   17.48/s  (0.471s,   16.97/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1200/2354 ( 51%)]  Loss: 2.402 (2.26)  Time: 0.467s,   17.13/s  (0.472s,   16.96/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1250/2354 ( 53%)]  Loss: 2.293 (2.26)  Time: 0.469s,   17.07/s  (0.472s,   16.97/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [1300/2354 ( 55%)]  Loss: 1.496 (2.26)  Time: 0.477s,   16.77/s  (0.471s,   16.97/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1350/2354 ( 57%)]  Loss: 2.304 (2.26)  Time: 0.463s,   17.30/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [1400/2354 ( 59%)]  Loss: 3.548 (2.26)  Time: 0.464s,   17.23/s  (0.471s,   16.97/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1450/2354 ( 62%)]  Loss: 3.288 (2.27)  Time: 0.467s,   17.12/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.009 (0.008)\n",
            "Train: 18 [1500/2354 ( 64%)]  Loss: 3.652 (2.27)  Time: 0.463s,   17.27/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.009 (0.008)\n",
            "Train: 18 [1550/2354 ( 66%)]  Loss: 1.818 (2.27)  Time: 0.464s,   17.23/s  (0.471s,   16.97/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [1600/2354 ( 68%)]  Loss: 2.220 (2.27)  Time: 0.470s,   17.02/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [1650/2354 ( 70%)]  Loss: 3.673 (2.27)  Time: 0.465s,   17.20/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [1700/2354 ( 72%)]  Loss: 2.088 (2.27)  Time: 0.469s,   17.05/s  (0.471s,   16.99/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1750/2354 ( 74%)]  Loss: 1.274 (2.27)  Time: 0.468s,   17.10/s  (0.471s,   16.97/s)  LR: 8.814e-05  Data: 0.009 (0.008)\n",
            "Train: 18 [1800/2354 ( 76%)]  Loss: 3.704 (2.27)  Time: 0.468s,   17.10/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [1850/2354 ( 79%)]  Loss: 1.962 (2.27)  Time: 0.465s,   17.21/s  (0.471s,   16.99/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [1900/2354 ( 81%)]  Loss: 3.217 (2.27)  Time: 0.467s,   17.14/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.009 (0.008)\n",
            "Train: 18 [1950/2354 ( 83%)]  Loss: 1.804 (2.27)  Time: 0.461s,   17.37/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [2000/2354 ( 85%)]  Loss: 1.315 (2.28)  Time: 0.470s,   17.03/s  (0.471s,   16.99/s)  LR: 8.814e-05  Data: 0.008 (0.008)\n",
            "Train: 18 [2050/2354 ( 87%)]  Loss: 3.166 (2.28)  Time: 0.463s,   17.26/s  (0.471s,   16.99/s)  LR: 8.814e-05  Data: 0.006 (0.008)\n",
            "Train: 18 [2100/2354 ( 89%)]  Loss: 2.051 (2.28)  Time: 0.461s,   17.36/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.007 (0.008)\n",
            "Train: 18 [2150/2354 ( 91%)]  Loss: 1.386 (2.27)  Time: 0.463s,   17.27/s  (0.471s,   16.99/s)  LR: 8.814e-05  Data: 0.010 (0.008)\n",
            "Train: 18 [2200/2354 ( 93%)]  Loss: 1.704 (2.27)  Time: 0.467s,   17.11/s  (0.471s,   16.99/s)  LR: 8.814e-05  Data: 0.010 (0.008)\n",
            "Train: 18 [2250/2354 ( 96%)]  Loss: 1.437 (2.28)  Time: 0.478s,   16.74/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.008 (0.008)\n",
            "Train: 18 [2300/2354 ( 98%)]  Loss: 1.794 (2.27)  Time: 0.471s,   16.98/s  (0.471s,   16.98/s)  LR: 8.814e-05  Data: 0.008 (0.008)\n",
            "Train: 18 [2350/2354 (100%)]  Loss: 2.202 (2.27)  Time: 0.465s,   17.20/s  (0.471s,   16.99/s)  LR: 8.814e-05  Data: 0.005 (0.008)\n",
            "Train: 18 [2353/2354 (100%)]  Loss: 2.389 (2.27)  Time: 0.455s,   17.58/s  (0.471s,   16.99/s)  LR: 8.814e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.595 (0.595)  Loss:  1.1895 (1.1895)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.130 (0.153)  Loss:  1.3701 (0.6373)  Acc@1: 75.0000 (88.7255)  Acc@5: 100.0000 (98.0392)\n",
            "Test: [ 100/2354]  Time: 0.166 (0.146)  Loss:  1.0791 (0.8171)  Acc@1: 100.0000 (86.3861)  Acc@5: 100.0000 (98.7624)\n",
            "Test: [ 150/2354]  Time: 0.167 (0.144)  Loss:  0.3950 (0.7891)  Acc@1: 100.0000 (85.5960)  Acc@5: 100.0000 (99.1722)\n",
            "Test: [ 200/2354]  Time: 0.163 (0.150)  Loss:  2.1035 (0.7235)  Acc@1:  0.0000 (86.0697)  Acc@5: 100.0000 (99.3781)\n",
            "Test: [ 250/2354]  Time: 0.100 (0.148)  Loss:  0.4241 (0.7486)  Acc@1: 75.0000 (85.8566)  Acc@5: 100.0000 (99.4024)\n",
            "Test: [ 300/2354]  Time: 0.084 (0.147)  Loss:  0.6479 (0.7469)  Acc@1: 100.0000 (85.3821)  Acc@5: 100.0000 (99.1694)\n",
            "Test: [ 350/2354]  Time: 0.169 (0.145)  Loss:  1.1357 (0.7509)  Acc@1: 50.0000 (83.6895)  Acc@5: 100.0000 (99.2165)\n",
            "Test: [ 400/2354]  Time: 0.140 (0.144)  Loss:  0.1614 (0.7341)  Acc@1: 100.0000 (83.9152)  Acc@5: 100.0000 (99.1272)\n",
            "Test: [ 450/2354]  Time: 0.117 (0.143)  Loss:  0.1868 (0.6986)  Acc@1: 100.0000 (85.0333)  Acc@5: 100.0000 (99.2239)\n",
            "Test: [ 500/2354]  Time: 0.194 (0.143)  Loss:  0.2776 (0.6807)  Acc@1: 100.0000 (85.8283)  Acc@5: 100.0000 (99.1517)\n",
            "Test: [ 550/2354]  Time: 0.132 (0.143)  Loss:  1.3184 (0.6911)  Acc@1: 75.0000 (85.1180)  Acc@5: 75.0000 (99.1379)\n",
            "Test: [ 600/2354]  Time: 0.202 (0.142)  Loss:  0.5327 (0.6756)  Acc@1: 75.0000 (85.9401)  Acc@5: 100.0000 (99.1265)\n",
            "Test: [ 650/2354]  Time: 0.177 (0.142)  Loss:  0.2213 (0.6577)  Acc@1: 100.0000 (86.3671)  Acc@5: 100.0000 (99.1167)\n",
            "Test: [ 700/2354]  Time: 0.127 (0.142)  Loss:  0.3823 (0.6502)  Acc@1: 100.0000 (86.6619)  Acc@5: 100.0000 (99.1441)\n",
            "Test: [ 750/2354]  Time: 0.234 (0.143)  Loss:  0.6021 (0.6415)  Acc@1: 75.0000 (86.9507)  Acc@5: 100.0000 (99.1678)\n",
            "Test: [ 800/2354]  Time: 0.166 (0.143)  Loss:  0.2300 (0.6424)  Acc@1: 100.0000 (86.8602)  Acc@5: 100.0000 (99.1885)\n",
            "Test: [ 850/2354]  Time: 0.167 (0.143)  Loss:  0.0345 (0.6361)  Acc@1: 100.0000 (86.8684)  Acc@5: 100.0000 (99.1481)\n",
            "Test: [ 900/2354]  Time: 0.203 (0.143)  Loss:  1.0420 (0.6178)  Acc@1: 75.0000 (87.4306)  Acc@5: 75.0000 (99.1676)\n",
            "Test: [ 950/2354]  Time: 0.190 (0.143)  Loss:  0.3271 (0.6056)  Acc@1: 100.0000 (87.8286)  Acc@5: 100.0000 (99.1588)\n",
            "Test: [1000/2354]  Time: 0.165 (0.142)  Loss:  0.1948 (0.6031)  Acc@1: 100.0000 (87.9371)  Acc@5: 100.0000 (99.2008)\n",
            "Test: [1050/2354]  Time: 0.110 (0.142)  Loss:  0.8481 (0.6009)  Acc@1: 75.0000 (87.9876)  Acc@5: 100.0000 (99.1912)\n",
            "Test: [1100/2354]  Time: 0.149 (0.142)  Loss:  0.8296 (0.6020)  Acc@1: 100.0000 (88.0790)  Acc@5: 100.0000 (99.1826)\n",
            "Test: [1150/2354]  Time: 0.141 (0.142)  Loss:  0.9355 (0.5986)  Acc@1: 100.0000 (88.3145)  Acc@5: 100.0000 (99.1529)\n",
            "Test: [1200/2354]  Time: 0.130 (0.142)  Loss:  0.9795 (0.6048)  Acc@1: 75.0000 (88.0933)  Acc@5: 75.0000 (99.0633)\n",
            "Test: [1250/2354]  Time: 0.158 (0.141)  Loss:  0.0667 (0.5977)  Acc@1: 100.0000 (88.3693)  Acc@5: 100.0000 (99.1007)\n",
            "Test: [1300/2354]  Time: 0.127 (0.141)  Loss:  0.1384 (0.6018)  Acc@1: 100.0000 (88.0861)  Acc@5: 100.0000 (99.0776)\n",
            "Test: [1350/2354]  Time: 0.129 (0.142)  Loss:  0.1448 (0.6006)  Acc@1: 100.0000 (88.2124)  Acc@5: 100.0000 (99.0933)\n",
            "Test: [1400/2354]  Time: 0.199 (0.142)  Loss:  0.4124 (0.5995)  Acc@1: 100.0000 (88.2584)  Acc@5: 100.0000 (99.0721)\n",
            "Test: [1450/2354]  Time: 0.161 (0.142)  Loss:  1.0742 (0.6014)  Acc@1: 50.0000 (88.1978)  Acc@5: 100.0000 (99.0696)\n",
            "Test: [1500/2354]  Time: 0.155 (0.142)  Loss:  0.0872 (0.6053)  Acc@1: 100.0000 (88.0580)  Acc@5: 100.0000 (99.0340)\n",
            "Test: [1550/2354]  Time: 0.115 (0.142)  Loss:  0.1947 (0.6147)  Acc@1: 100.0000 (87.8788)  Acc@5: 100.0000 (99.0168)\n",
            "Test: [1600/2354]  Time: 0.127 (0.142)  Loss:  0.5527 (0.6193)  Acc@1: 100.0000 (87.6952)  Acc@5: 100.0000 (99.0006)\n",
            "Test: [1650/2354]  Time: 0.119 (0.141)  Loss:  0.2466 (0.6263)  Acc@1: 100.0000 (87.4924)  Acc@5: 100.0000 (99.0006)\n",
            "Test: [1700/2354]  Time: 0.151 (0.141)  Loss:  0.0836 (0.6200)  Acc@1: 100.0000 (87.6984)  Acc@5: 100.0000 (98.9859)\n",
            "Test: [1750/2354]  Time: 0.124 (0.141)  Loss:  0.6953 (0.6308)  Acc@1: 75.0000 (87.2501)  Acc@5: 100.0000 (99.0148)\n",
            "Test: [1800/2354]  Time: 0.127 (0.141)  Loss:  0.4309 (0.6309)  Acc@1: 75.0000 (87.3126)  Acc@5: 100.0000 (99.0283)\n",
            "Test: [1850/2354]  Time: 0.123 (0.141)  Loss:  0.1476 (0.6274)  Acc@1: 100.0000 (87.2771)  Acc@5: 100.0000 (99.0546)\n",
            "Test: [1900/2354]  Time: 0.164 (0.141)  Loss:  1.0127 (0.6262)  Acc@1: 75.0000 (87.3356)  Acc@5: 100.0000 (99.0663)\n",
            "Test: [1950/2354]  Time: 0.161 (0.142)  Loss:  0.3203 (0.6238)  Acc@1: 100.0000 (87.4552)  Acc@5: 100.0000 (99.0646)\n",
            "Test: [2000/2354]  Time: 0.129 (0.142)  Loss:  0.1262 (0.6187)  Acc@1: 100.0000 (87.6812)  Acc@5: 100.0000 (99.0755)\n",
            "Test: [2050/2354]  Time: 0.167 (0.142)  Loss:  2.0508 (0.6286)  Acc@1: 25.0000 (87.1770)  Acc@5: 100.0000 (99.0249)\n",
            "Test: [2100/2354]  Time: 0.117 (0.142)  Loss:  0.5483 (0.6319)  Acc@1: 100.0000 (87.1728)  Acc@5: 100.0000 (99.0124)\n",
            "Test: [2150/2354]  Time: 0.139 (0.142)  Loss:  1.1807 (0.6398)  Acc@1: 75.0000 (87.0060)  Acc@5: 100.0000 (98.9888)\n",
            "Test: [2200/2354]  Time: 0.079 (0.142)  Loss:  1.6572 (0.6487)  Acc@1: 25.0000 (86.7674)  Acc@5: 100.0000 (98.9777)\n",
            "Test: [2250/2354]  Time: 0.086 (0.141)  Loss:  0.1788 (0.6492)  Acc@1: 100.0000 (86.8170)  Acc@5: 100.0000 (98.9893)\n",
            "Test: [2300/2354]  Time: 0.119 (0.141)  Loss:  0.1790 (0.6471)  Acc@1: 100.0000 (86.9405)  Acc@5: 100.0000 (98.9787)\n",
            "Test: [2350/2354]  Time: 0.076 (0.141)  Loss:  0.6899 (0.6455)  Acc@1: 100.0000 (86.8992)  Acc@5: 100.0000 (98.9898)\n",
            "Test: [2354/2354]  Time: 0.066 (0.141)  Loss:  0.3440 (0.6455)  Acc@1: 100.0000 (86.9094)  Acc@5: 100.0000 (98.9914)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-8.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar', 70.64444208514705)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-9.pth.tar', 68.34058817284213)\n",
            "\n",
            "Train: 19 [   0/2354 (  0%)]  Loss: 2.307 (2.31)  Time: 1.226s,    6.52/s  (1.226s,    6.52/s)  LR: 8.685e-05  Data: 0.458 (0.458)\n",
            "Train: 19 [  50/2354 (  2%)]  Loss: 2.734 (2.11)  Time: 0.465s,   17.22/s  (0.518s,   15.43/s)  LR: 8.685e-05  Data: 0.007 (0.018)\n",
            "Train: 19 [ 100/2354 (  4%)]  Loss: 1.652 (2.13)  Time: 0.466s,   17.16/s  (0.491s,   16.28/s)  LR: 8.685e-05  Data: 0.011 (0.013)\n",
            "Train: 19 [ 150/2354 (  6%)]  Loss: 2.752 (2.10)  Time: 0.468s,   17.08/s  (0.483s,   16.58/s)  LR: 8.685e-05  Data: 0.010 (0.011)\n",
            "Train: 19 [ 200/2354 (  8%)]  Loss: 2.297 (2.15)  Time: 0.467s,   17.14/s  (0.478s,   16.73/s)  LR: 8.685e-05  Data: 0.007 (0.010)\n",
            "Train: 19 [ 250/2354 ( 11%)]  Loss: 2.624 (2.18)  Time: 0.460s,   17.37/s  (0.479s,   16.71/s)  LR: 8.685e-05  Data: 0.007 (0.010)\n",
            "Train: 19 [ 300/2354 ( 13%)]  Loss: 2.767 (2.17)  Time: 0.458s,   17.48/s  (0.476s,   16.79/s)  LR: 8.685e-05  Data: 0.007 (0.010)\n",
            "Train: 19 [ 350/2354 ( 15%)]  Loss: 1.865 (2.18)  Time: 0.463s,   17.27/s  (0.475s,   16.85/s)  LR: 8.685e-05  Data: 0.008 (0.009)\n",
            "Train: 19 [ 400/2354 ( 17%)]  Loss: 2.944 (2.17)  Time: 0.463s,   17.27/s  (0.476s,   16.82/s)  LR: 8.685e-05  Data: 0.007 (0.009)\n",
            "Train: 19 [ 450/2354 ( 19%)]  Loss: 2.319 (2.19)  Time: 0.465s,   17.22/s  (0.474s,   16.87/s)  LR: 8.685e-05  Data: 0.011 (0.009)\n",
            "Train: 19 [ 500/2354 ( 21%)]  Loss: 4.050 (2.20)  Time: 0.474s,   16.88/s  (0.473s,   16.90/s)  LR: 8.685e-05  Data: 0.010 (0.009)\n",
            "Train: 19 [ 550/2354 ( 23%)]  Loss: 2.053 (2.23)  Time: 0.464s,   17.25/s  (0.473s,   16.93/s)  LR: 8.685e-05  Data: 0.007 (0.009)\n",
            "Train: 19 [ 600/2354 ( 25%)]  Loss: 1.768 (2.23)  Time: 0.472s,   16.96/s  (0.474s,   16.89/s)  LR: 8.685e-05  Data: 0.010 (0.009)\n",
            "Train: 19 [ 650/2354 ( 28%)]  Loss: 3.694 (2.24)  Time: 0.457s,   17.51/s  (0.473s,   16.92/s)  LR: 8.685e-05  Data: 0.010 (0.009)\n",
            "Train: 19 [ 700/2354 ( 30%)]  Loss: 2.785 (2.24)  Time: 0.462s,   17.31/s  (0.472s,   16.94/s)  LR: 8.685e-05  Data: 0.007 (0.009)\n",
            "Train: 19 [ 750/2354 ( 32%)]  Loss: 1.258 (2.24)  Time: 0.466s,   17.17/s  (0.473s,   16.92/s)  LR: 8.685e-05  Data: 0.006 (0.009)\n",
            "Train: 19 [ 800/2354 ( 34%)]  Loss: 1.849 (2.25)  Time: 0.466s,   17.18/s  (0.472s,   16.94/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [ 850/2354 ( 36%)]  Loss: 2.007 (2.24)  Time: 0.464s,   17.25/s  (0.472s,   16.96/s)  LR: 8.685e-05  Data: 0.009 (0.008)\n",
            "Train: 19 [ 900/2354 ( 38%)]  Loss: 3.823 (2.25)  Time: 0.538s,   14.86/s  (0.472s,   16.96/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [ 950/2354 ( 40%)]  Loss: 1.469 (2.24)  Time: 0.462s,   17.30/s  (0.472s,   16.96/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1000/2354 ( 42%)]  Loss: 3.758 (2.25)  Time: 0.457s,   17.49/s  (0.471s,   16.97/s)  LR: 8.685e-05  Data: 0.009 (0.008)\n",
            "Train: 19 [1050/2354 ( 45%)]  Loss: 2.079 (2.24)  Time: 0.461s,   17.37/s  (0.471s,   16.98/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1100/2354 ( 47%)]  Loss: 1.122 (2.24)  Time: 0.468s,   17.09/s  (0.472s,   16.96/s)  LR: 8.685e-05  Data: 0.008 (0.008)\n",
            "Train: 19 [1150/2354 ( 49%)]  Loss: 1.163 (2.23)  Time: 0.465s,   17.20/s  (0.471s,   16.97/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1200/2354 ( 51%)]  Loss: 3.016 (2.23)  Time: 0.463s,   17.27/s  (0.471s,   16.98/s)  LR: 8.685e-05  Data: 0.009 (0.008)\n",
            "Train: 19 [1250/2354 ( 53%)]  Loss: 2.739 (2.23)  Time: 0.652s,   12.27/s  (0.471s,   16.97/s)  LR: 8.685e-05  Data: 0.018 (0.008)\n",
            "Train: 19 [1300/2354 ( 55%)]  Loss: 1.390 (2.23)  Time: 0.462s,   17.32/s  (0.471s,   16.98/s)  LR: 8.685e-05  Data: 0.010 (0.008)\n",
            "Train: 19 [1350/2354 ( 57%)]  Loss: 2.487 (2.23)  Time: 0.457s,   17.51/s  (0.471s,   16.99/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1400/2354 ( 59%)]  Loss: 1.147 (2.23)  Time: 0.462s,   17.33/s  (0.471s,   16.99/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1450/2354 ( 62%)]  Loss: 1.063 (2.23)  Time: 0.469s,   17.06/s  (0.471s,   16.98/s)  LR: 8.685e-05  Data: 0.010 (0.008)\n",
            "Train: 19 [1500/2354 ( 64%)]  Loss: 1.822 (2.23)  Time: 0.461s,   17.37/s  (0.471s,   16.99/s)  LR: 8.685e-05  Data: 0.006 (0.008)\n",
            "Train: 19 [1550/2354 ( 66%)]  Loss: 3.054 (2.23)  Time: 0.464s,   17.25/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1600/2354 ( 68%)]  Loss: 2.945 (2.23)  Time: 0.574s,   13.93/s  (0.471s,   16.98/s)  LR: 8.685e-05  Data: 0.018 (0.008)\n",
            "Train: 19 [1650/2354 ( 70%)]  Loss: 2.815 (2.23)  Time: 0.458s,   17.46/s  (0.471s,   16.99/s)  LR: 8.685e-05  Data: 0.006 (0.008)\n",
            "Train: 19 [1700/2354 ( 72%)]  Loss: 1.405 (2.22)  Time: 0.466s,   17.16/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1750/2354 ( 74%)]  Loss: 3.752 (2.23)  Time: 0.467s,   17.12/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.010 (0.008)\n",
            "Train: 19 [1800/2354 ( 76%)]  Loss: 1.100 (2.23)  Time: 0.464s,   17.23/s  (0.471s,   16.99/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1850/2354 ( 79%)]  Loss: 1.460 (2.23)  Time: 0.461s,   17.36/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1900/2354 ( 81%)]  Loss: 3.542 (2.23)  Time: 0.460s,   17.38/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [1950/2354 ( 83%)]  Loss: 1.418 (2.23)  Time: 0.463s,   17.28/s  (0.471s,   16.99/s)  LR: 8.685e-05  Data: 0.006 (0.008)\n",
            "Train: 19 [2000/2354 ( 85%)]  Loss: 1.318 (2.23)  Time: 0.458s,   17.46/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [2050/2354 ( 87%)]  Loss: 2.910 (2.23)  Time: 0.460s,   17.41/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.006 (0.008)\n",
            "Train: 19 [2100/2354 ( 89%)]  Loss: 2.337 (2.23)  Time: 0.464s,   17.25/s  (0.470s,   17.01/s)  LR: 8.685e-05  Data: 0.010 (0.008)\n",
            "Train: 19 [2150/2354 ( 91%)]  Loss: 2.869 (2.23)  Time: 0.464s,   17.26/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [2200/2354 ( 93%)]  Loss: 1.651 (2.23)  Time: 0.462s,   17.30/s  (0.470s,   17.00/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [2250/2354 ( 96%)]  Loss: 1.828 (2.23)  Time: 0.462s,   17.33/s  (0.470s,   17.01/s)  LR: 8.685e-05  Data: 0.007 (0.008)\n",
            "Train: 19 [2300/2354 ( 98%)]  Loss: 3.296 (2.22)  Time: 0.466s,   17.18/s  (0.471s,   17.00/s)  LR: 8.685e-05  Data: 0.009 (0.008)\n",
            "Train: 19 [2350/2354 (100%)]  Loss: 2.032 (2.22)  Time: 0.453s,   17.67/s  (0.470s,   17.01/s)  LR: 8.685e-05  Data: 0.005 (0.008)\n",
            "Train: 19 [2353/2354 (100%)]  Loss: 1.626 (2.22)  Time: 0.451s,   17.74/s  (0.470s,   17.01/s)  LR: 8.685e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.598 (0.598)  Loss:  0.3225 (0.3225)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.143 (0.154)  Loss:  1.5957 (0.5046)  Acc@1: 25.0000 (91.1765)  Acc@5: 100.0000 (98.5294)\n",
            "Test: [ 100/2354]  Time: 0.100 (0.149)  Loss:  1.5957 (0.7168)  Acc@1: 50.0000 (86.6337)  Acc@5: 100.0000 (98.7624)\n",
            "Test: [ 150/2354]  Time: 0.113 (0.146)  Loss:  0.3645 (0.6899)  Acc@1: 100.0000 (86.7550)  Acc@5: 100.0000 (99.0066)\n",
            "Test: [ 200/2354]  Time: 0.116 (0.144)  Loss:  0.7578 (0.6481)  Acc@1: 75.0000 (88.0597)  Acc@5: 100.0000 (99.2537)\n",
            "Test: [ 250/2354]  Time: 0.102 (0.142)  Loss:  0.0698 (0.6701)  Acc@1: 100.0000 (86.7530)  Acc@5: 100.0000 (99.4024)\n",
            "Test: [ 300/2354]  Time: 0.104 (0.142)  Loss:  1.8662 (0.6591)  Acc@1: 25.0000 (86.7110)  Acc@5: 100.0000 (99.2525)\n",
            "Test: [ 350/2354]  Time: 0.094 (0.141)  Loss:  0.6284 (0.6922)  Acc@1: 100.0000 (84.6866)  Acc@5: 100.0000 (99.0741)\n",
            "Test: [ 400/2354]  Time: 0.108 (0.145)  Loss:  0.1416 (0.6779)  Acc@1: 100.0000 (84.9751)  Acc@5: 100.0000 (98.8778)\n",
            "Test: [ 450/2354]  Time: 0.084 (0.144)  Loss:  0.0672 (0.6465)  Acc@1: 100.0000 (86.0310)  Acc@5: 100.0000 (99.0022)\n",
            "Test: [ 500/2354]  Time: 0.182 (0.144)  Loss:  1.5752 (0.6269)  Acc@1: 50.0000 (86.3772)  Acc@5: 100.0000 (99.0020)\n",
            "Test: [ 550/2354]  Time: 0.135 (0.143)  Loss:  1.5449 (0.6260)  Acc@1: 75.0000 (86.5245)  Acc@5: 75.0000 (98.9111)\n",
            "Test: [ 600/2354]  Time: 0.116 (0.143)  Loss:  0.4004 (0.6213)  Acc@1: 100.0000 (86.4809)  Acc@5: 100.0000 (98.9185)\n",
            "Test: [ 650/2354]  Time: 0.158 (0.143)  Loss:  0.1616 (0.6003)  Acc@1: 100.0000 (87.0584)  Acc@5: 100.0000 (99.0015)\n",
            "Test: [ 700/2354]  Time: 0.137 (0.142)  Loss:  0.0531 (0.5861)  Acc@1: 100.0000 (87.6248)  Acc@5: 100.0000 (99.0371)\n",
            "Test: [ 750/2354]  Time: 0.171 (0.142)  Loss:  0.8550 (0.5748)  Acc@1: 75.0000 (88.0493)  Acc@5: 100.0000 (99.0346)\n",
            "Test: [ 800/2354]  Time: 0.171 (0.142)  Loss:  0.6104 (0.5989)  Acc@1: 100.0000 (87.1099)  Acc@5: 100.0000 (99.0325)\n",
            "Test: [ 850/2354]  Time: 0.208 (0.142)  Loss:  0.0701 (0.5978)  Acc@1: 100.0000 (87.2797)  Acc@5: 100.0000 (99.0012)\n",
            "Test: [ 900/2354]  Time: 0.144 (0.141)  Loss:  1.2891 (0.5882)  Acc@1: 75.0000 (87.6249)  Acc@5: 75.0000 (99.0289)\n",
            "Test: [ 950/2354]  Time: 0.270 (0.142)  Loss:  0.5371 (0.5810)  Acc@1: 100.0000 (87.9075)  Acc@5: 100.0000 (99.0273)\n",
            "Test: [1000/2354]  Time: 0.184 (0.143)  Loss:  0.1114 (0.5768)  Acc@1: 100.0000 (88.0619)  Acc@5: 100.0000 (99.0509)\n",
            "Test: [1050/2354]  Time: 0.163 (0.143)  Loss:  0.5483 (0.5743)  Acc@1: 75.0000 (88.2017)  Acc@5: 100.0000 (99.0485)\n",
            "Test: [1100/2354]  Time: 0.104 (0.142)  Loss:  0.3560 (0.5768)  Acc@1: 100.0000 (88.2834)  Acc@5: 100.0000 (99.0463)\n",
            "Test: [1150/2354]  Time: 0.165 (0.142)  Loss:  0.9087 (0.5696)  Acc@1: 100.0000 (88.4883)  Acc@5: 100.0000 (99.0226)\n",
            "Test: [1200/2354]  Time: 0.138 (0.142)  Loss:  1.1943 (0.5702)  Acc@1: 50.0000 (88.3639)  Acc@5: 100.0000 (98.9800)\n",
            "Test: [1250/2354]  Time: 0.122 (0.142)  Loss:  0.2185 (0.5637)  Acc@1: 100.0000 (88.5092)  Acc@5: 100.0000 (98.9608)\n",
            "Test: [1300/2354]  Time: 0.084 (0.142)  Loss:  0.0911 (0.5599)  Acc@1: 100.0000 (88.5857)  Acc@5: 100.0000 (98.9239)\n",
            "Test: [1350/2354]  Time: 0.131 (0.141)  Loss:  0.0230 (0.5578)  Acc@1: 100.0000 (88.5270)  Acc@5: 100.0000 (98.9452)\n",
            "Test: [1400/2354]  Time: 0.152 (0.141)  Loss:  0.1285 (0.5550)  Acc@1: 100.0000 (88.5974)  Acc@5: 100.0000 (98.8936)\n",
            "Test: [1450/2354]  Time: 0.160 (0.141)  Loss:  0.2847 (0.5499)  Acc@1: 100.0000 (88.6458)  Acc@5: 100.0000 (98.9145)\n",
            "Test: [1500/2354]  Time: 0.182 (0.141)  Loss:  0.1986 (0.5482)  Acc@1: 100.0000 (88.6076)  Acc@5: 100.0000 (98.9174)\n",
            "Test: [1550/2354]  Time: 0.130 (0.142)  Loss:  0.6113 (0.5585)  Acc@1: 100.0000 (88.2334)  Acc@5: 100.0000 (98.9039)\n",
            "Test: [1600/2354]  Time: 0.191 (0.142)  Loss:  0.1184 (0.5654)  Acc@1: 100.0000 (88.0543)  Acc@5: 100.0000 (98.8757)\n",
            "Test: [1650/2354]  Time: 0.168 (0.142)  Loss:  0.5791 (0.5719)  Acc@1: 75.0000 (87.7347)  Acc@5: 100.0000 (98.8340)\n",
            "Test: [1700/2354]  Time: 0.099 (0.142)  Loss:  0.1002 (0.5716)  Acc@1: 100.0000 (87.7866)  Acc@5: 100.0000 (98.8242)\n",
            "Test: [1750/2354]  Time: 0.155 (0.142)  Loss:  0.9478 (0.5808)  Acc@1: 75.0000 (87.4929)  Acc@5: 100.0000 (98.8150)\n",
            "Test: [1800/2354]  Time: 0.174 (0.142)  Loss:  0.7373 (0.5766)  Acc@1: 100.0000 (87.7152)  Acc@5: 100.0000 (98.8201)\n",
            "Test: [1850/2354]  Time: 0.116 (0.142)  Loss:  0.2808 (0.5753)  Acc@1: 100.0000 (87.7364)  Acc@5: 100.0000 (98.8250)\n",
            "Test: [1900/2354]  Time: 0.128 (0.141)  Loss:  0.9536 (0.5771)  Acc@1: 75.0000 (87.7170)  Acc@5: 100.0000 (98.8427)\n",
            "Test: [1950/2354]  Time: 0.173 (0.141)  Loss:  1.4229 (0.5768)  Acc@1:  0.0000 (87.7755)  Acc@5: 100.0000 (98.8339)\n",
            "Test: [2000/2354]  Time: 0.154 (0.141)  Loss:  0.0931 (0.5726)  Acc@1: 100.0000 (87.9185)  Acc@5: 100.0000 (98.8256)\n",
            "Test: [2050/2354]  Time: 0.215 (0.141)  Loss:  0.8838 (0.5823)  Acc@1: 75.0000 (87.5549)  Acc@5: 100.0000 (98.8055)\n",
            "Test: [2100/2354]  Time: 0.279 (0.141)  Loss:  0.4502 (0.5881)  Acc@1: 100.0000 (87.3989)  Acc@5: 100.0000 (98.7506)\n",
            "Test: [2150/2354]  Time: 0.158 (0.142)  Loss:  0.6836 (0.5981)  Acc@1: 100.0000 (87.1106)  Acc@5: 100.0000 (98.7448)\n",
            "Test: [2200/2354]  Time: 0.101 (0.142)  Loss:  1.7666 (0.6051)  Acc@1: 25.0000 (86.9945)  Acc@5: 100.0000 (98.7392)\n",
            "Test: [2250/2354]  Time: 0.149 (0.142)  Loss:  0.0523 (0.6037)  Acc@1: 100.0000 (87.0169)  Acc@5: 100.0000 (98.7561)\n",
            "Test: [2300/2354]  Time: 0.128 (0.142)  Loss:  0.1359 (0.6001)  Acc@1: 100.0000 (87.1252)  Acc@5: 100.0000 (98.7614)\n",
            "Test: [2350/2354]  Time: 0.075 (0.141)  Loss:  0.9102 (0.6006)  Acc@1: 75.0000 (87.1863)  Acc@5: 100.0000 (98.7665)\n",
            "Test: [2354/2354]  Time: 0.064 (0.141)  Loss:  0.1437 (0.6002)  Acc@1: 100.0000 (87.2067)  Acc@5: 100.0000 (98.7684)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-9.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar', 70.64444208514705)\n",
            "\n",
            "Train: 20 [   0/2354 (  0%)]  Loss: 2.921 (2.92)  Time: 1.284s,    6.23/s  (1.284s,    6.23/s)  LR: 8.550e-05  Data: 0.604 (0.604)\n",
            "Train: 20 [  50/2354 (  2%)]  Loss: 1.824 (2.08)  Time: 0.460s,   17.39/s  (0.497s,   16.09/s)  LR: 8.550e-05  Data: 0.007 (0.019)\n",
            "Train: 20 [ 100/2354 (  4%)]  Loss: 2.098 (2.12)  Time: 0.459s,   17.45/s  (0.489s,   16.35/s)  LR: 8.550e-05  Data: 0.006 (0.014)\n",
            "Train: 20 [ 150/2354 (  6%)]  Loss: 1.411 (2.10)  Time: 0.462s,   17.30/s  (0.481s,   16.64/s)  LR: 8.550e-05  Data: 0.008 (0.012)\n",
            "Train: 20 [ 200/2354 (  8%)]  Loss: 1.562 (2.13)  Time: 0.469s,   17.04/s  (0.476s,   16.79/s)  LR: 8.550e-05  Data: 0.007 (0.011)\n",
            "Train: 20 [ 250/2354 ( 11%)]  Loss: 1.424 (2.13)  Time: 0.466s,   17.17/s  (0.474s,   16.88/s)  LR: 8.550e-05  Data: 0.006 (0.010)\n",
            "Train: 20 [ 300/2354 ( 13%)]  Loss: 2.373 (2.13)  Time: 0.461s,   17.35/s  (0.475s,   16.85/s)  LR: 8.550e-05  Data: 0.007 (0.010)\n",
            "Train: 20 [ 350/2354 ( 15%)]  Loss: 1.533 (2.13)  Time: 0.464s,   17.26/s  (0.473s,   16.90/s)  LR: 8.550e-05  Data: 0.006 (0.009)\n",
            "Train: 20 [ 400/2354 ( 17%)]  Loss: 1.592 (2.13)  Time: 0.462s,   17.32/s  (0.472s,   16.94/s)  LR: 8.550e-05  Data: 0.007 (0.009)\n",
            "Train: 20 [ 450/2354 ( 19%)]  Loss: 1.684 (2.12)  Time: 0.464s,   17.26/s  (0.473s,   16.93/s)  LR: 8.550e-05  Data: 0.007 (0.009)\n",
            "Train: 20 [ 500/2354 ( 21%)]  Loss: 2.002 (2.14)  Time: 0.467s,   17.13/s  (0.472s,   16.96/s)  LR: 8.550e-05  Data: 0.008 (0.009)\n",
            "Train: 20 [ 550/2354 ( 23%)]  Loss: 1.706 (2.13)  Time: 0.464s,   17.23/s  (0.471s,   16.98/s)  LR: 8.550e-05  Data: 0.010 (0.009)\n",
            "Train: 20 [ 600/2354 ( 25%)]  Loss: 2.917 (2.13)  Time: 0.472s,   16.96/s  (0.471s,   17.00/s)  LR: 8.550e-05  Data: 0.010 (0.009)\n",
            "Train: 20 [ 650/2354 ( 28%)]  Loss: 2.600 (2.13)  Time: 0.471s,   16.99/s  (0.471s,   16.98/s)  LR: 8.550e-05  Data: 0.009 (0.009)\n",
            "Train: 20 [ 700/2354 ( 30%)]  Loss: 2.285 (2.14)  Time: 0.465s,   17.20/s  (0.471s,   16.99/s)  LR: 8.550e-05  Data: 0.010 (0.009)\n",
            "Train: 20 [ 750/2354 ( 32%)]  Loss: 2.766 (2.15)  Time: 0.461s,   17.34/s  (0.470s,   17.01/s)  LR: 8.550e-05  Data: 0.007 (0.009)\n",
            "Train: 20 [ 800/2354 ( 34%)]  Loss: 3.212 (2.16)  Time: 0.462s,   17.33/s  (0.471s,   16.98/s)  LR: 8.550e-05  Data: 0.010 (0.009)\n",
            "Train: 20 [ 850/2354 ( 36%)]  Loss: 1.599 (2.16)  Time: 0.460s,   17.39/s  (0.471s,   17.00/s)  LR: 8.550e-05  Data: 0.007 (0.009)\n",
            "Train: 20 [ 900/2354 ( 38%)]  Loss: 2.053 (2.15)  Time: 0.462s,   17.30/s  (0.470s,   17.01/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [ 950/2354 ( 40%)]  Loss: 2.280 (2.15)  Time: 0.459s,   17.42/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [1000/2354 ( 42%)]  Loss: 1.335 (2.15)  Time: 0.466s,   17.18/s  (0.470s,   17.01/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [1050/2354 ( 45%)]  Loss: 2.318 (2.15)  Time: 0.464s,   17.26/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [1100/2354 ( 47%)]  Loss: 2.447 (2.15)  Time: 0.466s,   17.16/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.011 (0.008)\n",
            "Train: 20 [1150/2354 ( 49%)]  Loss: 2.607 (2.15)  Time: 0.459s,   17.43/s  (0.470s,   17.00/s)  LR: 8.550e-05  Data: 0.006 (0.008)\n",
            "Train: 20 [1200/2354 ( 51%)]  Loss: 1.130 (2.15)  Time: 0.460s,   17.38/s  (0.470s,   17.01/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [1250/2354 ( 53%)]  Loss: 3.155 (2.14)  Time: 0.460s,   17.38/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.006 (0.008)\n",
            "Train: 20 [1300/2354 ( 55%)]  Loss: 1.232 (2.14)  Time: 0.459s,   17.42/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.006 (0.008)\n",
            "Train: 20 [1350/2354 ( 57%)]  Loss: 2.098 (2.15)  Time: 0.460s,   17.38/s  (0.470s,   17.01/s)  LR: 8.550e-05  Data: 0.006 (0.008)\n",
            "Train: 20 [1400/2354 ( 59%)]  Loss: 2.251 (2.15)  Time: 0.465s,   17.22/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.006 (0.008)\n",
            "Train: 20 [1450/2354 ( 62%)]  Loss: 1.415 (2.15)  Time: 0.473s,   16.93/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [1500/2354 ( 64%)]  Loss: 2.546 (2.15)  Time: 0.460s,   17.37/s  (0.470s,   17.01/s)  LR: 8.550e-05  Data: 0.010 (0.008)\n",
            "Train: 20 [1550/2354 ( 66%)]  Loss: 2.471 (2.15)  Time: 0.464s,   17.25/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.010 (0.008)\n",
            "Train: 20 [1600/2354 ( 68%)]  Loss: 3.153 (2.15)  Time: 0.461s,   17.35/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [1650/2354 ( 70%)]  Loss: 3.074 (2.16)  Time: 0.468s,   17.10/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [1700/2354 ( 72%)]  Loss: 2.715 (2.16)  Time: 0.471s,   17.00/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.011 (0.008)\n",
            "Train: 20 [1750/2354 ( 74%)]  Loss: 3.438 (2.16)  Time: 0.481s,   16.64/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [1800/2354 ( 76%)]  Loss: 1.627 (2.16)  Time: 0.461s,   17.34/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.006 (0.008)\n",
            "Train: 20 [1850/2354 ( 79%)]  Loss: 2.516 (2.16)  Time: 0.462s,   17.30/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.009 (0.008)\n",
            "Train: 20 [1900/2354 ( 81%)]  Loss: 2.557 (2.17)  Time: 0.463s,   17.28/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.009 (0.008)\n",
            "Train: 20 [1950/2354 ( 83%)]  Loss: 2.440 (2.17)  Time: 0.461s,   17.34/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [2000/2354 ( 85%)]  Loss: 2.521 (2.16)  Time: 0.463s,   17.28/s  (0.470s,   17.04/s)  LR: 8.550e-05  Data: 0.007 (0.008)\n",
            "Train: 20 [2050/2354 ( 87%)]  Loss: 3.471 (2.16)  Time: 0.470s,   17.03/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.006 (0.008)\n",
            "Train: 20 [2100/2354 ( 89%)]  Loss: 3.268 (2.16)  Time: 0.465s,   17.20/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.006 (0.008)\n",
            "Train: 20 [2150/2354 ( 91%)]  Loss: 3.016 (2.16)  Time: 0.465s,   17.21/s  (0.470s,   17.04/s)  LR: 8.550e-05  Data: 0.010 (0.008)\n",
            "Train: 20 [2200/2354 ( 93%)]  Loss: 1.687 (2.16)  Time: 0.530s,   15.08/s  (0.470s,   17.02/s)  LR: 8.550e-05  Data: 0.022 (0.008)\n",
            "Train: 20 [2250/2354 ( 96%)]  Loss: 1.246 (2.16)  Time: 0.463s,   17.29/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.010 (0.008)\n",
            "Train: 20 [2300/2354 ( 98%)]  Loss: 2.309 (2.16)  Time: 0.463s,   17.27/s  (0.470s,   17.03/s)  LR: 8.550e-05  Data: 0.010 (0.008)\n",
            "Train: 20 [2350/2354 (100%)]  Loss: 1.421 (2.16)  Time: 0.455s,   17.59/s  (0.470s,   17.04/s)  LR: 8.550e-05  Data: 0.005 (0.008)\n",
            "Train: 20 [2353/2354 (100%)]  Loss: 2.970 (2.16)  Time: 0.452s,   17.71/s  (0.469s,   17.04/s)  LR: 8.550e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.693 (0.693)  Loss:  0.5195 (0.5195)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.113 (0.153)  Loss:  0.6582 (0.4112)  Acc@1: 75.0000 (92.6471)  Acc@5: 100.0000 (99.5098)\n",
            "Test: [ 100/2354]  Time: 0.076 (0.163)  Loss:  1.2002 (0.4741)  Acc@1: 50.0000 (91.3366)  Acc@5: 100.0000 (99.2574)\n",
            "Test: [ 150/2354]  Time: 0.097 (0.155)  Loss:  0.2537 (0.4641)  Acc@1: 100.0000 (91.8874)  Acc@5: 100.0000 (99.3377)\n",
            "Test: [ 200/2354]  Time: 0.167 (0.151)  Loss:  1.2432 (0.4455)  Acc@1: 50.0000 (92.4129)  Acc@5: 100.0000 (99.5025)\n",
            "Test: [ 250/2354]  Time: 0.093 (0.148)  Loss:  0.0730 (0.4842)  Acc@1: 100.0000 (91.6335)  Acc@5: 100.0000 (99.4024)\n",
            "Test: [ 300/2354]  Time: 0.153 (0.146)  Loss:  1.4189 (0.4965)  Acc@1: 50.0000 (91.2791)  Acc@5: 100.0000 (99.2525)\n",
            "Test: [ 350/2354]  Time: 0.132 (0.144)  Loss:  0.6572 (0.5545)  Acc@1: 75.0000 (88.3191)  Acc@5: 100.0000 (99.3590)\n",
            "Test: [ 400/2354]  Time: 0.146 (0.144)  Loss:  0.6255 (0.5460)  Acc@1: 100.0000 (88.5287)  Acc@5: 100.0000 (99.3142)\n",
            "Test: [ 450/2354]  Time: 0.163 (0.143)  Loss:  0.1029 (0.5311)  Acc@1: 100.0000 (89.0798)  Acc@5: 100.0000 (99.3348)\n",
            "Test: [ 500/2354]  Time: 0.165 (0.143)  Loss:  0.4038 (0.5189)  Acc@1: 100.0000 (89.6707)  Acc@5: 100.0000 (99.3513)\n",
            "Test: [ 550/2354]  Time: 0.110 (0.142)  Loss:  1.7373 (0.5279)  Acc@1: 25.0000 (88.6116)  Acc@5: 75.0000 (99.2740)\n",
            "Test: [ 600/2354]  Time: 0.129 (0.142)  Loss:  0.3101 (0.5119)  Acc@1: 100.0000 (89.0183)  Acc@5: 100.0000 (99.2928)\n",
            "Test: [ 650/2354]  Time: 0.208 (0.142)  Loss:  0.7256 (0.5001)  Acc@1: 75.0000 (89.2089)  Acc@5: 100.0000 (99.3472)\n",
            "Test: [ 700/2354]  Time: 0.152 (0.144)  Loss:  0.0296 (0.4885)  Acc@1: 100.0000 (89.7290)  Acc@5: 100.0000 (99.3581)\n",
            "Test: [ 750/2354]  Time: 0.135 (0.144)  Loss:  0.7852 (0.4907)  Acc@1: 100.0000 (89.6804)  Acc@5: 100.0000 (99.2676)\n",
            "Test: [ 800/2354]  Time: 0.092 (0.144)  Loss:  0.0566 (0.5010)  Acc@1: 100.0000 (89.5755)  Acc@5: 100.0000 (99.2197)\n",
            "Test: [ 850/2354]  Time: 0.127 (0.143)  Loss:  0.1315 (0.5045)  Acc@1: 100.0000 (89.5711)  Acc@5: 100.0000 (99.1481)\n",
            "Test: [ 900/2354]  Time: 0.134 (0.143)  Loss:  0.7363 (0.4961)  Acc@1: 75.0000 (89.9834)  Acc@5: 100.0000 (99.1953)\n",
            "Test: [ 950/2354]  Time: 0.192 (0.142)  Loss:  0.2715 (0.4910)  Acc@1: 100.0000 (90.0631)  Acc@5: 100.0000 (99.1588)\n",
            "Test: [1000/2354]  Time: 0.130 (0.142)  Loss:  0.0738 (0.4868)  Acc@1: 100.0000 (90.2098)  Acc@5: 100.0000 (99.1508)\n",
            "Test: [1050/2354]  Time: 0.143 (0.142)  Loss:  0.4614 (0.4878)  Acc@1: 100.0000 (90.2474)  Acc@5: 100.0000 (99.1437)\n",
            "Test: [1100/2354]  Time: 0.178 (0.142)  Loss:  0.4207 (0.4895)  Acc@1: 100.0000 (90.2589)  Acc@5: 100.0000 (99.1599)\n",
            "Test: [1150/2354]  Time: 0.152 (0.141)  Loss:  1.5469 (0.4866)  Acc@1: 50.0000 (90.2259)  Acc@5: 100.0000 (99.1746)\n",
            "Test: [1200/2354]  Time: 0.118 (0.141)  Loss:  0.7383 (0.4868)  Acc@1: 75.0000 (90.0916)  Acc@5: 100.0000 (99.1674)\n",
            "Test: [1250/2354]  Time: 0.216 (0.142)  Loss:  0.0895 (0.4798)  Acc@1: 100.0000 (90.3477)  Acc@5: 100.0000 (99.1807)\n",
            "Test: [1300/2354]  Time: 0.170 (0.142)  Loss:  0.2462 (0.4772)  Acc@1: 100.0000 (90.5457)  Acc@5: 100.0000 (99.0968)\n",
            "Test: [1350/2354]  Time: 0.097 (0.142)  Loss:  0.0817 (0.4797)  Acc@1: 100.0000 (90.2665)  Acc@5: 100.0000 (99.1303)\n",
            "Test: [1400/2354]  Time: 0.132 (0.142)  Loss:  0.3137 (0.4780)  Acc@1: 100.0000 (90.3819)  Acc@5: 100.0000 (99.1256)\n",
            "Test: [1450/2354]  Time: 0.087 (0.142)  Loss:  0.4966 (0.4780)  Acc@1: 100.0000 (90.4376)  Acc@5: 100.0000 (99.1385)\n",
            "Test: [1500/2354]  Time: 0.089 (0.141)  Loss:  1.2783 (0.4790)  Acc@1: 50.0000 (90.3398)  Acc@5: 100.0000 (99.1339)\n",
            "Test: [1550/2354]  Time: 0.148 (0.141)  Loss:  0.5137 (0.4905)  Acc@1: 75.0000 (89.9420)  Acc@5: 100.0000 (99.1296)\n",
            "Test: [1600/2354]  Time: 0.112 (0.141)  Loss:  0.2433 (0.4996)  Acc@1: 100.0000 (89.7876)  Acc@5: 100.0000 (99.1099)\n",
            "Test: [1650/2354]  Time: 0.149 (0.141)  Loss:  0.3972 (0.5036)  Acc@1: 100.0000 (89.7032)  Acc@5: 100.0000 (99.0763)\n",
            "Test: [1700/2354]  Time: 0.123 (0.141)  Loss:  0.0474 (0.5064)  Acc@1: 100.0000 (89.6825)  Acc@5: 100.0000 (99.0594)\n",
            "Test: [1750/2354]  Time: 0.148 (0.141)  Loss:  0.3811 (0.5140)  Acc@1: 100.0000 (89.5346)  Acc@5: 100.0000 (99.0434)\n",
            "Test: [1800/2354]  Time: 0.106 (0.141)  Loss:  0.6367 (0.5153)  Acc@1: 75.0000 (89.6030)  Acc@5: 100.0000 (99.0422)\n",
            "Test: [1850/2354]  Time: 0.365 (0.142)  Loss:  0.3076 (0.5116)  Acc@1: 100.0000 (89.6813)  Acc@5: 100.0000 (99.0546)\n",
            "Test: [1900/2354]  Time: 0.179 (0.142)  Loss:  0.7085 (0.5091)  Acc@1: 75.0000 (89.7554)  Acc@5: 100.0000 (99.0663)\n",
            "Test: [1950/2354]  Time: 0.162 (0.142)  Loss:  0.2576 (0.5080)  Acc@1: 100.0000 (89.8385)  Acc@5: 100.0000 (99.0774)\n",
            "Test: [2000/2354]  Time: 0.147 (0.142)  Loss:  0.1498 (0.5067)  Acc@1: 100.0000 (89.9550)  Acc@5: 100.0000 (99.0880)\n",
            "Test: [2050/2354]  Time: 0.180 (0.141)  Loss:  0.6245 (0.5157)  Acc@1: 100.0000 (89.5783)  Acc@5: 100.0000 (99.0492)\n",
            "Test: [2100/2354]  Time: 0.092 (0.141)  Loss:  0.9604 (0.5232)  Acc@1: 75.0000 (89.2789)  Acc@5: 100.0000 (99.0600)\n",
            "Test: [2150/2354]  Time: 0.146 (0.141)  Loss:  0.8633 (0.5256)  Acc@1: 100.0000 (89.2957)  Acc@5: 100.0000 (99.0818)\n",
            "Test: [2200/2354]  Time: 0.121 (0.141)  Loss:  0.2255 (0.5374)  Acc@1: 100.0000 (88.8119)  Acc@5: 100.0000 (99.0232)\n",
            "Test: [2250/2354]  Time: 0.104 (0.141)  Loss:  0.0970 (0.5345)  Acc@1: 100.0000 (88.9382)  Acc@5: 100.0000 (99.0227)\n",
            "Test: [2300/2354]  Time: 0.113 (0.141)  Loss:  0.0461 (0.5302)  Acc@1: 100.0000 (89.0591)  Acc@5: 100.0000 (99.0222)\n",
            "Test: [2350/2354]  Time: 0.075 (0.141)  Loss:  0.5010 (0.5296)  Acc@1: 75.0000 (88.9834)  Acc@5: 100.0000 (99.0430)\n",
            "Test: [2354/2354]  Time: 0.065 (0.141)  Loss:  0.1731 (0.5296)  Acc@1: 100.0000 (88.9903)  Acc@5: 100.0000 (99.0445)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-10.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar', 74.48773755337709)\n",
            "\n",
            "Train: 21 [   0/2354 (  0%)]  Loss: 1.536 (1.54)  Time: 1.272s,    6.29/s  (1.272s,    6.29/s)  LR: 8.410e-05  Data: 0.432 (0.432)\n",
            "Train: 21 [  50/2354 (  2%)]  Loss: 1.832 (2.03)  Time: 0.464s,   17.25/s  (0.520s,   15.38/s)  LR: 8.410e-05  Data: 0.007 (0.017)\n",
            "Train: 21 [ 100/2354 (  4%)]  Loss: 2.045 (2.06)  Time: 0.460s,   17.38/s  (0.493s,   16.22/s)  LR: 8.410e-05  Data: 0.006 (0.012)\n",
            "Train: 21 [ 150/2354 (  6%)]  Loss: 2.128 (2.08)  Time: 0.465s,   17.21/s  (0.484s,   16.54/s)  LR: 8.410e-05  Data: 0.006 (0.011)\n",
            "Train: 21 [ 200/2354 (  8%)]  Loss: 1.383 (2.06)  Time: 0.467s,   17.14/s  (0.483s,   16.55/s)  LR: 8.410e-05  Data: 0.010 (0.010)\n",
            "Train: 21 [ 250/2354 ( 11%)]  Loss: 2.687 (2.09)  Time: 0.471s,   16.99/s  (0.480s,   16.67/s)  LR: 8.410e-05  Data: 0.009 (0.010)\n",
            "Train: 21 [ 300/2354 ( 13%)]  Loss: 1.818 (2.08)  Time: 0.462s,   17.31/s  (0.477s,   16.76/s)  LR: 8.410e-05  Data: 0.008 (0.009)\n",
            "Train: 21 [ 350/2354 ( 15%)]  Loss: 1.162 (2.09)  Time: 0.460s,   17.37/s  (0.475s,   16.83/s)  LR: 8.410e-05  Data: 0.007 (0.009)\n",
            "Train: 21 [ 400/2354 ( 17%)]  Loss: 1.774 (2.08)  Time: 0.470s,   17.01/s  (0.476s,   16.80/s)  LR: 8.410e-05  Data: 0.013 (0.009)\n",
            "Train: 21 [ 450/2354 ( 19%)]  Loss: 1.356 (2.08)  Time: 0.472s,   16.94/s  (0.475s,   16.84/s)  LR: 8.410e-05  Data: 0.006 (0.009)\n",
            "Train: 21 [ 500/2354 ( 21%)]  Loss: 1.172 (2.08)  Time: 0.469s,   17.07/s  (0.474s,   16.88/s)  LR: 8.410e-05  Data: 0.010 (0.009)\n",
            "Train: 21 [ 550/2354 ( 23%)]  Loss: 3.301 (2.09)  Time: 0.515s,   15.53/s  (0.473s,   16.90/s)  LR: 8.410e-05  Data: 0.007 (0.009)\n",
            "Train: 21 [ 600/2354 ( 25%)]  Loss: 2.459 (2.10)  Time: 0.474s,   16.87/s  (0.474s,   16.88/s)  LR: 8.410e-05  Data: 0.006 (0.009)\n",
            "Train: 21 [ 650/2354 ( 28%)]  Loss: 2.217 (2.09)  Time: 0.464s,   17.24/s  (0.473s,   16.91/s)  LR: 8.410e-05  Data: 0.011 (0.009)\n",
            "Train: 21 [ 700/2354 ( 30%)]  Loss: 1.421 (2.10)  Time: 0.461s,   17.36/s  (0.473s,   16.93/s)  LR: 8.410e-05  Data: 0.006 (0.008)\n",
            "Train: 21 [ 750/2354 ( 32%)]  Loss: 1.838 (2.09)  Time: 0.465s,   17.20/s  (0.473s,   16.91/s)  LR: 8.410e-05  Data: 0.010 (0.008)\n",
            "Train: 21 [ 800/2354 ( 34%)]  Loss: 2.443 (2.10)  Time: 0.465s,   17.22/s  (0.473s,   16.93/s)  LR: 8.410e-05  Data: 0.008 (0.008)\n",
            "Train: 21 [ 850/2354 ( 36%)]  Loss: 2.453 (2.10)  Time: 0.471s,   16.99/s  (0.472s,   16.94/s)  LR: 8.410e-05  Data: 0.013 (0.008)\n",
            "Train: 21 [ 900/2354 ( 38%)]  Loss: 2.165 (2.10)  Time: 0.463s,   17.27/s  (0.472s,   16.95/s)  LR: 8.410e-05  Data: 0.010 (0.008)\n",
            "Train: 21 [ 950/2354 ( 40%)]  Loss: 3.641 (2.10)  Time: 0.463s,   17.28/s  (0.472s,   16.94/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1000/2354 ( 42%)]  Loss: 1.384 (2.10)  Time: 0.480s,   16.67/s  (0.472s,   16.95/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1050/2354 ( 45%)]  Loss: 2.649 (2.10)  Time: 0.461s,   17.34/s  (0.472s,   16.96/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1100/2354 ( 47%)]  Loss: 2.075 (2.10)  Time: 0.482s,   16.61/s  (0.472s,   16.95/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1150/2354 ( 49%)]  Loss: 2.088 (2.10)  Time: 0.462s,   17.30/s  (0.472s,   16.96/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1200/2354 ( 51%)]  Loss: 2.524 (2.11)  Time: 0.466s,   17.16/s  (0.471s,   16.97/s)  LR: 8.410e-05  Data: 0.010 (0.008)\n",
            "Train: 21 [1250/2354 ( 53%)]  Loss: 2.039 (2.10)  Time: 0.464s,   17.24/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.009 (0.008)\n",
            "Train: 21 [1300/2354 ( 55%)]  Loss: 1.662 (2.10)  Time: 0.462s,   17.30/s  (0.472s,   16.96/s)  LR: 8.410e-05  Data: 0.006 (0.008)\n",
            "Train: 21 [1350/2354 ( 57%)]  Loss: 1.422 (2.10)  Time: 0.470s,   17.02/s  (0.471s,   16.97/s)  LR: 8.410e-05  Data: 0.008 (0.008)\n",
            "Train: 21 [1400/2354 ( 59%)]  Loss: 1.730 (2.10)  Time: 0.459s,   17.42/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1450/2354 ( 62%)]  Loss: 2.923 (2.10)  Time: 0.487s,   16.44/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.009 (0.008)\n",
            "Train: 21 [1500/2354 ( 64%)]  Loss: 2.183 (2.10)  Time: 0.461s,   17.34/s  (0.471s,   16.97/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1550/2354 ( 66%)]  Loss: 1.571 (2.10)  Time: 0.462s,   17.31/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.006 (0.008)\n",
            "Train: 21 [1600/2354 ( 68%)]  Loss: 2.258 (2.10)  Time: 0.471s,   16.99/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1650/2354 ( 70%)]  Loss: 2.259 (2.11)  Time: 0.469s,   17.07/s  (0.471s,   16.97/s)  LR: 8.410e-05  Data: 0.009 (0.008)\n",
            "Train: 21 [1700/2354 ( 72%)]  Loss: 1.729 (2.11)  Time: 0.471s,   16.97/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1750/2354 ( 74%)]  Loss: 2.847 (2.11)  Time: 0.460s,   17.40/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.006 (0.008)\n",
            "Train: 21 [1800/2354 ( 76%)]  Loss: 1.631 (2.11)  Time: 0.470s,   17.02/s  (0.471s,   16.99/s)  LR: 8.410e-05  Data: 0.009 (0.008)\n",
            "Train: 21 [1850/2354 ( 79%)]  Loss: 1.871 (2.11)  Time: 0.465s,   17.21/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.009 (0.008)\n",
            "Train: 21 [1900/2354 ( 81%)]  Loss: 2.332 (2.11)  Time: 0.466s,   17.18/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [1950/2354 ( 83%)]  Loss: 2.210 (2.11)  Time: 0.474s,   16.86/s  (0.471s,   16.99/s)  LR: 8.410e-05  Data: 0.009 (0.008)\n",
            "Train: 21 [2000/2354 ( 85%)]  Loss: 2.376 (2.11)  Time: 0.577s,   13.87/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.017 (0.008)\n",
            "Train: 21 [2050/2354 ( 87%)]  Loss: 2.526 (2.11)  Time: 0.469s,   17.06/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.007 (0.008)\n",
            "Train: 21 [2100/2354 ( 89%)]  Loss: 1.421 (2.11)  Time: 0.462s,   17.30/s  (0.471s,   16.99/s)  LR: 8.410e-05  Data: 0.010 (0.008)\n",
            "Train: 21 [2150/2354 ( 91%)]  Loss: 1.913 (2.12)  Time: 0.467s,   17.13/s  (0.471s,   16.99/s)  LR: 8.410e-05  Data: 0.011 (0.008)\n",
            "Train: 21 [2200/2354 ( 93%)]  Loss: 2.236 (2.12)  Time: 0.464s,   17.24/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.009 (0.008)\n",
            "Train: 21 [2250/2354 ( 96%)]  Loss: 2.735 (2.12)  Time: 0.472s,   16.95/s  (0.471s,   16.98/s)  LR: 8.410e-05  Data: 0.013 (0.008)\n",
            "Train: 21 [2300/2354 ( 98%)]  Loss: 3.290 (2.12)  Time: 0.461s,   17.34/s  (0.471s,   16.99/s)  LR: 8.410e-05  Data: 0.006 (0.008)\n",
            "Train: 21 [2350/2354 (100%)]  Loss: 1.265 (2.12)  Time: 0.459s,   17.44/s  (0.471s,   16.99/s)  LR: 8.410e-05  Data: 0.005 (0.008)\n",
            "Train: 21 [2353/2354 (100%)]  Loss: 2.909 (2.12)  Time: 0.456s,   17.56/s  (0.471s,   16.99/s)  LR: 8.410e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.603 (0.603)  Loss:  0.2549 (0.2549)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.144 (0.190)  Loss:  1.6592 (0.5417)  Acc@1: 50.0000 (93.1373)  Acc@5: 100.0000 (99.5098)\n",
            "Test: [ 100/2354]  Time: 0.111 (0.164)  Loss:  0.6626 (0.6096)  Acc@1: 100.0000 (90.5941)  Acc@5: 100.0000 (99.5050)\n",
            "Test: [ 150/2354]  Time: 0.138 (0.156)  Loss:  1.0840 (0.5792)  Acc@1: 50.0000 (90.0662)  Acc@5: 100.0000 (99.6689)\n",
            "Test: [ 200/2354]  Time: 0.100 (0.151)  Loss:  0.8398 (0.5577)  Acc@1: 75.0000 (89.8010)  Acc@5: 100.0000 (99.7512)\n",
            "Test: [ 250/2354]  Time: 0.102 (0.149)  Loss:  0.3477 (0.5687)  Acc@1: 100.0000 (89.7410)  Acc@5: 100.0000 (99.8008)\n",
            "Test: [ 300/2354]  Time: 0.133 (0.148)  Loss:  1.2119 (0.5747)  Acc@1: 75.0000 (89.5349)  Acc@5: 100.0000 (99.5847)\n",
            "Test: [ 350/2354]  Time: 0.081 (0.146)  Loss:  0.6528 (0.6136)  Acc@1: 75.0000 (88.0342)  Acc@5: 100.0000 (99.5726)\n",
            "Test: [ 400/2354]  Time: 0.157 (0.145)  Loss:  0.1718 (0.6114)  Acc@1: 100.0000 (88.0923)  Acc@5: 100.0000 (99.5636)\n",
            "Test: [ 450/2354]  Time: 0.083 (0.145)  Loss:  0.1750 (0.5789)  Acc@1: 100.0000 (88.9690)  Acc@5: 100.0000 (99.5565)\n",
            "Test: [ 500/2354]  Time: 0.193 (0.144)  Loss:  1.5186 (0.5752)  Acc@1: 25.0000 (88.4731)  Acc@5: 100.0000 (99.5509)\n",
            "Test: [ 550/2354]  Time: 0.183 (0.144)  Loss:  1.3672 (0.5760)  Acc@1: 75.0000 (88.4301)  Acc@5: 100.0000 (99.5917)\n",
            "Test: [ 600/2354]  Time: 0.242 (0.144)  Loss:  0.3684 (0.5667)  Acc@1: 100.0000 (89.0183)  Acc@5: 100.0000 (99.6256)\n",
            "Test: [ 650/2354]  Time: 0.170 (0.146)  Loss:  0.2017 (0.5505)  Acc@1: 100.0000 (89.5929)  Acc@5: 100.0000 (99.6160)\n",
            "Test: [ 700/2354]  Time: 0.125 (0.146)  Loss:  0.0514 (0.5336)  Acc@1: 100.0000 (90.1926)  Acc@5: 100.0000 (99.6077)\n",
            "Test: [ 750/2354]  Time: 0.081 (0.145)  Loss:  0.5332 (0.5236)  Acc@1: 100.0000 (90.5459)  Acc@5: 100.0000 (99.6005)\n",
            "Test: [ 800/2354]  Time: 0.202 (0.145)  Loss:  0.3787 (0.5294)  Acc@1: 100.0000 (90.2622)  Acc@5: 100.0000 (99.5630)\n",
            "Test: [ 850/2354]  Time: 0.120 (0.145)  Loss:  0.1666 (0.5278)  Acc@1: 100.0000 (90.3643)  Acc@5: 100.0000 (99.5593)\n",
            "Test: [ 900/2354]  Time: 0.098 (0.145)  Loss:  1.0098 (0.5200)  Acc@1: 75.0000 (90.7048)  Acc@5: 100.0000 (99.5560)\n",
            "Test: [ 950/2354]  Time: 0.082 (0.145)  Loss:  0.2712 (0.5110)  Acc@1: 100.0000 (91.0095)  Acc@5: 100.0000 (99.5531)\n",
            "Test: [1000/2354]  Time: 0.095 (0.144)  Loss:  0.0347 (0.5073)  Acc@1: 100.0000 (91.1588)  Acc@5: 100.0000 (99.5754)\n",
            "Test: [1050/2354]  Time: 0.173 (0.144)  Loss:  0.3499 (0.5038)  Acc@1: 100.0000 (91.1513)  Acc@5: 100.0000 (99.5956)\n",
            "Test: [1100/2354]  Time: 0.095 (0.144)  Loss:  0.6919 (0.5054)  Acc@1: 100.0000 (91.1444)  Acc@5: 100.0000 (99.5913)\n",
            "Test: [1150/2354]  Time: 0.081 (0.144)  Loss:  1.4785 (0.5022)  Acc@1: 50.0000 (91.2685)  Acc@5: 100.0000 (99.5873)\n",
            "Test: [1200/2354]  Time: 0.225 (0.144)  Loss:  1.2842 (0.5024)  Acc@1: 75.0000 (91.1740)  Acc@5: 75.0000 (99.5837)\n",
            "Test: [1250/2354]  Time: 0.105 (0.145)  Loss:  0.1772 (0.4989)  Acc@1: 100.0000 (91.2870)  Acc@5: 100.0000 (99.5803)\n",
            "Test: [1300/2354]  Time: 0.177 (0.145)  Loss:  0.2156 (0.5038)  Acc@1: 100.0000 (90.8148)  Acc@5: 100.0000 (99.5196)\n",
            "Test: [1350/2354]  Time: 0.152 (0.145)  Loss:  0.0916 (0.4988)  Acc@1: 100.0000 (91.0067)  Acc@5: 100.0000 (99.5374)\n",
            "Test: [1400/2354]  Time: 0.172 (0.144)  Loss:  0.4946 (0.4995)  Acc@1: 100.0000 (91.0064)  Acc@5: 100.0000 (99.5004)\n",
            "Test: [1450/2354]  Time: 0.107 (0.144)  Loss:  0.7109 (0.4974)  Acc@1: 100.0000 (91.1613)  Acc@5: 100.0000 (99.5003)\n",
            "Test: [1500/2354]  Time: 0.185 (0.144)  Loss:  0.1395 (0.4951)  Acc@1: 100.0000 (91.2059)  Acc@5: 100.0000 (99.4837)\n",
            "Test: [1550/2354]  Time: 0.176 (0.144)  Loss:  0.1232 (0.5082)  Acc@1: 100.0000 (90.8930)  Acc@5: 100.0000 (99.4520)\n",
            "Test: [1600/2354]  Time: 0.148 (0.144)  Loss:  0.1576 (0.5207)  Acc@1: 100.0000 (90.4122)  Acc@5: 100.0000 (99.3754)\n",
            "Test: [1650/2354]  Time: 0.101 (0.144)  Loss:  0.5312 (0.5225)  Acc@1: 100.0000 (90.4452)  Acc@5: 100.0000 (99.3792)\n",
            "Test: [1700/2354]  Time: 0.174 (0.143)  Loss:  0.0733 (0.5227)  Acc@1: 100.0000 (90.5497)  Acc@5: 100.0000 (99.3533)\n",
            "Test: [1750/2354]  Time: 0.136 (0.143)  Loss:  1.0312 (0.5359)  Acc@1: 75.0000 (89.9343)  Acc@5: 100.0000 (99.3718)\n",
            "Test: [1800/2354]  Time: 0.240 (0.144)  Loss:  0.5088 (0.5420)  Acc@1: 100.0000 (89.8251)  Acc@5: 100.0000 (99.3476)\n",
            "Test: [1850/2354]  Time: 0.098 (0.144)  Loss:  0.4124 (0.5392)  Acc@1: 100.0000 (89.9379)  Acc@5: 100.0000 (99.3517)\n",
            "Test: [1900/2354]  Time: 0.092 (0.144)  Loss:  1.0273 (0.5371)  Acc@1: 75.0000 (89.9658)  Acc@5: 75.0000 (99.3425)\n",
            "Test: [1950/2354]  Time: 0.179 (0.144)  Loss:  0.1061 (0.5384)  Acc@1: 100.0000 (90.0051)  Acc@5: 100.0000 (99.3465)\n",
            "Test: [2000/2354]  Time: 0.141 (0.144)  Loss:  0.1309 (0.5351)  Acc@1: 100.0000 (90.1174)  Acc@5: 100.0000 (99.3503)\n",
            "Test: [2050/2354]  Time: 0.177 (0.144)  Loss:  1.1768 (0.5411)  Acc@1: 75.0000 (89.9074)  Acc@5: 100.0000 (99.3296)\n",
            "Test: [2100/2354]  Time: 0.080 (0.144)  Loss:  1.8184 (0.5424)  Acc@1:  0.0000 (89.8025)  Acc@5: 100.0000 (99.3337)\n",
            "Test: [2150/2354]  Time: 0.130 (0.144)  Loss:  0.6519 (0.5515)  Acc@1: 100.0000 (89.4584)  Acc@5: 100.0000 (99.3375)\n",
            "Test: [2200/2354]  Time: 0.151 (0.143)  Loss:  0.9805 (0.5643)  Acc@1: 100.0000 (88.8233)  Acc@5: 100.0000 (99.3299)\n",
            "Test: [2250/2354]  Time: 0.137 (0.143)  Loss:  0.0743 (0.5619)  Acc@1: 100.0000 (88.8938)  Acc@5: 100.0000 (99.3225)\n",
            "Test: [2300/2354]  Time: 0.145 (0.143)  Loss:  0.0903 (0.5582)  Acc@1: 100.0000 (88.9613)  Acc@5: 100.0000 (99.3264)\n",
            "Test: [2350/2354]  Time: 0.075 (0.143)  Loss:  0.3184 (0.5567)  Acc@1: 100.0000 (88.9515)  Acc@5: 100.0000 (99.3301)\n",
            "Test: [2354/2354]  Time: 0.068 (0.143)  Loss:  0.1084 (0.5563)  Acc@1: 100.0000 (88.9585)  Acc@5: 100.0000 (99.3311)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-11.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar', 76.388151610071)\n",
            "\n",
            "Train: 22 [   0/2354 (  0%)]  Loss: 1.983 (1.98)  Time: 1.303s,    6.14/s  (1.303s,    6.14/s)  LR: 8.265e-05  Data: 0.553 (0.553)\n",
            "Train: 22 [  50/2354 (  2%)]  Loss: 2.099 (1.84)  Time: 0.462s,   17.31/s  (0.519s,   15.41/s)  LR: 8.265e-05  Data: 0.007 (0.019)\n",
            "Train: 22 [ 100/2354 (  4%)]  Loss: 1.450 (2.03)  Time: 0.465s,   17.20/s  (0.493s,   16.21/s)  LR: 8.265e-05  Data: 0.010 (0.013)\n",
            "Train: 22 [ 150/2354 (  6%)]  Loss: 2.152 (2.05)  Time: 0.468s,   17.10/s  (0.485s,   16.50/s)  LR: 8.265e-05  Data: 0.007 (0.012)\n",
            "Train: 22 [ 200/2354 (  8%)]  Loss: 2.596 (2.07)  Time: 0.473s,   16.92/s  (0.486s,   16.47/s)  LR: 8.265e-05  Data: 0.007 (0.011)\n",
            "Train: 22 [ 250/2354 ( 11%)]  Loss: 1.583 (2.10)  Time: 0.463s,   17.29/s  (0.482s,   16.61/s)  LR: 8.265e-05  Data: 0.009 (0.010)\n",
            "Train: 22 [ 300/2354 ( 13%)]  Loss: 3.632 (2.10)  Time: 0.471s,   16.99/s  (0.479s,   16.70/s)  LR: 8.265e-05  Data: 0.009 (0.010)\n",
            "Train: 22 [ 350/2354 ( 15%)]  Loss: 3.185 (2.09)  Time: 0.471s,   17.00/s  (0.477s,   16.76/s)  LR: 8.265e-05  Data: 0.007 (0.009)\n",
            "Train: 22 [ 400/2354 ( 17%)]  Loss: 2.221 (2.08)  Time: 0.465s,   17.20/s  (0.478s,   16.74/s)  LR: 8.265e-05  Data: 0.009 (0.009)\n",
            "Train: 22 [ 450/2354 ( 19%)]  Loss: 2.502 (2.07)  Time: 0.475s,   16.86/s  (0.477s,   16.78/s)  LR: 8.265e-05  Data: 0.009 (0.009)\n",
            "Train: 22 [ 500/2354 ( 21%)]  Loss: 1.878 (2.05)  Time: 0.467s,   17.15/s  (0.476s,   16.82/s)  LR: 8.265e-05  Data: 0.007 (0.009)\n",
            "Train: 22 [ 550/2354 ( 23%)]  Loss: 1.641 (2.06)  Time: 0.460s,   17.37/s  (0.475s,   16.85/s)  LR: 8.265e-05  Data: 0.007 (0.009)\n",
            "Train: 22 [ 600/2354 ( 25%)]  Loss: 2.046 (2.06)  Time: 0.459s,   17.41/s  (0.475s,   16.82/s)  LR: 8.265e-05  Data: 0.007 (0.009)\n",
            "Train: 22 [ 650/2354 ( 28%)]  Loss: 2.182 (2.06)  Time: 0.467s,   17.12/s  (0.475s,   16.85/s)  LR: 8.265e-05  Data: 0.006 (0.009)\n",
            "Train: 22 [ 700/2354 ( 30%)]  Loss: 2.130 (2.06)  Time: 0.463s,   17.28/s  (0.474s,   16.87/s)  LR: 8.265e-05  Data: 0.009 (0.009)\n",
            "Train: 22 [ 750/2354 ( 32%)]  Loss: 2.258 (2.08)  Time: 0.460s,   17.38/s  (0.475s,   16.85/s)  LR: 8.265e-05  Data: 0.007 (0.009)\n",
            "Train: 22 [ 800/2354 ( 34%)]  Loss: 1.256 (2.07)  Time: 0.464s,   17.24/s  (0.474s,   16.88/s)  LR: 8.265e-05  Data: 0.009 (0.009)\n",
            "Train: 22 [ 850/2354 ( 36%)]  Loss: 1.671 (2.07)  Time: 0.464s,   17.24/s  (0.474s,   16.89/s)  LR: 8.265e-05  Data: 0.007 (0.009)\n",
            "Train: 22 [ 900/2354 ( 38%)]  Loss: 1.838 (2.08)  Time: 0.460s,   17.41/s  (0.473s,   16.91/s)  LR: 8.265e-05  Data: 0.006 (0.009)\n",
            "Train: 22 [ 950/2354 ( 40%)]  Loss: 2.328 (2.08)  Time: 0.479s,   16.71/s  (0.474s,   16.88/s)  LR: 8.265e-05  Data: 0.009 (0.009)\n",
            "Train: 22 [1000/2354 ( 42%)]  Loss: 3.407 (2.09)  Time: 0.467s,   17.14/s  (0.473s,   16.90/s)  LR: 8.265e-05  Data: 0.006 (0.009)\n",
            "Train: 22 [1050/2354 ( 45%)]  Loss: 1.675 (2.09)  Time: 0.467s,   17.12/s  (0.473s,   16.91/s)  LR: 8.265e-05  Data: 0.010 (0.008)\n",
            "Train: 22 [1100/2354 ( 47%)]  Loss: 2.130 (2.09)  Time: 0.519s,   15.40/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.011 (0.008)\n",
            "Train: 22 [1150/2354 ( 49%)]  Loss: 2.825 (2.10)  Time: 0.463s,   17.29/s  (0.473s,   16.90/s)  LR: 8.265e-05  Data: 0.006 (0.008)\n",
            "Train: 22 [1200/2354 ( 51%)]  Loss: 2.152 (2.10)  Time: 0.461s,   17.36/s  (0.473s,   16.91/s)  LR: 8.265e-05  Data: 0.006 (0.008)\n",
            "Train: 22 [1250/2354 ( 53%)]  Loss: 1.228 (2.10)  Time: 0.465s,   17.22/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.010 (0.008)\n",
            "Train: 22 [1300/2354 ( 55%)]  Loss: 1.481 (2.10)  Time: 0.463s,   17.28/s  (0.473s,   16.90/s)  LR: 8.265e-05  Data: 0.010 (0.008)\n",
            "Train: 22 [1350/2354 ( 57%)]  Loss: 1.961 (2.10)  Time: 0.476s,   16.82/s  (0.473s,   16.91/s)  LR: 8.265e-05  Data: 0.009 (0.008)\n",
            "Train: 22 [1400/2354 ( 59%)]  Loss: 1.763 (2.10)  Time: 0.465s,   17.19/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.008 (0.008)\n",
            "Train: 22 [1450/2354 ( 62%)]  Loss: 1.640 (2.10)  Time: 0.463s,   17.28/s  (0.473s,   16.93/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [1500/2354 ( 64%)]  Loss: 1.729 (2.10)  Time: 0.465s,   17.21/s  (0.473s,   16.91/s)  LR: 8.265e-05  Data: 0.006 (0.008)\n",
            "Train: 22 [1550/2354 ( 66%)]  Loss: 1.770 (2.10)  Time: 0.470s,   17.02/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [1600/2354 ( 68%)]  Loss: 1.546 (2.10)  Time: 0.465s,   17.22/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.009 (0.008)\n",
            "Train: 22 [1650/2354 ( 70%)]  Loss: 1.389 (2.10)  Time: 0.463s,   17.28/s  (0.473s,   16.93/s)  LR: 8.265e-05  Data: 0.006 (0.008)\n",
            "Train: 22 [1700/2354 ( 72%)]  Loss: 1.900 (2.10)  Time: 0.468s,   17.08/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.010 (0.008)\n",
            "Train: 22 [1750/2354 ( 74%)]  Loss: 2.779 (2.10)  Time: 0.464s,   17.24/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.008 (0.008)\n",
            "Train: 22 [1800/2354 ( 76%)]  Loss: 1.989 (2.10)  Time: 0.479s,   16.71/s  (0.473s,   16.93/s)  LR: 8.265e-05  Data: 0.010 (0.008)\n",
            "Train: 22 [1850/2354 ( 79%)]  Loss: 2.246 (2.09)  Time: 0.463s,   17.28/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [1900/2354 ( 81%)]  Loss: 1.617 (2.09)  Time: 0.465s,   17.20/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.008 (0.008)\n",
            "Train: 22 [1950/2354 ( 83%)]  Loss: 2.713 (2.09)  Time: 0.473s,   16.90/s  (0.473s,   16.93/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [2000/2354 ( 85%)]  Loss: 2.003 (2.09)  Time: 0.462s,   17.31/s  (0.472s,   16.93/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [2050/2354 ( 87%)]  Loss: 3.254 (2.09)  Time: 0.468s,   17.10/s  (0.473s,   16.92/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [2100/2354 ( 89%)]  Loss: 3.423 (2.09)  Time: 0.464s,   17.24/s  (0.473s,   16.93/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [2150/2354 ( 91%)]  Loss: 2.145 (2.09)  Time: 0.463s,   17.28/s  (0.472s,   16.93/s)  LR: 8.265e-05  Data: 0.008 (0.008)\n",
            "Train: 22 [2200/2354 ( 93%)]  Loss: 1.915 (2.09)  Time: 0.467s,   17.12/s  (0.472s,   16.94/s)  LR: 8.265e-05  Data: 0.010 (0.008)\n",
            "Train: 22 [2250/2354 ( 96%)]  Loss: 1.737 (2.10)  Time: 0.463s,   17.28/s  (0.473s,   16.93/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [2300/2354 ( 98%)]  Loss: 3.520 (2.09)  Time: 0.460s,   17.38/s  (0.472s,   16.93/s)  LR: 8.265e-05  Data: 0.007 (0.008)\n",
            "Train: 22 [2350/2354 (100%)]  Loss: 3.073 (2.10)  Time: 0.464s,   17.24/s  (0.472s,   16.94/s)  LR: 8.265e-05  Data: 0.005 (0.008)\n",
            "Train: 22 [2353/2354 (100%)]  Loss: 2.176 (2.10)  Time: 0.451s,   17.73/s  (0.472s,   16.94/s)  LR: 8.265e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.717 (0.717)  Loss:  0.0525 (0.0525)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.140 (0.157)  Loss:  1.1357 (0.5253)  Acc@1: 75.0000 (91.1765)  Acc@5: 75.0000 (99.5098)\n",
            "Test: [ 100/2354]  Time: 0.142 (0.148)  Loss:  0.8760 (0.6808)  Acc@1: 50.0000 (89.3564)  Acc@5: 100.0000 (99.5050)\n",
            "Test: [ 150/2354]  Time: 0.147 (0.157)  Loss:  0.6118 (0.6602)  Acc@1: 75.0000 (87.5828)  Acc@5: 100.0000 (99.6689)\n",
            "Test: [ 200/2354]  Time: 0.176 (0.152)  Loss:  2.0391 (0.6451)  Acc@1:  0.0000 (87.5622)  Acc@5: 100.0000 (99.6269)\n",
            "Test: [ 250/2354]  Time: 0.132 (0.150)  Loss:  0.1801 (0.6202)  Acc@1: 100.0000 (87.9482)  Acc@5: 100.0000 (99.7012)\n",
            "Test: [ 300/2354]  Time: 0.148 (0.149)  Loss:  1.0156 (0.6329)  Acc@1: 75.0000 (87.1262)  Acc@5: 100.0000 (99.5847)\n",
            "Test: [ 350/2354]  Time: 0.130 (0.147)  Loss:  0.8721 (0.6343)  Acc@1: 50.0000 (86.6809)  Acc@5: 100.0000 (99.6439)\n",
            "Test: [ 400/2354]  Time: 0.106 (0.145)  Loss:  0.1781 (0.6415)  Acc@1: 100.0000 (86.7830)  Acc@5: 100.0000 (99.5012)\n",
            "Test: [ 450/2354]  Time: 0.116 (0.144)  Loss:  0.0903 (0.6151)  Acc@1: 100.0000 (87.6386)  Acc@5: 100.0000 (99.5565)\n",
            "Test: [ 500/2354]  Time: 0.167 (0.144)  Loss:  0.6904 (0.5919)  Acc@1: 100.0000 (88.4232)  Acc@5: 100.0000 (99.5509)\n",
            "Test: [ 550/2354]  Time: 0.082 (0.144)  Loss:  1.6338 (0.5889)  Acc@1: 50.0000 (88.6570)  Acc@5: 75.0000 (99.5009)\n",
            "Test: [ 600/2354]  Time: 0.148 (0.143)  Loss:  0.2512 (0.5803)  Acc@1: 100.0000 (88.7687)  Acc@5: 100.0000 (99.5008)\n",
            "Test: [ 650/2354]  Time: 0.171 (0.143)  Loss:  0.2067 (0.5570)  Acc@1: 100.0000 (89.4777)  Acc@5: 100.0000 (99.5008)\n",
            "Test: [ 700/2354]  Time: 0.166 (0.142)  Loss:  0.0626 (0.5411)  Acc@1: 100.0000 (89.8359)  Acc@5: 100.0000 (99.4650)\n",
            "Test: [ 750/2354]  Time: 0.300 (0.144)  Loss:  1.3154 (0.5600)  Acc@1: 50.0000 (88.9814)  Acc@5: 100.0000 (99.4008)\n",
            "Test: [ 800/2354]  Time: 0.080 (0.144)  Loss:  0.2659 (0.5607)  Acc@1: 100.0000 (88.9825)  Acc@5: 100.0000 (99.4382)\n",
            "Test: [ 850/2354]  Time: 0.180 (0.144)  Loss:  0.1714 (0.5574)  Acc@1: 100.0000 (89.0423)  Acc@5: 100.0000 (99.4418)\n",
            "Test: [ 900/2354]  Time: 0.163 (0.144)  Loss:  0.6885 (0.5489)  Acc@1: 75.0000 (89.4839)  Acc@5: 100.0000 (99.4728)\n",
            "Test: [ 950/2354]  Time: 0.114 (0.143)  Loss:  0.1685 (0.5371)  Acc@1: 100.0000 (89.8265)  Acc@5: 100.0000 (99.4479)\n",
            "Test: [1000/2354]  Time: 0.159 (0.143)  Loss:  0.0333 (0.5295)  Acc@1: 100.0000 (89.9850)  Acc@5: 100.0000 (99.4505)\n",
            "Test: [1050/2354]  Time: 0.154 (0.143)  Loss:  0.2976 (0.5344)  Acc@1: 100.0000 (89.7954)  Acc@5: 100.0000 (99.4291)\n",
            "Test: [1100/2354]  Time: 0.162 (0.143)  Loss:  0.3093 (0.5325)  Acc@1: 100.0000 (89.8728)  Acc@5: 100.0000 (99.4550)\n",
            "Test: [1150/2354]  Time: 0.117 (0.142)  Loss:  1.3311 (0.5313)  Acc@1: 100.0000 (90.0738)  Acc@5: 100.0000 (99.4136)\n",
            "Test: [1200/2354]  Time: 0.143 (0.142)  Loss:  1.0518 (0.5343)  Acc@1: 75.0000 (89.9875)  Acc@5: 75.0000 (99.3755)\n",
            "Test: [1250/2354]  Time: 0.174 (0.142)  Loss:  0.1562 (0.5247)  Acc@1: 100.0000 (90.2478)  Acc@5: 100.0000 (99.4005)\n",
            "Test: [1300/2354]  Time: 0.139 (0.142)  Loss:  0.1832 (0.5297)  Acc@1: 100.0000 (89.9885)  Acc@5: 100.0000 (99.3851)\n",
            "Test: [1350/2354]  Time: 0.113 (0.142)  Loss:  0.0870 (0.5266)  Acc@1: 100.0000 (90.1369)  Acc@5: 100.0000 (99.4078)\n",
            "Test: [1400/2354]  Time: 0.179 (0.143)  Loss:  0.5215 (0.5251)  Acc@1: 100.0000 (90.2570)  Acc@5: 100.0000 (99.4290)\n",
            "Test: [1450/2354]  Time: 0.120 (0.143)  Loss:  0.4282 (0.5264)  Acc@1: 100.0000 (90.3170)  Acc@5: 100.0000 (99.4142)\n",
            "Test: [1500/2354]  Time: 0.152 (0.142)  Loss:  0.3489 (0.5230)  Acc@1: 100.0000 (90.3897)  Acc@5: 100.0000 (99.3837)\n",
            "Test: [1550/2354]  Time: 0.146 (0.142)  Loss:  0.2773 (0.5362)  Acc@1: 100.0000 (89.7002)  Acc@5: 100.0000 (99.3714)\n",
            "Test: [1600/2354]  Time: 0.143 (0.142)  Loss:  0.2191 (0.5395)  Acc@1: 100.0000 (89.6315)  Acc@5: 100.0000 (99.3598)\n",
            "Test: [1650/2354]  Time: 0.102 (0.142)  Loss:  0.9180 (0.5533)  Acc@1: 75.0000 (88.9310)  Acc@5: 100.0000 (99.3186)\n",
            "Test: [1700/2354]  Time: 0.181 (0.142)  Loss:  0.0938 (0.5601)  Acc@1: 100.0000 (88.6831)  Acc@5: 100.0000 (99.3239)\n",
            "Test: [1750/2354]  Time: 0.129 (0.142)  Loss:  0.4146 (0.5642)  Acc@1: 100.0000 (88.5351)  Acc@5: 100.0000 (99.3432)\n",
            "Test: [1800/2354]  Time: 0.111 (0.142)  Loss:  0.8037 (0.5610)  Acc@1: 100.0000 (88.6591)  Acc@5: 100.0000 (99.3476)\n",
            "Test: [1850/2354]  Time: 0.152 (0.142)  Loss:  0.5967 (0.5545)  Acc@1: 75.0000 (88.7898)  Acc@5: 100.0000 (99.3517)\n",
            "Test: [1900/2354]  Time: 0.089 (0.141)  Loss:  1.0576 (0.5509)  Acc@1: 75.0000 (88.8874)  Acc@5: 75.0000 (99.3556)\n",
            "Test: [1950/2354]  Time: 0.135 (0.141)  Loss:  0.8247 (0.5496)  Acc@1: 50.0000 (88.9800)  Acc@5: 100.0000 (99.3080)\n",
            "Test: [2000/2354]  Time: 0.105 (0.142)  Loss:  0.1772 (0.5469)  Acc@1: 100.0000 (89.1054)  Acc@5: 100.0000 (99.3128)\n",
            "Test: [2050/2354]  Time: 0.156 (0.142)  Loss:  0.9395 (0.5545)  Acc@1: 100.0000 (88.8225)  Acc@5: 100.0000 (99.2930)\n",
            "Test: [2100/2354]  Time: 0.124 (0.142)  Loss:  0.3167 (0.5555)  Acc@1: 100.0000 (88.8267)  Acc@5: 100.0000 (99.3099)\n",
            "Test: [2150/2354]  Time: 0.182 (0.142)  Loss:  1.1768 (0.5620)  Acc@1: 100.0000 (88.7146)  Acc@5: 100.0000 (99.3259)\n",
            "Test: [2200/2354]  Time: 0.120 (0.142)  Loss:  0.3142 (0.5706)  Acc@1: 100.0000 (88.5166)  Acc@5: 100.0000 (99.3299)\n",
            "Test: [2250/2354]  Time: 0.141 (0.142)  Loss:  0.1666 (0.5687)  Acc@1: 100.0000 (88.6051)  Acc@5: 100.0000 (99.3447)\n",
            "Test: [2300/2354]  Time: 0.121 (0.142)  Loss:  0.0380 (0.5681)  Acc@1: 100.0000 (88.5919)  Acc@5: 100.0000 (99.3372)\n",
            "Test: [2350/2354]  Time: 0.075 (0.141)  Loss:  0.3665 (0.5668)  Acc@1: 100.0000 (88.6431)  Acc@5: 100.0000 (99.3513)\n",
            "Test: [2354/2354]  Time: 0.064 (0.141)  Loss:  0.1158 (0.5665)  Acc@1: 100.0000 (88.6612)  Acc@5: 100.0000 (99.3524)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-12.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar', 88.66121668966981)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar', 78.29918250345047)\n",
            "\n",
            "Train: 23 [   0/2354 (  0%)]  Loss: 1.448 (1.45)  Time: 1.347s,    5.94/s  (1.347s,    5.94/s)  LR: 8.115e-05  Data: 0.475 (0.475)\n",
            "Train: 23 [  50/2354 (  2%)]  Loss: 1.714 (1.97)  Time: 0.464s,   17.23/s  (0.502s,   15.94/s)  LR: 8.115e-05  Data: 0.007 (0.017)\n",
            "Train: 23 [ 100/2354 (  4%)]  Loss: 4.054 (2.07)  Time: 0.460s,   17.39/s  (0.493s,   16.24/s)  LR: 8.115e-05  Data: 0.007 (0.013)\n",
            "Train: 23 [ 150/2354 (  6%)]  Loss: 3.153 (2.00)  Time: 0.461s,   17.35/s  (0.484s,   16.53/s)  LR: 8.115e-05  Data: 0.007 (0.011)\n",
            "Train: 23 [ 200/2354 (  8%)]  Loss: 2.302 (2.02)  Time: 0.477s,   16.77/s  (0.479s,   16.69/s)  LR: 8.115e-05  Data: 0.006 (0.010)\n",
            "Train: 23 [ 250/2354 ( 11%)]  Loss: 3.345 (2.03)  Time: 0.461s,   17.34/s  (0.477s,   16.78/s)  LR: 8.115e-05  Data: 0.006 (0.010)\n",
            "Train: 23 [ 300/2354 ( 13%)]  Loss: 1.921 (2.06)  Time: 0.463s,   17.26/s  (0.478s,   16.73/s)  LR: 8.115e-05  Data: 0.010 (0.009)\n",
            "Train: 23 [ 350/2354 ( 15%)]  Loss: 3.051 (2.06)  Time: 0.461s,   17.35/s  (0.477s,   16.79/s)  LR: 8.115e-05  Data: 0.007 (0.009)\n",
            "Train: 23 [ 400/2354 ( 17%)]  Loss: 1.397 (2.04)  Time: 0.470s,   17.03/s  (0.475s,   16.83/s)  LR: 8.115e-05  Data: 0.009 (0.009)\n",
            "Train: 23 [ 450/2354 ( 19%)]  Loss: 2.022 (2.03)  Time: 0.641s,   12.47/s  (0.476s,   16.80/s)  LR: 8.115e-05  Data: 0.013 (0.009)\n",
            "Train: 23 [ 500/2354 ( 21%)]  Loss: 1.678 (2.03)  Time: 0.460s,   17.38/s  (0.475s,   16.84/s)  LR: 8.115e-05  Data: 0.008 (0.009)\n",
            "Train: 23 [ 550/2354 ( 23%)]  Loss: 1.703 (2.03)  Time: 0.467s,   17.13/s  (0.474s,   16.87/s)  LR: 8.115e-05  Data: 0.009 (0.009)\n",
            "Train: 23 [ 600/2354 ( 25%)]  Loss: 1.358 (2.01)  Time: 0.474s,   16.89/s  (0.474s,   16.90/s)  LR: 8.115e-05  Data: 0.007 (0.009)\n",
            "Train: 23 [ 650/2354 ( 28%)]  Loss: 2.610 (2.01)  Time: 0.464s,   17.23/s  (0.474s,   16.87/s)  LR: 8.115e-05  Data: 0.011 (0.009)\n",
            "Train: 23 [ 700/2354 ( 30%)]  Loss: 2.211 (2.01)  Time: 0.474s,   16.86/s  (0.474s,   16.89/s)  LR: 8.115e-05  Data: 0.008 (0.008)\n",
            "Train: 23 [ 750/2354 ( 32%)]  Loss: 1.133 (2.00)  Time: 0.466s,   17.18/s  (0.473s,   16.91/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [ 800/2354 ( 34%)]  Loss: 1.836 (2.00)  Time: 0.462s,   17.33/s  (0.473s,   16.93/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [ 850/2354 ( 36%)]  Loss: 2.261 (2.01)  Time: 0.463s,   17.26/s  (0.473s,   16.90/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [ 900/2354 ( 38%)]  Loss: 2.065 (2.00)  Time: 0.464s,   17.23/s  (0.473s,   16.92/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [ 950/2354 ( 40%)]  Loss: 1.905 (2.00)  Time: 0.462s,   17.33/s  (0.473s,   16.93/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [1000/2354 ( 42%)]  Loss: 1.247 (2.00)  Time: 0.464s,   17.23/s  (0.472s,   16.94/s)  LR: 8.115e-05  Data: 0.011 (0.008)\n",
            "Train: 23 [1050/2354 ( 45%)]  Loss: 2.269 (2.01)  Time: 0.466s,   17.17/s  (0.473s,   16.92/s)  LR: 8.115e-05  Data: 0.008 (0.008)\n",
            "Train: 23 [1100/2354 ( 47%)]  Loss: 1.141 (2.01)  Time: 0.469s,   17.06/s  (0.472s,   16.93/s)  LR: 8.115e-05  Data: 0.009 (0.008)\n",
            "Train: 23 [1150/2354 ( 49%)]  Loss: 1.763 (2.01)  Time: 0.470s,   17.01/s  (0.472s,   16.94/s)  LR: 8.115e-05  Data: 0.010 (0.008)\n",
            "Train: 23 [1200/2354 ( 51%)]  Loss: 3.000 (2.01)  Time: 0.466s,   17.15/s  (0.472s,   16.95/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [1250/2354 ( 53%)]  Loss: 1.775 (2.01)  Time: 0.473s,   16.90/s  (0.472s,   16.94/s)  LR: 8.115e-05  Data: 0.009 (0.008)\n",
            "Train: 23 [1300/2354 ( 55%)]  Loss: 1.426 (2.02)  Time: 0.374s,   21.38/s  (0.472s,   16.95/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [1350/2354 ( 57%)]  Loss: 1.476 (2.02)  Time: 0.465s,   17.22/s  (0.472s,   16.96/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [1400/2354 ( 59%)]  Loss: 1.626 (2.02)  Time: 0.646s,   12.38/s  (0.472s,   16.96/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [1450/2354 ( 62%)]  Loss: 2.401 (2.02)  Time: 0.466s,   17.16/s  (0.472s,   16.95/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [1500/2354 ( 64%)]  Loss: 1.489 (2.03)  Time: 0.463s,   17.29/s  (0.472s,   16.96/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [1550/2354 ( 66%)]  Loss: 2.075 (2.03)  Time: 0.461s,   17.36/s  (0.472s,   16.97/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [1600/2354 ( 68%)]  Loss: 1.499 (2.03)  Time: 0.465s,   17.21/s  (0.472s,   16.95/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [1650/2354 ( 70%)]  Loss: 1.649 (2.03)  Time: 0.464s,   17.25/s  (0.472s,   16.96/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [1700/2354 ( 72%)]  Loss: 1.683 (2.03)  Time: 0.464s,   17.24/s  (0.472s,   16.97/s)  LR: 8.115e-05  Data: 0.010 (0.008)\n",
            "Train: 23 [1750/2354 ( 74%)]  Loss: 1.325 (2.03)  Time: 0.464s,   17.23/s  (0.471s,   16.97/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [1800/2354 ( 76%)]  Loss: 2.219 (2.03)  Time: 0.475s,   16.84/s  (0.472s,   16.96/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [1850/2354 ( 79%)]  Loss: 1.929 (2.04)  Time: 0.462s,   17.31/s  (0.471s,   16.97/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [1900/2354 ( 81%)]  Loss: 2.418 (2.04)  Time: 0.464s,   17.23/s  (0.471s,   16.97/s)  LR: 8.115e-05  Data: 0.010 (0.008)\n",
            "Train: 23 [1950/2354 ( 83%)]  Loss: 1.466 (2.04)  Time: 0.482s,   16.61/s  (0.471s,   16.98/s)  LR: 8.115e-05  Data: 0.009 (0.008)\n",
            "Train: 23 [2000/2354 ( 85%)]  Loss: 1.199 (2.04)  Time: 0.463s,   17.28/s  (0.472s,   16.97/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [2050/2354 ( 87%)]  Loss: 1.349 (2.04)  Time: 0.464s,   17.25/s  (0.471s,   16.97/s)  LR: 8.115e-05  Data: 0.010 (0.008)\n",
            "Train: 23 [2100/2354 ( 89%)]  Loss: 1.804 (2.04)  Time: 0.463s,   17.26/s  (0.471s,   16.98/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [2150/2354 ( 91%)]  Loss: 2.451 (2.04)  Time: 0.466s,   17.17/s  (0.471s,   16.98/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [2200/2354 ( 93%)]  Loss: 1.319 (2.04)  Time: 0.464s,   17.23/s  (0.471s,   16.97/s)  LR: 8.115e-05  Data: 0.006 (0.008)\n",
            "Train: 23 [2250/2354 ( 96%)]  Loss: 1.327 (2.04)  Time: 0.466s,   17.17/s  (0.471s,   16.97/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [2300/2354 ( 98%)]  Loss: 3.117 (2.04)  Time: 0.467s,   17.14/s  (0.471s,   16.98/s)  LR: 8.115e-05  Data: 0.007 (0.008)\n",
            "Train: 23 [2350/2354 (100%)]  Loss: 2.134 (2.04)  Time: 0.457s,   17.51/s  (0.471s,   16.98/s)  LR: 8.115e-05  Data: 0.005 (0.008)\n",
            "Train: 23 [2353/2354 (100%)]  Loss: 1.757 (2.04)  Time: 0.452s,   17.72/s  (0.471s,   16.98/s)  LR: 8.115e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.669 (0.669)  Loss:  0.3823 (0.3823)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.133 (0.187)  Loss:  1.7637 (0.4774)  Acc@1: 50.0000 (91.6667)  Acc@5: 75.0000 (99.5098)\n",
            "Test: [ 100/2354]  Time: 0.149 (0.163)  Loss:  1.0098 (0.5252)  Acc@1: 75.0000 (90.8416)  Acc@5: 100.0000 (99.2574)\n",
            "Test: [ 150/2354]  Time: 0.141 (0.154)  Loss:  1.1094 (0.5366)  Acc@1: 50.0000 (88.7417)  Acc@5: 100.0000 (99.5033)\n",
            "Test: [ 200/2354]  Time: 0.155 (0.150)  Loss:  0.2769 (0.5152)  Acc@1: 100.0000 (89.1791)  Acc@5: 100.0000 (99.5025)\n",
            "Test: [ 250/2354]  Time: 0.128 (0.148)  Loss:  0.3025 (0.5282)  Acc@1: 100.0000 (89.4422)  Acc@5: 100.0000 (99.5020)\n",
            "Test: [ 300/2354]  Time: 0.083 (0.146)  Loss:  1.1289 (0.5179)  Acc@1: 50.0000 (89.7841)  Acc@5: 100.0000 (99.4186)\n",
            "Test: [ 350/2354]  Time: 0.082 (0.145)  Loss:  0.8682 (0.5274)  Acc@1: 50.0000 (89.6011)  Acc@5: 100.0000 (99.4302)\n",
            "Test: [ 400/2354]  Time: 0.076 (0.144)  Loss:  0.1768 (0.5383)  Acc@1: 100.0000 (88.6534)  Acc@5: 100.0000 (99.3766)\n",
            "Test: [ 450/2354]  Time: 0.096 (0.143)  Loss:  0.1255 (0.5117)  Acc@1: 100.0000 (89.5787)  Acc@5: 100.0000 (99.4457)\n",
            "Test: [ 500/2354]  Time: 0.148 (0.142)  Loss:  0.9067 (0.4926)  Acc@1: 50.0000 (90.0200)  Acc@5: 100.0000 (99.4511)\n",
            "Test: [ 550/2354]  Time: 0.165 (0.142)  Loss:  1.3525 (0.4855)  Acc@1: 75.0000 (90.2450)  Acc@5: 100.0000 (99.5009)\n",
            "Test: [ 600/2354]  Time: 0.136 (0.142)  Loss:  0.3875 (0.4805)  Acc@1: 100.0000 (90.3078)  Acc@5: 100.0000 (99.5008)\n",
            "Test: [ 650/2354]  Time: 0.113 (0.141)  Loss:  0.2710 (0.4685)  Acc@1: 100.0000 (90.7450)  Acc@5: 100.0000 (99.4624)\n",
            "Test: [ 700/2354]  Time: 0.175 (0.144)  Loss:  0.0633 (0.4600)  Acc@1: 100.0000 (91.2268)  Acc@5: 100.0000 (99.5007)\n",
            "Test: [ 750/2354]  Time: 0.115 (0.143)  Loss:  0.7939 (0.4597)  Acc@1: 100.0000 (91.3782)  Acc@5: 100.0000 (99.5007)\n",
            "Test: [ 800/2354]  Time: 0.171 (0.143)  Loss:  0.0715 (0.4652)  Acc@1: 100.0000 (91.4482)  Acc@5: 100.0000 (99.5006)\n",
            "Test: [ 850/2354]  Time: 0.141 (0.143)  Loss:  0.1577 (0.4639)  Acc@1: 100.0000 (91.3631)  Acc@5: 100.0000 (99.5006)\n",
            "Test: [ 900/2354]  Time: 0.199 (0.142)  Loss:  0.5039 (0.4558)  Acc@1: 75.0000 (91.6482)  Acc@5: 100.0000 (99.5283)\n",
            "Test: [ 950/2354]  Time: 0.152 (0.142)  Loss:  0.5322 (0.4487)  Acc@1: 75.0000 (91.8507)  Acc@5: 100.0000 (99.5268)\n",
            "Test: [1000/2354]  Time: 0.194 (0.142)  Loss:  0.1000 (0.4531)  Acc@1: 100.0000 (91.7832)  Acc@5: 100.0000 (99.5255)\n",
            "Test: [1050/2354]  Time: 0.163 (0.142)  Loss:  0.6929 (0.4468)  Acc@1: 100.0000 (91.9363)  Acc@5: 100.0000 (99.5480)\n",
            "Test: [1100/2354]  Time: 0.123 (0.142)  Loss:  0.7783 (0.4482)  Acc@1: 100.0000 (91.9164)  Acc@5: 100.0000 (99.5686)\n",
            "Test: [1150/2354]  Time: 0.180 (0.142)  Loss:  1.3789 (0.4470)  Acc@1: 100.0000 (91.9852)  Acc@5: 100.0000 (99.5656)\n",
            "Test: [1200/2354]  Time: 0.083 (0.142)  Loss:  1.0547 (0.4486)  Acc@1: 75.0000 (91.9442)  Acc@5: 75.0000 (99.5420)\n",
            "Test: [1250/2354]  Time: 0.187 (0.142)  Loss:  0.2798 (0.4432)  Acc@1: 100.0000 (92.1263)  Acc@5: 100.0000 (99.5404)\n",
            "Test: [1300/2354]  Time: 0.118 (0.142)  Loss:  0.0533 (0.4432)  Acc@1: 100.0000 (92.1407)  Acc@5: 100.0000 (99.5196)\n",
            "Test: [1350/2354]  Time: 0.192 (0.143)  Loss:  0.4204 (0.4423)  Acc@1: 100.0000 (92.3205)  Acc@5: 100.0000 (99.5374)\n",
            "Test: [1400/2354]  Time: 0.198 (0.143)  Loss:  0.2499 (0.4411)  Acc@1: 100.0000 (92.4697)  Acc@5: 100.0000 (99.5360)\n",
            "Test: [1450/2354]  Time: 0.077 (0.143)  Loss:  0.4104 (0.4391)  Acc@1: 100.0000 (92.5569)  Acc@5: 100.0000 (99.5348)\n",
            "Test: [1500/2354]  Time: 0.103 (0.143)  Loss:  0.0519 (0.4379)  Acc@1: 100.0000 (92.5716)  Acc@5: 100.0000 (99.5170)\n",
            "Test: [1550/2354]  Time: 0.118 (0.143)  Loss:  0.1667 (0.4519)  Acc@1: 100.0000 (91.9246)  Acc@5: 100.0000 (99.4842)\n",
            "Test: [1600/2354]  Time: 0.167 (0.143)  Loss:  0.3657 (0.4588)  Acc@1: 100.0000 (91.6771)  Acc@5: 100.0000 (99.4691)\n",
            "Test: [1650/2354]  Time: 0.155 (0.143)  Loss:  0.3711 (0.4647)  Acc@1: 100.0000 (91.4446)  Acc@5: 100.0000 (99.4700)\n",
            "Test: [1700/2354]  Time: 0.113 (0.143)  Loss:  0.1066 (0.4630)  Acc@1: 100.0000 (91.5344)  Acc@5: 100.0000 (99.4415)\n",
            "Test: [1750/2354]  Time: 0.220 (0.143)  Loss:  0.4131 (0.4652)  Acc@1: 100.0000 (91.4049)  Acc@5: 100.0000 (99.4575)\n",
            "Test: [1800/2354]  Time: 0.165 (0.143)  Loss:  0.9092 (0.4660)  Acc@1: 75.0000 (91.3937)  Acc@5: 100.0000 (99.4448)\n",
            "Test: [1850/2354]  Time: 0.188 (0.143)  Loss:  0.2578 (0.4637)  Acc@1: 100.0000 (91.4641)  Acc@5: 100.0000 (99.4462)\n",
            "Test: [1900/2354]  Time: 0.101 (0.143)  Loss:  0.6470 (0.4606)  Acc@1: 100.0000 (91.6097)  Acc@5: 100.0000 (99.4608)\n",
            "Test: [1950/2354]  Time: 0.243 (0.143)  Loss:  0.2278 (0.4602)  Acc@1: 100.0000 (91.6966)  Acc@5: 100.0000 (99.4618)\n",
            "Test: [2000/2354]  Time: 0.183 (0.144)  Loss:  0.1447 (0.4571)  Acc@1: 100.0000 (91.8666)  Acc@5: 100.0000 (99.4753)\n",
            "Test: [2050/2354]  Time: 0.205 (0.143)  Loss:  1.0420 (0.4683)  Acc@1: 100.0000 (91.3944)  Acc@5: 100.0000 (99.4271)\n",
            "Test: [2100/2354]  Time: 0.093 (0.143)  Loss:  1.0664 (0.4736)  Acc@1: 50.0000 (91.1709)  Acc@5: 100.0000 (99.4050)\n",
            "Test: [2150/2354]  Time: 0.165 (0.143)  Loss:  0.5967 (0.4812)  Acc@1: 100.0000 (91.0158)  Acc@5: 100.0000 (99.3724)\n",
            "Test: [2200/2354]  Time: 0.170 (0.143)  Loss:  0.7402 (0.4883)  Acc@1: 100.0000 (90.7883)  Acc@5: 100.0000 (99.3753)\n",
            "Test: [2250/2354]  Time: 0.132 (0.143)  Loss:  0.0273 (0.4868)  Acc@1: 100.0000 (90.8596)  Acc@5: 100.0000 (99.3892)\n",
            "Test: [2300/2354]  Time: 0.133 (0.143)  Loss:  0.2052 (0.4858)  Acc@1: 100.0000 (90.8735)  Acc@5: 100.0000 (99.3916)\n",
            "Test: [2350/2354]  Time: 0.075 (0.142)  Loss:  0.4600 (0.4858)  Acc@1: 100.0000 (90.8337)  Acc@5: 100.0000 (99.4045)\n",
            "Test: [2354/2354]  Time: 0.064 (0.142)  Loss:  0.0576 (0.4855)  Acc@1: 100.0000 (90.8483)  Acc@5: 100.0000 (99.4055)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-13.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar', 88.66121668966981)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar', 80.87907421169976)\n",
            "\n",
            "Train: 24 [   0/2354 (  0%)]  Loss: 1.527 (1.53)  Time: 1.313s,    6.09/s  (1.313s,    6.09/s)  LR: 7.960e-05  Data: 0.598 (0.598)\n",
            "Train: 24 [  50/2354 (  2%)]  Loss: 2.002 (1.87)  Time: 0.459s,   17.43/s  (0.502s,   15.95/s)  LR: 7.960e-05  Data: 0.007 (0.019)\n",
            "Train: 24 [ 100/2354 (  4%)]  Loss: 2.603 (1.91)  Time: 0.461s,   17.36/s  (0.491s,   16.28/s)  LR: 7.960e-05  Data: 0.006 (0.014)\n",
            "Train: 24 [ 150/2354 (  6%)]  Loss: 1.174 (1.90)  Time: 0.465s,   17.21/s  (0.482s,   16.59/s)  LR: 7.960e-05  Data: 0.007 (0.012)\n",
            "Train: 24 [ 200/2354 (  8%)]  Loss: 3.788 (1.95)  Time: 0.454s,   17.62/s  (0.477s,   16.76/s)  LR: 7.960e-05  Data: 0.007 (0.011)\n",
            "Train: 24 [ 250/2354 ( 11%)]  Loss: 2.150 (1.97)  Time: 0.473s,   16.90/s  (0.475s,   16.86/s)  LR: 7.960e-05  Data: 0.007 (0.010)\n",
            "Train: 24 [ 300/2354 ( 13%)]  Loss: 2.761 (1.96)  Time: 0.468s,   17.11/s  (0.476s,   16.82/s)  LR: 7.960e-05  Data: 0.007 (0.010)\n",
            "Train: 24 [ 350/2354 ( 15%)]  Loss: 1.945 (1.99)  Time: 0.468s,   17.10/s  (0.474s,   16.88/s)  LR: 7.960e-05  Data: 0.010 (0.009)\n",
            "Train: 24 [ 400/2354 ( 17%)]  Loss: 2.918 (2.00)  Time: 0.458s,   17.46/s  (0.473s,   16.93/s)  LR: 7.960e-05  Data: 0.006 (0.009)\n",
            "Train: 24 [ 450/2354 ( 19%)]  Loss: 1.656 (1.97)  Time: 0.473s,   16.90/s  (0.472s,   16.96/s)  LR: 7.960e-05  Data: 0.010 (0.009)\n",
            "Train: 24 [ 500/2354 ( 21%)]  Loss: 1.861 (1.97)  Time: 0.464s,   17.26/s  (0.473s,   16.92/s)  LR: 7.960e-05  Data: 0.007 (0.009)\n",
            "Train: 24 [ 550/2354 ( 23%)]  Loss: 1.854 (1.99)  Time: 0.467s,   17.12/s  (0.472s,   16.95/s)  LR: 7.960e-05  Data: 0.010 (0.009)\n",
            "Train: 24 [ 600/2354 ( 25%)]  Loss: 2.087 (1.98)  Time: 0.461s,   17.36/s  (0.471s,   16.97/s)  LR: 7.960e-05  Data: 0.007 (0.009)\n",
            "Train: 24 [ 650/2354 ( 28%)]  Loss: 1.987 (1.99)  Time: 0.465s,   17.21/s  (0.471s,   16.99/s)  LR: 7.960e-05  Data: 0.008 (0.009)\n",
            "Train: 24 [ 700/2354 ( 30%)]  Loss: 1.864 (1.99)  Time: 0.461s,   17.35/s  (0.472s,   16.97/s)  LR: 7.960e-05  Data: 0.007 (0.009)\n",
            "Train: 24 [ 750/2354 ( 32%)]  Loss: 2.803 (2.00)  Time: 0.469s,   17.07/s  (0.471s,   16.98/s)  LR: 7.960e-05  Data: 0.007 (0.009)\n",
            "Train: 24 [ 800/2354 ( 34%)]  Loss: 1.456 (1.99)  Time: 0.461s,   17.37/s  (0.471s,   17.00/s)  LR: 7.960e-05  Data: 0.006 (0.009)\n",
            "Train: 24 [ 850/2354 ( 36%)]  Loss: 2.915 (2.00)  Time: 0.463s,   17.26/s  (0.470s,   17.02/s)  LR: 7.960e-05  Data: 0.009 (0.009)\n",
            "Train: 24 [ 900/2354 ( 38%)]  Loss: 1.954 (2.00)  Time: 0.457s,   17.52/s  (0.471s,   16.99/s)  LR: 7.960e-05  Data: 0.009 (0.009)\n",
            "Train: 24 [ 950/2354 ( 40%)]  Loss: 2.266 (1.99)  Time: 0.462s,   17.32/s  (0.470s,   17.01/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1000/2354 ( 42%)]  Loss: 2.061 (2.00)  Time: 0.463s,   17.28/s  (0.470s,   17.02/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1050/2354 ( 45%)]  Loss: 2.650 (2.01)  Time: 0.478s,   16.74/s  (0.470s,   17.03/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1100/2354 ( 47%)]  Loss: 2.425 (2.01)  Time: 0.463s,   17.27/s  (0.470s,   17.00/s)  LR: 7.960e-05  Data: 0.010 (0.008)\n",
            "Train: 24 [1150/2354 ( 49%)]  Loss: 1.748 (2.00)  Time: 0.458s,   17.45/s  (0.470s,   17.01/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1200/2354 ( 51%)]  Loss: 2.829 (2.01)  Time: 0.465s,   17.20/s  (0.470s,   17.02/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1250/2354 ( 53%)]  Loss: 2.320 (2.00)  Time: 0.456s,   17.55/s  (0.470s,   17.03/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1300/2354 ( 55%)]  Loss: 1.316 (2.01)  Time: 0.463s,   17.26/s  (0.470s,   17.02/s)  LR: 7.960e-05  Data: 0.008 (0.008)\n",
            "Train: 24 [1350/2354 ( 57%)]  Loss: 2.180 (2.01)  Time: 0.470s,   17.01/s  (0.470s,   17.03/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1400/2354 ( 59%)]  Loss: 1.134 (2.01)  Time: 0.461s,   17.34/s  (0.470s,   17.04/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1450/2354 ( 62%)]  Loss: 2.234 (2.01)  Time: 0.462s,   17.33/s  (0.469s,   17.04/s)  LR: 7.960e-05  Data: 0.006 (0.008)\n",
            "Train: 24 [1500/2354 ( 64%)]  Loss: 1.353 (2.02)  Time: 0.458s,   17.46/s  (0.470s,   17.03/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1550/2354 ( 66%)]  Loss: 2.026 (2.02)  Time: 0.465s,   17.21/s  (0.469s,   17.04/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1600/2354 ( 68%)]  Loss: 2.114 (2.02)  Time: 0.457s,   17.52/s  (0.469s,   17.05/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1650/2354 ( 70%)]  Loss: 1.319 (2.02)  Time: 0.473s,   16.93/s  (0.469s,   17.05/s)  LR: 7.960e-05  Data: 0.008 (0.008)\n",
            "Train: 24 [1700/2354 ( 72%)]  Loss: 3.625 (2.02)  Time: 0.470s,   17.01/s  (0.470s,   17.04/s)  LR: 7.960e-05  Data: 0.010 (0.008)\n",
            "Train: 24 [1750/2354 ( 74%)]  Loss: 1.121 (2.03)  Time: 0.460s,   17.40/s  (0.469s,   17.04/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [1800/2354 ( 76%)]  Loss: 3.034 (2.03)  Time: 0.461s,   17.34/s  (0.469s,   17.05/s)  LR: 7.960e-05  Data: 0.008 (0.008)\n",
            "Train: 24 [1850/2354 ( 79%)]  Loss: 1.374 (2.03)  Time: 0.462s,   17.31/s  (0.469s,   17.05/s)  LR: 7.960e-05  Data: 0.006 (0.008)\n",
            "Train: 24 [1900/2354 ( 81%)]  Loss: 3.436 (2.03)  Time: 0.467s,   17.13/s  (0.469s,   17.04/s)  LR: 7.960e-05  Data: 0.010 (0.008)\n",
            "Train: 24 [1950/2354 ( 83%)]  Loss: 1.201 (2.03)  Time: 0.461s,   17.36/s  (0.469s,   17.05/s)  LR: 7.960e-05  Data: 0.009 (0.008)\n",
            "Train: 24 [2000/2354 ( 85%)]  Loss: 2.434 (2.03)  Time: 0.465s,   17.22/s  (0.469s,   17.05/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [2050/2354 ( 87%)]  Loss: 2.719 (2.03)  Time: 0.472s,   16.96/s  (0.469s,   17.06/s)  LR: 7.960e-05  Data: 0.006 (0.008)\n",
            "Train: 24 [2100/2354 ( 89%)]  Loss: 2.820 (2.03)  Time: 0.460s,   17.38/s  (0.469s,   17.05/s)  LR: 7.960e-05  Data: 0.006 (0.008)\n",
            "Train: 24 [2150/2354 ( 91%)]  Loss: 1.252 (2.03)  Time: 0.464s,   17.24/s  (0.469s,   17.06/s)  LR: 7.960e-05  Data: 0.010 (0.008)\n",
            "Train: 24 [2200/2354 ( 93%)]  Loss: 1.353 (2.03)  Time: 0.459s,   17.43/s  (0.469s,   17.06/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [2250/2354 ( 96%)]  Loss: 1.637 (2.03)  Time: 0.462s,   17.33/s  (0.469s,   17.06/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [2300/2354 ( 98%)]  Loss: 2.249 (2.03)  Time: 0.461s,   17.36/s  (0.469s,   17.05/s)  LR: 7.960e-05  Data: 0.007 (0.008)\n",
            "Train: 24 [2350/2354 (100%)]  Loss: 1.115 (2.02)  Time: 0.457s,   17.52/s  (0.469s,   17.06/s)  LR: 7.960e-05  Data: 0.005 (0.008)\n",
            "Train: 24 [2353/2354 (100%)]  Loss: 2.005 (2.03)  Time: 0.456s,   17.54/s  (0.469s,   17.06/s)  LR: 7.960e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.679 (0.679)  Loss:  0.3245 (0.3245)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.085 (0.155)  Loss:  0.4307 (0.2320)  Acc@1: 100.0000 (98.0392)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.082 (0.146)  Loss:  0.6084 (0.2961)  Acc@1: 100.0000 (97.5248)  Acc@5: 100.0000 (99.7525)\n",
            "Test: [ 150/2354]  Time: 0.113 (0.143)  Loss:  0.3716 (0.3176)  Acc@1: 100.0000 (96.3576)  Acc@5: 100.0000 (99.8344)\n",
            "Test: [ 200/2354]  Time: 0.220 (0.142)  Loss:  0.5713 (0.3214)  Acc@1: 100.0000 (95.6468)  Acc@5: 100.0000 (99.8756)\n",
            "Test: [ 250/2354]  Time: 0.076 (0.142)  Loss:  0.0588 (0.3549)  Acc@1: 100.0000 (95.0199)  Acc@5: 100.0000 (99.8008)\n",
            "Test: [ 300/2354]  Time: 0.189 (0.141)  Loss:  1.8027 (0.3552)  Acc@1: 25.0000 (94.6013)  Acc@5: 100.0000 (99.7508)\n",
            "Test: [ 350/2354]  Time: 0.117 (0.141)  Loss:  0.9199 (0.3966)  Acc@1: 50.0000 (91.8091)  Acc@5: 100.0000 (99.7151)\n",
            "Test: [ 400/2354]  Time: 0.172 (0.140)  Loss:  0.1603 (0.4114)  Acc@1: 100.0000 (91.7082)  Acc@5: 100.0000 (99.7506)\n",
            "Test: [ 450/2354]  Time: 0.153 (0.144)  Loss:  0.1692 (0.3958)  Acc@1: 100.0000 (92.2949)  Acc@5: 100.0000 (99.7783)\n",
            "Test: [ 500/2354]  Time: 0.095 (0.144)  Loss:  0.7358 (0.3905)  Acc@1: 100.0000 (92.6647)  Acc@5: 100.0000 (99.8004)\n",
            "Test: [ 550/2354]  Time: 0.173 (0.143)  Loss:  1.1436 (0.4009)  Acc@1: 100.0000 (92.6951)  Acc@5: 100.0000 (99.8185)\n",
            "Test: [ 600/2354]  Time: 0.133 (0.143)  Loss:  0.2040 (0.3903)  Acc@1: 100.0000 (93.1780)  Acc@5: 100.0000 (99.8336)\n",
            "Test: [ 650/2354]  Time: 0.159 (0.143)  Loss:  0.4104 (0.3809)  Acc@1: 100.0000 (93.6252)  Acc@5: 100.0000 (99.8080)\n",
            "Test: [ 700/2354]  Time: 0.132 (0.142)  Loss:  0.1550 (0.3800)  Acc@1: 100.0000 (93.8659)  Acc@5: 100.0000 (99.8217)\n",
            "Test: [ 750/2354]  Time: 0.089 (0.142)  Loss:  0.3816 (0.3794)  Acc@1: 100.0000 (94.0413)  Acc@5: 100.0000 (99.8003)\n",
            "Test: [ 800/2354]  Time: 0.093 (0.142)  Loss:  0.2317 (0.3866)  Acc@1: 100.0000 (93.6642)  Acc@5: 100.0000 (99.8127)\n",
            "Test: [ 850/2354]  Time: 0.170 (0.142)  Loss:  0.4160 (0.3881)  Acc@1: 100.0000 (93.6251)  Acc@5: 100.0000 (99.8237)\n",
            "Test: [ 900/2354]  Time: 0.177 (0.142)  Loss:  0.6641 (0.3767)  Acc@1: 75.0000 (93.9234)  Acc@5: 100.0000 (99.8335)\n",
            "Test: [ 950/2354]  Time: 0.156 (0.141)  Loss:  0.5146 (0.3697)  Acc@1: 75.0000 (94.0852)  Acc@5: 100.0000 (99.8423)\n",
            "Test: [1000/2354]  Time: 0.134 (0.141)  Loss:  0.0609 (0.3731)  Acc@1: 100.0000 (93.8811)  Acc@5: 100.0000 (99.8252)\n",
            "Test: [1050/2354]  Time: 0.199 (0.141)  Loss:  0.4927 (0.3743)  Acc@1: 75.0000 (93.9581)  Acc@5: 100.0000 (99.8335)\n",
            "Test: [1100/2354]  Time: 0.218 (0.141)  Loss:  0.3469 (0.3760)  Acc@1: 100.0000 (93.9827)  Acc@5: 100.0000 (99.8411)\n",
            "Test: [1150/2354]  Time: 0.126 (0.143)  Loss:  1.2852 (0.3739)  Acc@1: 50.0000 (94.1138)  Acc@5: 100.0000 (99.8045)\n",
            "Test: [1200/2354]  Time: 0.099 (0.143)  Loss:  0.5010 (0.3758)  Acc@1: 100.0000 (94.0674)  Acc@5: 100.0000 (99.7918)\n",
            "Test: [1250/2354]  Time: 0.180 (0.143)  Loss:  0.0400 (0.3699)  Acc@1: 100.0000 (94.2446)  Acc@5: 100.0000 (99.7802)\n",
            "Test: [1300/2354]  Time: 0.148 (0.143)  Loss:  0.3711 (0.3702)  Acc@1: 100.0000 (94.2929)  Acc@5: 100.0000 (99.7694)\n",
            "Test: [1350/2354]  Time: 0.146 (0.142)  Loss:  0.1881 (0.3742)  Acc@1: 100.0000 (94.3375)  Acc@5: 100.0000 (99.7779)\n",
            "Test: [1400/2354]  Time: 0.138 (0.142)  Loss:  0.2717 (0.3715)  Acc@1: 100.0000 (94.3969)  Acc@5: 100.0000 (99.7680)\n",
            "Test: [1450/2354]  Time: 0.137 (0.142)  Loss:  0.4133 (0.3726)  Acc@1: 100.0000 (94.3487)  Acc@5: 100.0000 (99.7760)\n",
            "Test: [1500/2354]  Time: 0.136 (0.142)  Loss:  0.3079 (0.3736)  Acc@1: 100.0000 (94.4204)  Acc@5: 100.0000 (99.7668)\n",
            "Test: [1550/2354]  Time: 0.136 (0.142)  Loss:  0.1039 (0.3853)  Acc@1: 100.0000 (94.0200)  Acc@5: 100.0000 (99.7582)\n",
            "Test: [1600/2354]  Time: 0.100 (0.142)  Loss:  0.0970 (0.3923)  Acc@1: 100.0000 (93.8632)  Acc@5: 100.0000 (99.7345)\n",
            "Test: [1650/2354]  Time: 0.225 (0.142)  Loss:  0.2859 (0.3952)  Acc@1: 100.0000 (93.8219)  Acc@5: 100.0000 (99.7274)\n",
            "Test: [1700/2354]  Time: 0.078 (0.142)  Loss:  0.0768 (0.3969)  Acc@1: 100.0000 (93.8713)  Acc@5: 100.0000 (99.7208)\n",
            "Test: [1750/2354]  Time: 0.152 (0.142)  Loss:  0.6099 (0.4090)  Acc@1: 100.0000 (93.4609)  Acc@5: 100.0000 (99.7144)\n",
            "Test: [1800/2354]  Time: 0.133 (0.142)  Loss:  0.3362 (0.4067)  Acc@1: 100.0000 (93.5730)  Acc@5: 100.0000 (99.6807)\n",
            "Test: [1850/2354]  Time: 0.156 (0.142)  Loss:  0.2031 (0.4048)  Acc@1: 100.0000 (93.5845)  Acc@5: 100.0000 (99.6759)\n",
            "Test: [1900/2354]  Time: 0.122 (0.142)  Loss:  0.7241 (0.4050)  Acc@1: 75.0000 (93.5429)  Acc@5: 100.0000 (99.6712)\n",
            "Test: [1950/2354]  Time: 0.097 (0.142)  Loss:  0.0918 (0.4024)  Acc@1: 100.0000 (93.6315)  Acc@5: 100.0000 (99.6668)\n",
            "Test: [2000/2354]  Time: 0.144 (0.142)  Loss:  0.1293 (0.3978)  Acc@1: 100.0000 (93.7531)  Acc@5: 100.0000 (99.6752)\n",
            "Test: [2050/2354]  Time: 0.129 (0.142)  Loss:  0.6948 (0.4068)  Acc@1: 75.0000 (93.5032)  Acc@5: 100.0000 (99.6465)\n",
            "Test: [2100/2354]  Time: 0.203 (0.142)  Loss:  0.5161 (0.4135)  Acc@1: 100.0000 (93.2532)  Acc@5: 100.0000 (99.6430)\n",
            "Test: [2150/2354]  Time: 0.141 (0.142)  Loss:  0.8462 (0.4180)  Acc@1: 100.0000 (93.1892)  Acc@5: 100.0000 (99.6513)\n",
            "Test: [2200/2354]  Time: 0.182 (0.142)  Loss:  0.5459 (0.4228)  Acc@1: 100.0000 (93.0373)  Acc@5: 100.0000 (99.6592)\n",
            "Test: [2250/2354]  Time: 0.147 (0.142)  Loss:  0.0467 (0.4235)  Acc@1: 100.0000 (93.0920)  Acc@5: 100.0000 (99.6668)\n",
            "Test: [2300/2354]  Time: 0.147 (0.142)  Loss:  0.0788 (0.4207)  Acc@1: 100.0000 (93.1660)  Acc@5: 100.0000 (99.6523)\n",
            "Test: [2350/2354]  Time: 0.074 (0.141)  Loss:  0.8013 (0.4212)  Acc@1: 75.0000 (93.1199)  Acc@5: 100.0000 (99.6597)\n",
            "Test: [2354/2354]  Time: 0.064 (0.141)  Loss:  0.0770 (0.4211)  Acc@1: 100.0000 (93.1309)  Acc@5: 100.0000 (99.6603)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-14.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar', 88.66121668966981)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar', 83.58636797961567)\n",
            "\n",
            "Train: 25 [   0/2354 (  0%)]  Loss: 2.582 (2.58)  Time: 1.468s,    5.45/s  (1.468s,    5.45/s)  LR: 7.800e-05  Data: 0.541 (0.541)\n",
            "Train: 25 [  50/2354 (  2%)]  Loss: 1.095 (1.84)  Time: 0.473s,   16.93/s  (0.528s,   15.15/s)  LR: 7.800e-05  Data: 0.007 (0.019)\n",
            "Train: 25 [ 100/2354 (  4%)]  Loss: 1.710 (1.87)  Time: 0.465s,   17.20/s  (0.498s,   16.08/s)  LR: 7.800e-05  Data: 0.007 (0.014)\n",
            "Train: 25 [ 150/2354 (  6%)]  Loss: 1.762 (1.94)  Time: 0.463s,   17.28/s  (0.487s,   16.41/s)  LR: 7.800e-05  Data: 0.006 (0.011)\n",
            "Train: 25 [ 200/2354 (  8%)]  Loss: 1.567 (1.93)  Time: 0.464s,   17.24/s  (0.482s,   16.60/s)  LR: 7.800e-05  Data: 0.006 (0.010)\n",
            "Train: 25 [ 250/2354 ( 11%)]  Loss: 3.047 (1.94)  Time: 0.460s,   17.39/s  (0.482s,   16.59/s)  LR: 7.800e-05  Data: 0.007 (0.010)\n",
            "Train: 25 [ 300/2354 ( 13%)]  Loss: 2.568 (1.94)  Time: 0.471s,   16.97/s  (0.480s,   16.68/s)  LR: 7.800e-05  Data: 0.006 (0.009)\n",
            "Train: 25 [ 350/2354 ( 15%)]  Loss: 2.085 (1.92)  Time: 0.470s,   17.01/s  (0.477s,   16.75/s)  LR: 7.800e-05  Data: 0.008 (0.009)\n",
            "Train: 25 [ 400/2354 ( 17%)]  Loss: 1.784 (1.92)  Time: 0.462s,   17.32/s  (0.476s,   16.81/s)  LR: 7.800e-05  Data: 0.007 (0.009)\n",
            "Train: 25 [ 450/2354 ( 19%)]  Loss: 1.904 (1.93)  Time: 0.464s,   17.26/s  (0.477s,   16.79/s)  LR: 7.800e-05  Data: 0.006 (0.009)\n",
            "Train: 25 [ 500/2354 ( 21%)]  Loss: 3.301 (1.94)  Time: 0.473s,   16.91/s  (0.476s,   16.82/s)  LR: 7.800e-05  Data: 0.009 (0.009)\n",
            "Train: 25 [ 550/2354 ( 23%)]  Loss: 1.487 (1.94)  Time: 0.461s,   17.35/s  (0.475s,   16.84/s)  LR: 7.800e-05  Data: 0.007 (0.009)\n",
            "Train: 25 [ 600/2354 ( 25%)]  Loss: 2.104 (1.95)  Time: 0.475s,   16.86/s  (0.474s,   16.87/s)  LR: 7.800e-05  Data: 0.006 (0.009)\n",
            "Train: 25 [ 650/2354 ( 28%)]  Loss: 2.259 (1.96)  Time: 0.663s,   12.07/s  (0.475s,   16.84/s)  LR: 7.800e-05  Data: 0.020 (0.009)\n",
            "Train: 25 [ 700/2354 ( 30%)]  Loss: 1.738 (1.95)  Time: 0.467s,   17.13/s  (0.474s,   16.87/s)  LR: 7.800e-05  Data: 0.007 (0.009)\n",
            "Train: 25 [ 750/2354 ( 32%)]  Loss: 1.753 (1.96)  Time: 0.463s,   17.27/s  (0.474s,   16.89/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [ 800/2354 ( 34%)]  Loss: 1.477 (1.96)  Time: 0.469s,   17.07/s  (0.473s,   16.91/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [ 850/2354 ( 36%)]  Loss: 2.224 (1.97)  Time: 0.461s,   17.37/s  (0.473s,   16.92/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [ 900/2354 ( 38%)]  Loss: 2.175 (1.97)  Time: 0.461s,   17.34/s  (0.473s,   16.90/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [ 950/2354 ( 40%)]  Loss: 2.619 (1.97)  Time: 0.463s,   17.27/s  (0.473s,   16.92/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [1000/2354 ( 42%)]  Loss: 1.576 (1.98)  Time: 0.459s,   17.42/s  (0.473s,   16.93/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [1050/2354 ( 45%)]  Loss: 1.998 (1.98)  Time: 0.465s,   17.21/s  (0.472s,   16.94/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [1100/2354 ( 47%)]  Loss: 3.899 (1.97)  Time: 0.465s,   17.19/s  (0.473s,   16.92/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [1150/2354 ( 49%)]  Loss: 2.001 (1.97)  Time: 0.469s,   17.05/s  (0.472s,   16.93/s)  LR: 7.800e-05  Data: 0.009 (0.008)\n",
            "Train: 25 [1200/2354 ( 51%)]  Loss: 2.248 (1.98)  Time: 0.462s,   17.31/s  (0.472s,   16.94/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [1250/2354 ( 53%)]  Loss: 1.175 (1.97)  Time: 0.465s,   17.21/s  (0.472s,   16.95/s)  LR: 7.800e-05  Data: 0.009 (0.008)\n",
            "Train: 25 [1300/2354 ( 55%)]  Loss: 2.165 (1.97)  Time: 0.461s,   17.36/s  (0.473s,   16.93/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [1350/2354 ( 57%)]  Loss: 1.952 (1.97)  Time: 0.464s,   17.25/s  (0.472s,   16.94/s)  LR: 7.800e-05  Data: 0.009 (0.008)\n",
            "Train: 25 [1400/2354 ( 59%)]  Loss: 2.299 (1.97)  Time: 0.469s,   17.05/s  (0.472s,   16.95/s)  LR: 7.800e-05  Data: 0.009 (0.008)\n",
            "Train: 25 [1450/2354 ( 62%)]  Loss: 3.046 (1.97)  Time: 0.463s,   17.26/s  (0.472s,   16.95/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [1500/2354 ( 64%)]  Loss: 1.796 (1.97)  Time: 0.468s,   17.10/s  (0.472s,   16.94/s)  LR: 7.800e-05  Data: 0.008 (0.008)\n",
            "Train: 25 [1550/2354 ( 66%)]  Loss: 1.425 (1.96)  Time: 0.463s,   17.30/s  (0.472s,   16.95/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [1600/2354 ( 68%)]  Loss: 1.745 (1.96)  Time: 0.463s,   17.26/s  (0.472s,   16.96/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [1650/2354 ( 70%)]  Loss: 1.773 (1.96)  Time: 0.468s,   17.08/s  (0.472s,   16.96/s)  LR: 7.800e-05  Data: 0.010 (0.008)\n",
            "Train: 25 [1700/2354 ( 72%)]  Loss: 2.789 (1.96)  Time: 0.472s,   16.95/s  (0.472s,   16.95/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [1750/2354 ( 74%)]  Loss: 3.728 (1.96)  Time: 0.468s,   17.10/s  (0.472s,   16.96/s)  LR: 7.800e-05  Data: 0.009 (0.008)\n",
            "Train: 25 [1800/2354 ( 76%)]  Loss: 2.442 (1.96)  Time: 0.469s,   17.06/s  (0.472s,   16.96/s)  LR: 7.800e-05  Data: 0.011 (0.008)\n",
            "Train: 25 [1850/2354 ( 79%)]  Loss: 1.386 (1.96)  Time: 0.468s,   17.09/s  (0.472s,   16.97/s)  LR: 7.800e-05  Data: 0.010 (0.008)\n",
            "Train: 25 [1900/2354 ( 81%)]  Loss: 2.316 (1.96)  Time: 0.664s,   12.05/s  (0.472s,   16.96/s)  LR: 7.800e-05  Data: 0.013 (0.008)\n",
            "Train: 25 [1950/2354 ( 83%)]  Loss: 1.949 (1.96)  Time: 0.460s,   17.41/s  (0.472s,   16.96/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [2000/2354 ( 85%)]  Loss: 2.902 (1.96)  Time: 0.460s,   17.38/s  (0.472s,   16.96/s)  LR: 7.800e-05  Data: 0.008 (0.008)\n",
            "Train: 25 [2050/2354 ( 87%)]  Loss: 2.052 (1.96)  Time: 0.460s,   17.37/s  (0.471s,   16.97/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [2100/2354 ( 89%)]  Loss: 2.712 (1.97)  Time: 0.470s,   17.03/s  (0.471s,   16.97/s)  LR: 7.800e-05  Data: 0.009 (0.008)\n",
            "Train: 25 [2150/2354 ( 91%)]  Loss: 1.385 (1.97)  Time: 0.468s,   17.10/s  (0.472s,   16.96/s)  LR: 7.800e-05  Data: 0.009 (0.008)\n",
            "Train: 25 [2200/2354 ( 93%)]  Loss: 2.706 (1.97)  Time: 0.466s,   17.16/s  (0.471s,   16.97/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [2250/2354 ( 96%)]  Loss: 1.570 (1.97)  Time: 0.470s,   17.03/s  (0.471s,   16.97/s)  LR: 7.800e-05  Data: 0.007 (0.008)\n",
            "Train: 25 [2300/2354 ( 98%)]  Loss: 1.833 (1.97)  Time: 0.460s,   17.38/s  (0.471s,   16.98/s)  LR: 7.800e-05  Data: 0.006 (0.008)\n",
            "Train: 25 [2350/2354 (100%)]  Loss: 2.717 (1.97)  Time: 0.457s,   17.52/s  (0.471s,   16.97/s)  LR: 7.800e-05  Data: 0.005 (0.008)\n",
            "Train: 25 [2353/2354 (100%)]  Loss: 1.602 (1.97)  Time: 0.455s,   17.58/s  (0.471s,   16.97/s)  LR: 7.800e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.662 (0.662)  Loss:  0.2471 (0.2471)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.196 (0.155)  Loss:  0.3059 (0.3469)  Acc@1: 100.0000 (96.5686)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.122 (0.145)  Loss:  0.6138 (0.3582)  Acc@1: 100.0000 (97.0297)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.151 (0.142)  Loss:  0.2498 (0.3705)  Acc@1: 100.0000 (95.5298)  Acc@5: 100.0000 (99.8344)\n",
            "Test: [ 200/2354]  Time: 0.150 (0.141)  Loss:  0.4600 (0.3464)  Acc@1: 100.0000 (95.2736)  Acc@5: 100.0000 (99.8756)\n",
            "Test: [ 250/2354]  Time: 0.084 (0.140)  Loss:  0.1322 (0.3703)  Acc@1: 100.0000 (95.2191)  Acc@5: 100.0000 (99.9004)\n",
            "Test: [ 300/2354]  Time: 0.134 (0.140)  Loss:  0.6943 (0.3691)  Acc@1: 100.0000 (95.2658)  Acc@5: 100.0000 (99.7508)\n",
            "Test: [ 350/2354]  Time: 0.145 (0.140)  Loss:  0.5796 (0.4093)  Acc@1: 100.0000 (94.1595)  Acc@5: 100.0000 (99.7863)\n",
            "Test: [ 400/2354]  Time: 0.144 (0.140)  Loss:  0.1035 (0.4202)  Acc@1: 100.0000 (93.8903)  Acc@5: 100.0000 (99.8130)\n",
            "Test: [ 450/2354]  Time: 0.149 (0.139)  Loss:  0.1200 (0.4172)  Acc@1: 100.0000 (94.0133)  Acc@5: 100.0000 (99.8337)\n",
            "Test: [ 500/2354]  Time: 0.159 (0.139)  Loss:  0.2158 (0.4124)  Acc@1: 100.0000 (94.1118)  Acc@5: 100.0000 (99.8503)\n",
            "Test: [ 550/2354]  Time: 0.085 (0.139)  Loss:  0.9966 (0.4387)  Acc@1: 100.0000 (92.6951)  Acc@5: 100.0000 (99.8639)\n",
            "Test: [ 600/2354]  Time: 0.244 (0.140)  Loss:  0.5479 (0.4323)  Acc@1: 75.0000 (92.9285)  Acc@5: 100.0000 (99.7920)\n",
            "Test: [ 650/2354]  Time: 0.090 (0.141)  Loss:  0.2076 (0.4200)  Acc@1: 100.0000 (93.3564)  Acc@5: 100.0000 (99.8080)\n",
            "Test: [ 700/2354]  Time: 0.164 (0.141)  Loss:  0.0275 (0.4051)  Acc@1: 100.0000 (93.7233)  Acc@5: 100.0000 (99.7860)\n",
            "Test: [ 750/2354]  Time: 0.139 (0.141)  Loss:  0.6763 (0.3922)  Acc@1: 75.0000 (94.0080)  Acc@5: 100.0000 (99.8003)\n",
            "Test: [ 800/2354]  Time: 0.163 (0.141)  Loss:  0.1456 (0.3945)  Acc@1: 100.0000 (93.7890)  Acc@5: 100.0000 (99.8127)\n",
            "Test: [ 850/2354]  Time: 0.118 (0.140)  Loss:  0.0875 (0.3911)  Acc@1: 100.0000 (93.8308)  Acc@5: 100.0000 (99.7944)\n",
            "Test: [ 900/2354]  Time: 0.197 (0.140)  Loss:  0.7661 (0.3820)  Acc@1: 75.0000 (94.1176)  Acc@5: 100.0000 (99.8058)\n",
            "Test: [ 950/2354]  Time: 0.183 (0.140)  Loss:  0.5630 (0.3840)  Acc@1: 100.0000 (94.2429)  Acc@5: 100.0000 (99.7897)\n",
            "Test: [1000/2354]  Time: 0.191 (0.140)  Loss:  0.1215 (0.3870)  Acc@1: 100.0000 (94.1558)  Acc@5: 100.0000 (99.8002)\n",
            "Test: [1050/2354]  Time: 0.143 (0.140)  Loss:  0.2158 (0.3841)  Acc@1: 100.0000 (94.1960)  Acc@5: 100.0000 (99.8097)\n",
            "Test: [1100/2354]  Time: 0.159 (0.140)  Loss:  0.3057 (0.3896)  Acc@1: 100.0000 (94.0509)  Acc@5: 100.0000 (99.8183)\n",
            "Test: [1150/2354]  Time: 0.154 (0.140)  Loss:  0.8877 (0.3879)  Acc@1: 100.0000 (94.1138)  Acc@5: 100.0000 (99.8045)\n",
            "Test: [1200/2354]  Time: 0.169 (0.139)  Loss:  0.4246 (0.3895)  Acc@1: 100.0000 (93.9842)  Acc@5: 100.0000 (99.7918)\n",
            "Test: [1250/2354]  Time: 0.082 (0.139)  Loss:  0.1930 (0.3851)  Acc@1: 100.0000 (94.1247)  Acc@5: 100.0000 (99.8002)\n",
            "Test: [1300/2354]  Time: 0.194 (0.139)  Loss:  0.0485 (0.3859)  Acc@1: 100.0000 (94.0430)  Acc@5: 100.0000 (99.8078)\n",
            "Test: [1350/2354]  Time: 0.172 (0.140)  Loss:  0.1041 (0.3830)  Acc@1: 100.0000 (94.2080)  Acc@5: 100.0000 (99.8150)\n",
            "Test: [1400/2354]  Time: 0.136 (0.140)  Loss:  0.1121 (0.3808)  Acc@1: 100.0000 (94.2541)  Acc@5: 100.0000 (99.8216)\n",
            "Test: [1450/2354]  Time: 0.127 (0.140)  Loss:  0.3215 (0.3785)  Acc@1: 100.0000 (94.2453)  Acc@5: 100.0000 (99.8105)\n",
            "Test: [1500/2354]  Time: 0.126 (0.140)  Loss:  0.1165 (0.3757)  Acc@1: 100.0000 (94.3538)  Acc@5: 100.0000 (99.8001)\n",
            "Test: [1550/2354]  Time: 0.176 (0.140)  Loss:  0.3359 (0.3820)  Acc@1: 100.0000 (94.1651)  Acc@5: 100.0000 (99.8066)\n",
            "Test: [1600/2354]  Time: 0.168 (0.140)  Loss:  0.3149 (0.3884)  Acc@1: 100.0000 (94.0194)  Acc@5: 100.0000 (99.7970)\n",
            "Test: [1650/2354]  Time: 0.189 (0.140)  Loss:  0.4495 (0.3906)  Acc@1: 100.0000 (94.0491)  Acc@5: 100.0000 (99.7880)\n",
            "Test: [1700/2354]  Time: 0.155 (0.140)  Loss:  0.1249 (0.3928)  Acc@1: 100.0000 (94.0623)  Acc@5: 100.0000 (99.7795)\n",
            "Test: [1750/2354]  Time: 0.105 (0.140)  Loss:  0.6611 (0.3964)  Acc@1: 100.0000 (93.9891)  Acc@5: 100.0000 (99.7858)\n",
            "Test: [1800/2354]  Time: 0.198 (0.140)  Loss:  0.4998 (0.3964)  Acc@1: 100.0000 (94.0172)  Acc@5: 100.0000 (99.7779)\n",
            "Test: [1850/2354]  Time: 0.095 (0.140)  Loss:  0.2146 (0.3964)  Acc@1: 100.0000 (94.0032)  Acc@5: 100.0000 (99.7704)\n",
            "Test: [1900/2354]  Time: 0.161 (0.140)  Loss:  0.3130 (0.3968)  Acc@1: 100.0000 (94.0295)  Acc@5: 100.0000 (99.7764)\n",
            "Test: [1950/2354]  Time: 0.152 (0.140)  Loss:  0.1351 (0.3942)  Acc@1: 100.0000 (94.0543)  Acc@5: 100.0000 (99.7693)\n",
            "Test: [2000/2354]  Time: 0.189 (0.140)  Loss:  0.3530 (0.3941)  Acc@1: 100.0000 (94.1029)  Acc@5: 100.0000 (99.7751)\n",
            "Test: [2050/2354]  Time: 0.181 (0.140)  Loss:  0.6646 (0.4021)  Acc@1: 75.0000 (93.6616)  Acc@5: 100.0000 (99.7440)\n",
            "Test: [2100/2354]  Time: 0.159 (0.140)  Loss:  0.7373 (0.4076)  Acc@1: 75.0000 (93.5507)  Acc@5: 100.0000 (99.7501)\n",
            "Test: [2150/2354]  Time: 0.187 (0.140)  Loss:  0.9404 (0.4136)  Acc@1: 75.0000 (93.4565)  Acc@5: 100.0000 (99.7559)\n",
            "Test: [2200/2354]  Time: 0.134 (0.140)  Loss:  0.9214 (0.4208)  Acc@1: 100.0000 (93.2417)  Acc@5: 100.0000 (99.7615)\n",
            "Test: [2250/2354]  Time: 0.188 (0.140)  Loss:  0.0581 (0.4187)  Acc@1: 100.0000 (93.3252)  Acc@5: 100.0000 (99.7668)\n",
            "Test: [2300/2354]  Time: 0.124 (0.140)  Loss:  0.1506 (0.4174)  Acc@1: 100.0000 (93.3942)  Acc@5: 100.0000 (99.7501)\n",
            "Test: [2350/2354]  Time: 0.075 (0.140)  Loss:  1.1172 (0.4170)  Acc@1: 100.0000 (93.4177)  Acc@5: 100.0000 (99.7554)\n",
            "Test: [2354/2354]  Time: 0.064 (0.140)  Loss:  0.0634 (0.4168)  Acc@1: 100.0000 (93.4282)  Acc@5: 100.0000 (99.7558)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-16.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar', 88.66121668966981)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar', 83.87302261386559)\n",
            "\n",
            "Train: 26 [   0/2354 (  0%)]  Loss: 2.980 (2.98)  Time: 1.336s,    5.99/s  (1.336s,    5.99/s)  LR: 7.636e-05  Data: 0.489 (0.489)\n",
            "Train: 26 [  50/2354 (  2%)]  Loss: 2.343 (1.99)  Time: 0.469s,   17.07/s  (0.503s,   15.90/s)  LR: 7.636e-05  Data: 0.007 (0.017)\n",
            "Train: 26 [ 100/2354 (  4%)]  Loss: 1.793 (1.93)  Time: 0.459s,   17.41/s  (0.485s,   16.51/s)  LR: 7.636e-05  Data: 0.007 (0.012)\n",
            "Train: 26 [ 150/2354 (  6%)]  Loss: 1.845 (1.92)  Time: 0.465s,   17.20/s  (0.484s,   16.53/s)  LR: 7.636e-05  Data: 0.009 (0.011)\n",
            "Train: 26 [ 200/2354 (  8%)]  Loss: 2.638 (1.88)  Time: 0.459s,   17.43/s  (0.479s,   16.69/s)  LR: 7.636e-05  Data: 0.006 (0.010)\n",
            "Train: 26 [ 250/2354 ( 11%)]  Loss: 1.630 (1.88)  Time: 0.469s,   17.04/s  (0.477s,   16.78/s)  LR: 7.636e-05  Data: 0.007 (0.010)\n",
            "Train: 26 [ 300/2354 ( 13%)]  Loss: 2.343 (1.91)  Time: 0.466s,   17.17/s  (0.475s,   16.85/s)  LR: 7.636e-05  Data: 0.007 (0.009)\n",
            "Train: 26 [ 350/2354 ( 15%)]  Loss: 2.580 (1.89)  Time: 0.464s,   17.24/s  (0.476s,   16.82/s)  LR: 7.636e-05  Data: 0.007 (0.009)\n",
            "Train: 26 [ 400/2354 ( 17%)]  Loss: 1.260 (1.91)  Time: 0.463s,   17.28/s  (0.475s,   16.86/s)  LR: 7.636e-05  Data: 0.007 (0.009)\n",
            "Train: 26 [ 450/2354 ( 19%)]  Loss: 3.147 (1.91)  Time: 0.462s,   17.31/s  (0.473s,   16.90/s)  LR: 7.636e-05  Data: 0.007 (0.009)\n",
            "Train: 26 [ 500/2354 ( 21%)]  Loss: 2.862 (1.91)  Time: 0.462s,   17.30/s  (0.473s,   16.93/s)  LR: 7.636e-05  Data: 0.008 (0.009)\n",
            "Train: 26 [ 550/2354 ( 23%)]  Loss: 1.794 (1.91)  Time: 0.464s,   17.25/s  (0.474s,   16.89/s)  LR: 7.636e-05  Data: 0.007 (0.009)\n",
            "Train: 26 [ 600/2354 ( 25%)]  Loss: 1.505 (1.91)  Time: 0.476s,   16.81/s  (0.473s,   16.91/s)  LR: 7.636e-05  Data: 0.009 (0.009)\n",
            "Train: 26 [ 650/2354 ( 28%)]  Loss: 2.722 (1.90)  Time: 0.466s,   17.18/s  (0.472s,   16.94/s)  LR: 7.636e-05  Data: 0.010 (0.009)\n",
            "Train: 26 [ 700/2354 ( 30%)]  Loss: 2.431 (1.90)  Time: 0.469s,   17.04/s  (0.472s,   16.95/s)  LR: 7.636e-05  Data: 0.008 (0.008)\n",
            "Train: 26 [ 750/2354 ( 32%)]  Loss: 1.983 (1.91)  Time: 0.528s,   15.15/s  (0.473s,   16.93/s)  LR: 7.636e-05  Data: 0.013 (0.008)\n",
            "Train: 26 [ 800/2354 ( 34%)]  Loss: 1.838 (1.92)  Time: 0.460s,   17.40/s  (0.472s,   16.94/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [ 850/2354 ( 36%)]  Loss: 2.539 (1.93)  Time: 0.460s,   17.40/s  (0.472s,   16.96/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [ 900/2354 ( 38%)]  Loss: 1.570 (1.92)  Time: 0.461s,   17.36/s  (0.471s,   16.97/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [ 950/2354 ( 40%)]  Loss: 1.183 (1.92)  Time: 0.481s,   16.64/s  (0.471s,   16.98/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [1000/2354 ( 42%)]  Loss: 2.990 (1.92)  Time: 0.465s,   17.20/s  (0.472s,   16.96/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [1050/2354 ( 45%)]  Loss: 1.164 (1.92)  Time: 0.477s,   16.78/s  (0.472s,   16.97/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [1100/2354 ( 47%)]  Loss: 1.899 (1.93)  Time: 0.460s,   17.39/s  (0.471s,   16.98/s)  LR: 7.636e-05  Data: 0.006 (0.008)\n",
            "Train: 26 [1150/2354 ( 49%)]  Loss: 1.082 (1.93)  Time: 0.459s,   17.41/s  (0.471s,   16.99/s)  LR: 7.636e-05  Data: 0.008 (0.008)\n",
            "Train: 26 [1200/2354 ( 51%)]  Loss: 2.959 (1.93)  Time: 0.468s,   17.08/s  (0.471s,   16.97/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [1250/2354 ( 53%)]  Loss: 1.586 (1.93)  Time: 0.462s,   17.33/s  (0.471s,   16.98/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [1300/2354 ( 55%)]  Loss: 1.042 (1.93)  Time: 0.477s,   16.77/s  (0.471s,   16.99/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [1350/2354 ( 57%)]  Loss: 1.714 (1.93)  Time: 0.464s,   17.23/s  (0.471s,   17.00/s)  LR: 7.636e-05  Data: 0.006 (0.008)\n",
            "Train: 26 [1400/2354 ( 59%)]  Loss: 2.744 (1.93)  Time: 0.477s,   16.77/s  (0.471s,   16.98/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [1450/2354 ( 62%)]  Loss: 1.142 (1.93)  Time: 0.459s,   17.42/s  (0.471s,   16.99/s)  LR: 7.636e-05  Data: 0.006 (0.008)\n",
            "Train: 26 [1500/2354 ( 64%)]  Loss: 2.975 (1.93)  Time: 0.461s,   17.36/s  (0.471s,   17.00/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [1550/2354 ( 66%)]  Loss: 2.134 (1.94)  Time: 0.469s,   17.06/s  (0.471s,   17.00/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [1600/2354 ( 68%)]  Loss: 1.916 (1.94)  Time: 0.460s,   17.39/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.006 (0.008)\n",
            "Train: 26 [1650/2354 ( 70%)]  Loss: 2.120 (1.94)  Time: 0.474s,   16.86/s  (0.471s,   17.00/s)  LR: 7.636e-05  Data: 0.008 (0.008)\n",
            "Train: 26 [1700/2354 ( 72%)]  Loss: 1.400 (1.94)  Time: 0.464s,   17.23/s  (0.471s,   17.00/s)  LR: 7.636e-05  Data: 0.006 (0.008)\n",
            "Train: 26 [1750/2354 ( 74%)]  Loss: 1.167 (1.94)  Time: 0.475s,   16.85/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [1800/2354 ( 76%)]  Loss: 2.705 (1.94)  Time: 0.461s,   17.36/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.006 (0.008)\n",
            "Train: 26 [1850/2354 ( 79%)]  Loss: 2.953 (1.94)  Time: 0.469s,   17.07/s  (0.471s,   17.00/s)  LR: 7.636e-05  Data: 0.010 (0.008)\n",
            "Train: 26 [1900/2354 ( 81%)]  Loss: 2.685 (1.94)  Time: 0.462s,   17.32/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [1950/2354 ( 83%)]  Loss: 2.282 (1.95)  Time: 0.462s,   17.33/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [2000/2354 ( 85%)]  Loss: 1.621 (1.95)  Time: 0.469s,   17.05/s  (0.470s,   17.02/s)  LR: 7.636e-05  Data: 0.010 (0.008)\n",
            "Train: 26 [2050/2354 ( 87%)]  Loss: 1.617 (1.95)  Time: 0.466s,   17.16/s  (0.471s,   17.00/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [2100/2354 ( 89%)]  Loss: 1.170 (1.95)  Time: 0.463s,   17.26/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [2150/2354 ( 91%)]  Loss: 1.377 (1.95)  Time: 0.466s,   17.17/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.010 (0.008)\n",
            "Train: 26 [2200/2354 ( 93%)]  Loss: 2.596 (1.95)  Time: 0.461s,   17.34/s  (0.470s,   17.02/s)  LR: 7.636e-05  Data: 0.010 (0.008)\n",
            "Train: 26 [2250/2354 ( 96%)]  Loss: 1.153 (1.95)  Time: 0.551s,   14.52/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.007 (0.008)\n",
            "Train: 26 [2300/2354 ( 98%)]  Loss: 1.148 (1.95)  Time: 0.462s,   17.32/s  (0.470s,   17.01/s)  LR: 7.636e-05  Data: 0.009 (0.008)\n",
            "Train: 26 [2350/2354 (100%)]  Loss: 2.248 (1.95)  Time: 0.461s,   17.35/s  (0.470s,   17.02/s)  LR: 7.636e-05  Data: 0.006 (0.008)\n",
            "Train: 26 [2353/2354 (100%)]  Loss: 1.648 (1.95)  Time: 0.456s,   17.54/s  (0.470s,   17.02/s)  LR: 7.636e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.627 (0.627)  Loss:  0.3494 (0.3494)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.117 (0.150)  Loss:  1.1904 (0.2935)  Acc@1: 50.0000 (96.0784)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.166 (0.143)  Loss:  0.5952 (0.3346)  Acc@1: 100.0000 (95.7921)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.168 (0.141)  Loss:  0.3911 (0.4174)  Acc@1: 100.0000 (91.3907)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.077 (0.139)  Loss:  1.2812 (0.3915)  Acc@1: 50.0000 (92.1642)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.149 (0.139)  Loss:  0.1641 (0.3972)  Acc@1: 100.0000 (92.3307)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.088 (0.138)  Loss:  0.5762 (0.3870)  Acc@1: 100.0000 (92.9402)  Acc@5: 100.0000 (99.9169)\n",
            "Test: [ 350/2354]  Time: 0.187 (0.138)  Loss:  0.3298 (0.4098)  Acc@1: 100.0000 (92.3789)  Acc@5: 100.0000 (99.8575)\n",
            "Test: [ 400/2354]  Time: 0.079 (0.142)  Loss:  0.0576 (0.4226)  Acc@1: 100.0000 (92.1446)  Acc@5: 100.0000 (99.8753)\n",
            "Test: [ 450/2354]  Time: 0.105 (0.141)  Loss:  0.1033 (0.4069)  Acc@1: 100.0000 (92.7938)  Acc@5: 100.0000 (99.8891)\n",
            "Test: [ 500/2354]  Time: 0.176 (0.141)  Loss:  0.7354 (0.3975)  Acc@1: 100.0000 (93.1138)  Acc@5: 100.0000 (99.9002)\n",
            "Test: [ 550/2354]  Time: 0.100 (0.140)  Loss:  0.6694 (0.3954)  Acc@1: 100.0000 (93.4211)  Acc@5: 100.0000 (99.9093)\n",
            "Test: [ 600/2354]  Time: 0.182 (0.141)  Loss:  0.0553 (0.3795)  Acc@1: 100.0000 (93.8020)  Acc@5: 100.0000 (99.8336)\n",
            "Test: [ 650/2354]  Time: 0.082 (0.140)  Loss:  0.1570 (0.3670)  Acc@1: 100.0000 (94.1244)  Acc@5: 100.0000 (99.8080)\n",
            "Test: [ 700/2354]  Time: 0.142 (0.140)  Loss:  0.1758 (0.3548)  Acc@1: 100.0000 (94.4722)  Acc@5: 100.0000 (99.8217)\n",
            "Test: [ 750/2354]  Time: 0.090 (0.140)  Loss:  1.1221 (0.3564)  Acc@1: 75.0000 (94.3742)  Acc@5: 100.0000 (99.8003)\n",
            "Test: [ 800/2354]  Time: 0.090 (0.140)  Loss:  0.0861 (0.3620)  Acc@1: 100.0000 (94.2572)  Acc@5: 100.0000 (99.8127)\n",
            "Test: [ 850/2354]  Time: 0.101 (0.140)  Loss:  0.3477 (0.3663)  Acc@1: 100.0000 (94.1539)  Acc@5: 100.0000 (99.8237)\n",
            "Test: [ 900/2354]  Time: 0.143 (0.140)  Loss:  0.7476 (0.3618)  Acc@1: 75.0000 (94.3674)  Acc@5: 100.0000 (99.8335)\n",
            "Test: [ 950/2354]  Time: 0.117 (0.140)  Loss:  0.3474 (0.3584)  Acc@1: 100.0000 (94.5584)  Acc@5: 100.0000 (99.8423)\n",
            "Test: [1000/2354]  Time: 0.102 (0.140)  Loss:  0.1072 (0.3551)  Acc@1: 100.0000 (94.6553)  Acc@5: 100.0000 (99.8501)\n",
            "Test: [1050/2354]  Time: 0.119 (0.140)  Loss:  0.3896 (0.3514)  Acc@1: 75.0000 (94.7193)  Acc@5: 100.0000 (99.8573)\n",
            "Test: [1100/2354]  Time: 0.235 (0.140)  Loss:  0.1718 (0.3527)  Acc@1: 100.0000 (94.7094)  Acc@5: 100.0000 (99.8411)\n",
            "Test: [1150/2354]  Time: 0.122 (0.141)  Loss:  1.4893 (0.3487)  Acc@1: 50.0000 (94.8089)  Acc@5: 100.0000 (99.8262)\n",
            "Test: [1200/2354]  Time: 0.099 (0.141)  Loss:  0.5757 (0.3546)  Acc@1: 100.0000 (94.5046)  Acc@5: 100.0000 (99.7918)\n",
            "Test: [1250/2354]  Time: 0.156 (0.141)  Loss:  0.0992 (0.3512)  Acc@1: 100.0000 (94.6043)  Acc@5: 100.0000 (99.8002)\n",
            "Test: [1300/2354]  Time: 0.099 (0.141)  Loss:  0.1268 (0.3516)  Acc@1: 100.0000 (94.6387)  Acc@5: 100.0000 (99.7694)\n",
            "Test: [1350/2354]  Time: 0.163 (0.140)  Loss:  0.0194 (0.3489)  Acc@1: 100.0000 (94.8001)  Acc@5: 100.0000 (99.7779)\n",
            "Test: [1400/2354]  Time: 0.125 (0.140)  Loss:  0.2781 (0.3456)  Acc@1: 100.0000 (94.9143)  Acc@5: 100.0000 (99.7680)\n",
            "Test: [1450/2354]  Time: 0.119 (0.140)  Loss:  0.2988 (0.3436)  Acc@1: 100.0000 (95.0207)  Acc@5: 100.0000 (99.7588)\n",
            "Test: [1500/2354]  Time: 0.096 (0.140)  Loss:  0.0986 (0.3412)  Acc@1: 100.0000 (95.1033)  Acc@5: 100.0000 (99.7502)\n",
            "Test: [1550/2354]  Time: 0.175 (0.140)  Loss:  0.1592 (0.3503)  Acc@1: 100.0000 (94.6970)  Acc@5: 100.0000 (99.7582)\n",
            "Test: [1600/2354]  Time: 0.157 (0.140)  Loss:  0.2396 (0.3537)  Acc@1: 100.0000 (94.5971)  Acc@5: 100.0000 (99.7502)\n",
            "Test: [1650/2354]  Time: 0.169 (0.140)  Loss:  0.1565 (0.3587)  Acc@1: 100.0000 (94.3973)  Acc@5: 100.0000 (99.7426)\n",
            "Test: [1700/2354]  Time: 0.099 (0.140)  Loss:  0.1537 (0.3587)  Acc@1: 100.0000 (94.4297)  Acc@5: 100.0000 (99.7208)\n",
            "Test: [1750/2354]  Time: 0.079 (0.140)  Loss:  0.2974 (0.3608)  Acc@1: 100.0000 (94.3604)  Acc@5: 100.0000 (99.7287)\n",
            "Test: [1800/2354]  Time: 0.165 (0.140)  Loss:  0.4355 (0.3604)  Acc@1: 100.0000 (94.4336)  Acc@5: 100.0000 (99.7085)\n",
            "Test: [1850/2354]  Time: 0.133 (0.140)  Loss:  1.1133 (0.3638)  Acc@1: 50.0000 (94.3004)  Acc@5: 100.0000 (99.7029)\n",
            "Test: [1900/2354]  Time: 0.166 (0.140)  Loss:  0.3535 (0.3653)  Acc@1: 100.0000 (94.2793)  Acc@5: 100.0000 (99.7107)\n",
            "Test: [1950/2354]  Time: 0.082 (0.140)  Loss:  0.7822 (0.3657)  Acc@1: 75.0000 (94.3106)  Acc@5: 100.0000 (99.6925)\n",
            "Test: [2000/2354]  Time: 0.085 (0.140)  Loss:  0.1157 (0.3633)  Acc@1: 100.0000 (94.4028)  Acc@5: 100.0000 (99.7001)\n",
            "Test: [2050/2354]  Time: 0.148 (0.140)  Loss:  0.4038 (0.3714)  Acc@1: 100.0000 (93.9542)  Acc@5: 100.0000 (99.6709)\n",
            "Test: [2100/2354]  Time: 0.152 (0.140)  Loss:  0.3872 (0.3744)  Acc@1: 100.0000 (93.8244)  Acc@5: 100.0000 (99.6668)\n",
            "Test: [2150/2354]  Time: 0.117 (0.140)  Loss:  1.4414 (0.3813)  Acc@1: 50.0000 (93.5263)  Acc@5: 100.0000 (99.6629)\n",
            "Test: [2200/2354]  Time: 0.106 (0.140)  Loss:  0.1813 (0.3869)  Acc@1: 100.0000 (93.3780)  Acc@5: 100.0000 (99.6706)\n",
            "Test: [2250/2354]  Time: 0.122 (0.140)  Loss:  0.0616 (0.3843)  Acc@1: 100.0000 (93.4807)  Acc@5: 100.0000 (99.6779)\n",
            "Test: [2300/2354]  Time: 0.199 (0.140)  Loss:  0.0524 (0.3827)  Acc@1: 100.0000 (93.5463)  Acc@5: 100.0000 (99.6741)\n",
            "Test: [2350/2354]  Time: 0.075 (0.139)  Loss:  0.4102 (0.3841)  Acc@1: 100.0000 (93.5028)  Acc@5: 100.0000 (99.6810)\n",
            "Test: [2354/2354]  Time: 0.070 (0.139)  Loss:  0.1083 (0.3842)  Acc@1: 100.0000 (93.4919)  Acc@5: 100.0000 (99.6815)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-15.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar', 88.66121668966981)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar', 86.42106380719822)\n",
            "\n",
            "Train: 27 [   0/2354 (  0%)]  Loss: 1.473 (1.47)  Time: 1.390s,    5.76/s  (1.390s,    5.76/s)  LR: 7.469e-05  Data: 0.775 (0.775)\n",
            "Train: 27 [  50/2354 (  2%)]  Loss: 1.188 (1.74)  Time: 0.464s,   17.24/s  (0.500s,   16.00/s)  LR: 7.469e-05  Data: 0.006 (0.023)\n",
            "Train: 27 [ 100/2354 (  4%)]  Loss: 1.646 (1.84)  Time: 0.469s,   17.07/s  (0.492s,   16.26/s)  LR: 7.469e-05  Data: 0.006 (0.015)\n",
            "Train: 27 [ 150/2354 (  6%)]  Loss: 1.093 (1.87)  Time: 0.461s,   17.35/s  (0.483s,   16.55/s)  LR: 7.469e-05  Data: 0.006 (0.013)\n",
            "Train: 27 [ 200/2354 (  8%)]  Loss: 2.127 (1.90)  Time: 0.464s,   17.26/s  (0.480s,   16.68/s)  LR: 7.469e-05  Data: 0.008 (0.012)\n",
            "Train: 27 [ 250/2354 ( 11%)]  Loss: 1.062 (1.88)  Time: 0.470s,   17.02/s  (0.477s,   16.78/s)  LR: 7.469e-05  Data: 0.006 (0.011)\n",
            "Train: 27 [ 300/2354 ( 13%)]  Loss: 1.338 (1.87)  Time: 0.463s,   17.30/s  (0.478s,   16.75/s)  LR: 7.469e-05  Data: 0.006 (0.010)\n",
            "Train: 27 [ 350/2354 ( 15%)]  Loss: 2.319 (1.91)  Time: 0.460s,   17.38/s  (0.476s,   16.81/s)  LR: 7.469e-05  Data: 0.006 (0.010)\n",
            "Train: 27 [ 400/2354 ( 17%)]  Loss: 1.229 (1.91)  Time: 0.464s,   17.25/s  (0.475s,   16.85/s)  LR: 7.469e-05  Data: 0.006 (0.010)\n",
            "Train: 27 [ 450/2354 ( 19%)]  Loss: 1.500 (1.90)  Time: 0.469s,   17.07/s  (0.474s,   16.89/s)  LR: 7.469e-05  Data: 0.007 (0.009)\n",
            "Train: 27 [ 500/2354 ( 21%)]  Loss: 4.181 (1.91)  Time: 0.467s,   17.14/s  (0.475s,   16.86/s)  LR: 7.469e-05  Data: 0.010 (0.009)\n",
            "Train: 27 [ 550/2354 ( 23%)]  Loss: 2.193 (1.92)  Time: 0.463s,   17.28/s  (0.474s,   16.89/s)  LR: 7.469e-05  Data: 0.009 (0.009)\n",
            "Train: 27 [ 600/2354 ( 25%)]  Loss: 1.536 (1.91)  Time: 0.468s,   17.10/s  (0.473s,   16.91/s)  LR: 7.469e-05  Data: 0.009 (0.009)\n",
            "Train: 27 [ 650/2354 ( 28%)]  Loss: 1.727 (1.92)  Time: 0.463s,   17.29/s  (0.472s,   16.93/s)  LR: 7.469e-05  Data: 0.007 (0.009)\n",
            "Train: 27 [ 700/2354 ( 30%)]  Loss: 1.181 (1.91)  Time: 0.460s,   17.39/s  (0.472s,   16.95/s)  LR: 7.469e-05  Data: 0.006 (0.009)\n",
            "Train: 27 [ 750/2354 ( 32%)]  Loss: 1.479 (1.91)  Time: 0.464s,   17.24/s  (0.472s,   16.93/s)  LR: 7.469e-05  Data: 0.006 (0.009)\n",
            "Train: 27 [ 800/2354 ( 34%)]  Loss: 1.717 (1.91)  Time: 0.474s,   16.87/s  (0.472s,   16.94/s)  LR: 7.469e-05  Data: 0.014 (0.009)\n",
            "Train: 27 [ 850/2354 ( 36%)]  Loss: 2.033 (1.92)  Time: 0.474s,   16.89/s  (0.472s,   16.96/s)  LR: 7.469e-05  Data: 0.009 (0.009)\n",
            "Train: 27 [ 900/2354 ( 38%)]  Loss: 1.448 (1.91)  Time: 0.467s,   17.12/s  (0.471s,   16.97/s)  LR: 7.469e-05  Data: 0.007 (0.009)\n",
            "Train: 27 [ 950/2354 ( 40%)]  Loss: 1.920 (1.92)  Time: 0.462s,   17.31/s  (0.472s,   16.95/s)  LR: 7.469e-05  Data: 0.007 (0.009)\n",
            "Train: 27 [1000/2354 ( 42%)]  Loss: 1.463 (1.92)  Time: 0.460s,   17.37/s  (0.472s,   16.96/s)  LR: 7.469e-05  Data: 0.007 (0.009)\n",
            "Train: 27 [1050/2354 ( 45%)]  Loss: 2.117 (1.92)  Time: 0.468s,   17.08/s  (0.471s,   16.97/s)  LR: 7.469e-05  Data: 0.009 (0.009)\n",
            "Train: 27 [1100/2354 ( 47%)]  Loss: 1.245 (1.93)  Time: 0.475s,   16.86/s  (0.471s,   16.98/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1150/2354 ( 49%)]  Loss: 1.710 (1.93)  Time: 0.464s,   17.22/s  (0.472s,   16.96/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1200/2354 ( 51%)]  Loss: 1.285 (1.92)  Time: 0.461s,   17.33/s  (0.471s,   16.97/s)  LR: 7.469e-05  Data: 0.006 (0.008)\n",
            "Train: 27 [1250/2354 ( 53%)]  Loss: 1.780 (1.92)  Time: 0.463s,   17.27/s  (0.471s,   16.98/s)  LR: 7.469e-05  Data: 0.006 (0.008)\n",
            "Train: 27 [1300/2354 ( 55%)]  Loss: 2.200 (1.91)  Time: 0.469s,   17.07/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1350/2354 ( 57%)]  Loss: 2.234 (1.91)  Time: 0.460s,   17.39/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1400/2354 ( 59%)]  Loss: 1.527 (1.91)  Time: 0.469s,   17.07/s  (0.471s,   16.97/s)  LR: 7.469e-05  Data: 0.009 (0.008)\n",
            "Train: 27 [1450/2354 ( 62%)]  Loss: 1.488 (1.91)  Time: 0.465s,   17.20/s  (0.471s,   16.98/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1500/2354 ( 64%)]  Loss: 2.542 (1.91)  Time: 0.464s,   17.26/s  (0.471s,   16.98/s)  LR: 7.469e-05  Data: 0.008 (0.008)\n",
            "Train: 27 [1550/2354 ( 66%)]  Loss: 2.422 (1.91)  Time: 0.466s,   17.17/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.009 (0.008)\n",
            "Train: 27 [1600/2354 ( 68%)]  Loss: 1.554 (1.91)  Time: 0.463s,   17.26/s  (0.471s,   16.98/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1650/2354 ( 70%)]  Loss: 2.235 (1.91)  Time: 0.463s,   17.29/s  (0.471s,   16.98/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1700/2354 ( 72%)]  Loss: 1.333 (1.91)  Time: 0.461s,   17.37/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1750/2354 ( 74%)]  Loss: 2.409 (1.91)  Time: 0.459s,   17.44/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1800/2354 ( 76%)]  Loss: 3.028 (1.91)  Time: 0.537s,   14.88/s  (0.471s,   16.98/s)  LR: 7.469e-05  Data: 0.013 (0.008)\n",
            "Train: 27 [1850/2354 ( 79%)]  Loss: 1.736 (1.91)  Time: 0.463s,   17.29/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1900/2354 ( 81%)]  Loss: 1.283 (1.91)  Time: 0.487s,   16.42/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [1950/2354 ( 83%)]  Loss: 2.088 (1.91)  Time: 0.468s,   17.09/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.006 (0.008)\n",
            "Train: 27 [2000/2354 ( 85%)]  Loss: 2.308 (1.91)  Time: 0.463s,   17.26/s  (0.471s,   17.00/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [2050/2354 ( 87%)]  Loss: 1.714 (1.91)  Time: 0.472s,   16.95/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [2100/2354 ( 89%)]  Loss: 1.552 (1.91)  Time: 0.458s,   17.46/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.006 (0.008)\n",
            "Train: 27 [2150/2354 ( 91%)]  Loss: 1.039 (1.91)  Time: 0.463s,   17.28/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [2200/2354 ( 93%)]  Loss: 1.969 (1.91)  Time: 0.473s,   16.92/s  (0.471s,   17.00/s)  LR: 7.469e-05  Data: 0.006 (0.008)\n",
            "Train: 27 [2250/2354 ( 96%)]  Loss: 1.429 (1.92)  Time: 0.462s,   17.31/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [2300/2354 ( 98%)]  Loss: 2.905 (1.92)  Time: 0.464s,   17.25/s  (0.471s,   16.99/s)  LR: 7.469e-05  Data: 0.007 (0.008)\n",
            "Train: 27 [2350/2354 (100%)]  Loss: 2.326 (1.92)  Time: 0.459s,   17.41/s  (0.471s,   17.00/s)  LR: 7.469e-05  Data: 0.005 (0.008)\n",
            "Train: 27 [2353/2354 (100%)]  Loss: 2.088 (1.92)  Time: 0.457s,   17.50/s  (0.471s,   17.00/s)  LR: 7.469e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.679 (0.679)  Loss:  0.2330 (0.2330)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.131 (0.156)  Loss:  1.0771 (0.3319)  Acc@1: 75.0000 (97.5490)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.104 (0.146)  Loss:  0.8955 (0.3552)  Acc@1: 100.0000 (94.8020)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.225 (0.143)  Loss:  0.1833 (0.3602)  Acc@1: 100.0000 (94.2053)  Acc@5: 100.0000 (99.8344)\n",
            "Test: [ 200/2354]  Time: 0.109 (0.141)  Loss:  0.7158 (0.3442)  Acc@1: 100.0000 (94.6517)  Acc@5: 100.0000 (99.8756)\n",
            "Test: [ 250/2354]  Time: 0.103 (0.141)  Loss:  0.1803 (0.3639)  Acc@1: 100.0000 (94.6215)  Acc@5: 100.0000 (99.9004)\n",
            "Test: [ 300/2354]  Time: 0.164 (0.140)  Loss:  0.4807 (0.3640)  Acc@1: 100.0000 (94.7674)  Acc@5: 100.0000 (99.7508)\n",
            "Test: [ 350/2354]  Time: 0.125 (0.145)  Loss:  0.8394 (0.4074)  Acc@1: 50.0000 (92.4501)  Acc@5: 100.0000 (99.7863)\n",
            "Test: [ 400/2354]  Time: 0.199 (0.144)  Loss:  0.3577 (0.4079)  Acc@1: 100.0000 (92.2070)  Acc@5: 100.0000 (99.8130)\n",
            "Test: [ 450/2354]  Time: 0.112 (0.143)  Loss:  0.1898 (0.3980)  Acc@1: 100.0000 (92.6275)  Acc@5: 100.0000 (99.7783)\n",
            "Test: [ 500/2354]  Time: 0.189 (0.142)  Loss:  0.7534 (0.3931)  Acc@1: 100.0000 (92.8643)  Acc@5: 100.0000 (99.8004)\n",
            "Test: [ 550/2354]  Time: 0.147 (0.142)  Loss:  0.5693 (0.3971)  Acc@1: 75.0000 (92.8312)  Acc@5: 100.0000 (99.8185)\n",
            "Test: [ 600/2354]  Time: 0.130 (0.142)  Loss:  0.4038 (0.3849)  Acc@1: 100.0000 (93.3028)  Acc@5: 100.0000 (99.8336)\n",
            "Test: [ 650/2354]  Time: 0.216 (0.141)  Loss:  0.1727 (0.3722)  Acc@1: 100.0000 (93.5868)  Acc@5: 100.0000 (99.8080)\n",
            "Test: [ 700/2354]  Time: 0.111 (0.141)  Loss:  0.0634 (0.3579)  Acc@1: 100.0000 (94.0086)  Acc@5: 100.0000 (99.7860)\n",
            "Test: [ 750/2354]  Time: 0.080 (0.141)  Loss:  1.0947 (0.3583)  Acc@1: 75.0000 (93.9414)  Acc@5: 100.0000 (99.8003)\n",
            "Test: [ 800/2354]  Time: 0.131 (0.141)  Loss:  0.0818 (0.3585)  Acc@1: 100.0000 (93.7578)  Acc@5: 100.0000 (99.8127)\n",
            "Test: [ 850/2354]  Time: 0.125 (0.141)  Loss:  0.2935 (0.3575)  Acc@1: 100.0000 (93.9189)  Acc@5: 100.0000 (99.8237)\n",
            "Test: [ 900/2354]  Time: 0.111 (0.141)  Loss:  0.7236 (0.3521)  Acc@1: 100.0000 (94.1454)  Acc@5: 100.0000 (99.8335)\n",
            "Test: [ 950/2354]  Time: 0.139 (0.141)  Loss:  0.4507 (0.3478)  Acc@1: 100.0000 (94.3218)  Acc@5: 100.0000 (99.8423)\n",
            "Test: [1000/2354]  Time: 0.152 (0.141)  Loss:  0.1375 (0.3484)  Acc@1: 100.0000 (94.3556)  Acc@5: 100.0000 (99.8501)\n",
            "Test: [1050/2354]  Time: 0.181 (0.142)  Loss:  0.3606 (0.3487)  Acc@1: 100.0000 (94.3149)  Acc@5: 100.0000 (99.8573)\n",
            "Test: [1100/2354]  Time: 0.093 (0.142)  Loss:  0.0613 (0.3462)  Acc@1: 100.0000 (94.4596)  Acc@5: 100.0000 (99.8638)\n",
            "Test: [1150/2354]  Time: 0.121 (0.141)  Loss:  0.9985 (0.3402)  Acc@1: 100.0000 (94.6568)  Acc@5: 100.0000 (99.8480)\n",
            "Test: [1200/2354]  Time: 0.157 (0.142)  Loss:  0.3752 (0.3426)  Acc@1: 100.0000 (94.6087)  Acc@5: 100.0000 (99.8543)\n",
            "Test: [1250/2354]  Time: 0.172 (0.141)  Loss:  0.2158 (0.3400)  Acc@1: 100.0000 (94.7042)  Acc@5: 100.0000 (99.8401)\n",
            "Test: [1300/2354]  Time: 0.184 (0.141)  Loss:  0.2147 (0.3550)  Acc@1: 100.0000 (94.1776)  Acc@5: 100.0000 (99.8078)\n",
            "Test: [1350/2354]  Time: 0.165 (0.141)  Loss:  0.0571 (0.3503)  Acc@1: 100.0000 (94.3190)  Acc@5: 100.0000 (99.8150)\n",
            "Test: [1400/2354]  Time: 0.118 (0.141)  Loss:  0.1550 (0.3509)  Acc@1: 100.0000 (94.3255)  Acc@5: 100.0000 (99.8216)\n",
            "Test: [1450/2354]  Time: 0.126 (0.141)  Loss:  0.1313 (0.3471)  Acc@1: 100.0000 (94.4349)  Acc@5: 100.0000 (99.8277)\n",
            "Test: [1500/2354]  Time: 0.100 (0.141)  Loss:  0.0848 (0.3465)  Acc@1: 100.0000 (94.4037)  Acc@5: 100.0000 (99.8168)\n",
            "Test: [1550/2354]  Time: 0.086 (0.141)  Loss:  0.4534 (0.3544)  Acc@1: 75.0000 (94.1651)  Acc@5: 100.0000 (99.8227)\n",
            "Test: [1600/2354]  Time: 0.198 (0.141)  Loss:  0.1838 (0.3614)  Acc@1: 100.0000 (93.9413)  Acc@5: 100.0000 (99.8126)\n",
            "Test: [1650/2354]  Time: 0.085 (0.140)  Loss:  0.1284 (0.3659)  Acc@1: 100.0000 (93.8522)  Acc@5: 100.0000 (99.8031)\n",
            "Test: [1700/2354]  Time: 0.152 (0.140)  Loss:  0.2118 (0.3657)  Acc@1: 100.0000 (93.9300)  Acc@5: 100.0000 (99.7795)\n",
            "Test: [1750/2354]  Time: 0.161 (0.140)  Loss:  0.4353 (0.3722)  Acc@1: 100.0000 (93.7607)  Acc@5: 100.0000 (99.7858)\n",
            "Test: [1800/2354]  Time: 0.142 (0.141)  Loss:  0.3672 (0.3703)  Acc@1: 100.0000 (93.8368)  Acc@5: 100.0000 (99.7779)\n",
            "Test: [1850/2354]  Time: 0.169 (0.141)  Loss:  0.1562 (0.3672)  Acc@1: 100.0000 (93.9357)  Acc@5: 100.0000 (99.7704)\n",
            "Test: [1900/2354]  Time: 0.172 (0.141)  Loss:  0.8506 (0.3654)  Acc@1: 75.0000 (93.9637)  Acc@5: 100.0000 (99.7633)\n",
            "Test: [1950/2354]  Time: 0.173 (0.141)  Loss:  0.2922 (0.3628)  Acc@1: 100.0000 (94.0415)  Acc@5: 100.0000 (99.7693)\n",
            "Test: [2000/2354]  Time: 0.143 (0.141)  Loss:  0.2225 (0.3611)  Acc@1: 100.0000 (94.1654)  Acc@5: 100.0000 (99.7751)\n",
            "Test: [2050/2354]  Time: 0.159 (0.141)  Loss:  0.5693 (0.3714)  Acc@1: 100.0000 (93.8810)  Acc@5: 100.0000 (99.7075)\n",
            "Test: [2100/2354]  Time: 0.119 (0.141)  Loss:  1.0518 (0.3787)  Acc@1: 50.0000 (93.6459)  Acc@5: 100.0000 (99.6787)\n",
            "Test: [2150/2354]  Time: 0.114 (0.140)  Loss:  0.4260 (0.3820)  Acc@1: 100.0000 (93.5728)  Acc@5: 100.0000 (99.6862)\n",
            "Test: [2200/2354]  Time: 0.174 (0.140)  Loss:  0.1758 (0.3921)  Acc@1: 100.0000 (93.1736)  Acc@5: 100.0000 (99.6706)\n",
            "Test: [2250/2354]  Time: 0.162 (0.140)  Loss:  0.0541 (0.3922)  Acc@1: 100.0000 (93.2141)  Acc@5: 100.0000 (99.6668)\n",
            "Test: [2300/2354]  Time: 0.170 (0.140)  Loss:  0.1245 (0.3902)  Acc@1: 100.0000 (93.2747)  Acc@5: 100.0000 (99.6632)\n",
            "Test: [2350/2354]  Time: 0.075 (0.140)  Loss:  0.1597 (0.3891)  Acc@1: 100.0000 (93.3645)  Acc@5: 100.0000 (99.6704)\n",
            "Test: [2354/2354]  Time: 0.064 (0.140)  Loss:  0.0663 (0.3889)  Acc@1: 100.0000 (93.3751)  Acc@5: 100.0000 (99.6709)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-17.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar', 93.37509289733518)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar', 88.66121668966981)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar', 86.90943836925364)\n",
            "\n",
            "Train: 28 [   0/2354 (  0%)]  Loss: 2.160 (2.16)  Time: 1.317s,    6.08/s  (1.317s,    6.08/s)  LR: 7.297e-05  Data: 0.710 (0.710)\n",
            "Train: 28 [  50/2354 (  2%)]  Loss: 1.155 (1.76)  Time: 0.473s,   16.91/s  (0.517s,   15.47/s)  LR: 7.297e-05  Data: 0.007 (0.022)\n",
            "Train: 28 [ 100/2354 (  4%)]  Loss: 1.722 (1.92)  Time: 0.469s,   17.06/s  (0.491s,   16.29/s)  LR: 7.297e-05  Data: 0.010 (0.015)\n",
            "Train: 28 [ 150/2354 (  6%)]  Loss: 1.635 (1.86)  Time: 0.465s,   17.22/s  (0.483s,   16.57/s)  LR: 7.297e-05  Data: 0.010 (0.013)\n",
            "Train: 28 [ 200/2354 (  8%)]  Loss: 1.496 (1.83)  Time: 0.467s,   17.14/s  (0.478s,   16.73/s)  LR: 7.297e-05  Data: 0.009 (0.011)\n",
            "Train: 28 [ 250/2354 ( 11%)]  Loss: 1.304 (1.81)  Time: 0.461s,   17.34/s  (0.476s,   16.82/s)  LR: 7.297e-05  Data: 0.006 (0.011)\n",
            "Train: 28 [ 300/2354 ( 13%)]  Loss: 1.278 (1.82)  Time: 0.476s,   16.80/s  (0.477s,   16.77/s)  LR: 7.297e-05  Data: 0.009 (0.010)\n",
            "Train: 28 [ 350/2354 ( 15%)]  Loss: 1.886 (1.82)  Time: 0.466s,   17.16/s  (0.475s,   16.83/s)  LR: 7.297e-05  Data: 0.009 (0.010)\n",
            "Train: 28 [ 400/2354 ( 17%)]  Loss: 1.086 (1.82)  Time: 0.464s,   17.24/s  (0.474s,   16.87/s)  LR: 7.297e-05  Data: 0.011 (0.010)\n",
            "Train: 28 [ 450/2354 ( 19%)]  Loss: 1.358 (1.82)  Time: 0.467s,   17.12/s  (0.473s,   16.91/s)  LR: 7.297e-05  Data: 0.010 (0.009)\n",
            "Train: 28 [ 500/2354 ( 21%)]  Loss: 2.017 (1.81)  Time: 0.463s,   17.26/s  (0.474s,   16.88/s)  LR: 7.297e-05  Data: 0.010 (0.009)\n",
            "Train: 28 [ 550/2354 ( 23%)]  Loss: 1.489 (1.82)  Time: 0.471s,   16.99/s  (0.473s,   16.90/s)  LR: 7.297e-05  Data: 0.011 (0.009)\n",
            "Train: 28 [ 600/2354 ( 25%)]  Loss: 1.182 (1.82)  Time: 0.461s,   17.37/s  (0.473s,   16.93/s)  LR: 7.297e-05  Data: 0.008 (0.009)\n",
            "Train: 28 [ 650/2354 ( 28%)]  Loss: 1.757 (1.83)  Time: 0.468s,   17.09/s  (0.472s,   16.94/s)  LR: 7.297e-05  Data: 0.010 (0.009)\n",
            "Train: 28 [ 700/2354 ( 30%)]  Loss: 1.423 (1.83)  Time: 0.468s,   17.09/s  (0.473s,   16.91/s)  LR: 7.297e-05  Data: 0.008 (0.009)\n",
            "Train: 28 [ 750/2354 ( 32%)]  Loss: 1.760 (1.83)  Time: 0.460s,   17.39/s  (0.473s,   16.92/s)  LR: 7.297e-05  Data: 0.007 (0.009)\n",
            "Train: 28 [ 800/2354 ( 34%)]  Loss: 1.672 (1.84)  Time: 0.464s,   17.23/s  (0.472s,   16.94/s)  LR: 7.297e-05  Data: 0.007 (0.009)\n",
            "Train: 28 [ 850/2354 ( 36%)]  Loss: 1.613 (1.84)  Time: 0.460s,   17.37/s  (0.472s,   16.95/s)  LR: 7.297e-05  Data: 0.006 (0.009)\n",
            "Train: 28 [ 900/2354 ( 38%)]  Loss: 2.564 (1.83)  Time: 0.462s,   17.30/s  (0.472s,   16.96/s)  LR: 7.297e-05  Data: 0.007 (0.009)\n",
            "Train: 28 [ 950/2354 ( 40%)]  Loss: 1.298 (1.83)  Time: 0.459s,   17.44/s  (0.472s,   16.95/s)  LR: 7.297e-05  Data: 0.007 (0.009)\n",
            "Train: 28 [1000/2354 ( 42%)]  Loss: 3.281 (1.83)  Time: 0.468s,   17.09/s  (0.472s,   16.96/s)  LR: 7.297e-05  Data: 0.007 (0.009)\n",
            "Train: 28 [1050/2354 ( 45%)]  Loss: 2.112 (1.84)  Time: 0.473s,   16.90/s  (0.471s,   16.97/s)  LR: 7.297e-05  Data: 0.006 (0.009)\n",
            "Train: 28 [1100/2354 ( 47%)]  Loss: 1.723 (1.84)  Time: 0.461s,   17.37/s  (0.471s,   16.98/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1150/2354 ( 49%)]  Loss: 1.105 (1.84)  Time: 0.468s,   17.11/s  (0.472s,   16.97/s)  LR: 7.297e-05  Data: 0.008 (0.008)\n",
            "Train: 28 [1200/2354 ( 51%)]  Loss: 1.315 (1.84)  Time: 0.462s,   17.30/s  (0.471s,   16.98/s)  LR: 7.297e-05  Data: 0.006 (0.008)\n",
            "Train: 28 [1250/2354 ( 53%)]  Loss: 1.872 (1.84)  Time: 0.464s,   17.24/s  (0.471s,   16.98/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1300/2354 ( 55%)]  Loss: 2.028 (1.84)  Time: 0.457s,   17.52/s  (0.471s,   16.99/s)  LR: 7.297e-05  Data: 0.006 (0.008)\n",
            "Train: 28 [1350/2354 ( 57%)]  Loss: 2.445 (1.85)  Time: 0.465s,   17.19/s  (0.471s,   16.98/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1400/2354 ( 59%)]  Loss: 2.212 (1.85)  Time: 0.464s,   17.23/s  (0.471s,   16.98/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1450/2354 ( 62%)]  Loss: 1.636 (1.85)  Time: 0.459s,   17.43/s  (0.471s,   16.99/s)  LR: 7.297e-05  Data: 0.006 (0.008)\n",
            "Train: 28 [1500/2354 ( 64%)]  Loss: 1.301 (1.85)  Time: 0.464s,   17.24/s  (0.471s,   17.00/s)  LR: 7.297e-05  Data: 0.006 (0.008)\n",
            "Train: 28 [1550/2354 ( 66%)]  Loss: 3.432 (1.85)  Time: 0.467s,   17.11/s  (0.471s,   17.00/s)  LR: 7.297e-05  Data: 0.009 (0.008)\n",
            "Train: 28 [1600/2354 ( 68%)]  Loss: 1.195 (1.85)  Time: 0.464s,   17.24/s  (0.471s,   16.99/s)  LR: 7.297e-05  Data: 0.010 (0.008)\n",
            "Train: 28 [1650/2354 ( 70%)]  Loss: 1.167 (1.85)  Time: 0.459s,   17.45/s  (0.471s,   16.99/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1700/2354 ( 72%)]  Loss: 1.528 (1.85)  Time: 0.469s,   17.06/s  (0.471s,   17.00/s)  LR: 7.297e-05  Data: 0.006 (0.008)\n",
            "Train: 28 [1750/2354 ( 74%)]  Loss: 2.747 (1.85)  Time: 0.468s,   17.11/s  (0.470s,   17.00/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1800/2354 ( 76%)]  Loss: 1.915 (1.85)  Time: 0.459s,   17.41/s  (0.471s,   16.99/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1850/2354 ( 79%)]  Loss: 1.637 (1.86)  Time: 0.465s,   17.21/s  (0.471s,   17.00/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1900/2354 ( 81%)]  Loss: 2.032 (1.85)  Time: 0.460s,   17.37/s  (0.471s,   17.00/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [1950/2354 ( 83%)]  Loss: 1.853 (1.85)  Time: 0.463s,   17.28/s  (0.470s,   17.01/s)  LR: 7.297e-05  Data: 0.009 (0.008)\n",
            "Train: 28 [2000/2354 ( 85%)]  Loss: 3.254 (1.86)  Time: 0.484s,   16.53/s  (0.471s,   17.00/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [2050/2354 ( 87%)]  Loss: 3.946 (1.86)  Time: 0.465s,   17.20/s  (0.471s,   17.00/s)  LR: 7.297e-05  Data: 0.006 (0.008)\n",
            "Train: 28 [2100/2354 ( 89%)]  Loss: 3.387 (1.86)  Time: 0.466s,   17.16/s  (0.470s,   17.00/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [2150/2354 ( 91%)]  Loss: 1.334 (1.86)  Time: 0.464s,   17.25/s  (0.470s,   17.01/s)  LR: 7.297e-05  Data: 0.010 (0.008)\n",
            "Train: 28 [2200/2354 ( 93%)]  Loss: 1.864 (1.87)  Time: 0.482s,   16.60/s  (0.470s,   17.01/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [2250/2354 ( 96%)]  Loss: 1.204 (1.87)  Time: 0.460s,   17.37/s  (0.471s,   17.00/s)  LR: 7.297e-05  Data: 0.006 (0.008)\n",
            "Train: 28 [2300/2354 ( 98%)]  Loss: 1.367 (1.86)  Time: 0.462s,   17.33/s  (0.470s,   17.01/s)  LR: 7.297e-05  Data: 0.007 (0.008)\n",
            "Train: 28 [2350/2354 (100%)]  Loss: 1.089 (1.86)  Time: 0.457s,   17.50/s  (0.470s,   17.01/s)  LR: 7.297e-05  Data: 0.005 (0.008)\n",
            "Train: 28 [2353/2354 (100%)]  Loss: 1.400 (1.86)  Time: 0.453s,   17.67/s  (0.470s,   17.01/s)  LR: 7.297e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.638 (0.638)  Loss:  0.2213 (0.2213)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.183 (0.154)  Loss:  0.5283 (0.2413)  Acc@1: 100.0000 (98.5294)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.076 (0.144)  Loss:  0.1011 (0.3195)  Acc@1: 100.0000 (95.2970)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.171 (0.142)  Loss:  0.1239 (0.3530)  Acc@1: 100.0000 (95.1987)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.148 (0.141)  Loss:  0.4570 (0.3367)  Acc@1: 100.0000 (95.2736)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.176 (0.141)  Loss:  0.0595 (0.3275)  Acc@1: 100.0000 (95.6175)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.157 (0.146)  Loss:  0.4861 (0.3161)  Acc@1: 100.0000 (96.0133)  Acc@5: 100.0000 (99.9169)\n",
            "Test: [ 350/2354]  Time: 0.082 (0.144)  Loss:  0.1174 (0.3600)  Acc@1: 100.0000 (94.3732)  Acc@5: 100.0000 (99.9288)\n",
            "Test: [ 400/2354]  Time: 0.130 (0.144)  Loss:  0.2998 (0.3570)  Acc@1: 100.0000 (94.3267)  Acc@5: 100.0000 (99.9377)\n",
            "Test: [ 450/2354]  Time: 0.117 (0.143)  Loss:  0.1117 (0.3518)  Acc@1: 100.0000 (94.6231)  Acc@5: 100.0000 (99.8891)\n",
            "Test: [ 500/2354]  Time: 0.108 (0.142)  Loss:  0.2450 (0.3400)  Acc@1: 100.0000 (94.9102)  Acc@5: 100.0000 (99.9002)\n",
            "Test: [ 550/2354]  Time: 0.161 (0.142)  Loss:  0.4670 (0.3389)  Acc@1: 100.0000 (95.0091)  Acc@5: 100.0000 (99.9093)\n",
            "Test: [ 600/2354]  Time: 0.152 (0.142)  Loss:  0.2456 (0.3348)  Acc@1: 100.0000 (95.0915)  Acc@5: 100.0000 (99.8752)\n",
            "Test: [ 650/2354]  Time: 0.128 (0.141)  Loss:  0.0455 (0.3253)  Acc@1: 100.0000 (95.3533)  Acc@5: 100.0000 (99.8848)\n",
            "Test: [ 700/2354]  Time: 0.127 (0.141)  Loss:  0.1722 (0.3196)  Acc@1: 100.0000 (95.5777)  Acc@5: 100.0000 (99.8930)\n",
            "Test: [ 750/2354]  Time: 0.109 (0.141)  Loss:  0.4285 (0.3211)  Acc@1: 100.0000 (95.7057)  Acc@5: 100.0000 (99.9001)\n",
            "Test: [ 800/2354]  Time: 0.224 (0.141)  Loss:  0.0612 (0.3259)  Acc@1: 100.0000 (95.5056)  Acc@5: 100.0000 (99.9064)\n",
            "Test: [ 850/2354]  Time: 0.197 (0.141)  Loss:  0.3425 (0.3218)  Acc@1: 75.0000 (95.6228)  Acc@5: 100.0000 (99.9119)\n",
            "Test: [ 900/2354]  Time: 0.164 (0.140)  Loss:  0.5254 (0.3160)  Acc@1: 100.0000 (95.8102)  Acc@5: 100.0000 (99.9168)\n",
            "Test: [ 950/2354]  Time: 0.143 (0.140)  Loss:  0.1547 (0.3060)  Acc@1: 100.0000 (96.0042)  Acc@5: 100.0000 (99.9211)\n",
            "Test: [1000/2354]  Time: 0.234 (0.141)  Loss:  0.1591 (0.3060)  Acc@1: 100.0000 (96.0290)  Acc@5: 100.0000 (99.9251)\n",
            "Test: [1050/2354]  Time: 0.181 (0.142)  Loss:  0.5322 (0.3063)  Acc@1: 100.0000 (96.0514)  Acc@5: 100.0000 (99.9286)\n",
            "Test: [1100/2354]  Time: 0.143 (0.142)  Loss:  0.1770 (0.3083)  Acc@1: 100.0000 (96.0490)  Acc@5: 100.0000 (99.9319)\n",
            "Test: [1150/2354]  Time: 0.142 (0.141)  Loss:  1.8008 (0.3097)  Acc@1: 50.0000 (95.9600)  Acc@5: 75.0000 (99.9131)\n",
            "Test: [1200/2354]  Time: 0.089 (0.141)  Loss:  0.4575 (0.3103)  Acc@1: 100.0000 (95.8993)  Acc@5: 100.0000 (99.8959)\n",
            "Test: [1250/2354]  Time: 0.178 (0.141)  Loss:  0.2433 (0.3063)  Acc@1: 100.0000 (95.9432)  Acc@5: 100.0000 (99.9001)\n",
            "Test: [1300/2354]  Time: 0.171 (0.141)  Loss:  0.0264 (0.3054)  Acc@1: 100.0000 (95.9454)  Acc@5: 100.0000 (99.8847)\n",
            "Test: [1350/2354]  Time: 0.169 (0.141)  Loss:  0.0671 (0.3090)  Acc@1: 100.0000 (95.7994)  Acc@5: 100.0000 (99.8890)\n",
            "Test: [1400/2354]  Time: 0.100 (0.141)  Loss:  0.2251 (0.3075)  Acc@1: 100.0000 (95.8066)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [1450/2354]  Time: 0.197 (0.140)  Loss:  0.2979 (0.3041)  Acc@1: 100.0000 (95.8822)  Acc@5: 100.0000 (99.8622)\n",
            "Test: [1500/2354]  Time: 0.099 (0.140)  Loss:  0.1638 (0.3031)  Acc@1: 100.0000 (95.9194)  Acc@5: 100.0000 (99.8668)\n",
            "Test: [1550/2354]  Time: 0.183 (0.140)  Loss:  0.1842 (0.3099)  Acc@1: 100.0000 (95.7447)  Acc@5: 100.0000 (99.8711)\n",
            "Test: [1600/2354]  Time: 0.118 (0.140)  Loss:  0.3079 (0.3180)  Acc@1: 100.0000 (95.5184)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [1650/2354]  Time: 0.203 (0.140)  Loss:  0.0996 (0.3188)  Acc@1: 100.0000 (95.5179)  Acc@5: 100.0000 (99.8637)\n",
            "Test: [1700/2354]  Time: 0.079 (0.140)  Loss:  0.0756 (0.3176)  Acc@1: 100.0000 (95.5614)  Acc@5: 100.0000 (99.8383)\n",
            "Test: [1750/2354]  Time: 0.164 (0.141)  Loss:  0.8076 (0.3226)  Acc@1: 75.0000 (95.3741)  Acc@5: 100.0000 (99.8429)\n",
            "Test: [1800/2354]  Time: 0.119 (0.141)  Loss:  0.5635 (0.3225)  Acc@1: 75.0000 (95.3776)  Acc@5: 100.0000 (99.8334)\n",
            "Test: [1850/2354]  Time: 0.141 (0.141)  Loss:  0.0947 (0.3228)  Acc@1: 100.0000 (95.4214)  Acc@5: 100.0000 (99.8244)\n",
            "Test: [1900/2354]  Time: 0.112 (0.141)  Loss:  0.4741 (0.3211)  Acc@1: 100.0000 (95.4629)  Acc@5: 100.0000 (99.8290)\n",
            "Test: [1950/2354]  Time: 0.113 (0.141)  Loss:  0.5103 (0.3243)  Acc@1: 100.0000 (95.3870)  Acc@5: 100.0000 (99.8206)\n",
            "Test: [2000/2354]  Time: 0.165 (0.141)  Loss:  0.0523 (0.3231)  Acc@1: 100.0000 (95.4148)  Acc@5: 100.0000 (99.8126)\n",
            "Test: [2050/2354]  Time: 0.171 (0.141)  Loss:  0.2048 (0.3263)  Acc@1: 100.0000 (95.2462)  Acc@5: 100.0000 (99.8050)\n",
            "Test: [2100/2354]  Time: 0.143 (0.141)  Loss:  0.7017 (0.3276)  Acc@1: 75.0000 (95.1571)  Acc@5: 100.0000 (99.8096)\n",
            "Test: [2150/2354]  Time: 0.112 (0.141)  Loss:  0.6748 (0.3301)  Acc@1: 75.0000 (95.1418)  Acc@5: 100.0000 (99.8024)\n",
            "Test: [2200/2354]  Time: 0.210 (0.141)  Loss:  0.4990 (0.3331)  Acc@1: 100.0000 (95.1045)  Acc@5: 100.0000 (99.8069)\n",
            "Test: [2250/2354]  Time: 0.090 (0.141)  Loss:  0.0448 (0.3324)  Acc@1: 100.0000 (95.1799)  Acc@5: 100.0000 (99.8112)\n",
            "Test: [2300/2354]  Time: 0.139 (0.140)  Loss:  0.0307 (0.3321)  Acc@1: 100.0000 (95.1869)  Acc@5: 100.0000 (99.8044)\n",
            "Test: [2350/2354]  Time: 0.075 (0.140)  Loss:  0.2783 (0.3328)  Acc@1: 100.0000 (95.1297)  Acc@5: 100.0000 (99.8086)\n",
            "Test: [2354/2354]  Time: 0.065 (0.140)  Loss:  0.0862 (0.3326)  Acc@1: 100.0000 (95.1375)  Acc@5: 100.0000 (99.8089)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-18.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar', 93.37509289733518)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar', 88.66121668966981)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar', 87.20670984180911)\n",
            "\n",
            "Train: 29 [   0/2354 (  0%)]  Loss: 2.088 (2.09)  Time: 1.433s,    5.58/s  (1.433s,    5.58/s)  LR: 7.122e-05  Data: 0.641 (0.641)\n",
            "Train: 29 [  50/2354 (  2%)]  Loss: 1.447 (1.93)  Time: 0.465s,   17.19/s  (0.529s,   15.11/s)  LR: 7.122e-05  Data: 0.007 (0.021)\n",
            "Train: 29 [ 100/2354 (  4%)]  Loss: 1.865 (1.91)  Time: 0.461s,   17.35/s  (0.499s,   16.04/s)  LR: 7.122e-05  Data: 0.009 (0.015)\n",
            "Train: 29 [ 150/2354 (  6%)]  Loss: 1.312 (1.86)  Time: 0.462s,   17.33/s  (0.488s,   16.39/s)  LR: 7.122e-05  Data: 0.007 (0.012)\n",
            "Train: 29 [ 200/2354 (  8%)]  Loss: 1.195 (1.85)  Time: 0.464s,   17.24/s  (0.483s,   16.58/s)  LR: 7.122e-05  Data: 0.009 (0.011)\n",
            "Train: 29 [ 250/2354 ( 11%)]  Loss: 1.204 (1.83)  Time: 0.481s,   16.63/s  (0.482s,   16.59/s)  LR: 7.122e-05  Data: 0.009 (0.011)\n",
            "Train: 29 [ 300/2354 ( 13%)]  Loss: 1.605 (1.80)  Time: 0.466s,   17.18/s  (0.480s,   16.68/s)  LR: 7.122e-05  Data: 0.010 (0.010)\n",
            "Train: 29 [ 350/2354 ( 15%)]  Loss: 1.710 (1.79)  Time: 0.464s,   17.24/s  (0.478s,   16.74/s)  LR: 7.122e-05  Data: 0.008 (0.010)\n",
            "Train: 29 [ 400/2354 ( 17%)]  Loss: 1.823 (1.81)  Time: 0.464s,   17.26/s  (0.476s,   16.79/s)  LR: 7.122e-05  Data: 0.007 (0.010)\n",
            "Train: 29 [ 450/2354 ( 19%)]  Loss: 1.618 (1.81)  Time: 0.460s,   17.40/s  (0.475s,   16.83/s)  LR: 7.122e-05  Data: 0.007 (0.009)\n",
            "Train: 29 [ 500/2354 ( 21%)]  Loss: 1.960 (1.81)  Time: 0.471s,   16.99/s  (0.476s,   16.81/s)  LR: 7.122e-05  Data: 0.007 (0.009)\n",
            "Train: 29 [ 550/2354 ( 23%)]  Loss: 1.614 (1.81)  Time: 0.462s,   17.30/s  (0.475s,   16.84/s)  LR: 7.122e-05  Data: 0.006 (0.009)\n",
            "Train: 29 [ 600/2354 ( 25%)]  Loss: 2.537 (1.81)  Time: 0.466s,   17.18/s  (0.474s,   16.86/s)  LR: 7.122e-05  Data: 0.007 (0.009)\n",
            "Train: 29 [ 650/2354 ( 28%)]  Loss: 2.042 (1.82)  Time: 0.473s,   16.93/s  (0.474s,   16.89/s)  LR: 7.122e-05  Data: 0.009 (0.009)\n",
            "Train: 29 [ 700/2354 ( 30%)]  Loss: 1.678 (1.82)  Time: 0.470s,   17.02/s  (0.474s,   16.86/s)  LR: 7.122e-05  Data: 0.006 (0.009)\n",
            "Train: 29 [ 750/2354 ( 32%)]  Loss: 1.158 (1.83)  Time: 0.468s,   17.09/s  (0.474s,   16.88/s)  LR: 7.122e-05  Data: 0.010 (0.009)\n",
            "Train: 29 [ 800/2354 ( 34%)]  Loss: 1.202 (1.83)  Time: 0.462s,   17.33/s  (0.473s,   16.90/s)  LR: 7.122e-05  Data: 0.006 (0.009)\n",
            "Train: 29 [ 850/2354 ( 36%)]  Loss: 1.737 (1.83)  Time: 0.462s,   17.32/s  (0.473s,   16.92/s)  LR: 7.122e-05  Data: 0.007 (0.009)\n",
            "Train: 29 [ 900/2354 ( 38%)]  Loss: 1.921 (1.83)  Time: 0.635s,   12.59/s  (0.473s,   16.92/s)  LR: 7.122e-05  Data: 0.020 (0.009)\n",
            "Train: 29 [ 950/2354 ( 40%)]  Loss: 1.799 (1.83)  Time: 0.466s,   17.18/s  (0.473s,   16.91/s)  LR: 7.122e-05  Data: 0.006 (0.009)\n",
            "Train: 29 [1000/2354 ( 42%)]  Loss: 2.077 (1.84)  Time: 0.465s,   17.19/s  (0.473s,   16.92/s)  LR: 7.122e-05  Data: 0.007 (0.009)\n",
            "Train: 29 [1050/2354 ( 45%)]  Loss: 2.736 (1.84)  Time: 0.478s,   16.73/s  (0.473s,   16.93/s)  LR: 7.122e-05  Data: 0.009 (0.008)\n",
            "Train: 29 [1100/2354 ( 47%)]  Loss: 1.953 (1.85)  Time: 0.468s,   17.08/s  (0.472s,   16.94/s)  LR: 7.122e-05  Data: 0.008 (0.008)\n",
            "Train: 29 [1150/2354 ( 49%)]  Loss: 2.469 (1.85)  Time: 0.462s,   17.30/s  (0.473s,   16.92/s)  LR: 7.122e-05  Data: 0.006 (0.008)\n",
            "Train: 29 [1200/2354 ( 51%)]  Loss: 2.020 (1.85)  Time: 0.457s,   17.50/s  (0.472s,   16.93/s)  LR: 7.122e-05  Data: 0.006 (0.008)\n",
            "Train: 29 [1250/2354 ( 53%)]  Loss: 1.719 (1.86)  Time: 0.466s,   17.17/s  (0.472s,   16.94/s)  LR: 7.122e-05  Data: 0.011 (0.008)\n",
            "Train: 29 [1300/2354 ( 55%)]  Loss: 1.756 (1.86)  Time: 0.465s,   17.19/s  (0.472s,   16.95/s)  LR: 7.122e-05  Data: 0.006 (0.008)\n",
            "Train: 29 [1350/2354 ( 57%)]  Loss: 2.326 (1.86)  Time: 0.471s,   17.00/s  (0.472s,   16.94/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1400/2354 ( 59%)]  Loss: 1.375 (1.86)  Time: 0.476s,   16.82/s  (0.472s,   16.95/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1450/2354 ( 62%)]  Loss: 1.133 (1.85)  Time: 0.466s,   17.15/s  (0.472s,   16.95/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1500/2354 ( 64%)]  Loss: 1.302 (1.85)  Time: 0.461s,   17.36/s  (0.472s,   16.96/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1550/2354 ( 66%)]  Loss: 2.534 (1.85)  Time: 0.462s,   17.30/s  (0.472s,   16.97/s)  LR: 7.122e-05  Data: 0.009 (0.008)\n",
            "Train: 29 [1600/2354 ( 68%)]  Loss: 2.091 (1.85)  Time: 0.461s,   17.34/s  (0.472s,   16.95/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1650/2354 ( 70%)]  Loss: 1.471 (1.85)  Time: 0.469s,   17.07/s  (0.472s,   16.96/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1700/2354 ( 72%)]  Loss: 2.281 (1.85)  Time: 0.465s,   17.22/s  (0.472s,   16.96/s)  LR: 7.122e-05  Data: 0.010 (0.008)\n",
            "Train: 29 [1750/2354 ( 74%)]  Loss: 1.842 (1.85)  Time: 0.466s,   17.16/s  (0.471s,   16.97/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1800/2354 ( 76%)]  Loss: 2.307 (1.85)  Time: 0.467s,   17.14/s  (0.472s,   16.96/s)  LR: 7.122e-05  Data: 0.009 (0.008)\n",
            "Train: 29 [1850/2354 ( 79%)]  Loss: 2.924 (1.85)  Time: 0.463s,   17.27/s  (0.472s,   16.96/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1900/2354 ( 81%)]  Loss: 2.776 (1.85)  Time: 0.465s,   17.22/s  (0.471s,   16.97/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [1950/2354 ( 83%)]  Loss: 2.418 (1.85)  Time: 0.464s,   17.23/s  (0.471s,   16.97/s)  LR: 7.122e-05  Data: 0.009 (0.008)\n",
            "Train: 29 [2000/2354 ( 85%)]  Loss: 1.663 (1.85)  Time: 0.581s,   13.77/s  (0.471s,   16.97/s)  LR: 7.122e-05  Data: 0.013 (0.008)\n",
            "Train: 29 [2050/2354 ( 87%)]  Loss: 1.294 (1.85)  Time: 0.467s,   17.12/s  (0.471s,   16.97/s)  LR: 7.122e-05  Data: 0.006 (0.008)\n",
            "Train: 29 [2100/2354 ( 89%)]  Loss: 1.851 (1.85)  Time: 0.468s,   17.08/s  (0.471s,   16.97/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [2150/2354 ( 91%)]  Loss: 1.543 (1.85)  Time: 0.470s,   17.02/s  (0.471s,   16.98/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [2200/2354 ( 93%)]  Loss: 2.062 (1.85)  Time: 0.467s,   17.13/s  (0.471s,   16.98/s)  LR: 7.122e-05  Data: 0.008 (0.008)\n",
            "Train: 29 [2250/2354 ( 96%)]  Loss: 2.718 (1.85)  Time: 0.462s,   17.32/s  (0.471s,   16.97/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [2300/2354 ( 98%)]  Loss: 2.672 (1.85)  Time: 0.462s,   17.33/s  (0.471s,   16.98/s)  LR: 7.122e-05  Data: 0.007 (0.008)\n",
            "Train: 29 [2350/2354 (100%)]  Loss: 1.238 (1.85)  Time: 0.462s,   17.33/s  (0.471s,   16.98/s)  LR: 7.122e-05  Data: 0.005 (0.008)\n",
            "Train: 29 [2353/2354 (100%)]  Loss: 1.204 (1.85)  Time: 0.455s,   17.57/s  (0.471s,   16.98/s)  LR: 7.122e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.639 (0.639)  Loss:  0.5005 (0.5005)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.111 (0.155)  Loss:  0.9512 (0.3035)  Acc@1: 100.0000 (97.5490)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.097 (0.148)  Loss:  0.5176 (0.3213)  Acc@1: 100.0000 (96.2871)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.113 (0.145)  Loss:  0.0739 (0.3833)  Acc@1: 100.0000 (93.8742)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.109 (0.144)  Loss:  0.5269 (0.3547)  Acc@1: 100.0000 (94.5274)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.148 (0.144)  Loss:  0.0865 (0.3393)  Acc@1: 100.0000 (95.2191)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.254 (0.148)  Loss:  0.5444 (0.3494)  Acc@1: 100.0000 (95.1827)  Acc@5: 100.0000 (99.8339)\n",
            "Test: [ 350/2354]  Time: 0.197 (0.147)  Loss:  0.2659 (0.3797)  Acc@1: 100.0000 (94.5869)  Acc@5: 100.0000 (99.8575)\n",
            "Test: [ 400/2354]  Time: 0.194 (0.147)  Loss:  0.1128 (0.3745)  Acc@1: 100.0000 (94.6384)  Acc@5: 100.0000 (99.8753)\n",
            "Test: [ 450/2354]  Time: 0.134 (0.146)  Loss:  0.2250 (0.3655)  Acc@1: 100.0000 (94.7894)  Acc@5: 100.0000 (99.8891)\n",
            "Test: [ 500/2354]  Time: 0.194 (0.145)  Loss:  0.2008 (0.3497)  Acc@1: 100.0000 (95.2096)  Acc@5: 100.0000 (99.9002)\n",
            "Test: [ 550/2354]  Time: 0.132 (0.145)  Loss:  0.7998 (0.3633)  Acc@1: 75.0000 (94.6007)  Acc@5: 100.0000 (99.9093)\n",
            "Test: [ 600/2354]  Time: 0.157 (0.144)  Loss:  0.2903 (0.3467)  Acc@1: 100.0000 (95.0083)  Acc@5: 100.0000 (99.9168)\n",
            "Test: [ 650/2354]  Time: 0.173 (0.144)  Loss:  0.0686 (0.3360)  Acc@1: 100.0000 (95.1997)  Acc@5: 100.0000 (99.9232)\n",
            "Test: [ 700/2354]  Time: 0.099 (0.144)  Loss:  0.0653 (0.3233)  Acc@1: 100.0000 (95.4351)  Acc@5: 100.0000 (99.9287)\n",
            "Test: [ 750/2354]  Time: 0.146 (0.144)  Loss:  0.2900 (0.3244)  Acc@1: 100.0000 (95.5060)  Acc@5: 100.0000 (99.9334)\n",
            "Test: [ 800/2354]  Time: 0.084 (0.143)  Loss:  0.0624 (0.3231)  Acc@1: 100.0000 (95.4120)  Acc@5: 100.0000 (99.9376)\n",
            "Test: [ 850/2354]  Time: 0.083 (0.143)  Loss:  0.0811 (0.3169)  Acc@1: 100.0000 (95.5934)  Acc@5: 100.0000 (99.9412)\n",
            "Test: [ 900/2354]  Time: 0.117 (0.143)  Loss:  0.7207 (0.3083)  Acc@1: 75.0000 (95.7547)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [ 950/2354]  Time: 0.113 (0.143)  Loss:  0.2189 (0.3043)  Acc@1: 100.0000 (95.8991)  Acc@5: 100.0000 (99.9474)\n",
            "Test: [1000/2354]  Time: 0.161 (0.143)  Loss:  0.0944 (0.3077)  Acc@1: 100.0000 (95.8541)  Acc@5: 100.0000 (99.9500)\n",
            "Test: [1050/2354]  Time: 0.098 (0.144)  Loss:  0.3699 (0.3022)  Acc@1: 100.0000 (95.9562)  Acc@5: 100.0000 (99.9524)\n",
            "Test: [1100/2354]  Time: 0.083 (0.144)  Loss:  0.3667 (0.3058)  Acc@1: 100.0000 (95.9128)  Acc@5: 100.0000 (99.9546)\n",
            "Test: [1150/2354]  Time: 0.157 (0.144)  Loss:  1.3994 (0.3038)  Acc@1: 50.0000 (95.8949)  Acc@5: 75.0000 (99.9348)\n",
            "Test: [1200/2354]  Time: 0.168 (0.143)  Loss:  0.7734 (0.3074)  Acc@1: 75.0000 (95.8160)  Acc@5: 100.0000 (99.9167)\n",
            "Test: [1250/2354]  Time: 0.150 (0.143)  Loss:  0.2878 (0.3066)  Acc@1: 100.0000 (95.9432)  Acc@5: 100.0000 (99.9001)\n",
            "Test: [1300/2354]  Time: 0.101 (0.143)  Loss:  0.1091 (0.3146)  Acc@1: 100.0000 (95.5803)  Acc@5: 100.0000 (99.8847)\n",
            "Test: [1350/2354]  Time: 0.184 (0.143)  Loss:  0.0610 (0.3097)  Acc@1: 100.0000 (95.7254)  Acc@5: 100.0000 (99.8890)\n",
            "Test: [1400/2354]  Time: 0.117 (0.142)  Loss:  0.0674 (0.3093)  Acc@1: 100.0000 (95.7530)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [1450/2354]  Time: 0.083 (0.142)  Loss:  0.3040 (0.3097)  Acc@1: 100.0000 (95.6926)  Acc@5: 100.0000 (99.8794)\n",
            "Test: [1500/2354]  Time: 0.151 (0.142)  Loss:  0.1088 (0.3083)  Acc@1: 100.0000 (95.6696)  Acc@5: 100.0000 (99.8668)\n",
            "Test: [1550/2354]  Time: 0.164 (0.142)  Loss:  0.1499 (0.3135)  Acc@1: 100.0000 (95.3095)  Acc@5: 100.0000 (99.8711)\n",
            "Test: [1600/2354]  Time: 0.148 (0.142)  Loss:  0.2078 (0.3198)  Acc@1: 100.0000 (95.1593)  Acc@5: 100.0000 (99.8595)\n",
            "Test: [1650/2354]  Time: 0.177 (0.142)  Loss:  0.1378 (0.3234)  Acc@1: 100.0000 (95.0939)  Acc@5: 100.0000 (99.8486)\n",
            "Test: [1700/2354]  Time: 0.119 (0.142)  Loss:  0.0512 (0.3221)  Acc@1: 100.0000 (95.1205)  Acc@5: 100.0000 (99.8383)\n",
            "Test: [1750/2354]  Time: 0.171 (0.142)  Loss:  0.2197 (0.3256)  Acc@1: 100.0000 (95.0600)  Acc@5: 100.0000 (99.8429)\n",
            "Test: [1800/2354]  Time: 0.112 (0.142)  Loss:  0.4844 (0.3275)  Acc@1: 100.0000 (95.0861)  Acc@5: 100.0000 (99.8195)\n",
            "Test: [1850/2354]  Time: 0.135 (0.142)  Loss:  0.4563 (0.3278)  Acc@1: 100.0000 (95.1513)  Acc@5: 100.0000 (99.8244)\n",
            "Test: [1900/2354]  Time: 0.125 (0.142)  Loss:  0.3140 (0.3267)  Acc@1: 100.0000 (95.2393)  Acc@5: 100.0000 (99.8290)\n",
            "Test: [1950/2354]  Time: 0.142 (0.142)  Loss:  0.2727 (0.3245)  Acc@1: 100.0000 (95.2973)  Acc@5: 100.0000 (99.8334)\n",
            "Test: [2000/2354]  Time: 0.093 (0.142)  Loss:  0.0873 (0.3232)  Acc@1: 100.0000 (95.3773)  Acc@5: 100.0000 (99.8376)\n",
            "Test: [2050/2354]  Time: 0.095 (0.142)  Loss:  0.6421 (0.3304)  Acc@1: 100.0000 (95.0878)  Acc@5: 100.0000 (99.8294)\n",
            "Test: [2100/2354]  Time: 0.154 (0.142)  Loss:  0.3606 (0.3316)  Acc@1: 100.0000 (95.0738)  Acc@5: 100.0000 (99.8334)\n",
            "Test: [2150/2354]  Time: 0.105 (0.142)  Loss:  0.5562 (0.3335)  Acc@1: 100.0000 (95.0256)  Acc@5: 100.0000 (99.8373)\n",
            "Test: [2200/2354]  Time: 0.128 (0.142)  Loss:  0.0922 (0.3391)  Acc@1: 100.0000 (94.8092)  Acc@5: 100.0000 (99.8410)\n",
            "Test: [2250/2354]  Time: 0.156 (0.142)  Loss:  0.0937 (0.3379)  Acc@1: 100.0000 (94.8801)  Acc@5: 100.0000 (99.8445)\n",
            "Test: [2300/2354]  Time: 0.142 (0.142)  Loss:  0.0338 (0.3353)  Acc@1: 100.0000 (94.9478)  Acc@5: 100.0000 (99.8370)\n",
            "Test: [2350/2354]  Time: 0.078 (0.142)  Loss:  0.3220 (0.3350)  Acc@1: 100.0000 (94.8958)  Acc@5: 100.0000 (99.8405)\n",
            "Test: [2354/2354]  Time: 0.064 (0.142)  Loss:  0.0645 (0.3346)  Acc@1: 100.0000 (94.9039)  Acc@5: 100.0000 (99.8407)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-19.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar', 93.37509289733518)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar', 88.66121668966981)\n",
            "\n",
            "Train: 30 [   0/2354 (  0%)]  Loss: 1.495 (1.49)  Time: 1.370s,    5.84/s  (1.370s,    5.84/s)  LR: 6.944e-05  Data: 0.748 (0.748)\n",
            "Train: 30 [  50/2354 (  2%)]  Loss: 1.689 (1.77)  Time: 0.459s,   17.44/s  (0.526s,   15.20/s)  LR: 6.944e-05  Data: 0.007 (0.022)\n",
            "Train: 30 [ 100/2354 (  4%)]  Loss: 1.532 (1.78)  Time: 0.467s,   17.14/s  (0.497s,   16.10/s)  LR: 6.944e-05  Data: 0.010 (0.015)\n",
            "Train: 30 [ 150/2354 (  6%)]  Loss: 1.259 (1.78)  Time: 0.471s,   16.99/s  (0.489s,   16.36/s)  LR: 6.944e-05  Data: 0.007 (0.013)\n",
            "Train: 30 [ 200/2354 (  8%)]  Loss: 1.469 (1.75)  Time: 0.473s,   16.93/s  (0.484s,   16.52/s)  LR: 6.944e-05  Data: 0.007 (0.011)\n",
            "Train: 30 [ 250/2354 ( 11%)]  Loss: 1.309 (1.80)  Time: 0.597s,   13.39/s  (0.483s,   16.55/s)  LR: 6.944e-05  Data: 0.007 (0.011)\n",
            "Train: 30 [ 300/2354 ( 13%)]  Loss: 2.962 (1.81)  Time: 0.467s,   17.14/s  (0.482s,   16.59/s)  LR: 6.944e-05  Data: 0.009 (0.010)\n",
            "Train: 30 [ 350/2354 ( 15%)]  Loss: 2.278 (1.80)  Time: 0.463s,   17.29/s  (0.480s,   16.67/s)  LR: 6.944e-05  Data: 0.007 (0.010)\n",
            "Train: 30 [ 400/2354 ( 17%)]  Loss: 1.484 (1.79)  Time: 0.461s,   17.36/s  (0.479s,   16.72/s)  LR: 6.944e-05  Data: 0.009 (0.010)\n",
            "Train: 30 [ 450/2354 ( 19%)]  Loss: 1.592 (1.80)  Time: 0.476s,   16.80/s  (0.477s,   16.76/s)  LR: 6.944e-05  Data: 0.008 (0.010)\n",
            "Train: 30 [ 500/2354 ( 21%)]  Loss: 1.594 (1.79)  Time: 0.472s,   16.93/s  (0.479s,   16.71/s)  LR: 6.944e-05  Data: 0.008 (0.009)\n",
            "Train: 30 [ 550/2354 ( 23%)]  Loss: 2.466 (1.79)  Time: 0.468s,   17.09/s  (0.478s,   16.72/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [ 600/2354 ( 25%)]  Loss: 1.117 (1.79)  Time: 0.487s,   16.43/s  (0.478s,   16.74/s)  LR: 6.944e-05  Data: 0.010 (0.009)\n",
            "Train: 30 [ 650/2354 ( 28%)]  Loss: 1.761 (1.79)  Time: 0.471s,   16.98/s  (0.477s,   16.76/s)  LR: 6.944e-05  Data: 0.010 (0.009)\n",
            "Train: 30 [ 700/2354 ( 30%)]  Loss: 1.887 (1.79)  Time: 0.467s,   17.14/s  (0.478s,   16.74/s)  LR: 6.944e-05  Data: 0.009 (0.009)\n",
            "Train: 30 [ 750/2354 ( 32%)]  Loss: 3.194 (1.78)  Time: 0.466s,   17.17/s  (0.477s,   16.76/s)  LR: 6.944e-05  Data: 0.010 (0.009)\n",
            "Train: 30 [ 800/2354 ( 34%)]  Loss: 1.491 (1.78)  Time: 0.466s,   17.17/s  (0.477s,   16.78/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [ 850/2354 ( 36%)]  Loss: 1.104 (1.79)  Time: 0.478s,   16.74/s  (0.476s,   16.80/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [ 900/2354 ( 38%)]  Loss: 2.737 (1.80)  Time: 0.463s,   17.29/s  (0.476s,   16.81/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [ 950/2354 ( 40%)]  Loss: 1.715 (1.79)  Time: 0.467s,   17.12/s  (0.476s,   16.80/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [1000/2354 ( 42%)]  Loss: 2.431 (1.80)  Time: 0.478s,   16.72/s  (0.476s,   16.81/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [1050/2354 ( 45%)]  Loss: 1.552 (1.80)  Time: 0.468s,   17.08/s  (0.476s,   16.82/s)  LR: 6.944e-05  Data: 0.010 (0.009)\n",
            "Train: 30 [1100/2354 ( 47%)]  Loss: 2.517 (1.80)  Time: 0.463s,   17.29/s  (0.475s,   16.83/s)  LR: 6.944e-05  Data: 0.009 (0.009)\n",
            "Train: 30 [1150/2354 ( 49%)]  Loss: 1.521 (1.80)  Time: 0.470s,   17.04/s  (0.476s,   16.82/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [1200/2354 ( 51%)]  Loss: 1.490 (1.80)  Time: 0.469s,   17.06/s  (0.475s,   16.83/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [1250/2354 ( 53%)]  Loss: 1.271 (1.80)  Time: 0.469s,   17.06/s  (0.475s,   16.84/s)  LR: 6.944e-05  Data: 0.013 (0.009)\n",
            "Train: 30 [1300/2354 ( 55%)]  Loss: 1.584 (1.81)  Time: 0.469s,   17.06/s  (0.475s,   16.85/s)  LR: 6.944e-05  Data: 0.009 (0.009)\n",
            "Train: 30 [1350/2354 ( 57%)]  Loss: 1.039 (1.81)  Time: 0.630s,   12.70/s  (0.475s,   16.85/s)  LR: 6.944e-05  Data: 0.013 (0.009)\n",
            "Train: 30 [1400/2354 ( 59%)]  Loss: 1.200 (1.81)  Time: 0.464s,   17.25/s  (0.475s,   16.85/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [1450/2354 ( 62%)]  Loss: 2.424 (1.81)  Time: 0.464s,   17.24/s  (0.475s,   16.86/s)  LR: 6.944e-05  Data: 0.007 (0.009)\n",
            "Train: 30 [1500/2354 ( 64%)]  Loss: 2.316 (1.82)  Time: 0.466s,   17.17/s  (0.474s,   16.87/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [1550/2354 ( 66%)]  Loss: 2.227 (1.82)  Time: 0.467s,   17.12/s  (0.474s,   16.87/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [1600/2354 ( 68%)]  Loss: 1.634 (1.81)  Time: 0.471s,   16.97/s  (0.475s,   16.86/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [1650/2354 ( 70%)]  Loss: 2.143 (1.82)  Time: 0.468s,   17.09/s  (0.474s,   16.87/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [1700/2354 ( 72%)]  Loss: 2.014 (1.82)  Time: 0.470s,   17.04/s  (0.474s,   16.87/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [1750/2354 ( 74%)]  Loss: 1.404 (1.82)  Time: 0.462s,   17.31/s  (0.474s,   16.88/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [1800/2354 ( 76%)]  Loss: 2.105 (1.81)  Time: 0.464s,   17.25/s  (0.474s,   16.87/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [1850/2354 ( 79%)]  Loss: 1.235 (1.81)  Time: 0.462s,   17.33/s  (0.474s,   16.87/s)  LR: 6.944e-05  Data: 0.008 (0.008)\n",
            "Train: 30 [1900/2354 ( 81%)]  Loss: 1.166 (1.81)  Time: 0.476s,   16.81/s  (0.474s,   16.88/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [1950/2354 ( 83%)]  Loss: 4.157 (1.81)  Time: 0.464s,   17.26/s  (0.474s,   16.89/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [2000/2354 ( 85%)]  Loss: 2.450 (1.81)  Time: 0.471s,   16.97/s  (0.474s,   16.89/s)  LR: 6.944e-05  Data: 0.009 (0.008)\n",
            "Train: 30 [2050/2354 ( 87%)]  Loss: 1.366 (1.81)  Time: 0.466s,   17.17/s  (0.474s,   16.88/s)  LR: 6.944e-05  Data: 0.006 (0.008)\n",
            "Train: 30 [2100/2354 ( 89%)]  Loss: 3.037 (1.81)  Time: 0.468s,   17.11/s  (0.474s,   16.89/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [2150/2354 ( 91%)]  Loss: 1.508 (1.82)  Time: 0.468s,   17.09/s  (0.474s,   16.89/s)  LR: 6.944e-05  Data: 0.011 (0.008)\n",
            "Train: 30 [2200/2354 ( 93%)]  Loss: 2.407 (1.82)  Time: 0.471s,   16.98/s  (0.474s,   16.89/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [2250/2354 ( 96%)]  Loss: 1.233 (1.82)  Time: 0.469s,   17.06/s  (0.474s,   16.88/s)  LR: 6.944e-05  Data: 0.009 (0.008)\n",
            "Train: 30 [2300/2354 ( 98%)]  Loss: 3.372 (1.82)  Time: 0.474s,   16.87/s  (0.474s,   16.89/s)  LR: 6.944e-05  Data: 0.007 (0.008)\n",
            "Train: 30 [2350/2354 (100%)]  Loss: 2.224 (1.82)  Time: 0.461s,   17.34/s  (0.474s,   16.89/s)  LR: 6.944e-05  Data: 0.005 (0.008)\n",
            "Train: 30 [2353/2354 (100%)]  Loss: 1.792 (1.82)  Time: 0.456s,   17.53/s  (0.474s,   16.89/s)  LR: 6.944e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.647 (0.647)  Loss:  0.2273 (0.2273)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.080 (0.155)  Loss:  0.8447 (0.2489)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.094 (0.148)  Loss:  0.5039 (0.2897)  Acc@1: 100.0000 (97.7723)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.100 (0.146)  Loss:  0.1241 (0.3133)  Acc@1: 100.0000 (97.0199)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.168 (0.145)  Loss:  0.6582 (0.3033)  Acc@1: 100.0000 (97.5124)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.169 (0.144)  Loss:  0.1078 (0.3114)  Acc@1: 100.0000 (97.6096)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.189 (0.144)  Loss:  1.0146 (0.3167)  Acc@1: 100.0000 (97.2591)  Acc@5: 100.0000 (99.8339)\n",
            "Test: [ 350/2354]  Time: 0.142 (0.148)  Loss:  0.4158 (0.3539)  Acc@1: 100.0000 (95.9402)  Acc@5: 100.0000 (99.8575)\n",
            "Test: [ 400/2354]  Time: 0.109 (0.148)  Loss:  0.1583 (0.3603)  Acc@1: 100.0000 (95.6983)  Acc@5: 100.0000 (99.8130)\n",
            "Test: [ 450/2354]  Time: 0.099 (0.147)  Loss:  0.1335 (0.3448)  Acc@1: 100.0000 (95.8980)  Acc@5: 100.0000 (99.8337)\n",
            "Test: [ 500/2354]  Time: 0.151 (0.147)  Loss:  0.6934 (0.3471)  Acc@1: 100.0000 (95.9581)  Acc@5: 100.0000 (99.8503)\n",
            "Test: [ 550/2354]  Time: 0.111 (0.146)  Loss:  0.4460 (0.3471)  Acc@1: 100.0000 (95.7804)  Acc@5: 100.0000 (99.8639)\n",
            "Test: [ 600/2354]  Time: 0.100 (0.146)  Loss:  0.1840 (0.3312)  Acc@1: 100.0000 (96.0899)  Acc@5: 100.0000 (99.8752)\n",
            "Test: [ 650/2354]  Time: 0.174 (0.146)  Loss:  0.1228 (0.3206)  Acc@1: 100.0000 (96.3134)  Acc@5: 100.0000 (99.8848)\n",
            "Test: [ 700/2354]  Time: 0.149 (0.146)  Loss:  0.0892 (0.3110)  Acc@1: 100.0000 (96.4693)  Acc@5: 100.0000 (99.8573)\n",
            "Test: [ 750/2354]  Time: 0.078 (0.145)  Loss:  0.3550 (0.3087)  Acc@1: 100.0000 (96.5379)  Acc@5: 100.0000 (99.8336)\n",
            "Test: [ 800/2354]  Time: 0.096 (0.145)  Loss:  0.0746 (0.3101)  Acc@1: 100.0000 (96.5044)  Acc@5: 100.0000 (99.8439)\n",
            "Test: [ 850/2354]  Time: 0.135 (0.145)  Loss:  0.0916 (0.3097)  Acc@1: 100.0000 (96.5335)  Acc@5: 100.0000 (99.8531)\n",
            "Test: [ 900/2354]  Time: 0.105 (0.145)  Loss:  0.3691 (0.3021)  Acc@1: 100.0000 (96.7259)  Acc@5: 100.0000 (99.8613)\n",
            "Test: [ 950/2354]  Time: 0.187 (0.145)  Loss:  0.2098 (0.2964)  Acc@1: 100.0000 (96.8454)  Acc@5: 100.0000 (99.8686)\n",
            "Test: [1000/2354]  Time: 0.143 (0.145)  Loss:  0.1377 (0.2989)  Acc@1: 100.0000 (96.8282)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [1050/2354]  Time: 0.101 (0.145)  Loss:  0.1024 (0.3005)  Acc@1: 100.0000 (96.7888)  Acc@5: 100.0000 (99.8811)\n",
            "Test: [1100/2354]  Time: 0.088 (0.146)  Loss:  0.3584 (0.2964)  Acc@1: 100.0000 (96.9119)  Acc@5: 100.0000 (99.8865)\n",
            "Test: [1150/2354]  Time: 0.102 (0.146)  Loss:  0.8340 (0.2933)  Acc@1: 100.0000 (97.0243)  Acc@5: 100.0000 (99.8697)\n",
            "Test: [1200/2354]  Time: 0.127 (0.146)  Loss:  1.0098 (0.2939)  Acc@1: 75.0000 (96.9609)  Acc@5: 100.0000 (99.8543)\n",
            "Test: [1250/2354]  Time: 0.177 (0.145)  Loss:  0.0976 (0.2914)  Acc@1: 100.0000 (97.0024)  Acc@5: 100.0000 (99.8401)\n",
            "Test: [1300/2354]  Time: 0.125 (0.145)  Loss:  0.2020 (0.2965)  Acc@1: 100.0000 (96.7141)  Acc@5: 100.0000 (99.8271)\n",
            "Test: [1350/2354]  Time: 0.099 (0.145)  Loss:  0.0948 (0.2943)  Acc@1: 100.0000 (96.7802)  Acc@5: 100.0000 (99.8335)\n",
            "Test: [1400/2354]  Time: 0.197 (0.145)  Loss:  0.1427 (0.2930)  Acc@1: 100.0000 (96.7880)  Acc@5: 100.0000 (99.8216)\n",
            "Test: [1450/2354]  Time: 0.099 (0.145)  Loss:  0.1891 (0.2893)  Acc@1: 100.0000 (96.8125)  Acc@5: 100.0000 (99.8277)\n",
            "Test: [1500/2354]  Time: 0.114 (0.145)  Loss:  0.0760 (0.2896)  Acc@1: 100.0000 (96.8021)  Acc@5: 100.0000 (99.8334)\n",
            "Test: [1550/2354]  Time: 0.099 (0.144)  Loss:  0.1426 (0.2952)  Acc@1: 100.0000 (96.6634)  Acc@5: 100.0000 (99.8388)\n",
            "Test: [1600/2354]  Time: 0.173 (0.144)  Loss:  0.2400 (0.3009)  Acc@1: 100.0000 (96.4397)  Acc@5: 100.0000 (99.8438)\n",
            "Test: [1650/2354]  Time: 0.219 (0.144)  Loss:  0.1912 (0.3002)  Acc@1: 100.0000 (96.4870)  Acc@5: 100.0000 (99.8334)\n",
            "Test: [1700/2354]  Time: 0.150 (0.144)  Loss:  0.1956 (0.2990)  Acc@1: 100.0000 (96.5021)  Acc@5: 100.0000 (99.8236)\n",
            "Test: [1750/2354]  Time: 0.171 (0.144)  Loss:  0.1582 (0.3045)  Acc@1: 100.0000 (96.2878)  Acc@5: 100.0000 (99.8287)\n",
            "Test: [1800/2354]  Time: 0.257 (0.144)  Loss:  0.7056 (0.3043)  Acc@1: 100.0000 (96.2798)  Acc@5: 100.0000 (99.8057)\n",
            "Test: [1850/2354]  Time: 0.078 (0.145)  Loss:  0.2783 (0.3022)  Acc@1: 100.0000 (96.3128)  Acc@5: 100.0000 (99.7974)\n",
            "Test: [1900/2354]  Time: 0.200 (0.145)  Loss:  0.6533 (0.3007)  Acc@1: 75.0000 (96.3440)  Acc@5: 100.0000 (99.8027)\n",
            "Test: [1950/2354]  Time: 0.172 (0.145)  Loss:  0.5674 (0.3001)  Acc@1: 100.0000 (96.3993)  Acc@5: 100.0000 (99.8078)\n",
            "Test: [2000/2354]  Time: 0.131 (0.145)  Loss:  0.0509 (0.2996)  Acc@1: 100.0000 (96.4143)  Acc@5: 100.0000 (99.8126)\n",
            "Test: [2050/2354]  Time: 0.081 (0.145)  Loss:  0.2119 (0.3040)  Acc@1: 100.0000 (96.2579)  Acc@5: 100.0000 (99.8050)\n",
            "Test: [2100/2354]  Time: 0.167 (0.145)  Loss:  0.3457 (0.3077)  Acc@1: 100.0000 (96.1209)  Acc@5: 100.0000 (99.8096)\n",
            "Test: [2150/2354]  Time: 0.146 (0.145)  Loss:  0.7622 (0.3119)  Acc@1: 100.0000 (95.9321)  Acc@5: 100.0000 (99.8140)\n",
            "Test: [2200/2354]  Time: 0.168 (0.144)  Loss:  0.4443 (0.3138)  Acc@1: 100.0000 (95.9337)  Acc@5: 100.0000 (99.8069)\n",
            "Test: [2250/2354]  Time: 0.133 (0.144)  Loss:  0.0901 (0.3114)  Acc@1: 100.0000 (96.0018)  Acc@5: 100.0000 (99.8112)\n",
            "Test: [2300/2354]  Time: 0.192 (0.144)  Loss:  0.0616 (0.3096)  Acc@1: 100.0000 (96.0561)  Acc@5: 100.0000 (99.8044)\n",
            "Test: [2350/2354]  Time: 0.075 (0.144)  Loss:  0.1647 (0.3107)  Acc@1: 100.0000 (96.0230)  Acc@5: 100.0000 (99.8086)\n",
            "Test: [2354/2354]  Time: 0.065 (0.144)  Loss:  0.0746 (0.3107)  Acc@1: 100.0000 (96.0293)  Acc@5: 100.0000 (99.8089)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-22.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar', 93.37509289733518)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar', 88.9584881622253)\n",
            "\n",
            "Train: 31 [   0/2354 (  0%)]  Loss: 2.740 (2.74)  Time: 1.334s,    6.00/s  (1.334s,    6.00/s)  LR: 6.763e-05  Data: 0.591 (0.591)\n",
            "Train: 31 [  50/2354 (  2%)]  Loss: 1.144 (1.75)  Time: 0.467s,   17.11/s  (0.519s,   15.40/s)  LR: 6.763e-05  Data: 0.007 (0.020)\n",
            "Train: 31 [ 100/2354 (  4%)]  Loss: 1.630 (1.83)  Time: 0.464s,   17.23/s  (0.494s,   16.18/s)  LR: 6.763e-05  Data: 0.009 (0.014)\n",
            "Train: 31 [ 150/2354 (  6%)]  Loss: 1.450 (1.85)  Time: 0.477s,   16.78/s  (0.485s,   16.48/s)  LR: 6.763e-05  Data: 0.010 (0.012)\n",
            "Train: 31 [ 200/2354 (  8%)]  Loss: 2.242 (1.81)  Time: 0.468s,   17.09/s  (0.481s,   16.64/s)  LR: 6.763e-05  Data: 0.007 (0.011)\n",
            "Train: 31 [ 250/2354 ( 11%)]  Loss: 1.462 (1.81)  Time: 0.466s,   17.17/s  (0.478s,   16.73/s)  LR: 6.763e-05  Data: 0.011 (0.010)\n",
            "Train: 31 [ 300/2354 ( 13%)]  Loss: 1.797 (1.82)  Time: 0.471s,   16.98/s  (0.480s,   16.68/s)  LR: 6.763e-05  Data: 0.010 (0.010)\n",
            "Train: 31 [ 350/2354 ( 15%)]  Loss: 2.153 (1.81)  Time: 0.464s,   17.24/s  (0.478s,   16.74/s)  LR: 6.763e-05  Data: 0.008 (0.010)\n",
            "Train: 31 [ 400/2354 ( 17%)]  Loss: 1.403 (1.79)  Time: 0.467s,   17.13/s  (0.477s,   16.78/s)  LR: 6.763e-05  Data: 0.006 (0.009)\n",
            "Train: 31 [ 450/2354 ( 19%)]  Loss: 1.320 (1.80)  Time: 0.465s,   17.21/s  (0.476s,   16.82/s)  LR: 6.763e-05  Data: 0.009 (0.009)\n",
            "Train: 31 [ 500/2354 ( 21%)]  Loss: 1.135 (1.79)  Time: 0.465s,   17.19/s  (0.477s,   16.78/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [ 550/2354 ( 23%)]  Loss: 1.080 (1.78)  Time: 0.467s,   17.15/s  (0.476s,   16.81/s)  LR: 6.763e-05  Data: 0.006 (0.009)\n",
            "Train: 31 [ 600/2354 ( 25%)]  Loss: 2.107 (1.77)  Time: 0.465s,   17.20/s  (0.475s,   16.84/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [ 650/2354 ( 28%)]  Loss: 2.647 (1.78)  Time: 0.463s,   17.29/s  (0.475s,   16.86/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [ 700/2354 ( 30%)]  Loss: 1.085 (1.78)  Time: 0.466s,   17.18/s  (0.474s,   16.87/s)  LR: 6.763e-05  Data: 0.008 (0.009)\n",
            "Train: 31 [ 750/2354 ( 32%)]  Loss: 1.332 (1.78)  Time: 0.471s,   16.97/s  (0.475s,   16.83/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [ 800/2354 ( 34%)]  Loss: 1.361 (1.79)  Time: 0.483s,   16.57/s  (0.475s,   16.85/s)  LR: 6.763e-05  Data: 0.010 (0.009)\n",
            "Train: 31 [ 850/2354 ( 36%)]  Loss: 1.847 (1.79)  Time: 0.472s,   16.96/s  (0.475s,   16.86/s)  LR: 6.763e-05  Data: 0.008 (0.009)\n",
            "Train: 31 [ 900/2354 ( 38%)]  Loss: 2.925 (1.80)  Time: 0.476s,   16.82/s  (0.474s,   16.87/s)  LR: 6.763e-05  Data: 0.009 (0.009)\n",
            "Train: 31 [ 950/2354 ( 40%)]  Loss: 1.175 (1.80)  Time: 0.475s,   16.85/s  (0.475s,   16.84/s)  LR: 6.763e-05  Data: 0.009 (0.009)\n",
            "Train: 31 [1000/2354 ( 42%)]  Loss: 1.238 (1.79)  Time: 0.465s,   17.21/s  (0.475s,   16.85/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [1050/2354 ( 45%)]  Loss: 1.118 (1.78)  Time: 0.474s,   16.87/s  (0.474s,   16.86/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [1100/2354 ( 47%)]  Loss: 2.822 (1.79)  Time: 0.465s,   17.19/s  (0.474s,   16.88/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [1150/2354 ( 49%)]  Loss: 1.574 (1.79)  Time: 0.466s,   17.15/s  (0.474s,   16.89/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [1200/2354 ( 51%)]  Loss: 1.275 (1.79)  Time: 0.474s,   16.88/s  (0.474s,   16.87/s)  LR: 6.763e-05  Data: 0.011 (0.009)\n",
            "Train: 31 [1250/2354 ( 53%)]  Loss: 1.835 (1.79)  Time: 0.470s,   17.02/s  (0.474s,   16.88/s)  LR: 6.763e-05  Data: 0.007 (0.009)\n",
            "Train: 31 [1300/2354 ( 55%)]  Loss: 2.912 (1.80)  Time: 0.467s,   17.12/s  (0.474s,   16.89/s)  LR: 6.763e-05  Data: 0.010 (0.009)\n",
            "Train: 31 [1350/2354 ( 57%)]  Loss: 1.204 (1.80)  Time: 0.483s,   16.56/s  (0.473s,   16.90/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [1400/2354 ( 59%)]  Loss: 1.221 (1.79)  Time: 0.464s,   17.22/s  (0.474s,   16.88/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [1450/2354 ( 62%)]  Loss: 1.197 (1.79)  Time: 0.472s,   16.96/s  (0.474s,   16.89/s)  LR: 6.763e-05  Data: 0.010 (0.008)\n",
            "Train: 31 [1500/2354 ( 64%)]  Loss: 1.650 (1.79)  Time: 0.474s,   16.87/s  (0.473s,   16.90/s)  LR: 6.763e-05  Data: 0.009 (0.008)\n",
            "Train: 31 [1550/2354 ( 66%)]  Loss: 1.635 (1.79)  Time: 0.461s,   17.36/s  (0.473s,   16.91/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [1600/2354 ( 68%)]  Loss: 1.085 (1.79)  Time: 0.466s,   17.16/s  (0.473s,   16.91/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [1650/2354 ( 70%)]  Loss: 1.112 (1.79)  Time: 0.464s,   17.25/s  (0.473s,   16.90/s)  LR: 6.763e-05  Data: 0.009 (0.008)\n",
            "Train: 31 [1700/2354 ( 72%)]  Loss: 1.929 (1.79)  Time: 0.460s,   17.40/s  (0.473s,   16.91/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [1750/2354 ( 74%)]  Loss: 1.697 (1.79)  Time: 0.467s,   17.15/s  (0.473s,   16.92/s)  LR: 6.763e-05  Data: 0.010 (0.008)\n",
            "Train: 31 [1800/2354 ( 76%)]  Loss: 1.339 (1.79)  Time: 0.468s,   17.08/s  (0.473s,   16.92/s)  LR: 6.763e-05  Data: 0.006 (0.008)\n",
            "Train: 31 [1850/2354 ( 79%)]  Loss: 1.232 (1.79)  Time: 0.465s,   17.21/s  (0.473s,   16.91/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [1900/2354 ( 81%)]  Loss: 2.402 (1.79)  Time: 0.464s,   17.26/s  (0.473s,   16.91/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [1950/2354 ( 83%)]  Loss: 1.259 (1.79)  Time: 0.471s,   16.99/s  (0.473s,   16.92/s)  LR: 6.763e-05  Data: 0.010 (0.008)\n",
            "Train: 31 [2000/2354 ( 85%)]  Loss: 3.206 (1.79)  Time: 0.462s,   17.31/s  (0.473s,   16.93/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [2050/2354 ( 87%)]  Loss: 1.669 (1.80)  Time: 0.463s,   17.29/s  (0.473s,   16.93/s)  LR: 6.763e-05  Data: 0.010 (0.008)\n",
            "Train: 31 [2100/2354 ( 89%)]  Loss: 2.029 (1.80)  Time: 0.460s,   17.40/s  (0.473s,   16.92/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [2150/2354 ( 91%)]  Loss: 2.101 (1.80)  Time: 0.476s,   16.81/s  (0.473s,   16.93/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [2200/2354 ( 93%)]  Loss: 1.267 (1.80)  Time: 0.475s,   16.84/s  (0.472s,   16.93/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [2250/2354 ( 96%)]  Loss: 1.486 (1.79)  Time: 0.463s,   17.29/s  (0.472s,   16.94/s)  LR: 6.763e-05  Data: 0.007 (0.008)\n",
            "Train: 31 [2300/2354 ( 98%)]  Loss: 3.189 (1.80)  Time: 0.641s,   12.48/s  (0.472s,   16.93/s)  LR: 6.763e-05  Data: 0.017 (0.008)\n",
            "Train: 31 [2350/2354 (100%)]  Loss: 2.343 (1.80)  Time: 0.456s,   17.53/s  (0.472s,   16.93/s)  LR: 6.763e-05  Data: 0.005 (0.008)\n",
            "Train: 31 [2353/2354 (100%)]  Loss: 1.976 (1.80)  Time: 0.458s,   17.45/s  (0.472s,   16.93/s)  LR: 6.763e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.644 (0.644)  Loss:  0.2410 (0.2410)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.159 (0.154)  Loss:  0.8096 (0.2587)  Acc@1: 100.0000 (98.0392)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.111 (0.147)  Loss:  0.7192 (0.2679)  Acc@1: 75.0000 (97.7723)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.148 (0.143)  Loss:  0.2140 (0.2746)  Acc@1: 100.0000 (96.6887)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.079 (0.142)  Loss:  0.2742 (0.2595)  Acc@1: 100.0000 (97.3881)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.140 (0.142)  Loss:  0.1605 (0.2787)  Acc@1: 100.0000 (96.9124)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.158 (0.141)  Loss:  0.2715 (0.2712)  Acc@1: 100.0000 (97.0100)  Acc@5: 100.0000 (99.9169)\n",
            "Test: [ 350/2354]  Time: 0.146 (0.140)  Loss:  0.3335 (0.3102)  Acc@1: 100.0000 (96.0826)  Acc@5: 100.0000 (99.9288)\n",
            "Test: [ 400/2354]  Time: 0.155 (0.140)  Loss:  0.1132 (0.3046)  Acc@1: 100.0000 (96.3217)  Acc@5: 100.0000 (99.9377)\n",
            "Test: [ 450/2354]  Time: 0.105 (0.140)  Loss:  0.0944 (0.2971)  Acc@1: 100.0000 (96.5632)  Acc@5: 100.0000 (99.8891)\n",
            "Test: [ 500/2354]  Time: 0.119 (0.140)  Loss:  0.4902 (0.2904)  Acc@1: 100.0000 (96.4072)  Acc@5: 100.0000 (99.9002)\n",
            "Test: [ 550/2354]  Time: 0.165 (0.140)  Loss:  0.3765 (0.2866)  Acc@1: 100.0000 (96.3702)  Acc@5: 100.0000 (99.9093)\n",
            "Test: [ 600/2354]  Time: 0.107 (0.143)  Loss:  0.4192 (0.2816)  Acc@1: 100.0000 (96.5890)  Acc@5: 100.0000 (99.8752)\n",
            "Test: [ 650/2354]  Time: 0.107 (0.143)  Loss:  0.2925 (0.2736)  Acc@1: 100.0000 (96.7742)  Acc@5: 100.0000 (99.8848)\n",
            "Test: [ 700/2354]  Time: 0.169 (0.143)  Loss:  0.0288 (0.2655)  Acc@1: 100.0000 (96.9330)  Acc@5: 100.0000 (99.8930)\n",
            "Test: [ 750/2354]  Time: 0.157 (0.143)  Loss:  0.2496 (0.2644)  Acc@1: 100.0000 (97.0706)  Acc@5: 100.0000 (99.9001)\n",
            "Test: [ 800/2354]  Time: 0.139 (0.143)  Loss:  0.0778 (0.2688)  Acc@1: 100.0000 (96.9101)  Acc@5: 100.0000 (99.9064)\n",
            "Test: [ 850/2354]  Time: 0.105 (0.143)  Loss:  0.0782 (0.2703)  Acc@1: 100.0000 (96.9448)  Acc@5: 100.0000 (99.9119)\n",
            "Test: [ 900/2354]  Time: 0.131 (0.143)  Loss:  0.2057 (0.2637)  Acc@1: 100.0000 (97.0588)  Acc@5: 100.0000 (99.9168)\n",
            "Test: [ 950/2354]  Time: 0.100 (0.143)  Loss:  0.4302 (0.2619)  Acc@1: 100.0000 (97.1083)  Acc@5: 100.0000 (99.9211)\n",
            "Test: [1000/2354]  Time: 0.098 (0.143)  Loss:  0.1493 (0.2577)  Acc@1: 100.0000 (97.2527)  Acc@5: 100.0000 (99.9251)\n",
            "Test: [1050/2354]  Time: 0.108 (0.142)  Loss:  0.4324 (0.2589)  Acc@1: 75.0000 (97.1694)  Acc@5: 100.0000 (99.9286)\n",
            "Test: [1100/2354]  Time: 0.156 (0.142)  Loss:  0.3430 (0.2627)  Acc@1: 100.0000 (97.0936)  Acc@5: 100.0000 (99.9319)\n",
            "Test: [1150/2354]  Time: 0.160 (0.142)  Loss:  0.7407 (0.2628)  Acc@1: 100.0000 (97.0243)  Acc@5: 100.0000 (99.9131)\n",
            "Test: [1200/2354]  Time: 0.187 (0.142)  Loss:  0.6704 (0.2663)  Acc@1: 75.0000 (96.8568)  Acc@5: 100.0000 (99.9167)\n",
            "Test: [1250/2354]  Time: 0.200 (0.142)  Loss:  0.2408 (0.2655)  Acc@1: 100.0000 (96.9025)  Acc@5: 100.0000 (99.9201)\n",
            "Test: [1300/2354]  Time: 0.128 (0.142)  Loss:  0.5420 (0.2688)  Acc@1: 75.0000 (96.7141)  Acc@5: 100.0000 (99.9231)\n",
            "Test: [1350/2354]  Time: 0.242 (0.143)  Loss:  0.0377 (0.2665)  Acc@1: 100.0000 (96.8172)  Acc@5: 100.0000 (99.9260)\n",
            "Test: [1400/2354]  Time: 0.126 (0.143)  Loss:  0.4316 (0.2665)  Acc@1: 100.0000 (96.7702)  Acc@5: 100.0000 (99.9286)\n",
            "Test: [1450/2354]  Time: 0.128 (0.143)  Loss:  0.1908 (0.2653)  Acc@1: 100.0000 (96.7609)  Acc@5: 100.0000 (99.9311)\n",
            "Test: [1500/2354]  Time: 0.100 (0.143)  Loss:  0.1014 (0.2641)  Acc@1: 100.0000 (96.7355)  Acc@5: 100.0000 (99.9167)\n",
            "Test: [1550/2354]  Time: 0.085 (0.142)  Loss:  0.0302 (0.2688)  Acc@1: 100.0000 (96.5184)  Acc@5: 100.0000 (99.9194)\n",
            "Test: [1600/2354]  Time: 0.106 (0.142)  Loss:  0.2859 (0.2747)  Acc@1: 100.0000 (96.4085)  Acc@5: 100.0000 (99.9063)\n",
            "Test: [1650/2354]  Time: 0.129 (0.142)  Loss:  0.3423 (0.2769)  Acc@1: 75.0000 (96.3356)  Acc@5: 100.0000 (99.8940)\n",
            "Test: [1700/2354]  Time: 0.142 (0.142)  Loss:  0.1814 (0.2761)  Acc@1: 100.0000 (96.3698)  Acc@5: 100.0000 (99.8824)\n",
            "Test: [1750/2354]  Time: 0.180 (0.142)  Loss:  0.2411 (0.2798)  Acc@1: 100.0000 (96.3021)  Acc@5: 100.0000 (99.8858)\n",
            "Test: [1800/2354]  Time: 0.166 (0.142)  Loss:  0.3108 (0.2792)  Acc@1: 100.0000 (96.3493)  Acc@5: 100.0000 (99.8890)\n",
            "Test: [1850/2354]  Time: 0.115 (0.142)  Loss:  0.2126 (0.2783)  Acc@1: 100.0000 (96.3803)  Acc@5: 100.0000 (99.8920)\n",
            "Test: [1900/2354]  Time: 0.105 (0.142)  Loss:  0.4036 (0.2776)  Acc@1: 100.0000 (96.4361)  Acc@5: 100.0000 (99.8948)\n",
            "Test: [1950/2354]  Time: 0.079 (0.142)  Loss:  0.4736 (0.2761)  Acc@1: 100.0000 (96.4762)  Acc@5: 100.0000 (99.8847)\n",
            "Test: [2000/2354]  Time: 0.161 (0.142)  Loss:  0.0710 (0.2743)  Acc@1: 100.0000 (96.5642)  Acc@5: 100.0000 (99.8876)\n",
            "Test: [2050/2354]  Time: 0.126 (0.142)  Loss:  0.1980 (0.2782)  Acc@1: 100.0000 (96.4651)  Acc@5: 100.0000 (99.8781)\n",
            "Test: [2100/2354]  Time: 0.120 (0.142)  Loss:  0.6436 (0.2823)  Acc@1: 100.0000 (96.3708)  Acc@5: 100.0000 (99.8810)\n",
            "Test: [2150/2354]  Time: 0.176 (0.142)  Loss:  1.0029 (0.2899)  Acc@1: 75.0000 (96.1297)  Acc@5: 100.0000 (99.8838)\n",
            "Test: [2200/2354]  Time: 0.131 (0.142)  Loss:  0.4961 (0.2985)  Acc@1: 100.0000 (95.8655)  Acc@5: 100.0000 (99.8864)\n",
            "Test: [2250/2354]  Time: 0.166 (0.142)  Loss:  0.1068 (0.2985)  Acc@1: 100.0000 (95.8685)  Acc@5: 100.0000 (99.8889)\n",
            "Test: [2300/2354]  Time: 0.172 (0.142)  Loss:  0.0645 (0.2983)  Acc@1: 100.0000 (95.8822)  Acc@5: 100.0000 (99.8805)\n",
            "Test: [2350/2354]  Time: 0.075 (0.142)  Loss:  0.0603 (0.2997)  Acc@1: 100.0000 (95.7784)  Acc@5: 100.0000 (99.8830)\n",
            "Test: [2354/2354]  Time: 0.067 (0.142)  Loss:  0.0198 (0.2996)  Acc@1: 100.0000 (95.7851)  Acc@5: 100.0000 (99.8832)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-21.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar', 93.37509289733518)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar', 88.99033867714195)\n",
            "\n",
            "Train: 32 [   0/2354 (  0%)]  Loss: 1.702 (1.70)  Time: 1.447s,    5.53/s  (1.447s,    5.53/s)  LR: 6.580e-05  Data: 0.606 (0.606)\n",
            "Train: 32 [  50/2354 (  2%)]  Loss: 1.907 (1.75)  Time: 0.463s,   17.27/s  (0.503s,   15.90/s)  LR: 6.580e-05  Data: 0.008 (0.019)\n",
            "Train: 32 [ 100/2354 (  4%)]  Loss: 1.254 (1.71)  Time: 0.461s,   17.36/s  (0.485s,   16.48/s)  LR: 6.580e-05  Data: 0.007 (0.014)\n",
            "Train: 32 [ 150/2354 (  6%)]  Loss: 1.522 (1.74)  Time: 0.617s,   12.96/s  (0.484s,   16.54/s)  LR: 6.580e-05  Data: 0.013 (0.012)\n",
            "Train: 32 [ 200/2354 (  8%)]  Loss: 1.802 (1.72)  Time: 0.464s,   17.26/s  (0.480s,   16.65/s)  LR: 6.580e-05  Data: 0.006 (0.011)\n",
            "Train: 32 [ 250/2354 ( 11%)]  Loss: 2.582 (1.72)  Time: 0.472s,   16.96/s  (0.478s,   16.75/s)  LR: 6.580e-05  Data: 0.007 (0.010)\n",
            "Train: 32 [ 300/2354 ( 13%)]  Loss: 1.002 (1.74)  Time: 0.468s,   17.11/s  (0.476s,   16.82/s)  LR: 6.580e-05  Data: 0.010 (0.010)\n",
            "Train: 32 [ 350/2354 ( 15%)]  Loss: 1.601 (1.75)  Time: 0.465s,   17.20/s  (0.474s,   16.86/s)  LR: 6.580e-05  Data: 0.007 (0.010)\n",
            "Train: 32 [ 400/2354 ( 17%)]  Loss: 1.132 (1.76)  Time: 0.475s,   16.86/s  (0.476s,   16.81/s)  LR: 6.580e-05  Data: 0.010 (0.010)\n",
            "Train: 32 [ 450/2354 ( 19%)]  Loss: 3.148 (1.75)  Time: 0.466s,   17.17/s  (0.475s,   16.85/s)  LR: 6.580e-05  Data: 0.010 (0.009)\n",
            "Train: 32 [ 500/2354 ( 21%)]  Loss: 1.804 (1.76)  Time: 0.468s,   17.10/s  (0.474s,   16.88/s)  LR: 6.580e-05  Data: 0.007 (0.009)\n",
            "Train: 32 [ 550/2354 ( 23%)]  Loss: 2.351 (1.75)  Time: 0.477s,   16.76/s  (0.473s,   16.90/s)  LR: 6.580e-05  Data: 0.009 (0.009)\n",
            "Train: 32 [ 600/2354 ( 25%)]  Loss: 1.814 (1.76)  Time: 0.467s,   17.13/s  (0.473s,   16.93/s)  LR: 6.580e-05  Data: 0.007 (0.009)\n",
            "Train: 32 [ 650/2354 ( 28%)]  Loss: 2.635 (1.77)  Time: 0.465s,   17.21/s  (0.474s,   16.89/s)  LR: 6.580e-05  Data: 0.008 (0.009)\n",
            "Train: 32 [ 700/2354 ( 30%)]  Loss: 2.617 (1.78)  Time: 0.470s,   17.03/s  (0.473s,   16.91/s)  LR: 6.580e-05  Data: 0.010 (0.009)\n",
            "Train: 32 [ 750/2354 ( 32%)]  Loss: 1.291 (1.77)  Time: 0.466s,   17.17/s  (0.473s,   16.92/s)  LR: 6.580e-05  Data: 0.007 (0.009)\n",
            "Train: 32 [ 800/2354 ( 34%)]  Loss: 1.187 (1.77)  Time: 0.466s,   17.18/s  (0.472s,   16.94/s)  LR: 6.580e-05  Data: 0.009 (0.009)\n",
            "Train: 32 [ 850/2354 ( 36%)]  Loss: 3.020 (1.78)  Time: 0.464s,   17.23/s  (0.473s,   16.91/s)  LR: 6.580e-05  Data: 0.009 (0.009)\n",
            "Train: 32 [ 900/2354 ( 38%)]  Loss: 1.638 (1.78)  Time: 0.466s,   17.15/s  (0.473s,   16.92/s)  LR: 6.580e-05  Data: 0.006 (0.009)\n",
            "Train: 32 [ 950/2354 ( 40%)]  Loss: 1.371 (1.77)  Time: 0.475s,   16.84/s  (0.472s,   16.93/s)  LR: 6.580e-05  Data: 0.009 (0.009)\n",
            "Train: 32 [1000/2354 ( 42%)]  Loss: 1.385 (1.77)  Time: 0.464s,   17.25/s  (0.472s,   16.94/s)  LR: 6.580e-05  Data: 0.007 (0.009)\n",
            "Train: 32 [1050/2354 ( 45%)]  Loss: 1.925 (1.77)  Time: 0.466s,   17.18/s  (0.472s,   16.95/s)  LR: 6.580e-05  Data: 0.007 (0.009)\n",
            "Train: 32 [1100/2354 ( 47%)]  Loss: 1.445 (1.78)  Time: 0.467s,   17.14/s  (0.472s,   16.94/s)  LR: 6.580e-05  Data: 0.010 (0.009)\n",
            "Train: 32 [1150/2354 ( 49%)]  Loss: 1.545 (1.77)  Time: 0.463s,   17.29/s  (0.472s,   16.95/s)  LR: 6.580e-05  Data: 0.009 (0.009)\n",
            "Train: 32 [1200/2354 ( 51%)]  Loss: 1.395 (1.77)  Time: 0.466s,   17.18/s  (0.472s,   16.96/s)  LR: 6.580e-05  Data: 0.006 (0.009)\n",
            "Train: 32 [1250/2354 ( 53%)]  Loss: 3.046 (1.77)  Time: 0.466s,   17.15/s  (0.471s,   16.97/s)  LR: 6.580e-05  Data: 0.009 (0.008)\n",
            "Train: 32 [1300/2354 ( 55%)]  Loss: 1.919 (1.77)  Time: 0.466s,   17.15/s  (0.471s,   16.98/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1350/2354 ( 57%)]  Loss: 1.059 (1.77)  Time: 0.461s,   17.35/s  (0.472s,   16.96/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1400/2354 ( 59%)]  Loss: 2.271 (1.77)  Time: 0.468s,   17.11/s  (0.472s,   16.96/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1450/2354 ( 62%)]  Loss: 1.558 (1.77)  Time: 0.470s,   17.04/s  (0.471s,   16.97/s)  LR: 6.580e-05  Data: 0.010 (0.008)\n",
            "Train: 32 [1500/2354 ( 64%)]  Loss: 1.771 (1.77)  Time: 0.475s,   16.86/s  (0.471s,   16.97/s)  LR: 6.580e-05  Data: 0.011 (0.008)\n",
            "Train: 32 [1550/2354 ( 66%)]  Loss: 1.660 (1.77)  Time: 0.464s,   17.25/s  (0.472s,   16.96/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1600/2354 ( 68%)]  Loss: 1.930 (1.77)  Time: 0.464s,   17.24/s  (0.472s,   16.96/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1650/2354 ( 70%)]  Loss: 3.419 (1.77)  Time: 0.471s,   16.98/s  (0.472s,   16.96/s)  LR: 6.580e-05  Data: 0.010 (0.008)\n",
            "Train: 32 [1700/2354 ( 72%)]  Loss: 1.963 (1.77)  Time: 0.471s,   16.98/s  (0.472s,   16.96/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1750/2354 ( 74%)]  Loss: 2.991 (1.77)  Time: 0.470s,   17.02/s  (0.472s,   16.96/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1800/2354 ( 76%)]  Loss: 1.631 (1.76)  Time: 0.468s,   17.09/s  (0.472s,   16.93/s)  LR: 6.580e-05  Data: 0.009 (0.008)\n",
            "Train: 32 [1850/2354 ( 79%)]  Loss: 1.522 (1.77)  Time: 0.480s,   16.68/s  (0.472s,   16.93/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1900/2354 ( 81%)]  Loss: 2.066 (1.77)  Time: 0.466s,   17.17/s  (0.472s,   16.93/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [1950/2354 ( 83%)]  Loss: 1.585 (1.77)  Time: 0.466s,   17.18/s  (0.472s,   16.94/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [2000/2354 ( 85%)]  Loss: 1.863 (1.78)  Time: 0.706s,   11.32/s  (0.473s,   16.92/s)  LR: 6.580e-05  Data: 0.017 (0.008)\n",
            "Train: 32 [2050/2354 ( 87%)]  Loss: 1.647 (1.78)  Time: 0.470s,   17.03/s  (0.473s,   16.92/s)  LR: 6.580e-05  Data: 0.010 (0.008)\n",
            "Train: 32 [2100/2354 ( 89%)]  Loss: 1.615 (1.78)  Time: 0.465s,   17.19/s  (0.473s,   16.92/s)  LR: 6.580e-05  Data: 0.008 (0.008)\n",
            "Train: 32 [2150/2354 ( 91%)]  Loss: 1.500 (1.78)  Time: 0.478s,   16.73/s  (0.473s,   16.92/s)  LR: 6.580e-05  Data: 0.010 (0.008)\n",
            "Train: 32 [2200/2354 ( 93%)]  Loss: 1.159 (1.78)  Time: 0.468s,   17.11/s  (0.473s,   16.93/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [2250/2354 ( 96%)]  Loss: 2.100 (1.78)  Time: 0.467s,   17.12/s  (0.473s,   16.91/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [2300/2354 ( 98%)]  Loss: 1.663 (1.78)  Time: 0.463s,   17.27/s  (0.473s,   16.91/s)  LR: 6.580e-05  Data: 0.007 (0.008)\n",
            "Train: 32 [2350/2354 (100%)]  Loss: 2.129 (1.78)  Time: 0.458s,   17.47/s  (0.473s,   16.92/s)  LR: 6.580e-05  Data: 0.005 (0.008)\n",
            "Train: 32 [2353/2354 (100%)]  Loss: 2.254 (1.78)  Time: 0.455s,   17.58/s  (0.473s,   16.92/s)  LR: 6.580e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.624 (0.624)  Loss:  0.1445 (0.1445)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.134 (0.158)  Loss:  0.4685 (0.2570)  Acc@1: 100.0000 (97.5490)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.175 (0.149)  Loss:  0.1573 (0.2465)  Acc@1: 100.0000 (98.0198)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.157 (0.146)  Loss:  0.1893 (0.2548)  Acc@1: 100.0000 (98.0132)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.100 (0.145)  Loss:  0.5830 (0.2998)  Acc@1: 100.0000 (97.0149)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.158 (0.145)  Loss:  0.1790 (0.3003)  Acc@1: 100.0000 (96.8127)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.082 (0.144)  Loss:  0.2061 (0.2902)  Acc@1: 100.0000 (96.8439)  Acc@5: 100.0000 (99.9169)\n",
            "Test: [ 350/2354]  Time: 0.254 (0.147)  Loss:  0.4502 (0.3175)  Acc@1: 100.0000 (94.8718)  Acc@5: 100.0000 (99.9288)\n",
            "Test: [ 400/2354]  Time: 0.159 (0.148)  Loss:  0.2424 (0.3193)  Acc@1: 100.0000 (94.9501)  Acc@5: 100.0000 (99.9377)\n",
            "Test: [ 450/2354]  Time: 0.117 (0.148)  Loss:  0.1205 (0.3108)  Acc@1: 100.0000 (95.1774)  Acc@5: 100.0000 (99.8891)\n",
            "Test: [ 500/2354]  Time: 0.113 (0.147)  Loss:  0.3318 (0.3007)  Acc@1: 100.0000 (95.5090)  Acc@5: 100.0000 (99.9002)\n",
            "Test: [ 550/2354]  Time: 0.133 (0.147)  Loss:  0.2471 (0.2989)  Acc@1: 100.0000 (95.7350)  Acc@5: 100.0000 (99.9093)\n",
            "Test: [ 600/2354]  Time: 0.137 (0.147)  Loss:  0.6440 (0.2963)  Acc@1: 75.0000 (95.8819)  Acc@5: 100.0000 (99.9168)\n",
            "Test: [ 650/2354]  Time: 0.166 (0.147)  Loss:  0.1337 (0.2842)  Acc@1: 100.0000 (96.1598)  Acc@5: 100.0000 (99.9232)\n",
            "Test: [ 700/2354]  Time: 0.121 (0.146)  Loss:  0.0401 (0.2729)  Acc@1: 100.0000 (96.3980)  Acc@5: 100.0000 (99.9287)\n",
            "Test: [ 750/2354]  Time: 0.098 (0.146)  Loss:  0.2262 (0.2703)  Acc@1: 100.0000 (96.5379)  Acc@5: 100.0000 (99.9334)\n",
            "Test: [ 800/2354]  Time: 0.132 (0.146)  Loss:  0.1214 (0.2824)  Acc@1: 100.0000 (96.2547)  Acc@5: 100.0000 (99.9376)\n",
            "Test: [ 850/2354]  Time: 0.134 (0.146)  Loss:  0.2688 (0.2800)  Acc@1: 100.0000 (96.3572)  Acc@5: 100.0000 (99.9412)\n",
            "Test: [ 900/2354]  Time: 0.105 (0.145)  Loss:  0.4685 (0.2722)  Acc@1: 100.0000 (96.5594)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [ 950/2354]  Time: 0.126 (0.146)  Loss:  0.4592 (0.2706)  Acc@1: 100.0000 (96.6877)  Acc@5: 100.0000 (99.9474)\n",
            "Test: [1000/2354]  Time: 0.137 (0.145)  Loss:  0.1228 (0.2663)  Acc@1: 100.0000 (96.8282)  Acc@5: 100.0000 (99.9500)\n",
            "Test: [1050/2354]  Time: 0.184 (0.145)  Loss:  0.5737 (0.2658)  Acc@1: 100.0000 (96.8839)  Acc@5: 100.0000 (99.9524)\n",
            "Test: [1100/2354]  Time: 0.107 (0.145)  Loss:  0.4509 (0.2691)  Acc@1: 100.0000 (96.8665)  Acc@5: 100.0000 (99.9546)\n",
            "Test: [1150/2354]  Time: 0.139 (0.146)  Loss:  1.2305 (0.2683)  Acc@1: 100.0000 (96.9374)  Acc@5: 100.0000 (99.9348)\n",
            "Test: [1200/2354]  Time: 0.138 (0.146)  Loss:  0.7891 (0.2742)  Acc@1: 75.0000 (96.6694)  Acc@5: 100.0000 (99.9376)\n",
            "Test: [1250/2354]  Time: 0.091 (0.146)  Loss:  0.0852 (0.2718)  Acc@1: 100.0000 (96.7426)  Acc@5: 100.0000 (99.9400)\n",
            "Test: [1300/2354]  Time: 0.134 (0.145)  Loss:  0.4744 (0.2726)  Acc@1: 100.0000 (96.7141)  Acc@5: 100.0000 (99.9424)\n",
            "Test: [1350/2354]  Time: 0.078 (0.145)  Loss:  0.3005 (0.2693)  Acc@1: 100.0000 (96.8172)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [1400/2354]  Time: 0.153 (0.145)  Loss:  0.2271 (0.2692)  Acc@1: 100.0000 (96.9129)  Acc@5: 100.0000 (99.9286)\n",
            "Test: [1450/2354]  Time: 0.175 (0.145)  Loss:  0.4351 (0.2724)  Acc@1: 100.0000 (96.9504)  Acc@5: 100.0000 (99.9311)\n",
            "Test: [1500/2354]  Time: 0.158 (0.144)  Loss:  0.1979 (0.2694)  Acc@1: 100.0000 (97.0520)  Acc@5: 100.0000 (99.9334)\n",
            "Test: [1550/2354]  Time: 0.188 (0.144)  Loss:  0.2335 (0.2752)  Acc@1: 100.0000 (96.7924)  Acc@5: 100.0000 (99.9355)\n",
            "Test: [1600/2354]  Time: 0.124 (0.144)  Loss:  0.2034 (0.2782)  Acc@1: 100.0000 (96.7676)  Acc@5: 100.0000 (99.9219)\n",
            "Test: [1650/2354]  Time: 0.151 (0.144)  Loss:  0.0596 (0.2782)  Acc@1: 100.0000 (96.7747)  Acc@5: 100.0000 (99.9091)\n",
            "Test: [1700/2354]  Time: 0.118 (0.144)  Loss:  0.0644 (0.2756)  Acc@1: 100.0000 (96.8107)  Acc@5: 100.0000 (99.8971)\n",
            "Test: [1750/2354]  Time: 0.162 (0.144)  Loss:  0.2822 (0.2777)  Acc@1: 100.0000 (96.8589)  Acc@5: 100.0000 (99.9001)\n",
            "Test: [1800/2354]  Time: 0.170 (0.144)  Loss:  0.4705 (0.2764)  Acc@1: 75.0000 (96.8767)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [1850/2354]  Time: 0.122 (0.143)  Loss:  0.0977 (0.2755)  Acc@1: 100.0000 (96.9206)  Acc@5: 100.0000 (99.8784)\n",
            "Test: [1900/2354]  Time: 0.134 (0.144)  Loss:  0.4795 (0.2746)  Acc@1: 100.0000 (96.9753)  Acc@5: 100.0000 (99.8816)\n",
            "Test: [1950/2354]  Time: 0.111 (0.144)  Loss:  0.2942 (0.2730)  Acc@1: 100.0000 (97.0144)  Acc@5: 100.0000 (99.8719)\n",
            "Test: [2000/2354]  Time: 0.154 (0.144)  Loss:  0.0885 (0.2709)  Acc@1: 100.0000 (97.0515)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [2050/2354]  Time: 0.134 (0.144)  Loss:  0.6118 (0.2753)  Acc@1: 75.0000 (96.8674)  Acc@5: 100.0000 (99.8781)\n",
            "Test: [2100/2354]  Time: 0.169 (0.144)  Loss:  0.8672 (0.2803)  Acc@1: 75.0000 (96.6802)  Acc@5: 100.0000 (99.8810)\n",
            "Test: [2150/2354]  Time: 0.171 (0.144)  Loss:  0.7808 (0.2835)  Acc@1: 75.0000 (96.6295)  Acc@5: 100.0000 (99.8838)\n",
            "Test: [2200/2354]  Time: 0.187 (0.144)  Loss:  0.1698 (0.2864)  Acc@1: 100.0000 (96.5584)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [2250/2354]  Time: 0.162 (0.144)  Loss:  0.0486 (0.2836)  Acc@1: 100.0000 (96.6015)  Acc@5: 100.0000 (99.8778)\n",
            "Test: [2300/2354]  Time: 0.172 (0.143)  Loss:  0.0502 (0.2818)  Acc@1: 100.0000 (96.6536)  Acc@5: 100.0000 (99.8696)\n",
            "Test: [2350/2354]  Time: 0.075 (0.143)  Loss:  0.0781 (0.2807)  Acc@1: 100.0000 (96.6610)  Acc@5: 100.0000 (99.8724)\n",
            "Test: [2354/2354]  Time: 0.064 (0.143)  Loss:  0.1024 (0.2808)  Acc@1: 100.0000 (96.6663)  Acc@5: 100.0000 (99.8726)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-20.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar', 93.37509289733518)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar', 90.84828538061366)\n",
            "\n",
            "Train: 33 [   0/2354 (  0%)]  Loss: 1.102 (1.10)  Time: 1.283s,    6.23/s  (1.283s,    6.23/s)  LR: 6.394e-05  Data: 0.575 (0.575)\n",
            "Train: 33 [  50/2354 (  2%)]  Loss: 1.114 (1.78)  Time: 0.467s,   17.15/s  (0.501s,   15.98/s)  LR: 6.394e-05  Data: 0.009 (0.019)\n",
            "Train: 33 [ 100/2354 (  4%)]  Loss: 1.237 (1.79)  Time: 0.472s,   16.94/s  (0.493s,   16.23/s)  LR: 6.394e-05  Data: 0.006 (0.014)\n",
            "Train: 33 [ 150/2354 (  6%)]  Loss: 1.462 (1.78)  Time: 0.466s,   17.18/s  (0.484s,   16.51/s)  LR: 6.394e-05  Data: 0.007 (0.012)\n",
            "Train: 33 [ 200/2354 (  8%)]  Loss: 2.229 (1.74)  Time: 0.468s,   17.10/s  (0.481s,   16.65/s)  LR: 6.394e-05  Data: 0.010 (0.011)\n",
            "Train: 33 [ 250/2354 ( 11%)]  Loss: 1.389 (1.73)  Time: 0.471s,   16.99/s  (0.478s,   16.74/s)  LR: 6.394e-05  Data: 0.009 (0.010)\n",
            "Train: 33 [ 300/2354 ( 13%)]  Loss: 1.638 (1.71)  Time: 0.473s,   16.93/s  (0.476s,   16.80/s)  LR: 6.394e-05  Data: 0.007 (0.010)\n",
            "Train: 33 [ 350/2354 ( 15%)]  Loss: 2.598 (1.71)  Time: 0.463s,   17.27/s  (0.477s,   16.76/s)  LR: 6.394e-05  Data: 0.006 (0.010)\n",
            "Train: 33 [ 400/2354 ( 17%)]  Loss: 2.237 (1.71)  Time: 0.466s,   17.17/s  (0.476s,   16.80/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [ 450/2354 ( 19%)]  Loss: 2.975 (1.72)  Time: 0.475s,   16.83/s  (0.475s,   16.83/s)  LR: 6.394e-05  Data: 0.009 (0.009)\n",
            "Train: 33 [ 500/2354 ( 21%)]  Loss: 1.663 (1.72)  Time: 0.467s,   17.15/s  (0.474s,   16.86/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [ 550/2354 ( 23%)]  Loss: 1.458 (1.72)  Time: 0.467s,   17.15/s  (0.474s,   16.88/s)  LR: 6.394e-05  Data: 0.010 (0.009)\n",
            "Train: 33 [ 600/2354 ( 25%)]  Loss: 1.486 (1.73)  Time: 0.475s,   16.85/s  (0.475s,   16.84/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [ 650/2354 ( 28%)]  Loss: 1.419 (1.74)  Time: 0.473s,   16.91/s  (0.475s,   16.85/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [ 700/2354 ( 30%)]  Loss: 1.971 (1.73)  Time: 0.463s,   17.28/s  (0.474s,   16.86/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [ 750/2354 ( 32%)]  Loss: 2.158 (1.73)  Time: 0.468s,   17.11/s  (0.474s,   16.88/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [ 800/2354 ( 34%)]  Loss: 1.444 (1.73)  Time: 0.574s,   13.94/s  (0.475s,   16.85/s)  LR: 6.394e-05  Data: 0.018 (0.009)\n",
            "Train: 33 [ 850/2354 ( 36%)]  Loss: 1.013 (1.72)  Time: 0.469s,   17.05/s  (0.475s,   16.86/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [ 900/2354 ( 38%)]  Loss: 2.086 (1.72)  Time: 0.467s,   17.13/s  (0.474s,   16.87/s)  LR: 6.394e-05  Data: 0.010 (0.009)\n",
            "Train: 33 [ 950/2354 ( 40%)]  Loss: 2.372 (1.72)  Time: 0.472s,   16.95/s  (0.474s,   16.88/s)  LR: 6.394e-05  Data: 0.010 (0.009)\n",
            "Train: 33 [1000/2354 ( 42%)]  Loss: 2.249 (1.73)  Time: 0.473s,   16.90/s  (0.474s,   16.89/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [1050/2354 ( 45%)]  Loss: 1.094 (1.73)  Time: 0.475s,   16.85/s  (0.474s,   16.87/s)  LR: 6.394e-05  Data: 0.009 (0.009)\n",
            "Train: 33 [1100/2354 ( 47%)]  Loss: 1.637 (1.72)  Time: 0.467s,   17.13/s  (0.474s,   16.88/s)  LR: 6.394e-05  Data: 0.007 (0.009)\n",
            "Train: 33 [1150/2354 ( 49%)]  Loss: 1.314 (1.72)  Time: 0.474s,   16.88/s  (0.474s,   16.89/s)  LR: 6.394e-05  Data: 0.008 (0.009)\n",
            "Train: 33 [1200/2354 ( 51%)]  Loss: 1.293 (1.72)  Time: 0.471s,   17.00/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1250/2354 ( 53%)]  Loss: 2.434 (1.73)  Time: 0.470s,   17.03/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.009 (0.008)\n",
            "Train: 33 [1300/2354 ( 55%)]  Loss: 1.760 (1.72)  Time: 0.467s,   17.12/s  (0.474s,   16.88/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1350/2354 ( 57%)]  Loss: 1.025 (1.72)  Time: 0.463s,   17.27/s  (0.474s,   16.89/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1400/2354 ( 59%)]  Loss: 1.607 (1.73)  Time: 0.474s,   16.88/s  (0.474s,   16.89/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1450/2354 ( 62%)]  Loss: 1.608 (1.73)  Time: 0.468s,   17.09/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.008 (0.008)\n",
            "Train: 33 [1500/2354 ( 64%)]  Loss: 2.587 (1.73)  Time: 0.466s,   17.17/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1550/2354 ( 66%)]  Loss: 1.616 (1.74)  Time: 0.468s,   17.11/s  (0.474s,   16.89/s)  LR: 6.394e-05  Data: 0.009 (0.008)\n",
            "Train: 33 [1600/2354 ( 68%)]  Loss: 2.384 (1.74)  Time: 0.462s,   17.30/s  (0.474s,   16.89/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1650/2354 ( 70%)]  Loss: 2.516 (1.74)  Time: 0.471s,   16.97/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1700/2354 ( 72%)]  Loss: 1.137 (1.74)  Time: 0.478s,   16.74/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.010 (0.008)\n",
            "Train: 33 [1750/2354 ( 74%)]  Loss: 1.300 (1.74)  Time: 0.461s,   17.34/s  (0.474s,   16.89/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1800/2354 ( 76%)]  Loss: 1.395 (1.74)  Time: 0.490s,   16.33/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.010 (0.008)\n",
            "Train: 33 [1850/2354 ( 79%)]  Loss: 1.587 (1.74)  Time: 0.468s,   17.10/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [1900/2354 ( 81%)]  Loss: 1.162 (1.74)  Time: 0.473s,   16.92/s  (0.473s,   16.91/s)  LR: 6.394e-05  Data: 0.010 (0.008)\n",
            "Train: 33 [1950/2354 ( 83%)]  Loss: 1.807 (1.75)  Time: 0.468s,   17.08/s  (0.473s,   16.91/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [2000/2354 ( 85%)]  Loss: 1.958 (1.75)  Time: 0.469s,   17.05/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [2050/2354 ( 87%)]  Loss: 2.891 (1.75)  Time: 0.473s,   16.90/s  (0.473s,   16.90/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [2100/2354 ( 89%)]  Loss: 1.610 (1.75)  Time: 0.479s,   16.69/s  (0.473s,   16.91/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [2150/2354 ( 91%)]  Loss: 1.715 (1.75)  Time: 0.471s,   16.97/s  (0.473s,   16.91/s)  LR: 6.394e-05  Data: 0.010 (0.008)\n",
            "Train: 33 [2200/2354 ( 93%)]  Loss: 1.153 (1.75)  Time: 0.466s,   17.18/s  (0.473s,   16.92/s)  LR: 6.394e-05  Data: 0.008 (0.008)\n",
            "Train: 33 [2250/2354 ( 96%)]  Loss: 1.141 (1.75)  Time: 0.465s,   17.22/s  (0.473s,   16.91/s)  LR: 6.394e-05  Data: 0.007 (0.008)\n",
            "Train: 33 [2300/2354 ( 98%)]  Loss: 1.109 (1.75)  Time: 0.465s,   17.22/s  (0.473s,   16.91/s)  LR: 6.394e-05  Data: 0.008 (0.008)\n",
            "Train: 33 [2350/2354 (100%)]  Loss: 1.351 (1.75)  Time: 0.465s,   17.20/s  (0.473s,   16.92/s)  LR: 6.394e-05  Data: 0.006 (0.008)\n",
            "Train: 33 [2353/2354 (100%)]  Loss: 1.280 (1.75)  Time: 0.455s,   17.57/s  (0.473s,   16.92/s)  LR: 6.394e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.668 (0.668)  Loss:  0.0746 (0.0746)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.144 (0.158)  Loss:  0.2581 (0.2193)  Acc@1: 100.0000 (98.0392)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.183 (0.150)  Loss:  0.1316 (0.2432)  Acc@1: 100.0000 (97.7723)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.185 (0.147)  Loss:  0.0384 (0.2701)  Acc@1: 100.0000 (97.3510)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.160 (0.145)  Loss:  0.2467 (0.2423)  Acc@1: 100.0000 (97.8856)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.109 (0.145)  Loss:  0.2452 (0.2456)  Acc@1: 100.0000 (97.9084)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.163 (0.145)  Loss:  1.0088 (0.2745)  Acc@1: 75.0000 (97.5083)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.100 (0.149)  Loss:  0.5020 (0.3062)  Acc@1: 75.0000 (96.5812)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.105 (0.148)  Loss:  0.0750 (0.3064)  Acc@1: 100.0000 (96.6334)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.129 (0.147)  Loss:  0.1877 (0.2905)  Acc@1: 100.0000 (96.8958)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.184 (0.147)  Loss:  0.1761 (0.2846)  Acc@1: 100.0000 (97.0060)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.144 (0.147)  Loss:  0.3359 (0.2938)  Acc@1: 100.0000 (96.7332)  Acc@5: 100.0000 (99.9546)\n",
            "Test: [ 600/2354]  Time: 0.097 (0.146)  Loss:  0.2759 (0.2869)  Acc@1: 100.0000 (96.9634)  Acc@5: 100.0000 (99.9584)\n",
            "Test: [ 650/2354]  Time: 0.172 (0.146)  Loss:  0.3218 (0.2799)  Acc@1: 100.0000 (97.0814)  Acc@5: 100.0000 (99.9616)\n",
            "Test: [ 700/2354]  Time: 0.153 (0.146)  Loss:  0.0580 (0.2764)  Acc@1: 100.0000 (97.2539)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [ 750/2354]  Time: 0.093 (0.146)  Loss:  0.4316 (0.2782)  Acc@1: 75.0000 (97.2703)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [ 800/2354]  Time: 0.166 (0.145)  Loss:  0.1614 (0.2790)  Acc@1: 100.0000 (97.0662)  Acc@5: 100.0000 (99.9688)\n",
            "Test: [ 850/2354]  Time: 0.176 (0.145)  Loss:  0.1002 (0.2760)  Acc@1: 100.0000 (97.1210)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [ 900/2354]  Time: 0.154 (0.145)  Loss:  0.7085 (0.2718)  Acc@1: 75.0000 (97.2253)  Acc@5: 100.0000 (99.9723)\n",
            "Test: [ 950/2354]  Time: 0.132 (0.145)  Loss:  0.2046 (0.2700)  Acc@1: 100.0000 (97.2135)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1000/2354]  Time: 0.114 (0.145)  Loss:  0.0533 (0.2691)  Acc@1: 100.0000 (97.1528)  Acc@5: 100.0000 (99.9750)\n",
            "Test: [1050/2354]  Time: 0.090 (0.145)  Loss:  0.2050 (0.2640)  Acc@1: 100.0000 (97.2645)  Acc@5: 100.0000 (99.9762)\n",
            "Test: [1100/2354]  Time: 0.134 (0.144)  Loss:  0.1902 (0.2635)  Acc@1: 100.0000 (97.2752)  Acc@5: 100.0000 (99.9773)\n",
            "Test: [1150/2354]  Time: 0.123 (0.146)  Loss:  0.7603 (0.2600)  Acc@1: 100.0000 (97.3284)  Acc@5: 100.0000 (99.9566)\n",
            "Test: [1200/2354]  Time: 0.167 (0.146)  Loss:  0.7593 (0.2626)  Acc@1: 75.0000 (97.2315)  Acc@5: 100.0000 (99.9376)\n",
            "Test: [1250/2354]  Time: 0.115 (0.146)  Loss:  0.1886 (0.2576)  Acc@1: 100.0000 (97.2822)  Acc@5: 100.0000 (99.9201)\n",
            "Test: [1300/2354]  Time: 0.144 (0.146)  Loss:  0.1327 (0.2589)  Acc@1: 100.0000 (97.2137)  Acc@5: 100.0000 (99.9039)\n",
            "Test: [1350/2354]  Time: 0.093 (0.146)  Loss:  0.1080 (0.2578)  Acc@1: 100.0000 (97.2243)  Acc@5: 100.0000 (99.9075)\n",
            "Test: [1400/2354]  Time: 0.127 (0.146)  Loss:  0.1040 (0.2566)  Acc@1: 100.0000 (97.2877)  Acc@5: 100.0000 (99.9108)\n",
            "Test: [1450/2354]  Time: 0.144 (0.145)  Loss:  0.2129 (0.2564)  Acc@1: 100.0000 (97.2605)  Acc@5: 100.0000 (99.9139)\n",
            "Test: [1500/2354]  Time: 0.109 (0.145)  Loss:  0.2157 (0.2540)  Acc@1: 100.0000 (97.2518)  Acc@5: 100.0000 (99.9001)\n",
            "Test: [1550/2354]  Time: 0.169 (0.145)  Loss:  0.0553 (0.2586)  Acc@1: 100.0000 (97.1792)  Acc@5: 100.0000 (99.9033)\n",
            "Test: [1600/2354]  Time: 0.135 (0.145)  Loss:  0.0720 (0.2625)  Acc@1: 100.0000 (97.0487)  Acc@5: 100.0000 (99.9063)\n",
            "Test: [1650/2354]  Time: 0.119 (0.145)  Loss:  0.0964 (0.2628)  Acc@1: 100.0000 (97.0472)  Acc@5: 100.0000 (99.8940)\n",
            "Test: [1700/2354]  Time: 0.158 (0.145)  Loss:  0.0743 (0.2608)  Acc@1: 100.0000 (97.0752)  Acc@5: 100.0000 (99.8824)\n",
            "Test: [1750/2354]  Time: 0.091 (0.145)  Loss:  0.3716 (0.2647)  Acc@1: 75.0000 (96.9446)  Acc@5: 100.0000 (99.8858)\n",
            "Test: [1800/2354]  Time: 0.153 (0.145)  Loss:  0.3105 (0.2641)  Acc@1: 100.0000 (96.9184)  Acc@5: 100.0000 (99.8612)\n",
            "Test: [1850/2354]  Time: 0.190 (0.145)  Loss:  0.1169 (0.2613)  Acc@1: 100.0000 (96.9746)  Acc@5: 100.0000 (99.8649)\n",
            "Test: [1900/2354]  Time: 0.145 (0.145)  Loss:  0.2029 (0.2594)  Acc@1: 100.0000 (97.0542)  Acc@5: 100.0000 (99.8685)\n",
            "Test: [1950/2354]  Time: 0.104 (0.145)  Loss:  0.1451 (0.2607)  Acc@1: 100.0000 (97.0400)  Acc@5: 100.0000 (99.8719)\n",
            "Test: [2000/2354]  Time: 0.182 (0.145)  Loss:  0.2908 (0.2592)  Acc@1: 100.0000 (97.0765)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [2050/2354]  Time: 0.086 (0.145)  Loss:  0.1931 (0.2622)  Acc@1: 100.0000 (97.0015)  Acc@5: 100.0000 (99.8659)\n",
            "Test: [2100/2354]  Time: 0.111 (0.145)  Loss:  0.4585 (0.2658)  Acc@1: 100.0000 (96.8824)  Acc@5: 100.0000 (99.8691)\n",
            "Test: [2150/2354]  Time: 0.147 (0.145)  Loss:  0.5703 (0.2726)  Acc@1: 100.0000 (96.6062)  Acc@5: 100.0000 (99.8722)\n",
            "Test: [2200/2354]  Time: 0.171 (0.145)  Loss:  0.2294 (0.2739)  Acc@1: 100.0000 (96.5811)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [2250/2354]  Time: 0.122 (0.145)  Loss:  0.0729 (0.2739)  Acc@1: 100.0000 (96.5904)  Acc@5: 100.0000 (99.8778)\n",
            "Test: [2300/2354]  Time: 0.172 (0.145)  Loss:  0.0550 (0.2736)  Acc@1: 100.0000 (96.6319)  Acc@5: 100.0000 (99.8696)\n",
            "Test: [2350/2354]  Time: 0.076 (0.145)  Loss:  0.0880 (0.2737)  Acc@1: 100.0000 (96.6291)  Acc@5: 100.0000 (99.8724)\n",
            "Test: [2354/2354]  Time: 0.066 (0.145)  Loss:  0.0629 (0.2735)  Acc@1: 100.0000 (96.6345)  Acc@5: 100.0000 (99.8726)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-23.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar', 93.37509289733518)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar', 93.13090561630746)\n",
            "\n",
            "Train: 34 [   0/2354 (  0%)]  Loss: 1.929 (1.93)  Time: 1.283s,    6.24/s  (1.283s,    6.24/s)  LR: 6.206e-05  Data: 0.481 (0.481)\n",
            "Train: 34 [  50/2354 (  2%)]  Loss: 1.530 (1.77)  Time: 0.473s,   16.90/s  (0.503s,   15.92/s)  LR: 6.206e-05  Data: 0.010 (0.017)\n",
            "Train: 34 [ 100/2354 (  4%)]  Loss: 2.660 (1.81)  Time: 0.464s,   17.25/s  (0.494s,   16.19/s)  LR: 6.206e-05  Data: 0.007 (0.013)\n",
            "Train: 34 [ 150/2354 (  6%)]  Loss: 1.118 (1.78)  Time: 0.467s,   17.13/s  (0.486s,   16.48/s)  LR: 6.206e-05  Data: 0.010 (0.011)\n",
            "Train: 34 [ 200/2354 (  8%)]  Loss: 1.375 (1.76)  Time: 0.462s,   17.30/s  (0.481s,   16.62/s)  LR: 6.206e-05  Data: 0.007 (0.010)\n",
            "Train: 34 [ 250/2354 ( 11%)]  Loss: 1.233 (1.73)  Time: 0.462s,   17.33/s  (0.479s,   16.71/s)  LR: 6.206e-05  Data: 0.007 (0.010)\n",
            "Train: 34 [ 300/2354 ( 13%)]  Loss: 1.638 (1.72)  Time: 0.468s,   17.08/s  (0.477s,   16.77/s)  LR: 6.206e-05  Data: 0.007 (0.010)\n",
            "Train: 34 [ 350/2354 ( 15%)]  Loss: 1.735 (1.73)  Time: 0.467s,   17.14/s  (0.478s,   16.72/s)  LR: 6.206e-05  Data: 0.010 (0.009)\n",
            "Train: 34 [ 400/2354 ( 17%)]  Loss: 1.068 (1.72)  Time: 0.469s,   17.07/s  (0.477s,   16.76/s)  LR: 6.206e-05  Data: 0.008 (0.009)\n",
            "Train: 34 [ 450/2354 ( 19%)]  Loss: 1.315 (1.72)  Time: 0.469s,   17.06/s  (0.476s,   16.80/s)  LR: 6.206e-05  Data: 0.010 (0.009)\n",
            "Train: 34 [ 500/2354 ( 21%)]  Loss: 2.013 (1.72)  Time: 0.465s,   17.20/s  (0.475s,   16.83/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [ 550/2354 ( 23%)]  Loss: 1.972 (1.72)  Time: 0.466s,   17.17/s  (0.475s,   16.86/s)  LR: 6.206e-05  Data: 0.009 (0.009)\n",
            "Train: 34 [ 600/2354 ( 25%)]  Loss: 1.127 (1.72)  Time: 0.465s,   17.20/s  (0.475s,   16.83/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [ 650/2354 ( 28%)]  Loss: 1.316 (1.71)  Time: 0.468s,   17.08/s  (0.475s,   16.85/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [ 700/2354 ( 30%)]  Loss: 1.231 (1.71)  Time: 0.474s,   16.86/s  (0.474s,   16.86/s)  LR: 6.206e-05  Data: 0.008 (0.009)\n",
            "Train: 34 [ 750/2354 ( 32%)]  Loss: 2.711 (1.71)  Time: 0.463s,   17.26/s  (0.474s,   16.88/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [ 800/2354 ( 34%)]  Loss: 1.147 (1.71)  Time: 0.464s,   17.24/s  (0.474s,   16.89/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [ 850/2354 ( 36%)]  Loss: 1.112 (1.72)  Time: 0.465s,   17.21/s  (0.474s,   16.87/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [ 900/2354 ( 38%)]  Loss: 1.008 (1.72)  Time: 0.461s,   17.36/s  (0.474s,   16.88/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [ 950/2354 ( 40%)]  Loss: 1.118 (1.73)  Time: 0.463s,   17.29/s  (0.474s,   16.89/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [1000/2354 ( 42%)]  Loss: 1.429 (1.73)  Time: 0.474s,   16.87/s  (0.473s,   16.90/s)  LR: 6.206e-05  Data: 0.010 (0.009)\n",
            "Train: 34 [1050/2354 ( 45%)]  Loss: 1.357 (1.73)  Time: 0.465s,   17.21/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.007 (0.009)\n",
            "Train: 34 [1100/2354 ( 47%)]  Loss: 2.073 (1.73)  Time: 0.464s,   17.23/s  (0.474s,   16.89/s)  LR: 6.206e-05  Data: 0.008 (0.009)\n",
            "Train: 34 [1150/2354 ( 49%)]  Loss: 1.341 (1.73)  Time: 0.468s,   17.09/s  (0.473s,   16.90/s)  LR: 6.206e-05  Data: 0.011 (0.008)\n",
            "Train: 34 [1200/2354 ( 51%)]  Loss: 1.917 (1.73)  Time: 0.482s,   16.59/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [1250/2354 ( 53%)]  Loss: 1.956 (1.72)  Time: 0.463s,   17.28/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.008 (0.008)\n",
            "Train: 34 [1300/2354 ( 55%)]  Loss: 1.075 (1.72)  Time: 0.631s,   12.67/s  (0.474s,   16.89/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [1350/2354 ( 57%)]  Loss: 1.629 (1.73)  Time: 0.469s,   17.06/s  (0.473s,   16.90/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [1400/2354 ( 59%)]  Loss: 1.464 (1.72)  Time: 0.474s,   16.89/s  (0.473s,   16.90/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [1450/2354 ( 62%)]  Loss: 1.483 (1.72)  Time: 0.466s,   17.17/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.010 (0.008)\n",
            "Train: 34 [1500/2354 ( 64%)]  Loss: 1.199 (1.72)  Time: 0.469s,   17.04/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.011 (0.008)\n",
            "Train: 34 [1550/2354 ( 66%)]  Loss: 2.985 (1.72)  Time: 0.467s,   17.14/s  (0.473s,   16.90/s)  LR: 6.206e-05  Data: 0.010 (0.008)\n",
            "Train: 34 [1600/2354 ( 68%)]  Loss: 2.597 (1.72)  Time: 0.473s,   16.93/s  (0.473s,   16.90/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [1650/2354 ( 70%)]  Loss: 1.041 (1.72)  Time: 0.463s,   17.30/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [1700/2354 ( 72%)]  Loss: 1.309 (1.72)  Time: 0.468s,   17.10/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.006 (0.008)\n",
            "Train: 34 [1750/2354 ( 74%)]  Loss: 2.046 (1.72)  Time: 0.466s,   17.16/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.010 (0.008)\n",
            "Train: 34 [1800/2354 ( 76%)]  Loss: 1.590 (1.72)  Time: 0.463s,   17.27/s  (0.473s,   16.90/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [1850/2354 ( 79%)]  Loss: 2.100 (1.73)  Time: 0.462s,   17.33/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [1900/2354 ( 81%)]  Loss: 1.568 (1.73)  Time: 0.465s,   17.22/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.008 (0.008)\n",
            "Train: 34 [1950/2354 ( 83%)]  Loss: 2.851 (1.73)  Time: 0.477s,   16.79/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.008 (0.008)\n",
            "Train: 34 [2000/2354 ( 85%)]  Loss: 1.569 (1.73)  Time: 0.461s,   17.36/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [2050/2354 ( 87%)]  Loss: 1.743 (1.73)  Time: 0.474s,   16.88/s  (0.473s,   16.91/s)  LR: 6.206e-05  Data: 0.010 (0.008)\n",
            "Train: 34 [2100/2354 ( 89%)]  Loss: 1.702 (1.73)  Time: 0.475s,   16.84/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [2150/2354 ( 91%)]  Loss: 1.348 (1.73)  Time: 0.463s,   17.30/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [2200/2354 ( 93%)]  Loss: 1.766 (1.73)  Time: 0.463s,   17.27/s  (0.473s,   16.93/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [2250/2354 ( 96%)]  Loss: 1.165 (1.73)  Time: 0.472s,   16.96/s  (0.473s,   16.93/s)  LR: 6.206e-05  Data: 0.009 (0.008)\n",
            "Train: 34 [2300/2354 ( 98%)]  Loss: 1.546 (1.73)  Time: 0.464s,   17.26/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.007 (0.008)\n",
            "Train: 34 [2350/2354 (100%)]  Loss: 1.024 (1.73)  Time: 0.458s,   17.46/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.005 (0.008)\n",
            "Train: 34 [2353/2354 (100%)]  Loss: 1.276 (1.73)  Time: 0.457s,   17.51/s  (0.473s,   16.92/s)  LR: 6.206e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.686 (0.686)  Loss:  0.0909 (0.0909)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.112 (0.159)  Loss:  0.4099 (0.2107)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (99.5098)\n",
            "Test: [ 100/2354]  Time: 0.184 (0.150)  Loss:  0.1065 (0.2234)  Acc@1: 100.0000 (98.2673)  Acc@5: 100.0000 (99.7525)\n",
            "Test: [ 150/2354]  Time: 0.119 (0.147)  Loss:  0.0482 (0.2530)  Acc@1: 100.0000 (97.6821)  Acc@5: 100.0000 (99.8344)\n",
            "Test: [ 200/2354]  Time: 0.131 (0.146)  Loss:  0.5981 (0.2353)  Acc@1: 75.0000 (97.7612)  Acc@5: 100.0000 (99.8756)\n",
            "Test: [ 250/2354]  Time: 0.166 (0.145)  Loss:  0.0416 (0.2324)  Acc@1: 100.0000 (97.8088)  Acc@5: 100.0000 (99.9004)\n",
            "Test: [ 300/2354]  Time: 0.180 (0.145)  Loss:  0.4607 (0.2257)  Acc@1: 100.0000 (97.8405)  Acc@5: 100.0000 (99.8339)\n",
            "Test: [ 350/2354]  Time: 0.123 (0.144)  Loss:  0.3481 (0.2538)  Acc@1: 100.0000 (97.2934)  Acc@5: 100.0000 (99.8575)\n",
            "Test: [ 400/2354]  Time: 0.137 (0.144)  Loss:  0.1429 (0.2542)  Acc@1: 100.0000 (97.0698)  Acc@5: 100.0000 (99.8753)\n",
            "Test: [ 450/2354]  Time: 0.169 (0.144)  Loss:  0.1066 (0.2575)  Acc@1: 100.0000 (97.0621)  Acc@5: 100.0000 (99.8891)\n",
            "Test: [ 500/2354]  Time: 0.145 (0.144)  Loss:  0.3320 (0.2526)  Acc@1: 100.0000 (97.1557)  Acc@5: 100.0000 (99.9002)\n",
            "Test: [ 550/2354]  Time: 0.214 (0.146)  Loss:  0.3091 (0.2508)  Acc@1: 100.0000 (97.1416)  Acc@5: 100.0000 (99.9093)\n",
            "Test: [ 600/2354]  Time: 0.146 (0.147)  Loss:  0.0534 (0.2453)  Acc@1: 100.0000 (97.2962)  Acc@5: 100.0000 (99.9168)\n",
            "Test: [ 650/2354]  Time: 0.140 (0.146)  Loss:  0.0865 (0.2364)  Acc@1: 100.0000 (97.4654)  Acc@5: 100.0000 (99.9232)\n",
            "Test: [ 700/2354]  Time: 0.083 (0.146)  Loss:  0.0346 (0.2295)  Acc@1: 100.0000 (97.6106)  Acc@5: 100.0000 (99.9287)\n",
            "Test: [ 750/2354]  Time: 0.092 (0.146)  Loss:  0.1448 (0.2317)  Acc@1: 100.0000 (97.6365)  Acc@5: 100.0000 (99.9334)\n",
            "Test: [ 800/2354]  Time: 0.125 (0.145)  Loss:  0.1315 (0.2424)  Acc@1: 100.0000 (97.3471)  Acc@5: 100.0000 (99.9376)\n",
            "Test: [ 850/2354]  Time: 0.144 (0.145)  Loss:  0.1515 (0.2393)  Acc@1: 100.0000 (97.4148)  Acc@5: 100.0000 (99.9119)\n",
            "Test: [ 900/2354]  Time: 0.150 (0.145)  Loss:  0.4751 (0.2324)  Acc@1: 100.0000 (97.5305)  Acc@5: 100.0000 (99.9168)\n",
            "Test: [ 950/2354]  Time: 0.128 (0.145)  Loss:  0.1819 (0.2293)  Acc@1: 100.0000 (97.5552)  Acc@5: 100.0000 (99.9211)\n",
            "Test: [1000/2354]  Time: 0.101 (0.145)  Loss:  0.0518 (0.2260)  Acc@1: 100.0000 (97.6274)  Acc@5: 100.0000 (99.9251)\n",
            "Test: [1050/2354]  Time: 0.126 (0.145)  Loss:  0.2749 (0.2263)  Acc@1: 100.0000 (97.6213)  Acc@5: 100.0000 (99.9286)\n",
            "Test: [1100/2354]  Time: 0.170 (0.145)  Loss:  0.1337 (0.2278)  Acc@1: 100.0000 (97.5931)  Acc@5: 100.0000 (99.9319)\n",
            "Test: [1150/2354]  Time: 0.164 (0.144)  Loss:  0.9731 (0.2267)  Acc@1: 100.0000 (97.5891)  Acc@5: 100.0000 (99.9131)\n",
            "Test: [1200/2354]  Time: 0.161 (0.144)  Loss:  0.8975 (0.2305)  Acc@1: 75.0000 (97.4813)  Acc@5: 100.0000 (99.8959)\n",
            "Test: [1250/2354]  Time: 0.151 (0.144)  Loss:  0.2356 (0.2262)  Acc@1: 100.0000 (97.5620)  Acc@5: 100.0000 (99.9001)\n",
            "Test: [1300/2354]  Time: 0.170 (0.144)  Loss:  0.0941 (0.2262)  Acc@1: 100.0000 (97.4827)  Acc@5: 100.0000 (99.9039)\n",
            "Test: [1350/2354]  Time: 0.235 (0.144)  Loss:  0.1277 (0.2265)  Acc@1: 100.0000 (97.5204)  Acc@5: 100.0000 (99.9075)\n",
            "Test: [1400/2354]  Time: 0.218 (0.145)  Loss:  0.1484 (0.2266)  Acc@1: 100.0000 (97.5018)  Acc@5: 100.0000 (99.9108)\n",
            "Test: [1450/2354]  Time: 0.139 (0.145)  Loss:  0.1395 (0.2255)  Acc@1: 100.0000 (97.5362)  Acc@5: 100.0000 (99.9139)\n",
            "Test: [1500/2354]  Time: 0.096 (0.145)  Loss:  0.1510 (0.2232)  Acc@1: 100.0000 (97.6016)  Acc@5: 100.0000 (99.9167)\n",
            "Test: [1550/2354]  Time: 0.140 (0.145)  Loss:  0.1061 (0.2297)  Acc@1: 100.0000 (97.2760)  Acc@5: 100.0000 (99.9194)\n",
            "Test: [1600/2354]  Time: 0.082 (0.145)  Loss:  0.0839 (0.2322)  Acc@1: 100.0000 (97.1893)  Acc@5: 100.0000 (99.9063)\n",
            "Test: [1650/2354]  Time: 0.162 (0.145)  Loss:  0.0781 (0.2369)  Acc@1: 100.0000 (97.0775)  Acc@5: 100.0000 (99.8940)\n",
            "Test: [1700/2354]  Time: 0.153 (0.145)  Loss:  0.2788 (0.2389)  Acc@1: 100.0000 (97.0459)  Acc@5: 100.0000 (99.8824)\n",
            "Test: [1750/2354]  Time: 0.149 (0.145)  Loss:  0.1609 (0.2419)  Acc@1: 100.0000 (97.0017)  Acc@5: 100.0000 (99.8858)\n",
            "Test: [1800/2354]  Time: 0.200 (0.145)  Loss:  0.3254 (0.2432)  Acc@1: 100.0000 (96.9739)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [1850/2354]  Time: 0.139 (0.145)  Loss:  0.2103 (0.2429)  Acc@1: 100.0000 (97.0016)  Acc@5: 100.0000 (99.8649)\n",
            "Test: [1900/2354]  Time: 0.100 (0.145)  Loss:  0.2019 (0.2402)  Acc@1: 100.0000 (97.0542)  Acc@5: 100.0000 (99.8685)\n",
            "Test: [1950/2354]  Time: 0.133 (0.145)  Loss:  0.2620 (0.2389)  Acc@1: 100.0000 (97.1169)  Acc@5: 100.0000 (99.8590)\n",
            "Test: [2000/2354]  Time: 0.178 (0.145)  Loss:  0.2388 (0.2375)  Acc@1: 100.0000 (97.1514)  Acc@5: 100.0000 (99.8626)\n",
            "Test: [2050/2354]  Time: 0.144 (0.145)  Loss:  0.1852 (0.2410)  Acc@1: 100.0000 (97.0502)  Acc@5: 100.0000 (99.8537)\n",
            "Test: [2100/2354]  Time: 0.145 (0.144)  Loss:  0.5962 (0.2462)  Acc@1: 100.0000 (96.8943)  Acc@5: 100.0000 (99.8572)\n",
            "Test: [2150/2354]  Time: 0.120 (0.144)  Loss:  0.4380 (0.2489)  Acc@1: 100.0000 (96.8503)  Acc@5: 100.0000 (99.8605)\n",
            "Test: [2200/2354]  Time: 0.160 (0.145)  Loss:  0.4021 (0.2503)  Acc@1: 75.0000 (96.8310)  Acc@5: 100.0000 (99.8637)\n",
            "Test: [2250/2354]  Time: 0.200 (0.145)  Loss:  0.0317 (0.2486)  Acc@1: 100.0000 (96.8792)  Acc@5: 100.0000 (99.8667)\n",
            "Test: [2300/2354]  Time: 0.183 (0.145)  Loss:  0.0300 (0.2460)  Acc@1: 100.0000 (96.9361)  Acc@5: 100.0000 (99.8588)\n",
            "Test: [2350/2354]  Time: 0.075 (0.145)  Loss:  0.0700 (0.2461)  Acc@1: 100.0000 (96.9268)  Acc@5: 100.0000 (99.8618)\n",
            "Test: [2354/2354]  Time: 0.064 (0.144)  Loss:  0.0475 (0.2460)  Acc@1: 100.0000 (96.9317)  Acc@5: 100.0000 (99.8620)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-24.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar', 93.37509289733518)\n",
            "\n",
            "Train: 35 [   0/2354 (  0%)]  Loss: 2.050 (2.05)  Time: 1.301s,    6.15/s  (1.301s,    6.15/s)  LR: 6.016e-05  Data: 0.544 (0.544)\n",
            "Train: 35 [  50/2354 (  2%)]  Loss: 1.180 (1.65)  Time: 0.473s,   16.92/s  (0.505s,   15.84/s)  LR: 6.016e-05  Data: 0.009 (0.018)\n",
            "Train: 35 [ 100/2354 (  4%)]  Loss: 1.306 (1.63)  Time: 0.481s,   16.65/s  (0.487s,   16.42/s)  LR: 6.016e-05  Data: 0.007 (0.013)\n",
            "Train: 35 [ 150/2354 (  6%)]  Loss: 3.058 (1.68)  Time: 0.472s,   16.96/s  (0.480s,   16.66/s)  LR: 6.016e-05  Data: 0.006 (0.011)\n",
            "Train: 35 [ 200/2354 (  8%)]  Loss: 1.370 (1.66)  Time: 0.469s,   17.04/s  (0.481s,   16.64/s)  LR: 6.016e-05  Data: 0.007 (0.011)\n",
            "Train: 35 [ 250/2354 ( 11%)]  Loss: 1.173 (1.65)  Time: 0.471s,   17.00/s  (0.478s,   16.72/s)  LR: 6.016e-05  Data: 0.010 (0.010)\n",
            "Train: 35 [ 300/2354 ( 13%)]  Loss: 1.690 (1.66)  Time: 0.464s,   17.25/s  (0.477s,   16.78/s)  LR: 6.016e-05  Data: 0.007 (0.010)\n",
            "Train: 35 [ 350/2354 ( 15%)]  Loss: 1.088 (1.66)  Time: 0.468s,   17.09/s  (0.475s,   16.83/s)  LR: 6.016e-05  Data: 0.007 (0.009)\n",
            "Train: 35 [ 400/2354 ( 17%)]  Loss: 1.562 (1.68)  Time: 0.472s,   16.96/s  (0.475s,   16.85/s)  LR: 6.016e-05  Data: 0.006 (0.009)\n",
            "Train: 35 [ 450/2354 ( 19%)]  Loss: 1.334 (1.69)  Time: 0.469s,   17.05/s  (0.476s,   16.82/s)  LR: 6.016e-05  Data: 0.010 (0.009)\n",
            "Train: 35 [ 500/2354 ( 21%)]  Loss: 1.137 (1.69)  Time: 0.465s,   17.20/s  (0.475s,   16.84/s)  LR: 6.016e-05  Data: 0.007 (0.009)\n",
            "Train: 35 [ 550/2354 ( 23%)]  Loss: 1.305 (1.69)  Time: 0.469s,   17.06/s  (0.474s,   16.86/s)  LR: 6.016e-05  Data: 0.007 (0.009)\n",
            "Train: 35 [ 600/2354 ( 25%)]  Loss: 1.029 (1.69)  Time: 0.467s,   17.12/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.010 (0.009)\n",
            "Train: 35 [ 650/2354 ( 28%)]  Loss: 1.743 (1.69)  Time: 0.477s,   16.77/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.010 (0.009)\n",
            "Train: 35 [ 700/2354 ( 30%)]  Loss: 1.788 (1.69)  Time: 0.465s,   17.20/s  (0.475s,   16.86/s)  LR: 6.016e-05  Data: 0.007 (0.009)\n",
            "Train: 35 [ 750/2354 ( 32%)]  Loss: 2.846 (1.69)  Time: 0.466s,   17.15/s  (0.474s,   16.87/s)  LR: 6.016e-05  Data: 0.007 (0.009)\n",
            "Train: 35 [ 800/2354 ( 34%)]  Loss: 1.927 (1.68)  Time: 0.473s,   16.91/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.007 (0.009)\n",
            "Train: 35 [ 850/2354 ( 36%)]  Loss: 1.298 (1.69)  Time: 0.473s,   16.90/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.007 (0.009)\n",
            "Train: 35 [ 900/2354 ( 38%)]  Loss: 1.611 (1.69)  Time: 0.471s,   16.97/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.009 (0.009)\n",
            "Train: 35 [ 950/2354 ( 40%)]  Loss: 1.366 (1.68)  Time: 0.464s,   17.22/s  (0.474s,   16.87/s)  LR: 6.016e-05  Data: 0.008 (0.008)\n",
            "Train: 35 [1000/2354 ( 42%)]  Loss: 1.247 (1.68)  Time: 0.464s,   17.26/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1050/2354 ( 45%)]  Loss: 1.671 (1.69)  Time: 0.469s,   17.07/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.009 (0.008)\n",
            "Train: 35 [1100/2354 ( 47%)]  Loss: 1.162 (1.69)  Time: 0.467s,   17.13/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1150/2354 ( 49%)]  Loss: 1.501 (1.69)  Time: 0.466s,   17.18/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1200/2354 ( 51%)]  Loss: 2.148 (1.69)  Time: 0.464s,   17.24/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.008 (0.008)\n",
            "Train: 35 [1250/2354 ( 53%)]  Loss: 1.060 (1.69)  Time: 0.469s,   17.06/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1300/2354 ( 55%)]  Loss: 1.348 (1.70)  Time: 0.481s,   16.65/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1350/2354 ( 57%)]  Loss: 1.209 (1.70)  Time: 0.464s,   17.25/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1400/2354 ( 59%)]  Loss: 1.069 (1.70)  Time: 0.462s,   17.30/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1450/2354 ( 62%)]  Loss: 1.816 (1.70)  Time: 0.468s,   17.11/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1500/2354 ( 64%)]  Loss: 1.265 (1.70)  Time: 0.472s,   16.94/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.010 (0.008)\n",
            "Train: 35 [1550/2354 ( 66%)]  Loss: 1.912 (1.70)  Time: 0.463s,   17.28/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1600/2354 ( 68%)]  Loss: 1.523 (1.70)  Time: 0.470s,   17.02/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.010 (0.008)\n",
            "Train: 35 [1650/2354 ( 70%)]  Loss: 1.099 (1.71)  Time: 0.476s,   16.80/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1700/2354 ( 72%)]  Loss: 1.489 (1.70)  Time: 0.474s,   16.88/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1750/2354 ( 74%)]  Loss: 1.222 (1.70)  Time: 0.465s,   17.21/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1800/2354 ( 76%)]  Loss: 1.198 (1.70)  Time: 0.480s,   16.66/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1850/2354 ( 79%)]  Loss: 1.898 (1.70)  Time: 0.463s,   17.26/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1900/2354 ( 81%)]  Loss: 1.101 (1.70)  Time: 0.463s,   17.26/s  (0.473s,   16.90/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [1950/2354 ( 83%)]  Loss: 1.643 (1.70)  Time: 0.470s,   17.01/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [2000/2354 ( 85%)]  Loss: 1.971 (1.71)  Time: 0.486s,   16.47/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [2050/2354 ( 87%)]  Loss: 1.442 (1.70)  Time: 0.470s,   17.04/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.010 (0.008)\n",
            "Train: 35 [2100/2354 ( 89%)]  Loss: 2.035 (1.70)  Time: 0.468s,   17.08/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.011 (0.008)\n",
            "Train: 35 [2150/2354 ( 91%)]  Loss: 1.664 (1.70)  Time: 0.487s,   16.44/s  (0.474s,   16.89/s)  LR: 6.016e-05  Data: 0.010 (0.008)\n",
            "Train: 35 [2200/2354 ( 93%)]  Loss: 1.097 (1.70)  Time: 0.466s,   17.15/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.008 (0.008)\n",
            "Train: 35 [2250/2354 ( 96%)]  Loss: 1.722 (1.70)  Time: 0.469s,   17.06/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.007 (0.008)\n",
            "Train: 35 [2300/2354 ( 98%)]  Loss: 2.943 (1.70)  Time: 0.476s,   16.80/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.010 (0.008)\n",
            "Train: 35 [2350/2354 (100%)]  Loss: 1.046 (1.70)  Time: 0.466s,   17.15/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.006 (0.008)\n",
            "Train: 35 [2353/2354 (100%)]  Loss: 1.545 (1.70)  Time: 0.457s,   17.51/s  (0.474s,   16.88/s)  LR: 6.016e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.654 (0.654)  Loss:  0.2388 (0.2388)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.158 (0.165)  Loss:  0.2062 (0.1687)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (99.5098)\n",
            "Test: [ 100/2354]  Time: 0.193 (0.157)  Loss:  0.2227 (0.1745)  Acc@1: 100.0000 (99.0099)  Acc@5: 100.0000 (99.7525)\n",
            "Test: [ 150/2354]  Time: 0.217 (0.154)  Loss:  0.0368 (0.2125)  Acc@1: 100.0000 (97.6821)  Acc@5: 100.0000 (99.8344)\n",
            "Test: [ 200/2354]  Time: 0.152 (0.161)  Loss:  0.2568 (0.2007)  Acc@1: 100.0000 (97.8856)  Acc@5: 100.0000 (99.8756)\n",
            "Test: [ 250/2354]  Time: 0.160 (0.159)  Loss:  0.0458 (0.1994)  Acc@1: 100.0000 (98.0080)  Acc@5: 100.0000 (99.9004)\n",
            "Test: [ 300/2354]  Time: 0.128 (0.156)  Loss:  0.6777 (0.2004)  Acc@1: 100.0000 (98.0897)  Acc@5: 100.0000 (99.9169)\n",
            "Test: [ 350/2354]  Time: 0.157 (0.155)  Loss:  0.2095 (0.2229)  Acc@1: 100.0000 (97.5783)  Acc@5: 100.0000 (99.9288)\n",
            "Test: [ 400/2354]  Time: 0.151 (0.154)  Loss:  0.1088 (0.2263)  Acc@1: 100.0000 (97.6933)  Acc@5: 100.0000 (99.9377)\n",
            "Test: [ 450/2354]  Time: 0.084 (0.153)  Loss:  0.0866 (0.2220)  Acc@1: 100.0000 (97.8381)  Acc@5: 100.0000 (99.9446)\n",
            "Test: [ 500/2354]  Time: 0.208 (0.153)  Loss:  0.2476 (0.2142)  Acc@1: 100.0000 (97.9541)  Acc@5: 100.0000 (99.9501)\n",
            "Test: [ 550/2354]  Time: 0.194 (0.153)  Loss:  0.2197 (0.2139)  Acc@1: 100.0000 (97.9583)  Acc@5: 100.0000 (99.9546)\n",
            "Test: [ 600/2354]  Time: 0.207 (0.153)  Loss:  0.0559 (0.2069)  Acc@1: 100.0000 (98.1281)  Acc@5: 100.0000 (99.9584)\n",
            "Test: [ 650/2354]  Time: 0.134 (0.152)  Loss:  0.1244 (0.2048)  Acc@1: 100.0000 (98.1951)  Acc@5: 100.0000 (99.9616)\n",
            "Test: [ 700/2354]  Time: 0.139 (0.152)  Loss:  0.0798 (0.2007)  Acc@1: 100.0000 (98.2882)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [ 750/2354]  Time: 0.106 (0.152)  Loss:  0.2092 (0.2007)  Acc@1: 100.0000 (98.3688)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [ 800/2354]  Time: 0.141 (0.152)  Loss:  0.0968 (0.2028)  Acc@1: 100.0000 (98.2210)  Acc@5: 100.0000 (99.9688)\n",
            "Test: [ 850/2354]  Time: 0.106 (0.151)  Loss:  0.1532 (0.2004)  Acc@1: 100.0000 (98.2961)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [ 900/2354]  Time: 0.169 (0.151)  Loss:  0.2917 (0.1962)  Acc@1: 100.0000 (98.3907)  Acc@5: 100.0000 (99.9723)\n",
            "Test: [ 950/2354]  Time: 0.130 (0.151)  Loss:  0.3462 (0.1948)  Acc@1: 100.0000 (98.3176)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1000/2354]  Time: 0.296 (0.152)  Loss:  0.0492 (0.1929)  Acc@1: 100.0000 (98.3766)  Acc@5: 100.0000 (99.9750)\n",
            "Test: [1050/2354]  Time: 0.129 (0.152)  Loss:  0.1743 (0.1917)  Acc@1: 100.0000 (98.4063)  Acc@5: 100.0000 (99.9762)\n",
            "Test: [1100/2354]  Time: 0.189 (0.152)  Loss:  0.1329 (0.1926)  Acc@1: 100.0000 (98.3878)  Acc@5: 100.0000 (99.9773)\n",
            "Test: [1150/2354]  Time: 0.157 (0.151)  Loss:  0.6030 (0.1926)  Acc@1: 100.0000 (98.3710)  Acc@5: 100.0000 (99.9566)\n",
            "Test: [1200/2354]  Time: 0.081 (0.151)  Loss:  0.6587 (0.1968)  Acc@1: 75.0000 (98.1474)  Acc@5: 100.0000 (99.9584)\n",
            "Test: [1250/2354]  Time: 0.101 (0.151)  Loss:  0.1638 (0.1941)  Acc@1: 100.0000 (98.1815)  Acc@5: 100.0000 (99.9600)\n",
            "Test: [1300/2354]  Time: 0.169 (0.151)  Loss:  0.1185 (0.1960)  Acc@1: 100.0000 (98.1937)  Acc@5: 100.0000 (99.9424)\n",
            "Test: [1350/2354]  Time: 0.175 (0.150)  Loss:  0.0568 (0.1991)  Acc@1: 100.0000 (98.1310)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [1400/2354]  Time: 0.193 (0.150)  Loss:  0.1807 (0.1979)  Acc@1: 100.0000 (98.1620)  Acc@5: 100.0000 (99.9465)\n",
            "Test: [1450/2354]  Time: 0.131 (0.150)  Loss:  0.0779 (0.1972)  Acc@1: 100.0000 (98.1392)  Acc@5: 100.0000 (99.9483)\n",
            "Test: [1500/2354]  Time: 0.118 (0.150)  Loss:  0.1288 (0.1960)  Acc@1: 100.0000 (98.1845)  Acc@5: 100.0000 (99.9500)\n",
            "Test: [1550/2354]  Time: 0.177 (0.150)  Loss:  0.1562 (0.2030)  Acc@1: 100.0000 (98.0980)  Acc@5: 100.0000 (99.9516)\n",
            "Test: [1600/2354]  Time: 0.180 (0.150)  Loss:  0.2203 (0.2066)  Acc@1: 100.0000 (98.0169)  Acc@5: 100.0000 (99.9375)\n",
            "Test: [1650/2354]  Time: 0.100 (0.149)  Loss:  0.2454 (0.2078)  Acc@1: 100.0000 (98.0315)  Acc@5: 100.0000 (99.9243)\n",
            "Test: [1700/2354]  Time: 0.150 (0.150)  Loss:  0.0848 (0.2078)  Acc@1: 100.0000 (97.9865)  Acc@5: 100.0000 (99.9118)\n",
            "Test: [1750/2354]  Time: 0.113 (0.149)  Loss:  0.1396 (0.2116)  Acc@1: 100.0000 (97.9298)  Acc@5: 100.0000 (99.9143)\n",
            "Test: [1800/2354]  Time: 0.132 (0.149)  Loss:  0.2642 (0.2120)  Acc@1: 100.0000 (97.9317)  Acc@5: 100.0000 (99.9028)\n",
            "Test: [1850/2354]  Time: 0.122 (0.150)  Loss:  0.0857 (0.2111)  Acc@1: 100.0000 (97.9471)  Acc@5: 100.0000 (99.9055)\n",
            "Test: [1900/2354]  Time: 0.137 (0.150)  Loss:  0.0809 (0.2108)  Acc@1: 100.0000 (97.9748)  Acc@5: 100.0000 (99.9079)\n",
            "Test: [1950/2354]  Time: 0.186 (0.150)  Loss:  0.0811 (0.2116)  Acc@1: 100.0000 (97.9626)  Acc@5: 100.0000 (99.8975)\n",
            "Test: [2000/2354]  Time: 0.131 (0.150)  Loss:  0.0695 (0.2104)  Acc@1: 100.0000 (97.9885)  Acc@5: 100.0000 (99.9000)\n",
            "Test: [2050/2354]  Time: 0.179 (0.150)  Loss:  0.2032 (0.2148)  Acc@1: 100.0000 (97.8913)  Acc@5: 100.0000 (99.9025)\n",
            "Test: [2100/2354]  Time: 0.165 (0.150)  Loss:  0.6265 (0.2191)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (99.8929)\n",
            "Test: [2150/2354]  Time: 0.116 (0.150)  Loss:  0.3147 (0.2230)  Acc@1: 75.0000 (97.6174)  Acc@5: 100.0000 (99.8954)\n",
            "Test: [2200/2354]  Time: 0.179 (0.150)  Loss:  0.3979 (0.2276)  Acc@1: 100.0000 (97.4103)  Acc@5: 100.0000 (99.8978)\n",
            "Test: [2250/2354]  Time: 0.166 (0.150)  Loss:  0.0721 (0.2272)  Acc@1: 100.0000 (97.4456)  Acc@5: 100.0000 (99.9000)\n",
            "Test: [2300/2354]  Time: 0.149 (0.150)  Loss:  0.0516 (0.2265)  Acc@1: 100.0000 (97.4902)  Acc@5: 100.0000 (99.8914)\n",
            "Test: [2350/2354]  Time: 0.076 (0.149)  Loss:  0.0377 (0.2267)  Acc@1: 100.0000 (97.4798)  Acc@5: 100.0000 (99.8937)\n",
            "Test: [2354/2354]  Time: 0.070 (0.149)  Loss:  0.0371 (0.2266)  Acc@1: 100.0000 (97.4838)  Acc@5: 100.0000 (99.8938)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-27.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar', 93.42817708886294)\n",
            "\n",
            "Train: 36 [   0/2354 (  0%)]  Loss: 1.210 (1.21)  Time: 1.391s,    5.75/s  (1.391s,    5.75/s)  LR: 5.824e-05  Data: 0.636 (0.636)\n",
            "Train: 36 [  50/2354 (  2%)]  Loss: 1.192 (1.70)  Time: 0.473s,   16.90/s  (0.515s,   15.54/s)  LR: 5.824e-05  Data: 0.011 (0.021)\n",
            "Train: 36 [ 100/2354 (  4%)]  Loss: 1.011 (1.67)  Time: 0.479s,   16.69/s  (0.505s,   15.85/s)  LR: 5.824e-05  Data: 0.008 (0.015)\n",
            "Train: 36 [ 150/2354 (  6%)]  Loss: 1.089 (1.64)  Time: 0.473s,   16.93/s  (0.494s,   16.21/s)  LR: 5.824e-05  Data: 0.010 (0.013)\n",
            "Train: 36 [ 200/2354 (  8%)]  Loss: 1.605 (1.64)  Time: 0.476s,   16.81/s  (0.489s,   16.37/s)  LR: 5.824e-05  Data: 0.011 (0.012)\n",
            "Train: 36 [ 250/2354 ( 11%)]  Loss: 4.803 (1.66)  Time: 0.471s,   16.97/s  (0.486s,   16.47/s)  LR: 5.824e-05  Data: 0.007 (0.011)\n",
            "Train: 36 [ 300/2354 ( 13%)]  Loss: 1.088 (1.65)  Time: 0.469s,   17.08/s  (0.484s,   16.54/s)  LR: 5.824e-05  Data: 0.008 (0.010)\n",
            "Train: 36 [ 350/2354 ( 15%)]  Loss: 3.675 (1.67)  Time: 0.476s,   16.81/s  (0.486s,   16.48/s)  LR: 5.824e-05  Data: 0.011 (0.010)\n",
            "Train: 36 [ 400/2354 ( 17%)]  Loss: 1.917 (1.68)  Time: 0.471s,   17.00/s  (0.484s,   16.53/s)  LR: 5.824e-05  Data: 0.007 (0.010)\n",
            "Train: 36 [ 450/2354 ( 19%)]  Loss: 1.539 (1.68)  Time: 0.468s,   17.10/s  (0.483s,   16.57/s)  LR: 5.824e-05  Data: 0.007 (0.010)\n",
            "Train: 36 [ 500/2354 ( 21%)]  Loss: 1.331 (1.67)  Time: 0.474s,   16.87/s  (0.482s,   16.61/s)  LR: 5.824e-05  Data: 0.007 (0.010)\n",
            "Train: 36 [ 550/2354 ( 23%)]  Loss: 1.631 (1.67)  Time: 0.476s,   16.81/s  (0.481s,   16.64/s)  LR: 5.824e-05  Data: 0.011 (0.010)\n",
            "Train: 36 [ 600/2354 ( 25%)]  Loss: 2.101 (1.67)  Time: 0.482s,   16.60/s  (0.482s,   16.61/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [ 650/2354 ( 28%)]  Loss: 1.199 (1.68)  Time: 0.471s,   16.99/s  (0.481s,   16.63/s)  LR: 5.824e-05  Data: 0.010 (0.009)\n",
            "Train: 36 [ 700/2354 ( 30%)]  Loss: 1.099 (1.67)  Time: 0.475s,   16.84/s  (0.480s,   16.65/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [ 750/2354 ( 32%)]  Loss: 1.738 (1.66)  Time: 0.471s,   16.97/s  (0.480s,   16.67/s)  LR: 5.824e-05  Data: 0.011 (0.009)\n",
            "Train: 36 [ 800/2354 ( 34%)]  Loss: 1.250 (1.67)  Time: 0.467s,   17.13/s  (0.479s,   16.69/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [ 850/2354 ( 36%)]  Loss: 2.363 (1.68)  Time: 0.563s,   14.22/s  (0.480s,   16.67/s)  LR: 5.824e-05  Data: 0.010 (0.009)\n",
            "Train: 36 [ 900/2354 ( 38%)]  Loss: 1.600 (1.68)  Time: 0.465s,   17.19/s  (0.479s,   16.70/s)  LR: 5.824e-05  Data: 0.011 (0.009)\n",
            "Train: 36 [ 950/2354 ( 40%)]  Loss: 2.440 (1.68)  Time: 0.466s,   17.17/s  (0.478s,   16.72/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1000/2354 ( 42%)]  Loss: 1.135 (1.69)  Time: 0.471s,   16.99/s  (0.478s,   16.74/s)  LR: 5.824e-05  Data: 0.009 (0.009)\n",
            "Train: 36 [1050/2354 ( 45%)]  Loss: 1.212 (1.68)  Time: 0.466s,   17.15/s  (0.477s,   16.76/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1100/2354 ( 47%)]  Loss: 1.958 (1.68)  Time: 0.469s,   17.07/s  (0.477s,   16.77/s)  LR: 5.824e-05  Data: 0.008 (0.009)\n",
            "Train: 36 [1150/2354 ( 49%)]  Loss: 1.136 (1.68)  Time: 0.466s,   17.17/s  (0.478s,   16.74/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1200/2354 ( 51%)]  Loss: 1.445 (1.68)  Time: 0.465s,   17.19/s  (0.477s,   16.76/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1250/2354 ( 53%)]  Loss: 1.984 (1.68)  Time: 0.467s,   17.12/s  (0.477s,   16.77/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1300/2354 ( 55%)]  Loss: 1.987 (1.68)  Time: 0.467s,   17.14/s  (0.477s,   16.78/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1350/2354 ( 57%)]  Loss: 1.430 (1.68)  Time: 0.468s,   17.08/s  (0.476s,   16.79/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1400/2354 ( 59%)]  Loss: 2.485 (1.68)  Time: 0.466s,   17.17/s  (0.477s,   16.77/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1450/2354 ( 62%)]  Loss: 1.441 (1.68)  Time: 0.466s,   17.18/s  (0.477s,   16.78/s)  LR: 5.824e-05  Data: 0.010 (0.009)\n",
            "Train: 36 [1500/2354 ( 64%)]  Loss: 1.737 (1.68)  Time: 0.464s,   17.26/s  (0.476s,   16.79/s)  LR: 5.824e-05  Data: 0.008 (0.009)\n",
            "Train: 36 [1550/2354 ( 66%)]  Loss: 1.350 (1.68)  Time: 0.470s,   17.04/s  (0.476s,   16.80/s)  LR: 5.824e-05  Data: 0.009 (0.009)\n",
            "Train: 36 [1600/2354 ( 68%)]  Loss: 1.428 (1.69)  Time: 0.482s,   16.59/s  (0.476s,   16.81/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1650/2354 ( 70%)]  Loss: 1.241 (1.69)  Time: 0.466s,   17.18/s  (0.476s,   16.79/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1700/2354 ( 72%)]  Loss: 2.383 (1.69)  Time: 0.468s,   17.08/s  (0.476s,   16.80/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1750/2354 ( 74%)]  Loss: 1.713 (1.69)  Time: 0.467s,   17.14/s  (0.476s,   16.81/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1800/2354 ( 76%)]  Loss: 1.090 (1.69)  Time: 0.485s,   16.48/s  (0.476s,   16.82/s)  LR: 5.824e-05  Data: 0.011 (0.009)\n",
            "Train: 36 [1850/2354 ( 79%)]  Loss: 1.281 (1.69)  Time: 0.468s,   17.09/s  (0.476s,   16.82/s)  LR: 5.824e-05  Data: 0.010 (0.009)\n",
            "Train: 36 [1900/2354 ( 81%)]  Loss: 1.127 (1.69)  Time: 0.478s,   16.74/s  (0.476s,   16.81/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [1950/2354 ( 83%)]  Loss: 2.188 (1.69)  Time: 0.464s,   17.25/s  (0.476s,   16.82/s)  LR: 5.824e-05  Data: 0.008 (0.009)\n",
            "Train: 36 [2000/2354 ( 85%)]  Loss: 1.175 (1.69)  Time: 0.472s,   16.95/s  (0.476s,   16.82/s)  LR: 5.824e-05  Data: 0.007 (0.009)\n",
            "Train: 36 [2050/2354 ( 87%)]  Loss: 1.093 (1.69)  Time: 0.472s,   16.94/s  (0.475s,   16.82/s)  LR: 5.824e-05  Data: 0.011 (0.009)\n",
            "Train: 36 [2100/2354 ( 89%)]  Loss: 2.567 (1.69)  Time: 0.467s,   17.13/s  (0.475s,   16.83/s)  LR: 5.824e-05  Data: 0.009 (0.009)\n",
            "Train: 36 [2150/2354 ( 91%)]  Loss: 1.870 (1.68)  Time: 0.466s,   17.15/s  (0.475s,   16.84/s)  LR: 5.824e-05  Data: 0.007 (0.008)\n",
            "Train: 36 [2200/2354 ( 93%)]  Loss: 1.640 (1.68)  Time: 0.478s,   16.74/s  (0.475s,   16.83/s)  LR: 5.824e-05  Data: 0.008 (0.008)\n",
            "Train: 36 [2250/2354 ( 96%)]  Loss: 2.792 (1.69)  Time: 0.471s,   17.00/s  (0.475s,   16.83/s)  LR: 5.824e-05  Data: 0.011 (0.008)\n",
            "Train: 36 [2300/2354 ( 98%)]  Loss: 1.463 (1.69)  Time: 0.465s,   17.19/s  (0.475s,   16.83/s)  LR: 5.824e-05  Data: 0.010 (0.008)\n",
            "Train: 36 [2350/2354 (100%)]  Loss: 1.444 (1.69)  Time: 0.465s,   17.20/s  (0.475s,   16.84/s)  LR: 5.824e-05  Data: 0.006 (0.008)\n",
            "Train: 36 [2353/2354 (100%)]  Loss: 1.430 (1.69)  Time: 0.461s,   17.37/s  (0.475s,   16.84/s)  LR: 5.824e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.771 (0.771)  Loss:  0.1729 (0.1729)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.173 (0.173)  Loss:  0.4084 (0.1980)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (99.5098)\n",
            "Test: [ 100/2354]  Time: 0.159 (0.162)  Loss:  0.2886 (0.2067)  Acc@1: 100.0000 (98.7624)  Acc@5: 100.0000 (99.7525)\n",
            "Test: [ 150/2354]  Time: 0.115 (0.159)  Loss:  0.0609 (0.2297)  Acc@1: 100.0000 (98.3444)  Acc@5: 100.0000 (99.8344)\n",
            "Test: [ 200/2354]  Time: 0.252 (0.164)  Loss:  0.3872 (0.2147)  Acc@1: 100.0000 (98.6318)  Acc@5: 100.0000 (99.8756)\n",
            "Test: [ 250/2354]  Time: 0.107 (0.165)  Loss:  0.1104 (0.2130)  Acc@1: 100.0000 (98.7052)  Acc@5: 100.0000 (99.9004)\n",
            "Test: [ 300/2354]  Time: 0.121 (0.163)  Loss:  0.7397 (0.2209)  Acc@1: 75.0000 (98.3389)  Acc@5: 100.0000 (99.9169)\n",
            "Test: [ 350/2354]  Time: 0.188 (0.162)  Loss:  0.4688 (0.2357)  Acc@1: 75.0000 (97.8632)  Acc@5: 100.0000 (99.9288)\n",
            "Test: [ 400/2354]  Time: 0.146 (0.160)  Loss:  0.1117 (0.2452)  Acc@1: 100.0000 (97.7556)  Acc@5: 100.0000 (99.9377)\n",
            "Test: [ 450/2354]  Time: 0.112 (0.160)  Loss:  0.1078 (0.2442)  Acc@1: 100.0000 (97.8381)  Acc@5: 100.0000 (99.9446)\n",
            "Test: [ 500/2354]  Time: 0.179 (0.159)  Loss:  0.2147 (0.2359)  Acc@1: 100.0000 (97.9541)  Acc@5: 100.0000 (99.9501)\n",
            "Test: [ 550/2354]  Time: 0.157 (0.159)  Loss:  0.1202 (0.2345)  Acc@1: 100.0000 (97.9129)  Acc@5: 100.0000 (99.9546)\n",
            "Test: [ 600/2354]  Time: 0.173 (0.158)  Loss:  0.1409 (0.2291)  Acc@1: 100.0000 (97.9617)  Acc@5: 100.0000 (99.9584)\n",
            "Test: [ 650/2354]  Time: 0.150 (0.158)  Loss:  0.1006 (0.2230)  Acc@1: 100.0000 (98.0799)  Acc@5: 100.0000 (99.9616)\n",
            "Test: [ 700/2354]  Time: 0.159 (0.157)  Loss:  0.0381 (0.2168)  Acc@1: 100.0000 (98.1812)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [ 750/2354]  Time: 0.166 (0.157)  Loss:  0.1890 (0.2142)  Acc@1: 100.0000 (98.2357)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [ 800/2354]  Time: 0.085 (0.157)  Loss:  0.2766 (0.2192)  Acc@1: 100.0000 (98.0961)  Acc@5: 100.0000 (99.9688)\n",
            "Test: [ 850/2354]  Time: 0.189 (0.157)  Loss:  0.1066 (0.2172)  Acc@1: 100.0000 (98.1492)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [ 900/2354]  Time: 0.184 (0.156)  Loss:  0.2646 (0.2119)  Acc@1: 100.0000 (98.2519)  Acc@5: 100.0000 (99.9723)\n",
            "Test: [ 950/2354]  Time: 0.118 (0.156)  Loss:  0.2197 (0.2104)  Acc@1: 100.0000 (98.2650)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1000/2354]  Time: 0.286 (0.157)  Loss:  0.0955 (0.2099)  Acc@1: 100.0000 (98.2018)  Acc@5: 100.0000 (99.9750)\n",
            "Test: [1050/2354]  Time: 0.153 (0.158)  Loss:  0.1223 (0.2083)  Acc@1: 100.0000 (98.2636)  Acc@5: 100.0000 (99.9762)\n",
            "Test: [1100/2354]  Time: 0.149 (0.158)  Loss:  0.3975 (0.2093)  Acc@1: 100.0000 (98.2516)  Acc@5: 100.0000 (99.9773)\n",
            "Test: [1150/2354]  Time: 0.210 (0.158)  Loss:  0.8657 (0.2084)  Acc@1: 100.0000 (98.3058)  Acc@5: 100.0000 (99.9783)\n",
            "Test: [1200/2354]  Time: 0.194 (0.158)  Loss:  0.9453 (0.2110)  Acc@1: 75.0000 (98.2515)  Acc@5: 100.0000 (99.9584)\n",
            "Test: [1250/2354]  Time: 0.096 (0.157)  Loss:  0.1072 (0.2100)  Acc@1: 100.0000 (98.2614)  Acc@5: 100.0000 (99.9400)\n",
            "Test: [1300/2354]  Time: 0.144 (0.157)  Loss:  0.0728 (0.2119)  Acc@1: 100.0000 (98.2513)  Acc@5: 100.0000 (99.9231)\n",
            "Test: [1350/2354]  Time: 0.144 (0.157)  Loss:  0.0637 (0.2110)  Acc@1: 100.0000 (98.2791)  Acc@5: 100.0000 (99.9260)\n",
            "Test: [1400/2354]  Time: 0.162 (0.157)  Loss:  0.0781 (0.2089)  Acc@1: 100.0000 (98.3048)  Acc@5: 100.0000 (99.9108)\n",
            "Test: [1450/2354]  Time: 0.108 (0.157)  Loss:  0.0941 (0.2073)  Acc@1: 100.0000 (98.2943)  Acc@5: 100.0000 (99.9139)\n",
            "Test: [1500/2354]  Time: 0.191 (0.157)  Loss:  0.0623 (0.2077)  Acc@1: 100.0000 (98.2345)  Acc@5: 100.0000 (99.9001)\n",
            "Test: [1550/2354]  Time: 0.214 (0.157)  Loss:  0.1426 (0.2110)  Acc@1: 100.0000 (98.1786)  Acc@5: 100.0000 (99.9033)\n",
            "Test: [1600/2354]  Time: 0.116 (0.157)  Loss:  0.1714 (0.2161)  Acc@1: 100.0000 (98.0793)  Acc@5: 100.0000 (99.8907)\n",
            "Test: [1650/2354]  Time: 0.179 (0.157)  Loss:  0.1029 (0.2201)  Acc@1: 100.0000 (97.9406)  Acc@5: 100.0000 (99.8940)\n",
            "Test: [1700/2354]  Time: 0.163 (0.157)  Loss:  0.1565 (0.2195)  Acc@1: 100.0000 (97.9718)  Acc@5: 100.0000 (99.8824)\n",
            "Test: [1750/2354]  Time: 0.194 (0.157)  Loss:  0.0917 (0.2242)  Acc@1: 100.0000 (97.8584)  Acc@5: 100.0000 (99.8858)\n",
            "Test: [1800/2354]  Time: 0.169 (0.158)  Loss:  0.6362 (0.2258)  Acc@1: 75.0000 (97.8068)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [1850/2354]  Time: 0.223 (0.158)  Loss:  0.0710 (0.2249)  Acc@1: 100.0000 (97.8255)  Acc@5: 100.0000 (99.8649)\n",
            "Test: [1900/2354]  Time: 0.190 (0.158)  Loss:  0.1808 (0.2258)  Acc@1: 100.0000 (97.8169)  Acc@5: 100.0000 (99.8685)\n",
            "Test: [1950/2354]  Time: 0.124 (0.158)  Loss:  0.0912 (0.2240)  Acc@1: 100.0000 (97.8601)  Acc@5: 100.0000 (99.8719)\n",
            "Test: [2000/2354]  Time: 0.138 (0.158)  Loss:  0.0700 (0.2240)  Acc@1: 100.0000 (97.8761)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [2050/2354]  Time: 0.150 (0.158)  Loss:  0.2993 (0.2278)  Acc@1: 100.0000 (97.7206)  Acc@5: 100.0000 (99.8659)\n",
            "Test: [2100/2354]  Time: 0.151 (0.158)  Loss:  0.2573 (0.2301)  Acc@1: 100.0000 (97.6797)  Acc@5: 100.0000 (99.8691)\n",
            "Test: [2150/2354]  Time: 0.098 (0.158)  Loss:  0.8379 (0.2333)  Acc@1: 100.0000 (97.6755)  Acc@5: 100.0000 (99.8722)\n",
            "Test: [2200/2354]  Time: 0.220 (0.158)  Loss:  0.1609 (0.2401)  Acc@1: 100.0000 (97.5579)  Acc@5: 100.0000 (99.8751)\n",
            "Test: [2250/2354]  Time: 0.190 (0.158)  Loss:  0.0407 (0.2396)  Acc@1: 100.0000 (97.5900)  Acc@5: 100.0000 (99.8778)\n",
            "Test: [2300/2354]  Time: 0.142 (0.158)  Loss:  0.0500 (0.2375)  Acc@1: 100.0000 (97.6315)  Acc@5: 100.0000 (99.8696)\n",
            "Test: [2350/2354]  Time: 0.076 (0.157)  Loss:  0.0581 (0.2370)  Acc@1: 100.0000 (97.6606)  Acc@5: 100.0000 (99.8724)\n",
            "Test: [2354/2354]  Time: 0.072 (0.157)  Loss:  0.0299 (0.2367)  Acc@1: 100.0000 (97.6643)  Acc@5: 100.0000 (99.8726)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-25.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar', 93.49187811869625)\n",
            "\n",
            "Train: 37 [   0/2354 (  0%)]  Loss: 1.871 (1.87)  Time: 1.416s,    5.65/s  (1.416s,    5.65/s)  LR: 5.632e-05  Data: 0.613 (0.613)\n",
            "Train: 37 [  50/2354 (  2%)]  Loss: 1.413 (1.58)  Time: 0.483s,   16.56/s  (0.516s,   15.52/s)  LR: 5.632e-05  Data: 0.007 (0.020)\n",
            "Train: 37 [ 100/2354 (  4%)]  Loss: 2.409 (1.58)  Time: 0.479s,   16.69/s  (0.508s,   15.73/s)  LR: 5.632e-05  Data: 0.007 (0.014)\n",
            "Train: 37 [ 150/2354 (  6%)]  Loss: 1.561 (1.61)  Time: 0.474s,   16.88/s  (0.498s,   16.05/s)  LR: 5.632e-05  Data: 0.007 (0.012)\n",
            "Train: 37 [ 200/2354 (  8%)]  Loss: 1.093 (1.63)  Time: 0.474s,   16.88/s  (0.493s,   16.22/s)  LR: 5.632e-05  Data: 0.007 (0.011)\n",
            "Train: 37 [ 250/2354 ( 11%)]  Loss: 1.392 (1.64)  Time: 0.473s,   16.90/s  (0.490s,   16.32/s)  LR: 5.632e-05  Data: 0.007 (0.011)\n",
            "Train: 37 [ 300/2354 ( 13%)]  Loss: 1.683 (1.65)  Time: 0.473s,   16.92/s  (0.488s,   16.39/s)  LR: 5.632e-05  Data: 0.007 (0.010)\n",
            "Train: 37 [ 350/2354 ( 15%)]  Loss: 1.836 (1.63)  Time: 0.489s,   16.37/s  (0.490s,   16.33/s)  LR: 5.632e-05  Data: 0.010 (0.010)\n",
            "Train: 37 [ 400/2354 ( 17%)]  Loss: 1.773 (1.62)  Time: 0.485s,   16.50/s  (0.488s,   16.39/s)  LR: 5.632e-05  Data: 0.007 (0.010)\n",
            "Train: 37 [ 450/2354 ( 19%)]  Loss: 1.672 (1.62)  Time: 0.494s,   16.19/s  (0.487s,   16.44/s)  LR: 5.632e-05  Data: 0.010 (0.010)\n",
            "Train: 37 [ 500/2354 ( 21%)]  Loss: 2.690 (1.62)  Time: 0.470s,   17.03/s  (0.486s,   16.47/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [ 550/2354 ( 23%)]  Loss: 1.083 (1.61)  Time: 0.469s,   17.05/s  (0.485s,   16.50/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [ 600/2354 ( 25%)]  Loss: 2.881 (1.61)  Time: 0.471s,   16.98/s  (0.486s,   16.46/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [ 650/2354 ( 28%)]  Loss: 1.133 (1.60)  Time: 0.471s,   16.99/s  (0.485s,   16.49/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [ 700/2354 ( 30%)]  Loss: 1.639 (1.61)  Time: 0.481s,   16.63/s  (0.484s,   16.51/s)  LR: 5.632e-05  Data: 0.011 (0.009)\n",
            "Train: 37 [ 750/2354 ( 32%)]  Loss: 2.506 (1.61)  Time: 0.473s,   16.93/s  (0.484s,   16.53/s)  LR: 5.632e-05  Data: 0.009 (0.009)\n",
            "Train: 37 [ 800/2354 ( 34%)]  Loss: 1.623 (1.61)  Time: 0.476s,   16.82/s  (0.483s,   16.55/s)  LR: 5.632e-05  Data: 0.008 (0.009)\n",
            "Train: 37 [ 850/2354 ( 36%)]  Loss: 1.144 (1.62)  Time: 0.613s,   13.06/s  (0.484s,   16.54/s)  LR: 5.632e-05  Data: 0.013 (0.009)\n",
            "Train: 37 [ 900/2354 ( 38%)]  Loss: 1.124 (1.61)  Time: 0.469s,   17.05/s  (0.483s,   16.55/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [ 950/2354 ( 40%)]  Loss: 1.867 (1.61)  Time: 0.482s,   16.61/s  (0.483s,   16.56/s)  LR: 5.632e-05  Data: 0.009 (0.009)\n",
            "Train: 37 [1000/2354 ( 42%)]  Loss: 1.981 (1.62)  Time: 0.466s,   17.16/s  (0.483s,   16.58/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1050/2354 ( 45%)]  Loss: 1.468 (1.63)  Time: 0.475s,   16.84/s  (0.482s,   16.59/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1100/2354 ( 47%)]  Loss: 1.685 (1.62)  Time: 0.477s,   16.77/s  (0.482s,   16.60/s)  LR: 5.632e-05  Data: 0.010 (0.009)\n",
            "Train: 37 [1150/2354 ( 49%)]  Loss: 1.076 (1.63)  Time: 0.475s,   16.85/s  (0.483s,   16.58/s)  LR: 5.632e-05  Data: 0.008 (0.009)\n",
            "Train: 37 [1200/2354 ( 51%)]  Loss: 1.003 (1.63)  Time: 0.471s,   16.98/s  (0.482s,   16.59/s)  LR: 5.632e-05  Data: 0.008 (0.009)\n",
            "Train: 37 [1250/2354 ( 53%)]  Loss: 1.889 (1.64)  Time: 0.472s,   16.95/s  (0.482s,   16.60/s)  LR: 5.632e-05  Data: 0.010 (0.009)\n",
            "Train: 37 [1300/2354 ( 55%)]  Loss: 2.592 (1.64)  Time: 0.472s,   16.95/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.008 (0.009)\n",
            "Train: 37 [1350/2354 ( 57%)]  Loss: 1.725 (1.64)  Time: 0.470s,   17.03/s  (0.481s,   16.62/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1400/2354 ( 59%)]  Loss: 2.112 (1.64)  Time: 0.475s,   16.83/s  (0.482s,   16.59/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1450/2354 ( 62%)]  Loss: 1.140 (1.64)  Time: 0.478s,   16.73/s  (0.482s,   16.60/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1500/2354 ( 64%)]  Loss: 1.182 (1.64)  Time: 0.490s,   16.32/s  (0.482s,   16.60/s)  LR: 5.632e-05  Data: 0.010 (0.009)\n",
            "Train: 37 [1550/2354 ( 66%)]  Loss: 1.022 (1.64)  Time: 0.475s,   16.83/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.009 (0.009)\n",
            "Train: 37 [1600/2354 ( 68%)]  Loss: 1.989 (1.64)  Time: 0.480s,   16.65/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.008 (0.009)\n",
            "Train: 37 [1650/2354 ( 70%)]  Loss: 1.761 (1.64)  Time: 0.493s,   16.23/s  (0.482s,   16.59/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1700/2354 ( 72%)]  Loss: 1.430 (1.64)  Time: 0.481s,   16.62/s  (0.482s,   16.60/s)  LR: 5.632e-05  Data: 0.011 (0.009)\n",
            "Train: 37 [1750/2354 ( 74%)]  Loss: 1.270 (1.64)  Time: 0.481s,   16.64/s  (0.482s,   16.60/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1800/2354 ( 76%)]  Loss: 1.698 (1.65)  Time: 0.470s,   17.01/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1850/2354 ( 79%)]  Loss: 1.131 (1.64)  Time: 0.474s,   16.87/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1900/2354 ( 81%)]  Loss: 0.9860 (1.64)  Time: 0.470s,   17.02/s  (0.481s,   16.62/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [1950/2354 ( 83%)]  Loss: 1.194 (1.64)  Time: 0.474s,   16.86/s  (0.482s,   16.60/s)  LR: 5.632e-05  Data: 0.010 (0.009)\n",
            "Train: 37 [2000/2354 ( 85%)]  Loss: 2.776 (1.65)  Time: 0.474s,   16.89/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.008 (0.009)\n",
            "Train: 37 [2050/2354 ( 87%)]  Loss: 1.171 (1.65)  Time: 0.480s,   16.66/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.008 (0.009)\n",
            "Train: 37 [2100/2354 ( 89%)]  Loss: 1.503 (1.65)  Time: 0.480s,   16.66/s  (0.481s,   16.62/s)  LR: 5.632e-05  Data: 0.009 (0.009)\n",
            "Train: 37 [2150/2354 ( 91%)]  Loss: 1.847 (1.65)  Time: 0.475s,   16.84/s  (0.481s,   16.62/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [2200/2354 ( 93%)]  Loss: 1.034 (1.65)  Time: 0.477s,   16.76/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [2250/2354 ( 96%)]  Loss: 1.719 (1.65)  Time: 0.474s,   16.87/s  (0.482s,   16.61/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [2300/2354 ( 98%)]  Loss: 1.795 (1.65)  Time: 0.472s,   16.93/s  (0.481s,   16.62/s)  LR: 5.632e-05  Data: 0.007 (0.009)\n",
            "Train: 37 [2350/2354 (100%)]  Loss: 1.924 (1.65)  Time: 0.468s,   17.08/s  (0.481s,   16.62/s)  LR: 5.632e-05  Data: 0.006 (0.009)\n",
            "Train: 37 [2353/2354 (100%)]  Loss: 2.583 (1.65)  Time: 0.464s,   17.26/s  (0.481s,   16.62/s)  LR: 5.632e-05  Data: 0.000 (0.009)\n",
            "Test: [   0/2354]  Time: 0.747 (0.747)  Loss:  0.0407 (0.0407)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.171 (0.171)  Loss:  0.2155 (0.1454)  Acc@1: 100.0000 (99.0196)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.102 (0.161)  Loss:  0.1265 (0.1426)  Acc@1: 100.0000 (99.5050)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.159 (0.159)  Loss:  0.1576 (0.1894)  Acc@1: 100.0000 (97.6821)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.189 (0.157)  Loss:  0.2656 (0.2026)  Acc@1: 100.0000 (97.7612)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.143 (0.156)  Loss:  0.0583 (0.2032)  Acc@1: 100.0000 (97.6096)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.141 (0.162)  Loss:  0.3965 (0.2049)  Acc@1: 100.0000 (97.7575)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.194 (0.160)  Loss:  0.1121 (0.2142)  Acc@1: 100.0000 (97.7208)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.181 (0.159)  Loss:  0.1648 (0.2143)  Acc@1: 100.0000 (97.6933)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.157 (0.158)  Loss:  0.1187 (0.2120)  Acc@1: 100.0000 (97.8381)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.109 (0.158)  Loss:  0.3213 (0.2050)  Acc@1: 100.0000 (98.0040)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.178 (0.157)  Loss:  0.6973 (0.2064)  Acc@1: 100.0000 (98.0490)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.202 (0.157)  Loss:  0.2362 (0.1996)  Acc@1: 100.0000 (98.2113)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.134 (0.157)  Loss:  0.0690 (0.1950)  Acc@1: 100.0000 (98.3103)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.163 (0.157)  Loss:  0.0541 (0.1870)  Acc@1: 100.0000 (98.3951)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.136 (0.156)  Loss:  0.1161 (0.1849)  Acc@1: 100.0000 (98.4354)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.179 (0.156)  Loss:  0.0999 (0.1894)  Acc@1: 100.0000 (98.2210)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.152 (0.156)  Loss:  0.0752 (0.1853)  Acc@1: 100.0000 (98.2961)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.185 (0.156)  Loss:  0.5142 (0.1810)  Acc@1: 100.0000 (98.3907)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.118 (0.155)  Loss:  0.1646 (0.1785)  Acc@1: 100.0000 (98.4490)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.152 (0.155)  Loss:  0.0506 (0.1820)  Acc@1: 100.0000 (98.2268)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.248 (0.155)  Loss:  0.2219 (0.1819)  Acc@1: 100.0000 (98.2873)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.117 (0.155)  Loss:  0.0542 (0.1815)  Acc@1: 100.0000 (98.3651)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.121 (0.156)  Loss:  0.8486 (0.1806)  Acc@1: 100.0000 (98.4144)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.205 (0.156)  Loss:  0.9800 (0.1865)  Acc@1: 75.0000 (98.2515)  Acc@5: 100.0000 (99.9792)\n",
            "Test: [1250/2354]  Time: 0.159 (0.156)  Loss:  0.0447 (0.1855)  Acc@1: 100.0000 (98.2414)  Acc@5: 100.0000 (99.9800)\n",
            "Test: [1300/2354]  Time: 0.162 (0.156)  Loss:  0.3296 (0.1870)  Acc@1: 100.0000 (98.1745)  Acc@5: 100.0000 (99.9616)\n",
            "Test: [1350/2354]  Time: 0.181 (0.156)  Loss:  0.0931 (0.1869)  Acc@1: 100.0000 (98.2050)  Acc@5: 100.0000 (99.9630)\n",
            "Test: [1400/2354]  Time: 0.153 (0.155)  Loss:  0.7646 (0.1904)  Acc@1: 50.0000 (98.0906)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [1450/2354]  Time: 0.087 (0.155)  Loss:  0.0648 (0.1914)  Acc@1: 100.0000 (98.0531)  Acc@5: 100.0000 (99.9655)\n",
            "Test: [1500/2354]  Time: 0.169 (0.155)  Loss:  0.0984 (0.1885)  Acc@1: 100.0000 (98.1179)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [1550/2354]  Time: 0.124 (0.155)  Loss:  0.1416 (0.1907)  Acc@1: 100.0000 (98.0980)  Acc@5: 100.0000 (99.9678)\n",
            "Test: [1600/2354]  Time: 0.161 (0.155)  Loss:  0.1163 (0.1944)  Acc@1: 100.0000 (98.0012)  Acc@5: 100.0000 (99.9688)\n",
            "Test: [1650/2354]  Time: 0.093 (0.155)  Loss:  0.1553 (0.1958)  Acc@1: 100.0000 (97.9861)  Acc@5: 100.0000 (99.9546)\n",
            "Test: [1700/2354]  Time: 0.096 (0.155)  Loss:  0.0845 (0.1945)  Acc@1: 100.0000 (98.0012)  Acc@5: 100.0000 (99.9412)\n",
            "Test: [1750/2354]  Time: 0.146 (0.154)  Loss:  0.2231 (0.1980)  Acc@1: 100.0000 (97.9583)  Acc@5: 100.0000 (99.9429)\n",
            "Test: [1800/2354]  Time: 0.174 (0.154)  Loss:  0.3252 (0.1981)  Acc@1: 100.0000 (97.9595)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [1850/2354]  Time: 0.129 (0.154)  Loss:  0.1298 (0.1964)  Acc@1: 100.0000 (98.0011)  Acc@5: 100.0000 (99.9460)\n",
            "Test: [1900/2354]  Time: 0.181 (0.154)  Loss:  0.3013 (0.1951)  Acc@1: 100.0000 (98.0405)  Acc@5: 100.0000 (99.9474)\n",
            "Test: [1950/2354]  Time: 0.168 (0.153)  Loss:  0.0475 (0.1937)  Acc@1: 100.0000 (98.0651)  Acc@5: 100.0000 (99.9487)\n",
            "Test: [2000/2354]  Time: 0.130 (0.154)  Loss:  0.0909 (0.1925)  Acc@1: 100.0000 (98.0760)  Acc@5: 100.0000 (99.9375)\n",
            "Test: [2050/2354]  Time: 0.089 (0.154)  Loss:  0.0336 (0.1965)  Acc@1: 100.0000 (97.9522)  Acc@5: 100.0000 (99.9391)\n",
            "Test: [2100/2354]  Time: 0.136 (0.154)  Loss:  0.3003 (0.1985)  Acc@1: 100.0000 (97.8939)  Acc@5: 100.0000 (99.9405)\n",
            "Test: [2150/2354]  Time: 0.086 (0.153)  Loss:  0.2476 (0.1999)  Acc@1: 100.0000 (97.8731)  Acc@5: 100.0000 (99.9419)\n",
            "Test: [2200/2354]  Time: 0.130 (0.153)  Loss:  0.0688 (0.2035)  Acc@1: 100.0000 (97.7624)  Acc@5: 100.0000 (99.9432)\n",
            "Test: [2250/2354]  Time: 0.083 (0.153)  Loss:  0.1021 (0.2030)  Acc@1: 100.0000 (97.8121)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [2300/2354]  Time: 0.176 (0.153)  Loss:  0.0278 (0.2017)  Acc@1: 100.0000 (97.8488)  Acc@5: 100.0000 (99.9348)\n",
            "Test: [2350/2354]  Time: 0.076 (0.153)  Loss:  0.0693 (0.2016)  Acc@1: 100.0000 (97.8626)  Acc@5: 100.0000 (99.9362)\n",
            "Test: [2354/2354]  Time: 0.065 (0.152)  Loss:  0.0378 (0.2014)  Acc@1: 100.0000 (97.8660)  Acc@5: 100.0000 (99.9363)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-26.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar', 94.90391761333476)\n",
            "\n",
            "Train: 38 [   0/2354 (  0%)]  Loss: 1.891 (1.89)  Time: 1.400s,    5.71/s  (1.400s,    5.71/s)  LR: 5.438e-05  Data: 0.624 (0.624)\n",
            "Train: 38 [  50/2354 (  2%)]  Loss: 2.004 (1.55)  Time: 0.485s,   16.48/s  (0.508s,   15.75/s)  LR: 5.438e-05  Data: 0.010 (0.020)\n",
            "Train: 38 [ 100/2354 (  4%)]  Loss: 1.171 (1.51)  Time: 0.464s,   17.23/s  (0.490s,   16.33/s)  LR: 5.438e-05  Data: 0.007 (0.014)\n",
            "Train: 38 [ 150/2354 (  6%)]  Loss: 2.032 (1.55)  Time: 0.669s,   11.96/s  (0.490s,   16.32/s)  LR: 5.438e-05  Data: 0.013 (0.012)\n",
            "Train: 38 [ 200/2354 (  8%)]  Loss: 1.631 (1.58)  Time: 0.468s,   17.11/s  (0.486s,   16.47/s)  LR: 5.438e-05  Data: 0.008 (0.011)\n",
            "Train: 38 [ 250/2354 ( 11%)]  Loss: 1.406 (1.60)  Time: 0.471s,   16.99/s  (0.483s,   16.57/s)  LR: 5.438e-05  Data: 0.007 (0.010)\n",
            "Train: 38 [ 300/2354 ( 13%)]  Loss: 2.418 (1.61)  Time: 0.468s,   17.10/s  (0.481s,   16.65/s)  LR: 5.438e-05  Data: 0.007 (0.010)\n",
            "Train: 38 [ 350/2354 ( 15%)]  Loss: 2.853 (1.60)  Time: 0.472s,   16.95/s  (0.480s,   16.68/s)  LR: 5.438e-05  Data: 0.007 (0.010)\n",
            "Train: 38 [ 400/2354 ( 17%)]  Loss: 1.246 (1.60)  Time: 0.472s,   16.95/s  (0.479s,   16.70/s)  LR: 5.438e-05  Data: 0.008 (0.010)\n",
            "Train: 38 [ 450/2354 ( 19%)]  Loss: 2.110 (1.59)  Time: 0.467s,   17.13/s  (0.481s,   16.64/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [ 500/2354 ( 21%)]  Loss: 1.026 (1.59)  Time: 0.470s,   17.01/s  (0.480s,   16.66/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [ 550/2354 ( 23%)]  Loss: 1.066 (1.58)  Time: 0.479s,   16.70/s  (0.479s,   16.69/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [ 600/2354 ( 25%)]  Loss: 1.955 (1.58)  Time: 0.473s,   16.90/s  (0.479s,   16.71/s)  LR: 5.438e-05  Data: 0.010 (0.009)\n",
            "Train: 38 [ 650/2354 ( 28%)]  Loss: 1.312 (1.59)  Time: 0.470s,   17.03/s  (0.478s,   16.73/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [ 700/2354 ( 30%)]  Loss: 1.043 (1.59)  Time: 0.651s,   12.29/s  (0.479s,   16.70/s)  LR: 5.438e-05  Data: 0.018 (0.009)\n",
            "Train: 38 [ 750/2354 ( 32%)]  Loss: 2.341 (1.60)  Time: 0.476s,   16.80/s  (0.478s,   16.72/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [ 800/2354 ( 34%)]  Loss: 1.594 (1.60)  Time: 0.462s,   17.31/s  (0.478s,   16.74/s)  LR: 5.438e-05  Data: 0.008 (0.009)\n",
            "Train: 38 [ 850/2354 ( 36%)]  Loss: 1.169 (1.60)  Time: 0.466s,   17.18/s  (0.477s,   16.76/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [ 900/2354 ( 38%)]  Loss: 1.898 (1.60)  Time: 0.468s,   17.09/s  (0.477s,   16.77/s)  LR: 5.438e-05  Data: 0.010 (0.009)\n",
            "Train: 38 [ 950/2354 ( 40%)]  Loss: 2.464 (1.60)  Time: 0.470s,   17.04/s  (0.477s,   16.79/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [1000/2354 ( 42%)]  Loss: 1.977 (1.59)  Time: 0.470s,   17.02/s  (0.477s,   16.76/s)  LR: 5.438e-05  Data: 0.009 (0.009)\n",
            "Train: 38 [1050/2354 ( 45%)]  Loss: 1.716 (1.61)  Time: 0.469s,   17.06/s  (0.477s,   16.77/s)  LR: 5.438e-05  Data: 0.008 (0.009)\n",
            "Train: 38 [1100/2354 ( 47%)]  Loss: 2.018 (1.61)  Time: 0.479s,   16.70/s  (0.477s,   16.78/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [1150/2354 ( 49%)]  Loss: 1.364 (1.62)  Time: 0.465s,   17.20/s  (0.477s,   16.79/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [1200/2354 ( 51%)]  Loss: 1.622 (1.62)  Time: 0.467s,   17.11/s  (0.476s,   16.80/s)  LR: 5.438e-05  Data: 0.008 (0.009)\n",
            "Train: 38 [1250/2354 ( 53%)]  Loss: 1.828 (1.61)  Time: 0.479s,   16.70/s  (0.476s,   16.80/s)  LR: 5.438e-05  Data: 0.010 (0.009)\n",
            "Train: 38 [1300/2354 ( 55%)]  Loss: 1.372 (1.61)  Time: 0.475s,   16.84/s  (0.477s,   16.78/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [1350/2354 ( 57%)]  Loss: 1.957 (1.61)  Time: 0.471s,   16.97/s  (0.477s,   16.79/s)  LR: 5.438e-05  Data: 0.009 (0.009)\n",
            "Train: 38 [1400/2354 ( 59%)]  Loss: 1.445 (1.60)  Time: 0.472s,   16.94/s  (0.476s,   16.80/s)  LR: 5.438e-05  Data: 0.009 (0.009)\n",
            "Train: 38 [1450/2354 ( 62%)]  Loss: 1.872 (1.60)  Time: 0.487s,   16.43/s  (0.476s,   16.80/s)  LR: 5.438e-05  Data: 0.007 (0.009)\n",
            "Train: 38 [1500/2354 ( 64%)]  Loss: 1.111 (1.60)  Time: 0.463s,   17.27/s  (0.476s,   16.81/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [1550/2354 ( 66%)]  Loss: 1.155 (1.61)  Time: 0.464s,   17.23/s  (0.476s,   16.79/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [1600/2354 ( 68%)]  Loss: 1.590 (1.61)  Time: 0.466s,   17.15/s  (0.476s,   16.80/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [1650/2354 ( 70%)]  Loss: 1.101 (1.61)  Time: 0.473s,   16.92/s  (0.476s,   16.80/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [1700/2354 ( 72%)]  Loss: 1.442 (1.61)  Time: 0.474s,   16.89/s  (0.476s,   16.81/s)  LR: 5.438e-05  Data: 0.008 (0.008)\n",
            "Train: 38 [1750/2354 ( 74%)]  Loss: 1.551 (1.61)  Time: 0.479s,   16.70/s  (0.476s,   16.82/s)  LR: 5.438e-05  Data: 0.009 (0.008)\n",
            "Train: 38 [1800/2354 ( 76%)]  Loss: 1.283 (1.61)  Time: 0.466s,   17.16/s  (0.476s,   16.82/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [1850/2354 ( 79%)]  Loss: 1.513 (1.61)  Time: 0.473s,   16.92/s  (0.476s,   16.81/s)  LR: 5.438e-05  Data: 0.010 (0.008)\n",
            "Train: 38 [1900/2354 ( 81%)]  Loss: 2.324 (1.61)  Time: 0.471s,   16.98/s  (0.476s,   16.81/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [1950/2354 ( 83%)]  Loss: 1.958 (1.61)  Time: 0.466s,   17.15/s  (0.476s,   16.82/s)  LR: 5.438e-05  Data: 0.010 (0.008)\n",
            "Train: 38 [2000/2354 ( 85%)]  Loss: 1.305 (1.61)  Time: 0.479s,   16.71/s  (0.476s,   16.82/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [2050/2354 ( 87%)]  Loss: 1.816 (1.61)  Time: 0.470s,   17.03/s  (0.475s,   16.83/s)  LR: 5.438e-05  Data: 0.009 (0.008)\n",
            "Train: 38 [2100/2354 ( 89%)]  Loss: 1.366 (1.61)  Time: 0.472s,   16.94/s  (0.476s,   16.82/s)  LR: 5.438e-05  Data: 0.008 (0.008)\n",
            "Train: 38 [2150/2354 ( 91%)]  Loss: 1.133 (1.61)  Time: 0.473s,   16.92/s  (0.476s,   16.82/s)  LR: 5.438e-05  Data: 0.011 (0.008)\n",
            "Train: 38 [2200/2354 ( 93%)]  Loss: 1.222 (1.61)  Time: 0.467s,   17.14/s  (0.476s,   16.82/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [2250/2354 ( 96%)]  Loss: 2.339 (1.61)  Time: 0.465s,   17.20/s  (0.475s,   16.83/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [2300/2354 ( 98%)]  Loss: 1.527 (1.62)  Time: 0.478s,   16.75/s  (0.475s,   16.83/s)  LR: 5.438e-05  Data: 0.007 (0.008)\n",
            "Train: 38 [2350/2354 (100%)]  Loss: 2.786 (1.62)  Time: 0.466s,   17.16/s  (0.475s,   16.84/s)  LR: 5.438e-05  Data: 0.006 (0.008)\n",
            "Train: 38 [2353/2354 (100%)]  Loss: 1.475 (1.62)  Time: 0.459s,   17.43/s  (0.475s,   16.84/s)  LR: 5.438e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.611 (0.611)  Loss:  0.0457 (0.0457)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.171 (0.203)  Loss:  0.6455 (0.1751)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.200 (0.174)  Loss:  0.1676 (0.1802)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.136 (0.165)  Loss:  0.1041 (0.2192)  Acc@1: 100.0000 (98.6755)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.157 (0.159)  Loss:  0.8828 (0.2178)  Acc@1: 100.0000 (98.6318)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.143 (0.156)  Loss:  0.3674 (0.2329)  Acc@1: 100.0000 (97.6096)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.139 (0.154)  Loss:  0.3940 (0.2331)  Acc@1: 100.0000 (97.7575)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.228 (0.153)  Loss:  0.1729 (0.2524)  Acc@1: 100.0000 (97.5071)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.127 (0.151)  Loss:  0.1293 (0.2560)  Acc@1: 100.0000 (97.6309)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.130 (0.150)  Loss:  0.1226 (0.2441)  Acc@1: 100.0000 (97.7273)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.164 (0.149)  Loss:  0.2356 (0.2357)  Acc@1: 100.0000 (97.8543)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.171 (0.148)  Loss:  0.1833 (0.2390)  Acc@1: 100.0000 (97.5045)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.148 (0.148)  Loss:  0.1974 (0.2316)  Acc@1: 100.0000 (97.6705)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.093 (0.148)  Loss:  0.1388 (0.2250)  Acc@1: 100.0000 (97.7727)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.182 (0.147)  Loss:  0.1003 (0.2186)  Acc@1: 100.0000 (97.8959)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.128 (0.147)  Loss:  0.1354 (0.2131)  Acc@1: 100.0000 (97.9694)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.142 (0.147)  Loss:  0.0937 (0.2127)  Acc@1: 100.0000 (97.9401)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.176 (0.146)  Loss:  0.1953 (0.2090)  Acc@1: 100.0000 (98.0024)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.084 (0.146)  Loss:  0.3557 (0.2072)  Acc@1: 100.0000 (98.1132)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.172 (0.148)  Loss:  0.1704 (0.2039)  Acc@1: 100.0000 (98.1861)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.120 (0.148)  Loss:  0.0289 (0.2069)  Acc@1: 100.0000 (98.1768)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.183 (0.147)  Loss:  0.1379 (0.2066)  Acc@1: 100.0000 (98.2398)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.155 (0.147)  Loss:  0.1237 (0.2049)  Acc@1: 100.0000 (98.2743)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.080 (0.147)  Loss:  1.2148 (0.2075)  Acc@1: 100.0000 (98.3275)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.123 (0.147)  Loss:  0.6313 (0.2083)  Acc@1: 75.0000 (98.3139)  Acc@5: 100.0000 (99.9792)\n",
            "Test: [1250/2354]  Time: 0.087 (0.146)  Loss:  0.0685 (0.2064)  Acc@1: 100.0000 (98.3413)  Acc@5: 100.0000 (99.9600)\n",
            "Test: [1300/2354]  Time: 0.166 (0.146)  Loss:  0.0861 (0.2066)  Acc@1: 100.0000 (98.2706)  Acc@5: 100.0000 (99.9616)\n",
            "Test: [1350/2354]  Time: 0.098 (0.146)  Loss:  0.0630 (0.2072)  Acc@1: 100.0000 (98.2420)  Acc@5: 100.0000 (99.9630)\n",
            "Test: [1400/2354]  Time: 0.080 (0.146)  Loss:  0.2111 (0.2063)  Acc@1: 100.0000 (98.2512)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [1450/2354]  Time: 0.089 (0.145)  Loss:  0.0591 (0.2051)  Acc@1: 100.0000 (98.2943)  Acc@5: 100.0000 (99.9655)\n",
            "Test: [1500/2354]  Time: 0.076 (0.145)  Loss:  0.0870 (0.2039)  Acc@1: 100.0000 (98.3178)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [1550/2354]  Time: 0.152 (0.145)  Loss:  0.2556 (0.2087)  Acc@1: 100.0000 (98.1947)  Acc@5: 100.0000 (99.9678)\n",
            "Test: [1600/2354]  Time: 0.108 (0.145)  Loss:  0.3181 (0.2142)  Acc@1: 100.0000 (98.0949)  Acc@5: 100.0000 (99.9532)\n",
            "Test: [1650/2354]  Time: 0.100 (0.145)  Loss:  0.2712 (0.2200)  Acc@1: 100.0000 (97.8649)  Acc@5: 100.0000 (99.9394)\n",
            "Test: [1700/2354]  Time: 0.194 (0.145)  Loss:  0.1809 (0.2197)  Acc@1: 100.0000 (97.8689)  Acc@5: 100.0000 (99.9412)\n",
            "Test: [1750/2354]  Time: 0.196 (0.145)  Loss:  0.3120 (0.2228)  Acc@1: 100.0000 (97.8155)  Acc@5: 100.0000 (99.9429)\n",
            "Test: [1800/2354]  Time: 0.111 (0.145)  Loss:  0.3618 (0.2215)  Acc@1: 100.0000 (97.8484)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [1850/2354]  Time: 0.146 (0.144)  Loss:  0.3093 (0.2198)  Acc@1: 100.0000 (97.8525)  Acc@5: 100.0000 (99.9460)\n",
            "Test: [1900/2354]  Time: 0.174 (0.145)  Loss:  0.1868 (0.2185)  Acc@1: 100.0000 (97.8958)  Acc@5: 100.0000 (99.9474)\n",
            "Test: [1950/2354]  Time: 0.139 (0.145)  Loss:  0.2256 (0.2169)  Acc@1: 100.0000 (97.9370)  Acc@5: 100.0000 (99.9487)\n",
            "Test: [2000/2354]  Time: 0.190 (0.145)  Loss:  0.0934 (0.2154)  Acc@1: 100.0000 (97.9635)  Acc@5: 100.0000 (99.9375)\n",
            "Test: [2050/2354]  Time: 0.155 (0.145)  Loss:  0.1444 (0.2169)  Acc@1: 100.0000 (97.9278)  Acc@5: 100.0000 (99.9391)\n",
            "Test: [2100/2354]  Time: 0.116 (0.145)  Loss:  0.4150 (0.2212)  Acc@1: 75.0000 (97.8701)  Acc@5: 100.0000 (99.9405)\n",
            "Test: [2150/2354]  Time: 0.147 (0.145)  Loss:  0.6792 (0.2263)  Acc@1: 100.0000 (97.6987)  Acc@5: 100.0000 (99.9419)\n",
            "Test: [2200/2354]  Time: 0.176 (0.145)  Loss:  0.2075 (0.2282)  Acc@1: 100.0000 (97.7283)  Acc@5: 100.0000 (99.9432)\n",
            "Test: [2250/2354]  Time: 0.116 (0.145)  Loss:  0.0953 (0.2266)  Acc@1: 100.0000 (97.7566)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [2300/2354]  Time: 0.086 (0.145)  Loss:  0.1122 (0.2251)  Acc@1: 100.0000 (97.7944)  Acc@5: 100.0000 (99.9348)\n",
            "Test: [2350/2354]  Time: 0.075 (0.144)  Loss:  0.2135 (0.2242)  Acc@1: 100.0000 (97.8307)  Acc@5: 100.0000 (99.9362)\n",
            "Test: [2354/2354]  Time: 0.066 (0.144)  Loss:  0.3145 (0.2246)  Acc@1: 100.0000 (97.8235)  Acc@5: 100.0000 (99.9363)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-29.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar', 95.13748805605691)\n",
            "\n",
            "Train: 39 [   0/2354 (  0%)]  Loss: 1.743 (1.74)  Time: 1.340s,    5.97/s  (1.340s,    5.97/s)  LR: 5.244e-05  Data: 0.546 (0.546)\n",
            "Train: 39 [  50/2354 (  2%)]  Loss: 1.452 (1.65)  Time: 0.466s,   17.16/s  (0.507s,   15.79/s)  LR: 5.244e-05  Data: 0.006 (0.018)\n",
            "Train: 39 [ 100/2354 (  4%)]  Loss: 1.266 (1.55)  Time: 0.477s,   16.76/s  (0.488s,   16.40/s)  LR: 5.244e-05  Data: 0.007 (0.013)\n",
            "Train: 39 [ 150/2354 (  6%)]  Loss: 1.241 (1.60)  Time: 0.470s,   17.03/s  (0.487s,   16.42/s)  LR: 5.244e-05  Data: 0.007 (0.012)\n",
            "Train: 39 [ 200/2354 (  8%)]  Loss: 1.420 (1.60)  Time: 0.473s,   16.92/s  (0.483s,   16.56/s)  LR: 5.244e-05  Data: 0.010 (0.011)\n",
            "Train: 39 [ 250/2354 ( 11%)]  Loss: 2.243 (1.60)  Time: 0.465s,   17.20/s  (0.481s,   16.65/s)  LR: 5.244e-05  Data: 0.007 (0.010)\n",
            "Train: 39 [ 300/2354 ( 13%)]  Loss: 1.169 (1.61)  Time: 0.478s,   16.74/s  (0.478s,   16.72/s)  LR: 5.244e-05  Data: 0.009 (0.010)\n",
            "Train: 39 [ 350/2354 ( 15%)]  Loss: 0.9989 (1.60)  Time: 0.460s,   17.38/s  (0.477s,   16.76/s)  LR: 5.244e-05  Data: 0.007 (0.010)\n",
            "Train: 39 [ 400/2354 ( 17%)]  Loss: 1.653 (1.58)  Time: 0.647s,   12.37/s  (0.477s,   16.76/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [ 450/2354 ( 19%)]  Loss: 1.432 (1.58)  Time: 0.469s,   17.04/s  (0.478s,   16.74/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [ 500/2354 ( 21%)]  Loss: 1.127 (1.59)  Time: 0.474s,   16.87/s  (0.477s,   16.77/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [ 550/2354 ( 23%)]  Loss: 1.126 (1.59)  Time: 0.468s,   17.11/s  (0.476s,   16.80/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [ 600/2354 ( 25%)]  Loss: 1.128 (1.59)  Time: 0.475s,   16.84/s  (0.476s,   16.81/s)  LR: 5.244e-05  Data: 0.010 (0.009)\n",
            "Train: 39 [ 650/2354 ( 28%)]  Loss: 2.214 (1.59)  Time: 0.470s,   17.01/s  (0.475s,   16.83/s)  LR: 5.244e-05  Data: 0.012 (0.009)\n",
            "Train: 39 [ 700/2354 ( 30%)]  Loss: 1.476 (1.59)  Time: 0.463s,   17.27/s  (0.476s,   16.80/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [ 750/2354 ( 32%)]  Loss: 1.585 (1.60)  Time: 0.487s,   16.44/s  (0.476s,   16.81/s)  LR: 5.244e-05  Data: 0.008 (0.009)\n",
            "Train: 39 [ 800/2354 ( 34%)]  Loss: 1.062 (1.60)  Time: 0.466s,   17.16/s  (0.476s,   16.82/s)  LR: 5.244e-05  Data: 0.008 (0.009)\n",
            "Train: 39 [ 850/2354 ( 36%)]  Loss: 1.013 (1.60)  Time: 0.470s,   17.01/s  (0.475s,   16.84/s)  LR: 5.244e-05  Data: 0.010 (0.009)\n",
            "Train: 39 [ 900/2354 ( 38%)]  Loss: 1.354 (1.60)  Time: 0.467s,   17.14/s  (0.475s,   16.85/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [ 950/2354 ( 40%)]  Loss: 1.192 (1.60)  Time: 0.466s,   17.17/s  (0.475s,   16.86/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [1000/2354 ( 42%)]  Loss: 1.899 (1.61)  Time: 0.467s,   17.12/s  (0.475s,   16.83/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [1050/2354 ( 45%)]  Loss: 1.434 (1.61)  Time: 0.464s,   17.25/s  (0.475s,   16.84/s)  LR: 5.244e-05  Data: 0.010 (0.009)\n",
            "Train: 39 [1100/2354 ( 47%)]  Loss: 1.472 (1.61)  Time: 0.470s,   17.03/s  (0.475s,   16.85/s)  LR: 5.244e-05  Data: 0.009 (0.009)\n",
            "Train: 39 [1150/2354 ( 49%)]  Loss: 1.008 (1.60)  Time: 0.468s,   17.09/s  (0.474s,   16.86/s)  LR: 5.244e-05  Data: 0.009 (0.009)\n",
            "Train: 39 [1200/2354 ( 51%)]  Loss: 1.574 (1.61)  Time: 0.466s,   17.18/s  (0.474s,   16.87/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [1250/2354 ( 53%)]  Loss: 1.100 (1.60)  Time: 0.612s,   13.08/s  (0.475s,   16.85/s)  LR: 5.244e-05  Data: 0.013 (0.009)\n",
            "Train: 39 [1300/2354 ( 55%)]  Loss: 2.216 (1.60)  Time: 0.465s,   17.22/s  (0.475s,   16.86/s)  LR: 5.244e-05  Data: 0.007 (0.009)\n",
            "Train: 39 [1350/2354 ( 57%)]  Loss: 2.030 (1.61)  Time: 0.466s,   17.17/s  (0.475s,   16.86/s)  LR: 5.244e-05  Data: 0.007 (0.008)\n",
            "Train: 39 [1400/2354 ( 59%)]  Loss: 1.029 (1.61)  Time: 0.468s,   17.09/s  (0.474s,   16.86/s)  LR: 5.244e-05  Data: 0.010 (0.008)\n",
            "Train: 39 [1450/2354 ( 62%)]  Loss: 1.996 (1.61)  Time: 0.474s,   16.89/s  (0.474s,   16.87/s)  LR: 5.244e-05  Data: 0.011 (0.008)\n",
            "Train: 39 [1500/2354 ( 64%)]  Loss: 1.583 (1.61)  Time: 0.475s,   16.86/s  (0.474s,   16.87/s)  LR: 5.244e-05  Data: 0.007 (0.008)\n",
            "Train: 39 [1550/2354 ( 66%)]  Loss: 1.839 (1.61)  Time: 0.468s,   17.10/s  (0.474s,   16.86/s)  LR: 5.244e-05  Data: 0.010 (0.008)\n",
            "Train: 39 [1600/2354 ( 68%)]  Loss: 1.256 (1.61)  Time: 0.472s,   16.95/s  (0.474s,   16.87/s)  LR: 5.244e-05  Data: 0.012 (0.008)\n",
            "Train: 39 [1650/2354 ( 70%)]  Loss: 1.352 (1.61)  Time: 0.471s,   17.00/s  (0.474s,   16.87/s)  LR: 5.244e-05  Data: 0.008 (0.008)\n",
            "Train: 39 [1700/2354 ( 72%)]  Loss: 1.859 (1.61)  Time: 0.476s,   16.80/s  (0.474s,   16.88/s)  LR: 5.244e-05  Data: 0.010 (0.008)\n",
            "Train: 39 [1750/2354 ( 74%)]  Loss: 1.575 (1.61)  Time: 0.461s,   17.34/s  (0.474s,   16.88/s)  LR: 5.244e-05  Data: 0.007 (0.008)\n",
            "Train: 39 [1800/2354 ( 76%)]  Loss: 2.325 (1.61)  Time: 0.471s,   17.00/s  (0.474s,   16.89/s)  LR: 5.244e-05  Data: 0.007 (0.008)\n",
            "Train: 39 [1850/2354 ( 79%)]  Loss: 1.190 (1.61)  Time: 0.474s,   16.87/s  (0.474s,   16.87/s)  LR: 5.244e-05  Data: 0.014 (0.008)\n",
            "Train: 39 [1900/2354 ( 81%)]  Loss: 1.012 (1.61)  Time: 0.467s,   17.12/s  (0.474s,   16.87/s)  LR: 5.244e-05  Data: 0.007 (0.008)\n",
            "Train: 39 [1950/2354 ( 83%)]  Loss: 2.084 (1.61)  Time: 0.479s,   16.69/s  (0.474s,   16.88/s)  LR: 5.244e-05  Data: 0.008 (0.008)\n",
            "Train: 39 [2000/2354 ( 85%)]  Loss: 1.040 (1.61)  Time: 0.468s,   17.08/s  (0.474s,   16.88/s)  LR: 5.244e-05  Data: 0.010 (0.008)\n",
            "Train: 39 [2050/2354 ( 87%)]  Loss: 1.720 (1.61)  Time: 0.466s,   17.17/s  (0.474s,   16.89/s)  LR: 5.244e-05  Data: 0.007 (0.008)\n",
            "Train: 39 [2100/2354 ( 89%)]  Loss: 1.653 (1.61)  Time: 0.465s,   17.20/s  (0.474s,   16.89/s)  LR: 5.244e-05  Data: 0.008 (0.008)\n",
            "Train: 39 [2150/2354 ( 91%)]  Loss: 1.231 (1.61)  Time: 0.474s,   16.86/s  (0.474s,   16.87/s)  LR: 5.244e-05  Data: 0.008 (0.008)\n",
            "Train: 39 [2200/2354 ( 93%)]  Loss: 1.173 (1.61)  Time: 0.483s,   16.55/s  (0.474s,   16.88/s)  LR: 5.244e-05  Data: 0.010 (0.008)\n",
            "Train: 39 [2250/2354 ( 96%)]  Loss: 2.727 (1.61)  Time: 0.470s,   17.03/s  (0.474s,   16.88/s)  LR: 5.244e-05  Data: 0.009 (0.008)\n",
            "Train: 39 [2300/2354 ( 98%)]  Loss: 1.117 (1.61)  Time: 0.470s,   17.02/s  (0.474s,   16.88/s)  LR: 5.244e-05  Data: 0.007 (0.008)\n",
            "Train: 39 [2350/2354 (100%)]  Loss: 1.361 (1.61)  Time: 0.464s,   17.24/s  (0.474s,   16.89/s)  LR: 5.244e-05  Data: 0.006 (0.008)\n",
            "Train: 39 [2353/2354 (100%)]  Loss: 1.164 (1.61)  Time: 0.458s,   17.45/s  (0.474s,   16.89/s)  LR: 5.244e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.734 (0.734)  Loss:  1.1758 (1.1758)  Acc@1: 75.0000 (75.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.184 (0.165)  Loss:  0.1494 (0.1706)  Acc@1: 100.0000 (97.5490)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.122 (0.155)  Loss:  0.0923 (0.1437)  Acc@1: 100.0000 (98.5149)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.140 (0.165)  Loss:  0.4333 (0.1730)  Acc@1: 75.0000 (97.3510)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.178 (0.160)  Loss:  0.2810 (0.1711)  Acc@1: 100.0000 (97.5124)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.125 (0.157)  Loss:  0.0846 (0.1864)  Acc@1: 100.0000 (97.3108)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.155 (0.155)  Loss:  0.9395 (0.1923)  Acc@1: 75.0000 (97.5083)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.151 (0.155)  Loss:  0.1602 (0.2116)  Acc@1: 100.0000 (97.2934)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.092 (0.154)  Loss:  0.1141 (0.2091)  Acc@1: 100.0000 (97.3815)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.155 (0.153)  Loss:  0.0704 (0.2026)  Acc@1: 100.0000 (97.5610)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.182 (0.152)  Loss:  0.1257 (0.1957)  Acc@1: 100.0000 (97.7046)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.156 (0.151)  Loss:  0.1555 (0.1970)  Acc@1: 100.0000 (97.8221)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.188 (0.151)  Loss:  0.6294 (0.1963)  Acc@1: 100.0000 (97.9201)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.118 (0.151)  Loss:  0.1020 (0.1911)  Acc@1: 100.0000 (98.0415)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.105 (0.151)  Loss:  0.0576 (0.1887)  Acc@1: 100.0000 (98.1455)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.132 (0.150)  Loss:  0.1370 (0.1870)  Acc@1: 100.0000 (98.2024)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.102 (0.150)  Loss:  0.1355 (0.1877)  Acc@1: 100.0000 (98.0337)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.111 (0.150)  Loss:  0.1003 (0.1863)  Acc@1: 100.0000 (98.1199)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.177 (0.149)  Loss:  0.3691 (0.1842)  Acc@1: 100.0000 (98.2242)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.082 (0.149)  Loss:  0.3274 (0.1827)  Acc@1: 100.0000 (98.2387)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.184 (0.149)  Loss:  0.1306 (0.1830)  Acc@1: 100.0000 (98.2268)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.227 (0.151)  Loss:  0.0997 (0.1822)  Acc@1: 100.0000 (98.2398)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.167 (0.150)  Loss:  0.0424 (0.1810)  Acc@1: 100.0000 (98.2743)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.139 (0.150)  Loss:  1.0830 (0.1816)  Acc@1: 50.0000 (98.2624)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.080 (0.150)  Loss:  0.8726 (0.1834)  Acc@1: 75.0000 (98.2098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.144 (0.150)  Loss:  0.1896 (0.1816)  Acc@1: 100.0000 (98.2414)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.145 (0.150)  Loss:  0.0673 (0.1813)  Acc@1: 100.0000 (98.2898)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.152 (0.150)  Loss:  0.1151 (0.1808)  Acc@1: 100.0000 (98.2791)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.167 (0.149)  Loss:  0.1061 (0.1810)  Acc@1: 100.0000 (98.3226)  Acc@5: 100.0000 (99.9822)\n",
            "Test: [1450/2354]  Time: 0.150 (0.149)  Loss:  0.0817 (0.1793)  Acc@1: 100.0000 (98.3804)  Acc@5: 100.0000 (99.9828)\n",
            "Test: [1500/2354]  Time: 0.175 (0.149)  Loss:  0.2456 (0.1786)  Acc@1: 100.0000 (98.4177)  Acc@5: 100.0000 (99.9833)\n",
            "Test: [1550/2354]  Time: 0.183 (0.149)  Loss:  0.0801 (0.1815)  Acc@1: 100.0000 (98.3398)  Acc@5: 100.0000 (99.9839)\n",
            "Test: [1600/2354]  Time: 0.154 (0.149)  Loss:  0.1317 (0.1858)  Acc@1: 100.0000 (98.2823)  Acc@5: 100.0000 (99.9844)\n",
            "Test: [1650/2354]  Time: 0.162 (0.149)  Loss:  0.0813 (0.1881)  Acc@1: 100.0000 (98.2435)  Acc@5: 100.0000 (99.9697)\n",
            "Test: [1700/2354]  Time: 0.105 (0.149)  Loss:  0.1192 (0.1873)  Acc@1: 100.0000 (98.2510)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [1750/2354]  Time: 0.094 (0.149)  Loss:  0.2463 (0.1920)  Acc@1: 100.0000 (98.2296)  Acc@5: 100.0000 (99.9714)\n",
            "Test: [1800/2354]  Time: 0.152 (0.149)  Loss:  0.4187 (0.1933)  Acc@1: 100.0000 (98.2371)  Acc@5: 100.0000 (99.9584)\n",
            "Test: [1850/2354]  Time: 0.087 (0.149)  Loss:  0.1689 (0.1927)  Acc@1: 100.0000 (98.2577)  Acc@5: 100.0000 (99.9595)\n",
            "Test: [1900/2354]  Time: 0.108 (0.149)  Loss:  0.0498 (0.1906)  Acc@1: 100.0000 (98.3035)  Acc@5: 100.0000 (99.9605)\n",
            "Test: [1950/2354]  Time: 0.264 (0.149)  Loss:  0.0894 (0.1903)  Acc@1: 100.0000 (98.3214)  Acc@5: 100.0000 (99.9616)\n",
            "Test: [2000/2354]  Time: 0.129 (0.150)  Loss:  0.0925 (0.1896)  Acc@1: 100.0000 (98.3508)  Acc@5: 100.0000 (99.9625)\n",
            "Test: [2050/2354]  Time: 0.241 (0.150)  Loss:  0.1318 (0.1911)  Acc@1: 100.0000 (98.2813)  Acc@5: 100.0000 (99.9634)\n",
            "Test: [2100/2354]  Time: 0.142 (0.149)  Loss:  0.3728 (0.1937)  Acc@1: 100.0000 (98.2270)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [2150/2354]  Time: 0.114 (0.149)  Loss:  0.3005 (0.1962)  Acc@1: 100.0000 (98.1753)  Acc@5: 100.0000 (99.9651)\n",
            "Test: [2200/2354]  Time: 0.134 (0.149)  Loss:  0.0679 (0.1997)  Acc@1: 100.0000 (98.0804)  Acc@5: 100.0000 (99.9659)\n",
            "Test: [2250/2354]  Time: 0.144 (0.149)  Loss:  0.0709 (0.2005)  Acc@1: 100.0000 (98.1008)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [2300/2354]  Time: 0.149 (0.149)  Loss:  0.0699 (0.1988)  Acc@1: 100.0000 (98.1312)  Acc@5: 100.0000 (99.9565)\n",
            "Test: [2350/2354]  Time: 0.076 (0.149)  Loss:  0.0909 (0.1990)  Acc@1: 100.0000 (98.1178)  Acc@5: 100.0000 (99.9575)\n",
            "Test: [2354/2354]  Time: 0.078 (0.149)  Loss:  0.0103 (0.1988)  Acc@1: 100.0000 (98.1208)  Acc@5: 100.0000 (99.9575)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-28.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar', 95.78511519269561)\n",
            "\n",
            "Train: 40 [   0/2354 (  0%)]  Loss: 1.908 (1.91)  Time: 1.481s,    5.40/s  (1.481s,    5.40/s)  LR: 5.050e-05  Data: 0.669 (0.669)\n",
            "Train: 40 [  50/2354 (  2%)]  Loss: 1.304 (1.65)  Time: 0.473s,   16.91/s  (0.512s,   15.62/s)  LR: 5.050e-05  Data: 0.009 (0.021)\n",
            "Train: 40 [ 100/2354 (  4%)]  Loss: 1.139 (1.57)  Time: 0.468s,   17.09/s  (0.492s,   16.25/s)  LR: 5.050e-05  Data: 0.007 (0.014)\n",
            "Train: 40 [ 150/2354 (  6%)]  Loss: 1.573 (1.59)  Time: 0.475s,   16.84/s  (0.493s,   16.24/s)  LR: 5.050e-05  Data: 0.007 (0.013)\n",
            "Train: 40 [ 200/2354 (  8%)]  Loss: 1.128 (1.59)  Time: 0.468s,   17.09/s  (0.487s,   16.41/s)  LR: 5.050e-05  Data: 0.008 (0.011)\n",
            "Train: 40 [ 250/2354 ( 11%)]  Loss: 1.516 (1.60)  Time: 0.475s,   16.84/s  (0.484s,   16.53/s)  LR: 5.050e-05  Data: 0.007 (0.011)\n",
            "Train: 40 [ 300/2354 ( 13%)]  Loss: 1.341 (1.61)  Time: 0.471s,   16.99/s  (0.482s,   16.60/s)  LR: 5.050e-05  Data: 0.007 (0.010)\n",
            "Train: 40 [ 350/2354 ( 15%)]  Loss: 1.257 (1.59)  Time: 0.478s,   16.74/s  (0.480s,   16.65/s)  LR: 5.050e-05  Data: 0.009 (0.010)\n",
            "Train: 40 [ 400/2354 ( 17%)]  Loss: 1.487 (1.59)  Time: 0.469s,   17.04/s  (0.479s,   16.69/s)  LR: 5.050e-05  Data: 0.007 (0.010)\n",
            "Train: 40 [ 450/2354 ( 19%)]  Loss: 1.148 (1.58)  Time: 0.467s,   17.14/s  (0.481s,   16.64/s)  LR: 5.050e-05  Data: 0.006 (0.010)\n",
            "Train: 40 [ 500/2354 ( 21%)]  Loss: 1.399 (1.57)  Time: 0.479s,   16.70/s  (0.480s,   16.67/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [ 550/2354 ( 23%)]  Loss: 1.435 (1.57)  Time: 0.468s,   17.11/s  (0.479s,   16.70/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [ 600/2354 ( 25%)]  Loss: 1.942 (1.58)  Time: 0.473s,   16.90/s  (0.478s,   16.72/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [ 650/2354 ( 28%)]  Loss: 1.379 (1.58)  Time: 0.473s,   16.91/s  (0.478s,   16.74/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [ 700/2354 ( 30%)]  Loss: 1.505 (1.59)  Time: 0.467s,   17.14/s  (0.477s,   16.76/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [ 750/2354 ( 32%)]  Loss: 1.755 (1.59)  Time: 0.471s,   16.98/s  (0.478s,   16.72/s)  LR: 5.050e-05  Data: 0.008 (0.009)\n",
            "Train: 40 [ 800/2354 ( 34%)]  Loss: 1.354 (1.59)  Time: 0.473s,   16.93/s  (0.478s,   16.74/s)  LR: 5.050e-05  Data: 0.008 (0.009)\n",
            "Train: 40 [ 850/2354 ( 36%)]  Loss: 1.423 (1.60)  Time: 0.473s,   16.91/s  (0.478s,   16.75/s)  LR: 5.050e-05  Data: 0.012 (0.009)\n",
            "Train: 40 [ 900/2354 ( 38%)]  Loss: 1.335 (1.59)  Time: 0.468s,   17.09/s  (0.477s,   16.76/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [ 950/2354 ( 40%)]  Loss: 1.605 (1.59)  Time: 0.461s,   17.34/s  (0.477s,   16.78/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1000/2354 ( 42%)]  Loss: 1.121 (1.58)  Time: 0.470s,   17.02/s  (0.478s,   16.75/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1050/2354 ( 45%)]  Loss: 1.009 (1.58)  Time: 0.470s,   17.01/s  (0.477s,   16.76/s)  LR: 5.050e-05  Data: 0.009 (0.009)\n",
            "Train: 40 [1100/2354 ( 47%)]  Loss: 0.9952 (1.58)  Time: 0.469s,   17.07/s  (0.477s,   16.77/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1150/2354 ( 49%)]  Loss: 1.504 (1.58)  Time: 0.470s,   17.01/s  (0.477s,   16.78/s)  LR: 5.050e-05  Data: 0.010 (0.009)\n",
            "Train: 40 [1200/2354 ( 51%)]  Loss: 1.015 (1.58)  Time: 0.471s,   16.99/s  (0.476s,   16.79/s)  LR: 5.050e-05  Data: 0.010 (0.009)\n",
            "Train: 40 [1250/2354 ( 53%)]  Loss: 1.010 (1.58)  Time: 0.483s,   16.56/s  (0.476s,   16.80/s)  LR: 5.050e-05  Data: 0.008 (0.009)\n",
            "Train: 40 [1300/2354 ( 55%)]  Loss: 1.065 (1.58)  Time: 0.459s,   17.42/s  (0.477s,   16.79/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1350/2354 ( 57%)]  Loss: 1.500 (1.59)  Time: 0.465s,   17.21/s  (0.476s,   16.80/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1400/2354 ( 59%)]  Loss: 1.373 (1.59)  Time: 0.466s,   17.15/s  (0.476s,   16.81/s)  LR: 5.050e-05  Data: 0.009 (0.009)\n",
            "Train: 40 [1450/2354 ( 62%)]  Loss: 2.308 (1.59)  Time: 0.474s,   16.87/s  (0.476s,   16.82/s)  LR: 5.050e-05  Data: 0.010 (0.009)\n",
            "Train: 40 [1500/2354 ( 64%)]  Loss: 0.9953 (1.59)  Time: 0.467s,   17.12/s  (0.475s,   16.83/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1550/2354 ( 66%)]  Loss: 2.003 (1.59)  Time: 0.685s,   11.68/s  (0.476s,   16.82/s)  LR: 5.050e-05  Data: 0.019 (0.009)\n",
            "Train: 40 [1600/2354 ( 68%)]  Loss: 1.028 (1.59)  Time: 0.469s,   17.05/s  (0.476s,   16.82/s)  LR: 5.050e-05  Data: 0.011 (0.009)\n",
            "Train: 40 [1650/2354 ( 70%)]  Loss: 1.160 (1.59)  Time: 0.459s,   17.43/s  (0.475s,   16.83/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1700/2354 ( 72%)]  Loss: 1.037 (1.59)  Time: 0.467s,   17.12/s  (0.475s,   16.84/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1750/2354 ( 74%)]  Loss: 1.853 (1.59)  Time: 0.464s,   17.25/s  (0.475s,   16.85/s)  LR: 5.050e-05  Data: 0.007 (0.009)\n",
            "Train: 40 [1800/2354 ( 76%)]  Loss: 1.053 (1.59)  Time: 0.467s,   17.13/s  (0.475s,   16.85/s)  LR: 5.050e-05  Data: 0.010 (0.009)\n",
            "Train: 40 [1850/2354 ( 79%)]  Loss: 1.026 (1.59)  Time: 0.474s,   16.88/s  (0.475s,   16.84/s)  LR: 5.050e-05  Data: 0.011 (0.009)\n",
            "Train: 40 [1900/2354 ( 81%)]  Loss: 1.617 (1.59)  Time: 0.469s,   17.04/s  (0.475s,   16.84/s)  LR: 5.050e-05  Data: 0.009 (0.009)\n",
            "Train: 40 [1950/2354 ( 83%)]  Loss: 0.9906 (1.59)  Time: 0.471s,   16.97/s  (0.475s,   16.85/s)  LR: 5.050e-05  Data: 0.008 (0.008)\n",
            "Train: 40 [2000/2354 ( 85%)]  Loss: 1.381 (1.59)  Time: 0.470s,   17.03/s  (0.475s,   16.85/s)  LR: 5.050e-05  Data: 0.007 (0.008)\n",
            "Train: 40 [2050/2354 ( 87%)]  Loss: 1.219 (1.59)  Time: 0.473s,   16.90/s  (0.475s,   16.85/s)  LR: 5.050e-05  Data: 0.011 (0.008)\n",
            "Train: 40 [2100/2354 ( 89%)]  Loss: 2.385 (1.59)  Time: 0.474s,   16.90/s  (0.475s,   16.85/s)  LR: 5.050e-05  Data: 0.007 (0.008)\n",
            "Train: 40 [2150/2354 ( 91%)]  Loss: 1.330 (1.59)  Time: 0.470s,   17.01/s  (0.475s,   16.83/s)  LR: 5.050e-05  Data: 0.007 (0.008)\n",
            "Train: 40 [2200/2354 ( 93%)]  Loss: 1.473 (1.60)  Time: 0.479s,   16.71/s  (0.475s,   16.83/s)  LR: 5.050e-05  Data: 0.008 (0.008)\n",
            "Train: 40 [2250/2354 ( 96%)]  Loss: 1.545 (1.60)  Time: 0.471s,   16.99/s  (0.475s,   16.83/s)  LR: 5.050e-05  Data: 0.008 (0.008)\n",
            "Train: 40 [2300/2354 ( 98%)]  Loss: 1.666 (1.60)  Time: 0.474s,   16.87/s  (0.475s,   16.83/s)  LR: 5.050e-05  Data: 0.009 (0.008)\n",
            "Train: 40 [2350/2354 (100%)]  Loss: 2.359 (1.60)  Time: 0.464s,   17.23/s  (0.475s,   16.83/s)  LR: 5.050e-05  Data: 0.006 (0.008)\n",
            "Train: 40 [2353/2354 (100%)]  Loss: 2.101 (1.60)  Time: 0.465s,   17.21/s  (0.475s,   16.83/s)  LR: 5.050e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.711 (0.711)  Loss:  0.1874 (0.1874)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.170 (0.167)  Loss:  0.3379 (0.2268)  Acc@1: 100.0000 (98.0392)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.311 (0.162)  Loss:  0.0752 (0.2145)  Acc@1: 100.0000 (98.7624)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.167 (0.166)  Loss:  0.1499 (0.2347)  Acc@1: 100.0000 (98.3444)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.188 (0.161)  Loss:  0.2866 (0.2239)  Acc@1: 100.0000 (98.6318)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.173 (0.159)  Loss:  0.2007 (0.2193)  Acc@1: 100.0000 (98.9044)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.169 (0.156)  Loss:  0.1819 (0.2204)  Acc@1: 100.0000 (98.7542)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.131 (0.155)  Loss:  0.1115 (0.2321)  Acc@1: 100.0000 (98.4330)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.113 (0.153)  Loss:  0.4409 (0.2383)  Acc@1: 100.0000 (98.1920)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.170 (0.153)  Loss:  0.1318 (0.2354)  Acc@1: 100.0000 (98.3370)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.128 (0.152)  Loss:  0.5024 (0.2296)  Acc@1: 100.0000 (98.3533)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.084 (0.152)  Loss:  0.3533 (0.2303)  Acc@1: 100.0000 (98.2759)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.147 (0.151)  Loss:  0.2617 (0.2243)  Acc@1: 100.0000 (98.3777)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.081 (0.151)  Loss:  0.1616 (0.2190)  Acc@1: 100.0000 (98.5023)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.167 (0.150)  Loss:  0.1438 (0.2180)  Acc@1: 100.0000 (98.5735)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.184 (0.150)  Loss:  0.2020 (0.2205)  Acc@1: 100.0000 (98.6019)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.166 (0.149)  Loss:  0.1730 (0.2210)  Acc@1: 100.0000 (98.4395)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.181 (0.149)  Loss:  0.1130 (0.2187)  Acc@1: 100.0000 (98.4724)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.191 (0.149)  Loss:  0.4500 (0.2153)  Acc@1: 100.0000 (98.5572)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.080 (0.148)  Loss:  0.1980 (0.2165)  Acc@1: 100.0000 (98.5804)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.126 (0.148)  Loss:  0.0532 (0.2142)  Acc@1: 100.0000 (98.6264)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.120 (0.150)  Loss:  0.2321 (0.2151)  Acc@1: 100.0000 (98.6204)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.099 (0.149)  Loss:  0.0588 (0.2130)  Acc@1: 100.0000 (98.6603)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.112 (0.149)  Loss:  1.2344 (0.2135)  Acc@1: 100.0000 (98.6968)  Acc@5: 100.0000 (99.9783)\n",
            "Test: [1200/2354]  Time: 0.193 (0.149)  Loss:  0.7104 (0.2147)  Acc@1: 75.0000 (98.6678)  Acc@5: 100.0000 (99.9584)\n",
            "Test: [1250/2354]  Time: 0.105 (0.148)  Loss:  0.0766 (0.2116)  Acc@1: 100.0000 (98.7210)  Acc@5: 100.0000 (99.9600)\n",
            "Test: [1300/2354]  Time: 0.099 (0.148)  Loss:  0.1335 (0.2123)  Acc@1: 100.0000 (98.6549)  Acc@5: 100.0000 (99.9616)\n",
            "Test: [1350/2354]  Time: 0.136 (0.148)  Loss:  0.1215 (0.2109)  Acc@1: 100.0000 (98.6862)  Acc@5: 100.0000 (99.9630)\n",
            "Test: [1400/2354]  Time: 0.131 (0.147)  Loss:  0.0873 (0.2121)  Acc@1: 100.0000 (98.6617)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [1450/2354]  Time: 0.093 (0.147)  Loss:  0.1743 (0.2104)  Acc@1: 100.0000 (98.6906)  Acc@5: 100.0000 (99.9655)\n",
            "Test: [1500/2354]  Time: 0.107 (0.147)  Loss:  0.0874 (0.2089)  Acc@1: 100.0000 (98.7175)  Acc@5: 100.0000 (99.9500)\n",
            "Test: [1550/2354]  Time: 0.173 (0.147)  Loss:  0.0988 (0.2124)  Acc@1: 100.0000 (98.6783)  Acc@5: 100.0000 (99.9516)\n",
            "Test: [1600/2354]  Time: 0.146 (0.147)  Loss:  0.1056 (0.2156)  Acc@1: 100.0000 (98.5790)  Acc@5: 100.0000 (99.9532)\n",
            "Test: [1650/2354]  Time: 0.084 (0.146)  Loss:  0.2169 (0.2171)  Acc@1: 100.0000 (98.5161)  Acc@5: 100.0000 (99.9394)\n",
            "Test: [1700/2354]  Time: 0.171 (0.146)  Loss:  0.1332 (0.2169)  Acc@1: 100.0000 (98.5156)  Acc@5: 100.0000 (99.9265)\n",
            "Test: [1750/2354]  Time: 0.120 (0.146)  Loss:  0.6196 (0.2192)  Acc@1: 75.0000 (98.4295)  Acc@5: 100.0000 (99.9286)\n",
            "Test: [1800/2354]  Time: 0.147 (0.146)  Loss:  0.4688 (0.2202)  Acc@1: 100.0000 (98.4175)  Acc@5: 100.0000 (99.9167)\n",
            "Test: [1850/2354]  Time: 0.121 (0.146)  Loss:  0.5029 (0.2203)  Acc@1: 100.0000 (98.3928)  Acc@5: 100.0000 (99.9190)\n",
            "Test: [1900/2354]  Time: 0.165 (0.146)  Loss:  0.1525 (0.2193)  Acc@1: 100.0000 (98.4087)  Acc@5: 100.0000 (99.9211)\n",
            "Test: [1950/2354]  Time: 0.229 (0.146)  Loss:  0.1584 (0.2190)  Acc@1: 100.0000 (98.4111)  Acc@5: 100.0000 (99.9103)\n",
            "Test: [2000/2354]  Time: 0.116 (0.146)  Loss:  0.1245 (0.2185)  Acc@1: 100.0000 (98.4258)  Acc@5: 100.0000 (99.9125)\n",
            "Test: [2050/2354]  Time: 0.147 (0.146)  Loss:  0.2085 (0.2227)  Acc@1: 100.0000 (98.3423)  Acc@5: 100.0000 (99.9147)\n",
            "Test: [2100/2354]  Time: 0.124 (0.146)  Loss:  0.2554 (0.2247)  Acc@1: 100.0000 (98.3341)  Acc@5: 100.0000 (99.9167)\n",
            "Test: [2150/2354]  Time: 0.083 (0.146)  Loss:  0.4055 (0.2266)  Acc@1: 100.0000 (98.3031)  Acc@5: 100.0000 (99.9186)\n",
            "Test: [2200/2354]  Time: 0.145 (0.146)  Loss:  0.0350 (0.2286)  Acc@1: 100.0000 (98.3076)  Acc@5: 100.0000 (99.9091)\n",
            "Test: [2250/2354]  Time: 0.191 (0.146)  Loss:  0.0457 (0.2279)  Acc@1: 100.0000 (98.3119)  Acc@5: 100.0000 (99.9112)\n",
            "Test: [2300/2354]  Time: 0.172 (0.145)  Loss:  0.1136 (0.2260)  Acc@1: 100.0000 (98.3377)  Acc@5: 100.0000 (99.9022)\n",
            "Test: [2350/2354]  Time: 0.075 (0.145)  Loss:  0.1097 (0.2261)  Acc@1: 100.0000 (98.3624)  Acc@5: 100.0000 (99.9043)\n",
            "Test: [2354/2354]  Time: 0.065 (0.145)  Loss:  0.0235 (0.2258)  Acc@1: 100.0000 (98.3650)  Acc@5: 100.0000 (99.9044)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-31.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar', 96.02930247372332)\n",
            "\n",
            "Train: 41 [   0/2354 (  0%)]  Loss: 1.185 (1.19)  Time: 1.400s,    5.71/s  (1.400s,    5.71/s)  LR: 4.856e-05  Data: 0.523 (0.523)\n",
            "Train: 41 [  50/2354 (  2%)]  Loss: 1.551 (1.50)  Time: 0.468s,   17.10/s  (0.504s,   15.86/s)  LR: 4.856e-05  Data: 0.007 (0.018)\n",
            "Train: 41 [ 100/2354 (  4%)]  Loss: 1.963 (1.53)  Time: 0.465s,   17.21/s  (0.487s,   16.42/s)  LR: 4.856e-05  Data: 0.007 (0.013)\n",
            "Train: 41 [ 150/2354 (  6%)]  Loss: 2.223 (1.59)  Time: 0.479s,   16.71/s  (0.481s,   16.64/s)  LR: 4.856e-05  Data: 0.011 (0.011)\n",
            "Train: 41 [ 200/2354 (  8%)]  Loss: 1.494 (1.59)  Time: 0.464s,   17.24/s  (0.482s,   16.60/s)  LR: 4.856e-05  Data: 0.007 (0.011)\n",
            "Train: 41 [ 250/2354 ( 11%)]  Loss: 1.083 (1.60)  Time: 0.473s,   16.93/s  (0.479s,   16.69/s)  LR: 4.856e-05  Data: 0.010 (0.010)\n",
            "Train: 41 [ 300/2354 ( 13%)]  Loss: 1.405 (1.61)  Time: 0.474s,   16.89/s  (0.477s,   16.76/s)  LR: 4.856e-05  Data: 0.009 (0.010)\n",
            "Train: 41 [ 350/2354 ( 15%)]  Loss: 1.224 (1.58)  Time: 0.468s,   17.10/s  (0.476s,   16.80/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [ 400/2354 ( 17%)]  Loss: 1.453 (1.59)  Time: 0.476s,   16.82/s  (0.475s,   16.83/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [ 450/2354 ( 19%)]  Loss: 1.137 (1.58)  Time: 0.463s,   17.27/s  (0.477s,   16.78/s)  LR: 4.856e-05  Data: 0.008 (0.009)\n",
            "Train: 41 [ 500/2354 ( 21%)]  Loss: 1.047 (1.58)  Time: 0.465s,   17.22/s  (0.476s,   16.81/s)  LR: 4.856e-05  Data: 0.008 (0.009)\n",
            "Train: 41 [ 550/2354 ( 23%)]  Loss: 1.486 (1.59)  Time: 0.463s,   17.26/s  (0.475s,   16.84/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [ 600/2354 ( 25%)]  Loss: 2.384 (1.60)  Time: 0.471s,   16.98/s  (0.475s,   16.86/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [ 650/2354 ( 28%)]  Loss: 1.378 (1.59)  Time: 0.464s,   17.26/s  (0.474s,   16.87/s)  LR: 4.856e-05  Data: 0.009 (0.009)\n",
            "Train: 41 [ 700/2354 ( 30%)]  Loss: 1.109 (1.58)  Time: 0.475s,   16.85/s  (0.474s,   16.88/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [ 750/2354 ( 32%)]  Loss: 1.248 (1.58)  Time: 0.466s,   17.16/s  (0.475s,   16.84/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [ 800/2354 ( 34%)]  Loss: 0.9892 (1.58)  Time: 0.468s,   17.09/s  (0.475s,   16.86/s)  LR: 4.856e-05  Data: 0.009 (0.009)\n",
            "Train: 41 [ 850/2354 ( 36%)]  Loss: 1.251 (1.58)  Time: 0.461s,   17.34/s  (0.474s,   16.87/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [ 900/2354 ( 38%)]  Loss: 1.122 (1.58)  Time: 0.465s,   17.20/s  (0.474s,   16.88/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [ 950/2354 ( 40%)]  Loss: 2.607 (1.58)  Time: 0.468s,   17.08/s  (0.474s,   16.89/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [1000/2354 ( 42%)]  Loss: 1.532 (1.58)  Time: 0.468s,   17.10/s  (0.474s,   16.89/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [1050/2354 ( 45%)]  Loss: 1.163 (1.58)  Time: 0.479s,   16.68/s  (0.474s,   16.87/s)  LR: 4.856e-05  Data: 0.009 (0.009)\n",
            "Train: 41 [1100/2354 ( 47%)]  Loss: 1.795 (1.57)  Time: 0.469s,   17.08/s  (0.474s,   16.88/s)  LR: 4.856e-05  Data: 0.007 (0.009)\n",
            "Train: 41 [1150/2354 ( 49%)]  Loss: 1.174 (1.56)  Time: 0.461s,   17.35/s  (0.474s,   16.89/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [1200/2354 ( 51%)]  Loss: 1.608 (1.56)  Time: 0.463s,   17.28/s  (0.474s,   16.90/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [1250/2354 ( 53%)]  Loss: 1.001 (1.56)  Time: 0.466s,   17.16/s  (0.473s,   16.90/s)  LR: 4.856e-05  Data: 0.009 (0.008)\n",
            "Train: 41 [1300/2354 ( 55%)]  Loss: 1.179 (1.57)  Time: 0.468s,   17.10/s  (0.474s,   16.88/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [1350/2354 ( 57%)]  Loss: 1.049 (1.57)  Time: 0.466s,   17.18/s  (0.474s,   16.89/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [1400/2354 ( 59%)]  Loss: 1.118 (1.56)  Time: 0.471s,   16.98/s  (0.473s,   16.90/s)  LR: 4.856e-05  Data: 0.010 (0.008)\n",
            "Train: 41 [1450/2354 ( 62%)]  Loss: 1.199 (1.56)  Time: 0.477s,   16.77/s  (0.473s,   16.90/s)  LR: 4.856e-05  Data: 0.014 (0.008)\n",
            "Train: 41 [1500/2354 ( 64%)]  Loss: 1.265 (1.56)  Time: 0.474s,   16.86/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.010 (0.008)\n",
            "Train: 41 [1550/2354 ( 66%)]  Loss: 1.653 (1.56)  Time: 0.473s,   16.90/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [1600/2354 ( 68%)]  Loss: 1.062 (1.56)  Time: 0.465s,   17.19/s  (0.474s,   16.89/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [1650/2354 ( 70%)]  Loss: 1.800 (1.56)  Time: 0.467s,   17.13/s  (0.473s,   16.90/s)  LR: 4.856e-05  Data: 0.009 (0.008)\n",
            "Train: 41 [1700/2354 ( 72%)]  Loss: 1.140 (1.56)  Time: 0.467s,   17.13/s  (0.473s,   16.90/s)  LR: 4.856e-05  Data: 0.009 (0.008)\n",
            "Train: 41 [1750/2354 ( 74%)]  Loss: 1.131 (1.56)  Time: 0.468s,   17.08/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [1800/2354 ( 76%)]  Loss: 1.157 (1.56)  Time: 0.468s,   17.10/s  (0.473s,   16.92/s)  LR: 4.856e-05  Data: 0.009 (0.008)\n",
            "Train: 41 [1850/2354 ( 79%)]  Loss: 2.075 (1.56)  Time: 0.468s,   17.09/s  (0.473s,   16.92/s)  LR: 4.856e-05  Data: 0.010 (0.008)\n",
            "Train: 41 [1900/2354 ( 81%)]  Loss: 1.118 (1.57)  Time: 0.461s,   17.34/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [1950/2354 ( 83%)]  Loss: 1.061 (1.57)  Time: 0.466s,   17.18/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.009 (0.008)\n",
            "Train: 41 [2000/2354 ( 85%)]  Loss: 1.322 (1.57)  Time: 0.469s,   17.06/s  (0.473s,   16.92/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [2050/2354 ( 87%)]  Loss: 1.662 (1.57)  Time: 0.469s,   17.07/s  (0.473s,   16.92/s)  LR: 4.856e-05  Data: 0.008 (0.008)\n",
            "Train: 41 [2100/2354 ( 89%)]  Loss: 1.728 (1.57)  Time: 0.472s,   16.94/s  (0.473s,   16.92/s)  LR: 4.856e-05  Data: 0.010 (0.008)\n",
            "Train: 41 [2150/2354 ( 91%)]  Loss: 2.908 (1.58)  Time: 0.480s,   16.65/s  (0.473s,   16.90/s)  LR: 4.856e-05  Data: 0.008 (0.008)\n",
            "Train: 41 [2200/2354 ( 93%)]  Loss: 2.288 (1.58)  Time: 0.467s,   17.14/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [2250/2354 ( 96%)]  Loss: 1.683 (1.58)  Time: 0.465s,   17.19/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.010 (0.008)\n",
            "Train: 41 [2300/2354 ( 98%)]  Loss: 1.189 (1.58)  Time: 0.467s,   17.15/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.007 (0.008)\n",
            "Train: 41 [2350/2354 (100%)]  Loss: 1.401 (1.58)  Time: 0.467s,   17.14/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.006 (0.008)\n",
            "Train: 41 [2353/2354 (100%)]  Loss: 1.085 (1.57)  Time: 0.461s,   17.36/s  (0.473s,   16.91/s)  LR: 4.856e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.685 (0.685)  Loss:  0.2656 (0.2656)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.100 (0.160)  Loss:  0.1114 (0.1492)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.169 (0.151)  Loss:  0.0775 (0.1447)  Acc@1: 100.0000 (99.5050)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.114 (0.147)  Loss:  0.1316 (0.1691)  Acc@1: 100.0000 (99.1722)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.182 (0.146)  Loss:  0.1858 (0.1770)  Acc@1: 100.0000 (99.1294)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.183 (0.153)  Loss:  0.1775 (0.1758)  Acc@1: 100.0000 (99.3028)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.169 (0.151)  Loss:  0.8271 (0.1774)  Acc@1: 75.0000 (99.1694)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.146 (0.150)  Loss:  0.1628 (0.1960)  Acc@1: 100.0000 (98.2194)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.171 (0.149)  Loss:  0.0588 (0.2004)  Acc@1: 100.0000 (98.2544)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.180 (0.149)  Loss:  0.1758 (0.1975)  Acc@1: 100.0000 (98.2816)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.099 (0.148)  Loss:  0.3955 (0.1926)  Acc@1: 100.0000 (98.3533)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.173 (0.148)  Loss:  0.0610 (0.1963)  Acc@1: 100.0000 (98.3212)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.112 (0.147)  Loss:  0.2174 (0.1915)  Acc@1: 100.0000 (98.4609)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.167 (0.147)  Loss:  0.1019 (0.1890)  Acc@1: 100.0000 (98.5791)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.109 (0.146)  Loss:  0.0406 (0.1819)  Acc@1: 100.0000 (98.6805)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.166 (0.146)  Loss:  0.0871 (0.1812)  Acc@1: 100.0000 (98.6684)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [ 800/2354]  Time: 0.205 (0.146)  Loss:  0.1398 (0.1832)  Acc@1: 100.0000 (98.7203)  Acc@5: 100.0000 (99.9688)\n",
            "Test: [ 850/2354]  Time: 0.104 (0.146)  Loss:  0.1965 (0.1831)  Acc@1: 100.0000 (98.7368)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [ 900/2354]  Time: 0.076 (0.145)  Loss:  0.3289 (0.1793)  Acc@1: 100.0000 (98.8069)  Acc@5: 100.0000 (99.9723)\n",
            "Test: [ 950/2354]  Time: 0.157 (0.145)  Loss:  0.2131 (0.1776)  Acc@1: 100.0000 (98.8696)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1000/2354]  Time: 0.167 (0.145)  Loss:  0.2100 (0.1787)  Acc@1: 100.0000 (98.9011)  Acc@5: 100.0000 (99.9750)\n",
            "Test: [1050/2354]  Time: 0.125 (0.145)  Loss:  0.1801 (0.1802)  Acc@1: 100.0000 (98.8820)  Acc@5: 100.0000 (99.9762)\n",
            "Test: [1100/2354]  Time: 0.115 (0.144)  Loss:  0.0346 (0.1795)  Acc@1: 100.0000 (98.9328)  Acc@5: 100.0000 (99.9773)\n",
            "Test: [1150/2354]  Time: 0.199 (0.146)  Loss:  0.8008 (0.1804)  Acc@1: 75.0000 (98.8923)  Acc@5: 100.0000 (99.9783)\n",
            "Test: [1200/2354]  Time: 0.105 (0.146)  Loss:  0.7324 (0.1833)  Acc@1: 75.0000 (98.7719)  Acc@5: 100.0000 (99.9792)\n",
            "Test: [1250/2354]  Time: 0.080 (0.145)  Loss:  0.1493 (0.1803)  Acc@1: 100.0000 (98.8209)  Acc@5: 100.0000 (99.9800)\n",
            "Test: [1300/2354]  Time: 0.135 (0.145)  Loss:  0.0763 (0.1820)  Acc@1: 100.0000 (98.7894)  Acc@5: 100.0000 (99.9808)\n",
            "Test: [1350/2354]  Time: 0.153 (0.145)  Loss:  0.1175 (0.1826)  Acc@1: 100.0000 (98.7972)  Acc@5: 100.0000 (99.9815)\n",
            "Test: [1400/2354]  Time: 0.161 (0.145)  Loss:  0.1897 (0.1816)  Acc@1: 100.0000 (98.8223)  Acc@5: 100.0000 (99.9822)\n",
            "Test: [1450/2354]  Time: 0.172 (0.144)  Loss:  0.1094 (0.1814)  Acc@1: 100.0000 (98.8456)  Acc@5: 100.0000 (99.9828)\n",
            "Test: [1500/2354]  Time: 0.144 (0.144)  Loss:  0.1282 (0.1819)  Acc@1: 100.0000 (98.8508)  Acc@5: 100.0000 (99.9833)\n",
            "Test: [1550/2354]  Time: 0.106 (0.144)  Loss:  0.1183 (0.1837)  Acc@1: 100.0000 (98.8233)  Acc@5: 100.0000 (99.9839)\n",
            "Test: [1600/2354]  Time: 0.184 (0.144)  Loss:  0.1199 (0.1847)  Acc@1: 100.0000 (98.8132)  Acc@5: 100.0000 (99.9844)\n",
            "Test: [1650/2354]  Time: 0.079 (0.144)  Loss:  0.1593 (0.1880)  Acc@1: 100.0000 (98.7583)  Acc@5: 100.0000 (99.9697)\n",
            "Test: [1700/2354]  Time: 0.135 (0.144)  Loss:  0.1128 (0.1876)  Acc@1: 100.0000 (98.7507)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [1750/2354]  Time: 0.139 (0.144)  Loss:  0.2087 (0.1910)  Acc@1: 100.0000 (98.7007)  Acc@5: 100.0000 (99.9714)\n",
            "Test: [1800/2354]  Time: 0.076 (0.144)  Loss:  0.2756 (0.1913)  Acc@1: 100.0000 (98.7091)  Acc@5: 100.0000 (99.9722)\n",
            "Test: [1850/2354]  Time: 0.152 (0.143)  Loss:  0.1106 (0.1917)  Acc@1: 100.0000 (98.7304)  Acc@5: 100.0000 (99.9730)\n",
            "Test: [1900/2354]  Time: 0.130 (0.143)  Loss:  0.2637 (0.1926)  Acc@1: 100.0000 (98.7638)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1950/2354]  Time: 0.163 (0.143)  Loss:  0.2871 (0.1922)  Acc@1: 100.0000 (98.7699)  Acc@5: 100.0000 (99.9744)\n",
            "Test: [2000/2354]  Time: 0.140 (0.143)  Loss:  0.0980 (0.1915)  Acc@1: 100.0000 (98.7631)  Acc@5: 100.0000 (99.9750)\n",
            "Test: [2050/2354]  Time: 0.158 (0.143)  Loss:  0.1790 (0.1926)  Acc@1: 100.0000 (98.7079)  Acc@5: 100.0000 (99.9756)\n",
            "Test: [2100/2354]  Time: 0.148 (0.144)  Loss:  0.2231 (0.1937)  Acc@1: 100.0000 (98.7030)  Acc@5: 100.0000 (99.9762)\n",
            "Test: [2150/2354]  Time: 0.113 (0.144)  Loss:  0.3213 (0.1947)  Acc@1: 100.0000 (98.6867)  Acc@5: 100.0000 (99.9768)\n",
            "Test: [2200/2354]  Time: 0.209 (0.144)  Loss:  0.0587 (0.1959)  Acc@1: 100.0000 (98.6483)  Acc@5: 100.0000 (99.9659)\n",
            "Test: [2250/2354]  Time: 0.156 (0.144)  Loss:  0.0779 (0.1953)  Acc@1: 100.0000 (98.6562)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [2300/2354]  Time: 0.142 (0.144)  Loss:  0.1313 (0.1933)  Acc@1: 100.0000 (98.6745)  Acc@5: 100.0000 (99.9565)\n",
            "Test: [2350/2354]  Time: 0.075 (0.144)  Loss:  0.0668 (0.1922)  Acc@1: 100.0000 (98.6920)  Acc@5: 100.0000 (99.9575)\n",
            "Test: [2354/2354]  Time: 0.064 (0.143)  Loss:  0.0857 (0.1921)  Acc@1: 100.0000 (98.6941)  Acc@5: 100.0000 (99.9575)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-30.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar', 96.63446225713983)\n",
            "\n",
            "Train: 42 [   0/2354 (  0%)]  Loss: 1.329 (1.33)  Time: 1.318s,    6.07/s  (1.318s,    6.07/s)  LR: 4.662e-05  Data: 0.606 (0.606)\n",
            "Train: 42 [  50/2354 (  2%)]  Loss: 1.379 (1.59)  Time: 0.457s,   17.50/s  (0.500s,   16.00/s)  LR: 4.662e-05  Data: 0.007 (0.020)\n",
            "Train: 42 [ 100/2354 (  4%)]  Loss: 1.071 (1.55)  Time: 0.464s,   17.24/s  (0.484s,   16.52/s)  LR: 4.662e-05  Data: 0.009 (0.014)\n",
            "Train: 42 [ 150/2354 (  6%)]  Loss: 1.356 (1.51)  Time: 0.468s,   17.09/s  (0.479s,   16.71/s)  LR: 4.662e-05  Data: 0.007 (0.012)\n",
            "Train: 42 [ 200/2354 (  8%)]  Loss: 1.143 (1.53)  Time: 0.619s,   12.93/s  (0.478s,   16.75/s)  LR: 4.662e-05  Data: 0.013 (0.011)\n",
            "Train: 42 [ 250/2354 ( 11%)]  Loss: 1.330 (1.54)  Time: 0.465s,   17.21/s  (0.478s,   16.75/s)  LR: 4.662e-05  Data: 0.007 (0.010)\n",
            "Train: 42 [ 300/2354 ( 13%)]  Loss: 0.9962 (1.51)  Time: 0.476s,   16.80/s  (0.476s,   16.80/s)  LR: 4.662e-05  Data: 0.007 (0.010)\n",
            "Train: 42 [ 350/2354 ( 15%)]  Loss: 1.860 (1.52)  Time: 0.466s,   17.17/s  (0.475s,   16.85/s)  LR: 4.662e-05  Data: 0.007 (0.010)\n",
            "Train: 42 [ 400/2354 ( 17%)]  Loss: 1.228 (1.53)  Time: 0.462s,   17.32/s  (0.474s,   16.87/s)  LR: 4.662e-05  Data: 0.007 (0.009)\n",
            "Train: 42 [ 450/2354 ( 19%)]  Loss: 1.553 (1.53)  Time: 0.461s,   17.36/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.007 (0.009)\n",
            "Train: 42 [ 500/2354 ( 21%)]  Loss: 1.525 (1.54)  Time: 0.468s,   17.09/s  (0.475s,   16.84/s)  LR: 4.662e-05  Data: 0.007 (0.009)\n",
            "Train: 42 [ 550/2354 ( 23%)]  Loss: 1.839 (1.54)  Time: 0.463s,   17.27/s  (0.474s,   16.86/s)  LR: 4.662e-05  Data: 0.007 (0.009)\n",
            "Train: 42 [ 600/2354 ( 25%)]  Loss: 1.018 (1.54)  Time: 0.467s,   17.14/s  (0.474s,   16.88/s)  LR: 4.662e-05  Data: 0.007 (0.009)\n",
            "Train: 42 [ 650/2354 ( 28%)]  Loss: 0.9608 (1.54)  Time: 0.469s,   17.07/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.009 (0.009)\n",
            "Train: 42 [ 700/2354 ( 30%)]  Loss: 1.088 (1.55)  Time: 0.470s,   17.02/s  (0.473s,   16.91/s)  LR: 4.662e-05  Data: 0.011 (0.009)\n",
            "Train: 42 [ 750/2354 ( 32%)]  Loss: 1.786 (1.55)  Time: 0.459s,   17.42/s  (0.473s,   16.92/s)  LR: 4.662e-05  Data: 0.007 (0.009)\n",
            "Train: 42 [ 800/2354 ( 34%)]  Loss: 2.079 (1.55)  Time: 0.474s,   16.88/s  (0.474s,   16.88/s)  LR: 4.662e-05  Data: 0.008 (0.009)\n",
            "Train: 42 [ 850/2354 ( 36%)]  Loss: 1.161 (1.54)  Time: 0.467s,   17.11/s  (0.474s,   16.88/s)  LR: 4.662e-05  Data: 0.007 (0.009)\n",
            "Train: 42 [ 900/2354 ( 38%)]  Loss: 1.548 (1.53)  Time: 0.472s,   16.95/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.010 (0.009)\n",
            "Train: 42 [ 950/2354 ( 40%)]  Loss: 1.884 (1.53)  Time: 0.482s,   16.59/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.009 (0.009)\n",
            "Train: 42 [1000/2354 ( 42%)]  Loss: 1.382 (1.54)  Time: 0.472s,   16.93/s  (0.473s,   16.91/s)  LR: 4.662e-05  Data: 0.010 (0.009)\n",
            "Train: 42 [1050/2354 ( 45%)]  Loss: 1.133 (1.53)  Time: 0.467s,   17.13/s  (0.474s,   16.88/s)  LR: 4.662e-05  Data: 0.007 (0.009)\n",
            "Train: 42 [1100/2354 ( 47%)]  Loss: 2.494 (1.54)  Time: 0.462s,   17.31/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.010 (0.009)\n",
            "Train: 42 [1150/2354 ( 49%)]  Loss: 1.806 (1.53)  Time: 0.473s,   16.91/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.010 (0.009)\n",
            "Train: 42 [1200/2354 ( 51%)]  Loss: 1.213 (1.53)  Time: 0.478s,   16.75/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [1250/2354 ( 53%)]  Loss: 1.438 (1.53)  Time: 0.473s,   16.93/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [1300/2354 ( 55%)]  Loss: 3.497 (1.54)  Time: 0.470s,   17.02/s  (0.473s,   16.91/s)  LR: 4.662e-05  Data: 0.011 (0.008)\n",
            "Train: 42 [1350/2354 ( 57%)]  Loss: 1.017 (1.54)  Time: 0.471s,   16.97/s  (0.474s,   16.88/s)  LR: 4.662e-05  Data: 0.009 (0.008)\n",
            "Train: 42 [1400/2354 ( 59%)]  Loss: 1.437 (1.54)  Time: 0.476s,   16.82/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [1450/2354 ( 62%)]  Loss: 0.9888 (1.54)  Time: 0.461s,   17.37/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [1500/2354 ( 64%)]  Loss: 1.103 (1.53)  Time: 0.470s,   17.00/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [1550/2354 ( 66%)]  Loss: 1.560 (1.53)  Time: 0.469s,   17.05/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.009 (0.008)\n",
            "Train: 42 [1600/2354 ( 68%)]  Loss: 2.319 (1.54)  Time: 0.618s,   12.94/s  (0.474s,   16.88/s)  LR: 4.662e-05  Data: 0.017 (0.008)\n",
            "Train: 42 [1650/2354 ( 70%)]  Loss: 1.145 (1.53)  Time: 0.474s,   16.87/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [1700/2354 ( 72%)]  Loss: 1.291 (1.53)  Time: 0.471s,   17.00/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [1750/2354 ( 74%)]  Loss: 1.340 (1.54)  Time: 0.465s,   17.19/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.009 (0.008)\n",
            "Train: 42 [1800/2354 ( 76%)]  Loss: 1.328 (1.54)  Time: 0.468s,   17.08/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [1850/2354 ( 79%)]  Loss: 3.305 (1.54)  Time: 0.467s,   17.12/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.010 (0.008)\n",
            "Train: 42 [1900/2354 ( 81%)]  Loss: 1.095 (1.55)  Time: 0.487s,   16.44/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.008 (0.008)\n",
            "Train: 42 [1950/2354 ( 83%)]  Loss: 1.098 (1.55)  Time: 0.474s,   16.88/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.010 (0.008)\n",
            "Train: 42 [2000/2354 ( 85%)]  Loss: 1.233 (1.55)  Time: 0.468s,   17.08/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [2050/2354 ( 87%)]  Loss: 1.216 (1.55)  Time: 0.468s,   17.08/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [2100/2354 ( 89%)]  Loss: 2.029 (1.55)  Time: 0.467s,   17.12/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.008 (0.008)\n",
            "Train: 42 [2150/2354 ( 91%)]  Loss: 1.513 (1.55)  Time: 0.593s,   13.50/s  (0.473s,   16.90/s)  LR: 4.662e-05  Data: 0.009 (0.008)\n",
            "Train: 42 [2200/2354 ( 93%)]  Loss: 1.095 (1.55)  Time: 0.467s,   17.13/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [2250/2354 ( 96%)]  Loss: 1.181 (1.55)  Time: 0.477s,   16.78/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.011 (0.008)\n",
            "Train: 42 [2300/2354 ( 98%)]  Loss: 1.057 (1.55)  Time: 0.474s,   16.89/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.007 (0.008)\n",
            "Train: 42 [2350/2354 (100%)]  Loss: 1.383 (1.55)  Time: 0.467s,   17.15/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.005 (0.008)\n",
            "Train: 42 [2353/2354 (100%)]  Loss: 2.270 (1.55)  Time: 0.455s,   17.57/s  (0.474s,   16.89/s)  LR: 4.662e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.604 (0.604)  Loss:  0.0903 (0.0903)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.152 (0.164)  Loss:  0.1122 (0.1049)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.191 (0.154)  Loss:  0.1254 (0.1257)  Acc@1: 100.0000 (99.5050)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.153 (0.152)  Loss:  0.0298 (0.1561)  Acc@1: 100.0000 (99.0066)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.191 (0.151)  Loss:  0.2747 (0.1452)  Acc@1: 100.0000 (99.1294)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.132 (0.158)  Loss:  0.0928 (0.1461)  Acc@1: 100.0000 (99.0040)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.132 (0.156)  Loss:  0.3655 (0.1481)  Acc@1: 100.0000 (99.0864)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.169 (0.154)  Loss:  0.0983 (0.1695)  Acc@1: 100.0000 (98.9316)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.174 (0.153)  Loss:  0.0999 (0.1685)  Acc@1: 100.0000 (98.9401)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.166 (0.152)  Loss:  0.1389 (0.1697)  Acc@1: 100.0000 (98.9468)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.104 (0.152)  Loss:  0.2595 (0.1650)  Acc@1: 100.0000 (99.0519)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.114 (0.151)  Loss:  0.1432 (0.1676)  Acc@1: 100.0000 (99.0926)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.203 (0.151)  Loss:  0.1157 (0.1632)  Acc@1: 100.0000 (99.1681)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.125 (0.150)  Loss:  0.0953 (0.1630)  Acc@1: 100.0000 (99.1167)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.105 (0.150)  Loss:  0.1028 (0.1619)  Acc@1: 100.0000 (99.1797)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.103 (0.150)  Loss:  0.1110 (0.1631)  Acc@1: 100.0000 (99.1345)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.177 (0.150)  Loss:  0.1499 (0.1645)  Acc@1: 100.0000 (99.1261)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.210 (0.150)  Loss:  0.1277 (0.1637)  Acc@1: 100.0000 (99.0893)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.148 (0.150)  Loss:  0.3315 (0.1641)  Acc@1: 100.0000 (99.1121)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.176 (0.149)  Loss:  0.1565 (0.1629)  Acc@1: 100.0000 (99.1325)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.157 (0.149)  Loss:  0.0982 (0.1625)  Acc@1: 100.0000 (99.1259)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.114 (0.149)  Loss:  0.0898 (0.1607)  Acc@1: 100.0000 (99.1675)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.321 (0.150)  Loss:  0.1151 (0.1592)  Acc@1: 100.0000 (99.2053)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.177 (0.150)  Loss:  0.7671 (0.1599)  Acc@1: 75.0000 (99.1312)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.119 (0.150)  Loss:  0.3552 (0.1637)  Acc@1: 100.0000 (98.9592)  Acc@5: 100.0000 (99.9792)\n",
            "Test: [1250/2354]  Time: 0.180 (0.150)  Loss:  0.0910 (0.1624)  Acc@1: 100.0000 (99.0008)  Acc@5: 100.0000 (99.9800)\n",
            "Test: [1300/2354]  Time: 0.093 (0.150)  Loss:  0.1282 (0.1626)  Acc@1: 100.0000 (99.0008)  Acc@5: 100.0000 (99.9808)\n",
            "Test: [1350/2354]  Time: 0.123 (0.149)  Loss:  0.0899 (0.1627)  Acc@1: 100.0000 (99.0007)  Acc@5: 100.0000 (99.9815)\n",
            "Test: [1400/2354]  Time: 0.160 (0.149)  Loss:  0.2715 (0.1624)  Acc@1: 100.0000 (99.0364)  Acc@5: 100.0000 (99.9822)\n",
            "Test: [1450/2354]  Time: 0.121 (0.149)  Loss:  0.1697 (0.1636)  Acc@1: 100.0000 (99.0524)  Acc@5: 100.0000 (99.9828)\n",
            "Test: [1500/2354]  Time: 0.129 (0.149)  Loss:  0.2286 (0.1623)  Acc@1: 100.0000 (99.0673)  Acc@5: 100.0000 (99.9833)\n",
            "Test: [1550/2354]  Time: 0.200 (0.149)  Loss:  0.1036 (0.1654)  Acc@1: 100.0000 (99.0490)  Acc@5: 100.0000 (99.9839)\n",
            "Test: [1600/2354]  Time: 0.106 (0.149)  Loss:  0.1110 (0.1670)  Acc@1: 100.0000 (99.0319)  Acc@5: 100.0000 (99.9844)\n",
            "Test: [1650/2354]  Time: 0.171 (0.149)  Loss:  0.0640 (0.1691)  Acc@1: 100.0000 (98.9400)  Acc@5: 100.0000 (99.9697)\n",
            "Test: [1700/2354]  Time: 0.165 (0.148)  Loss:  0.0571 (0.1683)  Acc@1: 100.0000 (98.9418)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [1750/2354]  Time: 0.133 (0.148)  Loss:  0.2771 (0.1705)  Acc@1: 100.0000 (98.9006)  Acc@5: 100.0000 (99.9714)\n",
            "Test: [1800/2354]  Time: 0.176 (0.148)  Loss:  0.1635 (0.1700)  Acc@1: 100.0000 (98.8895)  Acc@5: 100.0000 (99.9722)\n",
            "Test: [1850/2354]  Time: 0.154 (0.148)  Loss:  0.1316 (0.1701)  Acc@1: 100.0000 (98.8925)  Acc@5: 100.0000 (99.9730)\n",
            "Test: [1900/2354]  Time: 0.164 (0.147)  Loss:  0.0688 (0.1684)  Acc@1: 100.0000 (98.9085)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1950/2354]  Time: 0.184 (0.147)  Loss:  0.1071 (0.1676)  Acc@1: 100.0000 (98.9108)  Acc@5: 100.0000 (99.9744)\n",
            "Test: [2000/2354]  Time: 0.183 (0.148)  Loss:  0.1472 (0.1666)  Acc@1: 100.0000 (98.9130)  Acc@5: 100.0000 (99.9750)\n",
            "Test: [2050/2354]  Time: 0.175 (0.148)  Loss:  0.0737 (0.1683)  Acc@1: 100.0000 (98.9030)  Acc@5: 100.0000 (99.9756)\n",
            "Test: [2100/2354]  Time: 0.105 (0.148)  Loss:  0.2810 (0.1707)  Acc@1: 100.0000 (98.8696)  Acc@5: 100.0000 (99.9762)\n",
            "Test: [2150/2354]  Time: 0.125 (0.148)  Loss:  0.3818 (0.1731)  Acc@1: 100.0000 (98.8494)  Acc@5: 100.0000 (99.9768)\n",
            "Test: [2200/2354]  Time: 0.138 (0.147)  Loss:  0.1375 (0.1759)  Acc@1: 100.0000 (98.7392)  Acc@5: 100.0000 (99.9773)\n",
            "Test: [2250/2354]  Time: 0.169 (0.147)  Loss:  0.0894 (0.1749)  Acc@1: 100.0000 (98.7450)  Acc@5: 100.0000 (99.9778)\n",
            "Test: [2300/2354]  Time: 0.127 (0.147)  Loss:  0.1509 (0.1745)  Acc@1: 100.0000 (98.7614)  Acc@5: 100.0000 (99.9674)\n",
            "Test: [2350/2354]  Time: 0.075 (0.147)  Loss:  0.1176 (0.1750)  Acc@1: 100.0000 (98.7452)  Acc@5: 100.0000 (99.9681)\n",
            "Test: [2354/2354]  Time: 0.068 (0.147)  Loss:  0.0295 (0.1748)  Acc@1: 100.0000 (98.7472)  Acc@5: 100.0000 (99.9681)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-33.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar', 96.66631277205649)\n",
            "\n",
            "Train: 43 [   0/2354 (  0%)]  Loss: 1.098 (1.10)  Time: 1.307s,    6.12/s  (1.307s,    6.12/s)  LR: 4.468e-05  Data: 0.597 (0.597)\n",
            "Train: 43 [  50/2354 (  2%)]  Loss: 0.9588 (1.47)  Time: 0.470s,   17.01/s  (0.498s,   16.07/s)  LR: 4.468e-05  Data: 0.007 (0.020)\n",
            "Train: 43 [ 100/2354 (  4%)]  Loss: 1.800 (1.52)  Time: 0.463s,   17.28/s  (0.483s,   16.57/s)  LR: 4.468e-05  Data: 0.006 (0.014)\n",
            "Train: 43 [ 150/2354 (  6%)]  Loss: 2.697 (1.50)  Time: 0.465s,   17.21/s  (0.478s,   16.75/s)  LR: 4.468e-05  Data: 0.008 (0.012)\n",
            "Train: 43 [ 200/2354 (  8%)]  Loss: 2.944 (1.52)  Time: 0.467s,   17.13/s  (0.479s,   16.69/s)  LR: 4.468e-05  Data: 0.007 (0.011)\n",
            "Train: 43 [ 250/2354 ( 11%)]  Loss: 1.438 (1.54)  Time: 0.471s,   16.98/s  (0.477s,   16.76/s)  LR: 4.468e-05  Data: 0.007 (0.010)\n",
            "Train: 43 [ 300/2354 ( 13%)]  Loss: 1.407 (1.53)  Time: 0.458s,   17.49/s  (0.475s,   16.83/s)  LR: 4.468e-05  Data: 0.007 (0.010)\n",
            "Train: 43 [ 350/2354 ( 15%)]  Loss: 1.013 (1.52)  Time: 0.467s,   17.12/s  (0.474s,   16.87/s)  LR: 4.468e-05  Data: 0.009 (0.010)\n",
            "Train: 43 [ 400/2354 ( 17%)]  Loss: 2.226 (1.52)  Time: 0.468s,   17.08/s  (0.474s,   16.89/s)  LR: 4.468e-05  Data: 0.011 (0.009)\n",
            "Train: 43 [ 450/2354 ( 19%)]  Loss: 1.051 (1.53)  Time: 0.468s,   17.09/s  (0.475s,   16.83/s)  LR: 4.468e-05  Data: 0.007 (0.009)\n",
            "Train: 43 [ 500/2354 ( 21%)]  Loss: 1.292 (1.53)  Time: 0.463s,   17.29/s  (0.474s,   16.86/s)  LR: 4.468e-05  Data: 0.007 (0.009)\n",
            "Train: 43 [ 550/2354 ( 23%)]  Loss: 1.758 (1.53)  Time: 0.473s,   16.93/s  (0.474s,   16.88/s)  LR: 4.468e-05  Data: 0.009 (0.009)\n",
            "Train: 43 [ 600/2354 ( 25%)]  Loss: 1.027 (1.52)  Time: 0.465s,   17.22/s  (0.474s,   16.90/s)  LR: 4.468e-05  Data: 0.009 (0.009)\n",
            "Train: 43 [ 650/2354 ( 28%)]  Loss: 1.059 (1.51)  Time: 0.468s,   17.08/s  (0.473s,   16.91/s)  LR: 4.468e-05  Data: 0.010 (0.009)\n",
            "Train: 43 [ 700/2354 ( 30%)]  Loss: 1.325 (1.51)  Time: 0.463s,   17.28/s  (0.473s,   16.92/s)  LR: 4.468e-05  Data: 0.007 (0.009)\n",
            "Train: 43 [ 750/2354 ( 32%)]  Loss: 3.245 (1.52)  Time: 0.478s,   16.75/s  (0.474s,   16.88/s)  LR: 4.468e-05  Data: 0.007 (0.009)\n",
            "Train: 43 [ 800/2354 ( 34%)]  Loss: 1.659 (1.53)  Time: 0.468s,   17.09/s  (0.473s,   16.90/s)  LR: 4.468e-05  Data: 0.008 (0.009)\n",
            "Train: 43 [ 850/2354 ( 36%)]  Loss: 1.132 (1.54)  Time: 0.468s,   17.08/s  (0.473s,   16.91/s)  LR: 4.468e-05  Data: 0.007 (0.009)\n",
            "Train: 43 [ 900/2354 ( 38%)]  Loss: 1.049 (1.54)  Time: 0.466s,   17.17/s  (0.473s,   16.92/s)  LR: 4.468e-05  Data: 0.007 (0.009)\n",
            "Train: 43 [ 950/2354 ( 40%)]  Loss: 2.112 (1.54)  Time: 0.472s,   16.95/s  (0.473s,   16.92/s)  LR: 4.468e-05  Data: 0.009 (0.009)\n",
            "Train: 43 [1000/2354 ( 42%)]  Loss: 1.445 (1.54)  Time: 0.462s,   17.32/s  (0.473s,   16.90/s)  LR: 4.468e-05  Data: 0.010 (0.009)\n",
            "Train: 43 [1050/2354 ( 45%)]  Loss: 1.106 (1.54)  Time: 0.467s,   17.12/s  (0.473s,   16.91/s)  LR: 4.468e-05  Data: 0.010 (0.009)\n",
            "Train: 43 [1100/2354 ( 47%)]  Loss: 2.754 (1.54)  Time: 0.469s,   17.07/s  (0.473s,   16.92/s)  LR: 4.468e-05  Data: 0.010 (0.009)\n",
            "Train: 43 [1150/2354 ( 49%)]  Loss: 1.625 (1.54)  Time: 0.468s,   17.08/s  (0.473s,   16.93/s)  LR: 4.468e-05  Data: 0.010 (0.009)\n",
            "Train: 43 [1200/2354 ( 51%)]  Loss: 2.049 (1.54)  Time: 0.462s,   17.31/s  (0.472s,   16.94/s)  LR: 4.468e-05  Data: 0.007 (0.009)\n",
            "Train: 43 [1250/2354 ( 53%)]  Loss: 1.394 (1.54)  Time: 0.470s,   17.01/s  (0.472s,   16.94/s)  LR: 4.468e-05  Data: 0.009 (0.009)\n",
            "Train: 43 [1300/2354 ( 55%)]  Loss: 2.211 (1.54)  Time: 0.462s,   17.31/s  (0.473s,   16.92/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1350/2354 ( 57%)]  Loss: 2.401 (1.54)  Time: 0.465s,   17.21/s  (0.472s,   16.93/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1400/2354 ( 59%)]  Loss: 1.076 (1.54)  Time: 0.466s,   17.16/s  (0.472s,   16.94/s)  LR: 4.468e-05  Data: 0.010 (0.008)\n",
            "Train: 43 [1450/2354 ( 62%)]  Loss: 1.337 (1.54)  Time: 0.467s,   17.11/s  (0.472s,   16.94/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1500/2354 ( 64%)]  Loss: 1.775 (1.54)  Time: 0.465s,   17.19/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1550/2354 ( 66%)]  Loss: 2.779 (1.54)  Time: 0.467s,   17.15/s  (0.472s,   16.93/s)  LR: 4.468e-05  Data: 0.010 (0.008)\n",
            "Train: 43 [1600/2354 ( 68%)]  Loss: 1.586 (1.54)  Time: 0.472s,   16.95/s  (0.472s,   16.94/s)  LR: 4.468e-05  Data: 0.010 (0.008)\n",
            "Train: 43 [1650/2354 ( 70%)]  Loss: 1.098 (1.54)  Time: 0.465s,   17.19/s  (0.472s,   16.94/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1700/2354 ( 72%)]  Loss: 1.933 (1.54)  Time: 0.460s,   17.40/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1750/2354 ( 74%)]  Loss: 1.164 (1.54)  Time: 0.467s,   17.15/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1800/2354 ( 76%)]  Loss: 1.013 (1.54)  Time: 0.474s,   16.87/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.010 (0.008)\n",
            "Train: 43 [1850/2354 ( 79%)]  Loss: 1.245 (1.54)  Time: 0.464s,   17.24/s  (0.472s,   16.94/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1900/2354 ( 81%)]  Loss: 1.164 (1.54)  Time: 0.463s,   17.29/s  (0.472s,   16.94/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [1950/2354 ( 83%)]  Loss: 1.978 (1.54)  Time: 0.478s,   16.72/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.006 (0.008)\n",
            "Train: 43 [2000/2354 ( 85%)]  Loss: 2.528 (1.54)  Time: 0.469s,   17.07/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.006 (0.008)\n",
            "Train: 43 [2050/2354 ( 87%)]  Loss: 1.670 (1.55)  Time: 0.458s,   17.47/s  (0.472s,   16.96/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [2100/2354 ( 89%)]  Loss: 1.026 (1.55)  Time: 0.628s,   12.74/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.017 (0.008)\n",
            "Train: 43 [2150/2354 ( 91%)]  Loss: 1.423 (1.55)  Time: 0.479s,   16.69/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.010 (0.008)\n",
            "Train: 43 [2200/2354 ( 93%)]  Loss: 1.067 (1.55)  Time: 0.463s,   17.27/s  (0.472s,   16.95/s)  LR: 4.468e-05  Data: 0.006 (0.008)\n",
            "Train: 43 [2250/2354 ( 96%)]  Loss: 1.686 (1.55)  Time: 0.471s,   16.98/s  (0.472s,   16.96/s)  LR: 4.468e-05  Data: 0.007 (0.008)\n",
            "Train: 43 [2300/2354 ( 98%)]  Loss: 1.020 (1.55)  Time: 0.468s,   17.11/s  (0.472s,   16.96/s)  LR: 4.468e-05  Data: 0.008 (0.008)\n",
            "Train: 43 [2350/2354 (100%)]  Loss: 1.144 (1.55)  Time: 0.461s,   17.35/s  (0.472s,   16.96/s)  LR: 4.468e-05  Data: 0.006 (0.008)\n",
            "Train: 43 [2353/2354 (100%)]  Loss: 1.118 (1.55)  Time: 0.454s,   17.63/s  (0.472s,   16.96/s)  LR: 4.468e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.658 (0.658)  Loss:  0.0879 (0.0879)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.279 (0.169)  Loss:  0.0839 (0.1211)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.167 (0.166)  Loss:  0.2410 (0.1318)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.138 (0.157)  Loss:  0.0845 (0.1380)  Acc@1: 100.0000 (99.8344)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.131 (0.153)  Loss:  0.0927 (0.1498)  Acc@1: 100.0000 (99.8756)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.196 (0.151)  Loss:  0.0970 (0.1459)  Acc@1: 100.0000 (99.9004)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.120 (0.148)  Loss:  0.5664 (0.1429)  Acc@1: 100.0000 (99.9169)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.146 (0.147)  Loss:  0.0738 (0.1649)  Acc@1: 100.0000 (99.5014)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.122 (0.146)  Loss:  0.0710 (0.1608)  Acc@1: 100.0000 (99.4389)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.139 (0.145)  Loss:  0.0758 (0.1577)  Acc@1: 100.0000 (99.4457)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.102 (0.145)  Loss:  0.1421 (0.1546)  Acc@1: 100.0000 (99.4012)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.123 (0.144)  Loss:  0.1440 (0.1525)  Acc@1: 100.0000 (99.3648)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.176 (0.144)  Loss:  0.1254 (0.1502)  Acc@1: 100.0000 (99.4176)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.098 (0.143)  Loss:  0.1437 (0.1493)  Acc@1: 100.0000 (99.4624)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.097 (0.143)  Loss:  0.0677 (0.1499)  Acc@1: 100.0000 (99.5007)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.153 (0.143)  Loss:  0.1267 (0.1523)  Acc@1: 100.0000 (99.4341)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.134 (0.142)  Loss:  0.0787 (0.1549)  Acc@1: 100.0000 (99.3134)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.086 (0.142)  Loss:  0.1343 (0.1583)  Acc@1: 100.0000 (99.2362)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.163 (0.142)  Loss:  0.2169 (0.1559)  Acc@1: 100.0000 (99.2786)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.180 (0.142)  Loss:  0.1484 (0.1552)  Acc@1: 100.0000 (99.3165)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.148 (0.144)  Loss:  0.0761 (0.1554)  Acc@1: 100.0000 (99.3257)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.159 (0.143)  Loss:  0.1606 (0.1546)  Acc@1: 100.0000 (99.3102)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.170 (0.143)  Loss:  0.0977 (0.1563)  Acc@1: 100.0000 (99.2961)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.176 (0.143)  Loss:  0.6323 (0.1569)  Acc@1: 100.0000 (99.2615)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.123 (0.143)  Loss:  0.2246 (0.1585)  Acc@1: 100.0000 (99.2090)  Acc@5: 100.0000 (99.9792)\n",
            "Test: [1250/2354]  Time: 0.113 (0.143)  Loss:  0.1312 (0.1579)  Acc@1: 100.0000 (99.2006)  Acc@5: 100.0000 (99.9800)\n",
            "Test: [1300/2354]  Time: 0.101 (0.143)  Loss:  0.1188 (0.1583)  Acc@1: 100.0000 (99.2121)  Acc@5: 100.0000 (99.9808)\n",
            "Test: [1350/2354]  Time: 0.123 (0.142)  Loss:  0.0676 (0.1601)  Acc@1: 100.0000 (99.2043)  Acc@5: 100.0000 (99.9815)\n",
            "Test: [1400/2354]  Time: 0.169 (0.142)  Loss:  0.1899 (0.1598)  Acc@1: 100.0000 (99.2148)  Acc@5: 100.0000 (99.9822)\n",
            "Test: [1450/2354]  Time: 0.116 (0.142)  Loss:  0.0746 (0.1609)  Acc@1: 100.0000 (99.1902)  Acc@5: 100.0000 (99.9828)\n",
            "Test: [1500/2354]  Time: 0.160 (0.142)  Loss:  0.1410 (0.1603)  Acc@1: 100.0000 (99.2005)  Acc@5: 100.0000 (99.9833)\n",
            "Test: [1550/2354]  Time: 0.141 (0.142)  Loss:  0.2058 (0.1629)  Acc@1: 100.0000 (99.1135)  Acc@5: 100.0000 (99.9839)\n",
            "Test: [1600/2354]  Time: 0.147 (0.142)  Loss:  0.2249 (0.1646)  Acc@1: 100.0000 (99.0943)  Acc@5: 100.0000 (99.9844)\n",
            "Test: [1650/2354]  Time: 0.153 (0.142)  Loss:  0.2915 (0.1668)  Acc@1: 100.0000 (99.0309)  Acc@5: 100.0000 (99.9697)\n",
            "Test: [1700/2354]  Time: 0.079 (0.142)  Loss:  0.2139 (0.1683)  Acc@1: 100.0000 (99.0006)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [1750/2354]  Time: 0.101 (0.142)  Loss:  0.1703 (0.1693)  Acc@1: 100.0000 (99.0148)  Acc@5: 100.0000 (99.9714)\n",
            "Test: [1800/2354]  Time: 0.213 (0.142)  Loss:  0.2920 (0.1712)  Acc@1: 100.0000 (98.9867)  Acc@5: 100.0000 (99.9722)\n",
            "Test: [1850/2354]  Time: 0.146 (0.142)  Loss:  0.1702 (0.1714)  Acc@1: 100.0000 (98.9870)  Acc@5: 100.0000 (99.9730)\n",
            "Test: [1900/2354]  Time: 0.163 (0.143)  Loss:  0.0758 (0.1706)  Acc@1: 100.0000 (99.0137)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1950/2354]  Time: 0.170 (0.143)  Loss:  0.1536 (0.1705)  Acc@1: 100.0000 (99.0261)  Acc@5: 100.0000 (99.9744)\n",
            "Test: [2000/2354]  Time: 0.161 (0.143)  Loss:  0.1030 (0.1699)  Acc@1: 100.0000 (99.0255)  Acc@5: 100.0000 (99.9625)\n",
            "Test: [2050/2354]  Time: 0.097 (0.143)  Loss:  0.0820 (0.1720)  Acc@1: 100.0000 (98.9639)  Acc@5: 100.0000 (99.9634)\n",
            "Test: [2100/2354]  Time: 0.141 (0.142)  Loss:  0.1917 (0.1740)  Acc@1: 100.0000 (98.9410)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [2150/2354]  Time: 0.178 (0.142)  Loss:  0.4780 (0.1765)  Acc@1: 100.0000 (98.8842)  Acc@5: 100.0000 (99.9651)\n",
            "Test: [2200/2354]  Time: 0.173 (0.143)  Loss:  0.0820 (0.1781)  Acc@1: 100.0000 (98.8414)  Acc@5: 100.0000 (99.9659)\n",
            "Test: [2250/2354]  Time: 0.195 (0.143)  Loss:  0.0787 (0.1773)  Acc@1: 100.0000 (98.8561)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [2300/2354]  Time: 0.169 (0.143)  Loss:  0.0757 (0.1769)  Acc@1: 100.0000 (98.8701)  Acc@5: 100.0000 (99.9674)\n",
            "Test: [2350/2354]  Time: 0.075 (0.142)  Loss:  0.0790 (0.1774)  Acc@1: 100.0000 (98.8728)  Acc@5: 100.0000 (99.9681)\n",
            "Test: [2354/2354]  Time: 0.066 (0.142)  Loss:  0.1091 (0.1774)  Acc@1: 100.0000 (98.8746)  Acc@5: 100.0000 (99.9681)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-32.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar', 96.9317337296953)\n",
            "\n",
            "Train: 44 [   0/2354 (  0%)]  Loss: 1.165 (1.17)  Time: 1.336s,    5.99/s  (1.336s,    5.99/s)  LR: 4.276e-05  Data: 0.692 (0.692)\n",
            "Train: 44 [  50/2354 (  2%)]  Loss: 1.254 (1.54)  Time: 0.479s,   16.69/s  (0.502s,   15.92/s)  LR: 4.276e-05  Data: 0.006 (0.022)\n",
            "Train: 44 [ 100/2354 (  4%)]  Loss: 2.133 (1.52)  Time: 0.466s,   17.18/s  (0.485s,   16.51/s)  LR: 4.276e-05  Data: 0.007 (0.015)\n",
            "Train: 44 [ 150/2354 (  6%)]  Loss: 1.910 (1.50)  Time: 0.465s,   17.22/s  (0.484s,   16.52/s)  LR: 4.276e-05  Data: 0.009 (0.013)\n",
            "Train: 44 [ 200/2354 (  8%)]  Loss: 1.291 (1.49)  Time: 0.462s,   17.33/s  (0.480s,   16.66/s)  LR: 4.276e-05  Data: 0.006 (0.011)\n",
            "Train: 44 [ 250/2354 ( 11%)]  Loss: 1.019 (1.48)  Time: 0.463s,   17.27/s  (0.477s,   16.76/s)  LR: 4.276e-05  Data: 0.007 (0.011)\n",
            "Train: 44 [ 300/2354 ( 13%)]  Loss: 1.381 (1.49)  Time: 0.463s,   17.26/s  (0.476s,   16.82/s)  LR: 4.276e-05  Data: 0.007 (0.010)\n",
            "Train: 44 [ 350/2354 ( 15%)]  Loss: 1.098 (1.47)  Time: 0.478s,   16.74/s  (0.475s,   16.86/s)  LR: 4.276e-05  Data: 0.011 (0.010)\n",
            "Train: 44 [ 400/2354 ( 17%)]  Loss: 1.132 (1.49)  Time: 0.464s,   17.23/s  (0.476s,   16.81/s)  LR: 4.276e-05  Data: 0.009 (0.010)\n",
            "Train: 44 [ 450/2354 ( 19%)]  Loss: 1.190 (1.49)  Time: 0.472s,   16.95/s  (0.475s,   16.84/s)  LR: 4.276e-05  Data: 0.010 (0.010)\n",
            "Train: 44 [ 500/2354 ( 21%)]  Loss: 1.056 (1.49)  Time: 0.467s,   17.13/s  (0.474s,   16.87/s)  LR: 4.276e-05  Data: 0.010 (0.009)\n",
            "Train: 44 [ 550/2354 ( 23%)]  Loss: 1.516 (1.48)  Time: 0.461s,   17.37/s  (0.473s,   16.90/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [ 600/2354 ( 25%)]  Loss: 1.023 (1.48)  Time: 0.481s,   16.63/s  (0.473s,   16.92/s)  LR: 4.276e-05  Data: 0.010 (0.009)\n",
            "Train: 44 [ 650/2354 ( 28%)]  Loss: 1.189 (1.47)  Time: 0.476s,   16.79/s  (0.472s,   16.93/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [ 700/2354 ( 30%)]  Loss: 1.133 (1.47)  Time: 0.472s,   16.97/s  (0.473s,   16.90/s)  LR: 4.276e-05  Data: 0.010 (0.009)\n",
            "Train: 44 [ 750/2354 ( 32%)]  Loss: 2.280 (1.47)  Time: 0.470s,   17.01/s  (0.473s,   16.92/s)  LR: 4.276e-05  Data: 0.010 (0.009)\n",
            "Train: 44 [ 800/2354 ( 34%)]  Loss: 1.175 (1.48)  Time: 0.461s,   17.36/s  (0.472s,   16.93/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [ 850/2354 ( 36%)]  Loss: 1.531 (1.48)  Time: 0.468s,   17.11/s  (0.472s,   16.94/s)  LR: 4.276e-05  Data: 0.009 (0.009)\n",
            "Train: 44 [ 900/2354 ( 38%)]  Loss: 1.953 (1.48)  Time: 0.468s,   17.09/s  (0.472s,   16.95/s)  LR: 4.276e-05  Data: 0.009 (0.009)\n",
            "Train: 44 [ 950/2354 ( 40%)]  Loss: 1.399 (1.49)  Time: 0.469s,   17.05/s  (0.473s,   16.93/s)  LR: 4.276e-05  Data: 0.006 (0.009)\n",
            "Train: 44 [1000/2354 ( 42%)]  Loss: 1.010 (1.49)  Time: 0.470s,   17.00/s  (0.472s,   16.93/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [1050/2354 ( 45%)]  Loss: 2.086 (1.50)  Time: 0.465s,   17.20/s  (0.472s,   16.94/s)  LR: 4.276e-05  Data: 0.008 (0.009)\n",
            "Train: 44 [1100/2354 ( 47%)]  Loss: 2.040 (1.51)  Time: 0.467s,   17.12/s  (0.472s,   16.95/s)  LR: 4.276e-05  Data: 0.008 (0.009)\n",
            "Train: 44 [1150/2354 ( 49%)]  Loss: 1.152 (1.51)  Time: 0.463s,   17.27/s  (0.472s,   16.96/s)  LR: 4.276e-05  Data: 0.009 (0.009)\n",
            "Train: 44 [1200/2354 ( 51%)]  Loss: 1.163 (1.51)  Time: 0.465s,   17.22/s  (0.472s,   16.96/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [1250/2354 ( 53%)]  Loss: 2.312 (1.51)  Time: 0.462s,   17.33/s  (0.472s,   16.94/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [1300/2354 ( 55%)]  Loss: 0.9970 (1.51)  Time: 0.466s,   17.17/s  (0.472s,   16.95/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [1350/2354 ( 57%)]  Loss: 1.066 (1.51)  Time: 0.466s,   17.16/s  (0.472s,   16.96/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [1400/2354 ( 59%)]  Loss: 1.238 (1.51)  Time: 0.465s,   17.20/s  (0.472s,   16.96/s)  LR: 4.276e-05  Data: 0.007 (0.009)\n",
            "Train: 44 [1450/2354 ( 62%)]  Loss: 1.378 (1.51)  Time: 0.473s,   16.92/s  (0.471s,   16.97/s)  LR: 4.276e-05  Data: 0.007 (0.008)\n",
            "Train: 44 [1500/2354 ( 64%)]  Loss: 1.724 (1.51)  Time: 0.463s,   17.28/s  (0.472s,   16.95/s)  LR: 4.276e-05  Data: 0.006 (0.008)\n",
            "Train: 44 [1550/2354 ( 66%)]  Loss: 1.494 (1.51)  Time: 0.462s,   17.30/s  (0.472s,   16.96/s)  LR: 4.276e-05  Data: 0.007 (0.008)\n",
            "Train: 44 [1600/2354 ( 68%)]  Loss: 1.473 (1.51)  Time: 0.467s,   17.14/s  (0.472s,   16.96/s)  LR: 4.276e-05  Data: 0.007 (0.008)\n",
            "Train: 44 [1650/2354 ( 70%)]  Loss: 1.091 (1.51)  Time: 0.464s,   17.23/s  (0.472s,   16.97/s)  LR: 4.276e-05  Data: 0.006 (0.008)\n",
            "Train: 44 [1700/2354 ( 72%)]  Loss: 1.493 (1.51)  Time: 0.465s,   17.22/s  (0.471s,   16.97/s)  LR: 4.276e-05  Data: 0.007 (0.008)\n",
            "Train: 44 [1750/2354 ( 74%)]  Loss: 1.701 (1.51)  Time: 0.470s,   17.02/s  (0.471s,   16.97/s)  LR: 4.276e-05  Data: 0.011 (0.008)\n",
            "Train: 44 [1800/2354 ( 76%)]  Loss: 1.207 (1.51)  Time: 0.466s,   17.17/s  (0.472s,   16.96/s)  LR: 4.276e-05  Data: 0.009 (0.008)\n",
            "Train: 44 [1850/2354 ( 79%)]  Loss: 2.044 (1.51)  Time: 0.462s,   17.33/s  (0.471s,   16.97/s)  LR: 4.276e-05  Data: 0.007 (0.008)\n",
            "Train: 44 [1900/2354 ( 81%)]  Loss: 1.342 (1.51)  Time: 0.483s,   16.57/s  (0.471s,   16.97/s)  LR: 4.276e-05  Data: 0.007 (0.008)\n",
            "Train: 44 [1950/2354 ( 83%)]  Loss: 1.134 (1.51)  Time: 0.464s,   17.23/s  (0.471s,   16.98/s)  LR: 4.276e-05  Data: 0.010 (0.008)\n",
            "Train: 44 [2000/2354 ( 85%)]  Loss: 2.709 (1.51)  Time: 0.465s,   17.22/s  (0.471s,   16.98/s)  LR: 4.276e-05  Data: 0.009 (0.008)\n",
            "Train: 44 [2050/2354 ( 87%)]  Loss: 0.9646 (1.51)  Time: 0.466s,   17.15/s  (0.471s,   16.97/s)  LR: 4.276e-05  Data: 0.010 (0.008)\n",
            "Train: 44 [2100/2354 ( 89%)]  Loss: 1.724 (1.51)  Time: 0.465s,   17.22/s  (0.471s,   16.98/s)  LR: 4.276e-05  Data: 0.006 (0.008)\n",
            "Train: 44 [2150/2354 ( 91%)]  Loss: 1.127 (1.52)  Time: 0.464s,   17.22/s  (0.471s,   16.98/s)  LR: 4.276e-05  Data: 0.008 (0.008)\n",
            "Train: 44 [2200/2354 ( 93%)]  Loss: 1.354 (1.52)  Time: 0.463s,   17.28/s  (0.471s,   16.98/s)  LR: 4.276e-05  Data: 0.007 (0.008)\n",
            "Train: 44 [2250/2354 ( 96%)]  Loss: 1.086 (1.52)  Time: 0.464s,   17.23/s  (0.471s,   16.99/s)  LR: 4.276e-05  Data: 0.007 (0.008)\n",
            "Train: 44 [2300/2354 ( 98%)]  Loss: 2.436 (1.52)  Time: 0.462s,   17.31/s  (0.471s,   16.99/s)  LR: 4.276e-05  Data: 0.006 (0.008)\n",
            "Train: 44 [2350/2354 (100%)]  Loss: 1.215 (1.52)  Time: 0.462s,   17.32/s  (0.471s,   16.98/s)  LR: 4.276e-05  Data: 0.006 (0.008)\n",
            "Train: 44 [2353/2354 (100%)]  Loss: 2.423 (1.52)  Time: 0.455s,   17.59/s  (0.471s,   16.98/s)  LR: 4.276e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.613 (0.613)  Loss:  0.0421 (0.0421)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.187 (0.158)  Loss:  0.1993 (0.1109)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.165 (0.147)  Loss:  0.1210 (0.1083)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.119 (0.143)  Loss:  0.1060 (0.1385)  Acc@1: 100.0000 (99.6689)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.109 (0.142)  Loss:  0.1703 (0.1394)  Acc@1: 100.0000 (99.5025)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.205 (0.141)  Loss:  0.0799 (0.1372)  Acc@1: 100.0000 (99.5020)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.084 (0.141)  Loss:  0.4397 (0.1570)  Acc@1: 100.0000 (99.3355)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.159 (0.140)  Loss:  0.0383 (0.1876)  Acc@1: 100.0000 (98.7892)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.090 (0.140)  Loss:  0.1307 (0.1849)  Acc@1: 100.0000 (98.7531)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.179 (0.139)  Loss:  0.1616 (0.1827)  Acc@1: 100.0000 (98.7805)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.241 (0.140)  Loss:  0.2791 (0.1775)  Acc@1: 100.0000 (98.7525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.214 (0.140)  Loss:  0.0812 (0.1788)  Acc@1: 100.0000 (98.7750)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.106 (0.140)  Loss:  0.0786 (0.1731)  Acc@1: 100.0000 (98.8353)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.170 (0.140)  Loss:  0.0989 (0.1689)  Acc@1: 100.0000 (98.9247)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.078 (0.140)  Loss:  0.2054 (0.1686)  Acc@1: 100.0000 (99.0014)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.090 (0.140)  Loss:  0.1981 (0.1693)  Acc@1: 100.0000 (99.0346)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.143 (0.142)  Loss:  0.1635 (0.1677)  Acc@1: 100.0000 (99.0949)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.155 (0.142)  Loss:  0.1035 (0.1656)  Acc@1: 100.0000 (99.1187)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.117 (0.142)  Loss:  0.1140 (0.1622)  Acc@1: 100.0000 (99.1676)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.160 (0.142)  Loss:  0.1761 (0.1600)  Acc@1: 100.0000 (99.1851)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.091 (0.141)  Loss:  0.0828 (0.1593)  Acc@1: 100.0000 (99.2008)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.089 (0.141)  Loss:  0.1132 (0.1591)  Acc@1: 100.0000 (99.2150)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.127 (0.141)  Loss:  0.0742 (0.1583)  Acc@1: 100.0000 (99.2280)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.088 (0.141)  Loss:  0.7686 (0.1578)  Acc@1: 100.0000 (99.2398)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.089 (0.141)  Loss:  0.7637 (0.1584)  Acc@1: 75.0000 (99.2090)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.190 (0.141)  Loss:  0.0526 (0.1566)  Acc@1: 100.0000 (99.2406)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.182 (0.141)  Loss:  0.1235 (0.1572)  Acc@1: 100.0000 (99.2314)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.181 (0.141)  Loss:  0.0817 (0.1553)  Acc@1: 100.0000 (99.2413)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.095 (0.141)  Loss:  0.1350 (0.1559)  Acc@1: 100.0000 (99.2327)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.195 (0.141)  Loss:  0.0564 (0.1553)  Acc@1: 100.0000 (99.2247)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.102 (0.141)  Loss:  0.0684 (0.1542)  Acc@1: 100.0000 (99.2505)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.204 (0.141)  Loss:  0.1027 (0.1555)  Acc@1: 100.0000 (99.2424)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.170 (0.141)  Loss:  0.1339 (0.1579)  Acc@1: 100.0000 (99.2036)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.076 (0.140)  Loss:  0.1014 (0.1596)  Acc@1: 100.0000 (99.1823)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.204 (0.142)  Loss:  0.0517 (0.1589)  Acc@1: 100.0000 (99.1917)  Acc@5: 100.0000 (99.9853)\n",
            "Test: [1750/2354]  Time: 0.166 (0.142)  Loss:  0.1678 (0.1619)  Acc@1: 100.0000 (99.1719)  Acc@5: 100.0000 (99.9857)\n",
            "Test: [1800/2354]  Time: 0.135 (0.141)  Loss:  0.1709 (0.1612)  Acc@1: 100.0000 (99.1532)  Acc@5: 100.0000 (99.9861)\n",
            "Test: [1850/2354]  Time: 0.159 (0.142)  Loss:  0.1278 (0.1612)  Acc@1: 100.0000 (99.1356)  Acc@5: 100.0000 (99.9865)\n",
            "Test: [1900/2354]  Time: 0.154 (0.142)  Loss:  0.0577 (0.1605)  Acc@1: 100.0000 (99.1320)  Acc@5: 100.0000 (99.9868)\n",
            "Test: [1950/2354]  Time: 0.166 (0.142)  Loss:  0.0745 (0.1597)  Acc@1: 100.0000 (99.1287)  Acc@5: 100.0000 (99.9872)\n",
            "Test: [2000/2354]  Time: 0.171 (0.142)  Loss:  0.0715 (0.1590)  Acc@1: 100.0000 (99.1129)  Acc@5: 100.0000 (99.9875)\n",
            "Test: [2050/2354]  Time: 0.110 (0.142)  Loss:  0.2891 (0.1606)  Acc@1: 100.0000 (99.0371)  Acc@5: 100.0000 (99.9878)\n",
            "Test: [2100/2354]  Time: 0.150 (0.141)  Loss:  0.1360 (0.1642)  Acc@1: 100.0000 (98.9886)  Acc@5: 100.0000 (99.9881)\n",
            "Test: [2150/2354]  Time: 0.146 (0.141)  Loss:  0.2856 (0.1668)  Acc@1: 100.0000 (98.9656)  Acc@5: 100.0000 (99.9884)\n",
            "Test: [2200/2354]  Time: 0.132 (0.142)  Loss:  0.0788 (0.1687)  Acc@1: 100.0000 (98.9096)  Acc@5: 100.0000 (99.9886)\n",
            "Test: [2250/2354]  Time: 0.090 (0.141)  Loss:  0.0426 (0.1680)  Acc@1: 100.0000 (98.9116)  Acc@5: 100.0000 (99.9889)\n",
            "Test: [2300/2354]  Time: 0.145 (0.141)  Loss:  0.0251 (0.1672)  Acc@1: 100.0000 (98.9244)  Acc@5: 100.0000 (99.9783)\n",
            "Test: [2350/2354]  Time: 0.076 (0.141)  Loss:  0.0740 (0.1666)  Acc@1: 100.0000 (98.9260)  Acc@5: 100.0000 (99.9787)\n",
            "Test: [2354/2354]  Time: 0.065 (0.141)  Loss:  0.0105 (0.1664)  Acc@1: 100.0000 (98.9277)  Acc@5: 100.0000 (99.9788)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-34.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar', 97.48380932158403)\n",
            "\n",
            "Train: 45 [   0/2354 (  0%)]  Loss: 1.107 (1.11)  Time: 1.394s,    5.74/s  (1.394s,    5.74/s)  LR: 4.084e-05  Data: 0.699 (0.699)\n",
            "Train: 45 [  50/2354 (  2%)]  Loss: 2.730 (1.50)  Time: 0.486s,   16.47/s  (0.501s,   15.96/s)  LR: 4.084e-05  Data: 0.007 (0.021)\n",
            "Train: 45 [ 100/2354 (  4%)]  Loss: 1.106 (1.49)  Time: 0.466s,   17.16/s  (0.493s,   16.22/s)  LR: 4.084e-05  Data: 0.010 (0.015)\n",
            "Train: 45 [ 150/2354 (  6%)]  Loss: 1.171 (1.47)  Time: 0.468s,   17.08/s  (0.485s,   16.51/s)  LR: 4.084e-05  Data: 0.009 (0.013)\n",
            "Train: 45 [ 200/2354 (  8%)]  Loss: 1.481 (1.49)  Time: 0.463s,   17.29/s  (0.480s,   16.66/s)  LR: 4.084e-05  Data: 0.006 (0.012)\n",
            "Train: 45 [ 250/2354 ( 11%)]  Loss: 1.161 (1.50)  Time: 0.470s,   17.03/s  (0.478s,   16.75/s)  LR: 4.084e-05  Data: 0.007 (0.011)\n",
            "Train: 45 [ 300/2354 ( 13%)]  Loss: 1.161 (1.50)  Time: 0.462s,   17.30/s  (0.476s,   16.81/s)  LR: 4.084e-05  Data: 0.007 (0.010)\n",
            "Train: 45 [ 350/2354 ( 15%)]  Loss: 1.364 (1.48)  Time: 0.468s,   17.10/s  (0.477s,   16.76/s)  LR: 4.084e-05  Data: 0.006 (0.010)\n",
            "Train: 45 [ 400/2354 ( 17%)]  Loss: 1.569 (1.48)  Time: 0.475s,   16.84/s  (0.476s,   16.80/s)  LR: 4.084e-05  Data: 0.007 (0.010)\n",
            "Train: 45 [ 450/2354 ( 19%)]  Loss: 1.097 (1.48)  Time: 0.462s,   17.32/s  (0.475s,   16.83/s)  LR: 4.084e-05  Data: 0.006 (0.010)\n",
            "Train: 45 [ 500/2354 ( 21%)]  Loss: 2.300 (1.49)  Time: 0.469s,   17.07/s  (0.475s,   16.85/s)  LR: 4.084e-05  Data: 0.007 (0.009)\n",
            "Train: 45 [ 550/2354 ( 23%)]  Loss: 1.122 (1.51)  Time: 0.464s,   17.25/s  (0.474s,   16.88/s)  LR: 4.084e-05  Data: 0.010 (0.009)\n",
            "Train: 45 [ 600/2354 ( 25%)]  Loss: 1.575 (1.51)  Time: 0.468s,   17.09/s  (0.475s,   16.85/s)  LR: 4.084e-05  Data: 0.009 (0.009)\n",
            "Train: 45 [ 650/2354 ( 28%)]  Loss: 1.096 (1.50)  Time: 0.468s,   17.10/s  (0.474s,   16.87/s)  LR: 4.084e-05  Data: 0.007 (0.009)\n",
            "Train: 45 [ 700/2354 ( 30%)]  Loss: 1.454 (1.50)  Time: 0.464s,   17.25/s  (0.474s,   16.88/s)  LR: 4.084e-05  Data: 0.010 (0.009)\n",
            "Train: 45 [ 750/2354 ( 32%)]  Loss: 1.191 (1.50)  Time: 0.468s,   17.11/s  (0.473s,   16.90/s)  LR: 4.084e-05  Data: 0.008 (0.009)\n",
            "Train: 45 [ 800/2354 ( 34%)]  Loss: 0.9908 (1.49)  Time: 0.464s,   17.25/s  (0.473s,   16.91/s)  LR: 4.084e-05  Data: 0.007 (0.009)\n",
            "Train: 45 [ 850/2354 ( 36%)]  Loss: 2.206 (1.49)  Time: 0.468s,   17.09/s  (0.473s,   16.92/s)  LR: 4.084e-05  Data: 0.007 (0.009)\n",
            "Train: 45 [ 900/2354 ( 38%)]  Loss: 2.243 (1.48)  Time: 0.475s,   16.84/s  (0.474s,   16.89/s)  LR: 4.084e-05  Data: 0.010 (0.009)\n",
            "Train: 45 [ 950/2354 ( 40%)]  Loss: 1.228 (1.49)  Time: 0.467s,   17.12/s  (0.473s,   16.91/s)  LR: 4.084e-05  Data: 0.007 (0.009)\n",
            "Train: 45 [1000/2354 ( 42%)]  Loss: 1.289 (1.49)  Time: 0.463s,   17.27/s  (0.473s,   16.92/s)  LR: 4.084e-05  Data: 0.009 (0.009)\n",
            "Train: 45 [1050/2354 ( 45%)]  Loss: 1.035 (1.50)  Time: 0.461s,   17.36/s  (0.473s,   16.93/s)  LR: 4.084e-05  Data: 0.007 (0.009)\n",
            "Train: 45 [1100/2354 ( 47%)]  Loss: 1.271 (1.50)  Time: 0.470s,   17.03/s  (0.472s,   16.94/s)  LR: 4.084e-05  Data: 0.010 (0.009)\n",
            "Train: 45 [1150/2354 ( 49%)]  Loss: 1.100 (1.50)  Time: 0.464s,   17.24/s  (0.473s,   16.92/s)  LR: 4.084e-05  Data: 0.009 (0.009)\n",
            "Train: 45 [1200/2354 ( 51%)]  Loss: 1.966 (1.50)  Time: 0.469s,   17.05/s  (0.473s,   16.92/s)  LR: 4.084e-05  Data: 0.010 (0.009)\n",
            "Train: 45 [1250/2354 ( 53%)]  Loss: 2.900 (1.50)  Time: 0.462s,   17.31/s  (0.472s,   16.93/s)  LR: 4.084e-05  Data: 0.007 (0.009)\n",
            "Train: 45 [1300/2354 ( 55%)]  Loss: 1.096 (1.50)  Time: 0.468s,   17.08/s  (0.472s,   16.94/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1350/2354 ( 57%)]  Loss: 1.534 (1.50)  Time: 0.470s,   17.02/s  (0.472s,   16.95/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1400/2354 ( 59%)]  Loss: 1.078 (1.51)  Time: 0.463s,   17.28/s  (0.473s,   16.93/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1450/2354 ( 62%)]  Loss: 1.957 (1.51)  Time: 0.469s,   17.05/s  (0.472s,   16.94/s)  LR: 4.084e-05  Data: 0.010 (0.008)\n",
            "Train: 45 [1500/2354 ( 64%)]  Loss: 1.030 (1.51)  Time: 0.475s,   16.85/s  (0.472s,   16.94/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1550/2354 ( 66%)]  Loss: 1.390 (1.51)  Time: 0.469s,   17.06/s  (0.472s,   16.95/s)  LR: 4.084e-05  Data: 0.011 (0.008)\n",
            "Train: 45 [1600/2354 ( 68%)]  Loss: 1.106 (1.50)  Time: 0.462s,   17.33/s  (0.472s,   16.95/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1650/2354 ( 70%)]  Loss: 2.536 (1.50)  Time: 0.465s,   17.20/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.006 (0.008)\n",
            "Train: 45 [1700/2354 ( 72%)]  Loss: 1.238 (1.50)  Time: 0.462s,   17.31/s  (0.472s,   16.94/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1750/2354 ( 74%)]  Loss: 1.718 (1.50)  Time: 0.478s,   16.74/s  (0.472s,   16.95/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1800/2354 ( 76%)]  Loss: 1.207 (1.50)  Time: 0.474s,   16.88/s  (0.472s,   16.95/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1850/2354 ( 79%)]  Loss: 1.563 (1.50)  Time: 0.470s,   17.03/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [1900/2354 ( 81%)]  Loss: 1.100 (1.50)  Time: 0.470s,   17.03/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.011 (0.008)\n",
            "Train: 45 [1950/2354 ( 83%)]  Loss: 1.129 (1.51)  Time: 0.471s,   16.98/s  (0.472s,   16.95/s)  LR: 4.084e-05  Data: 0.010 (0.008)\n",
            "Train: 45 [2000/2354 ( 85%)]  Loss: 1.089 (1.50)  Time: 0.473s,   16.93/s  (0.472s,   16.95/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [2050/2354 ( 87%)]  Loss: 1.125 (1.50)  Time: 0.464s,   17.26/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [2100/2354 ( 89%)]  Loss: 1.017 (1.50)  Time: 0.463s,   17.28/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [2150/2354 ( 91%)]  Loss: 1.063 (1.50)  Time: 0.466s,   17.18/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [2200/2354 ( 93%)]  Loss: 2.485 (1.50)  Time: 0.465s,   17.20/s  (0.472s,   16.95/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [2250/2354 ( 96%)]  Loss: 2.004 (1.50)  Time: 0.467s,   17.13/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.008 (0.008)\n",
            "Train: 45 [2300/2354 ( 98%)]  Loss: 2.126 (1.50)  Time: 0.473s,   16.92/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.007 (0.008)\n",
            "Train: 45 [2350/2354 (100%)]  Loss: 1.191 (1.50)  Time: 0.462s,   17.32/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.006 (0.008)\n",
            "Train: 45 [2353/2354 (100%)]  Loss: 2.550 (1.50)  Time: 0.475s,   16.85/s  (0.472s,   16.96/s)  LR: 4.084e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.693 (0.693)  Loss:  0.0620 (0.0620)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.166 (0.161)  Loss:  0.0271 (0.1349)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.216 (0.153)  Loss:  0.0694 (0.1289)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.102 (0.150)  Loss:  0.1738 (0.1422)  Acc@1: 100.0000 (99.6689)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.140 (0.148)  Loss:  0.4858 (0.1507)  Acc@1: 100.0000 (99.6269)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.109 (0.147)  Loss:  0.1929 (0.1557)  Acc@1: 100.0000 (99.7012)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.191 (0.146)  Loss:  0.2297 (0.1580)  Acc@1: 100.0000 (99.5847)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.137 (0.150)  Loss:  0.0977 (0.1739)  Acc@1: 100.0000 (98.9316)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.103 (0.149)  Loss:  0.0789 (0.1667)  Acc@1: 100.0000 (99.0025)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.141 (0.149)  Loss:  0.0898 (0.1653)  Acc@1: 100.0000 (99.0022)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.142 (0.148)  Loss:  0.2178 (0.1611)  Acc@1: 100.0000 (99.0519)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.126 (0.148)  Loss:  0.0778 (0.1603)  Acc@1: 100.0000 (99.0472)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.186 (0.147)  Loss:  0.1252 (0.1544)  Acc@1: 100.0000 (99.1265)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.113 (0.147)  Loss:  0.0999 (0.1519)  Acc@1: 100.0000 (99.1551)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.104 (0.147)  Loss:  0.0803 (0.1502)  Acc@1: 100.0000 (99.2154)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.129 (0.146)  Loss:  0.1151 (0.1503)  Acc@1: 100.0000 (99.2011)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.107 (0.146)  Loss:  0.0756 (0.1514)  Acc@1: 100.0000 (99.1573)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.199 (0.146)  Loss:  0.1375 (0.1509)  Acc@1: 100.0000 (99.1774)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.087 (0.146)  Loss:  0.1018 (0.1490)  Acc@1: 100.0000 (99.2231)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.137 (0.146)  Loss:  0.2856 (0.1490)  Acc@1: 100.0000 (99.2376)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.148 (0.145)  Loss:  0.0520 (0.1482)  Acc@1: 100.0000 (99.2258)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.160 (0.145)  Loss:  0.0871 (0.1471)  Acc@1: 100.0000 (99.2388)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.079 (0.145)  Loss:  0.0804 (0.1458)  Acc@1: 100.0000 (99.2507)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.175 (0.145)  Loss:  0.5679 (0.1457)  Acc@1: 100.0000 (99.2615)  Acc@5: 100.0000 (99.9783)\n",
            "Test: [1200/2354]  Time: 0.170 (0.146)  Loss:  0.2822 (0.1467)  Acc@1: 100.0000 (99.2298)  Acc@5: 100.0000 (99.9792)\n",
            "Test: [1250/2354]  Time: 0.179 (0.146)  Loss:  0.0607 (0.1452)  Acc@1: 100.0000 (99.2606)  Acc@5: 100.0000 (99.9800)\n",
            "Test: [1300/2354]  Time: 0.168 (0.146)  Loss:  0.0812 (0.1458)  Acc@1: 100.0000 (99.2698)  Acc@5: 100.0000 (99.9808)\n",
            "Test: [1350/2354]  Time: 0.088 (0.146)  Loss:  0.1036 (0.1456)  Acc@1: 100.0000 (99.2783)  Acc@5: 100.0000 (99.9815)\n",
            "Test: [1400/2354]  Time: 0.153 (0.146)  Loss:  0.2153 (0.1456)  Acc@1: 100.0000 (99.2862)  Acc@5: 100.0000 (99.9822)\n",
            "Test: [1450/2354]  Time: 0.112 (0.145)  Loss:  0.1313 (0.1464)  Acc@1: 100.0000 (99.2936)  Acc@5: 100.0000 (99.9828)\n",
            "Test: [1500/2354]  Time: 0.203 (0.145)  Loss:  0.1438 (0.1458)  Acc@1: 100.0000 (99.3171)  Acc@5: 100.0000 (99.9833)\n",
            "Test: [1550/2354]  Time: 0.171 (0.145)  Loss:  0.0887 (0.1508)  Acc@1: 100.0000 (99.1618)  Acc@5: 100.0000 (99.9839)\n",
            "Test: [1600/2354]  Time: 0.095 (0.145)  Loss:  0.1512 (0.1533)  Acc@1: 100.0000 (99.1412)  Acc@5: 100.0000 (99.9844)\n",
            "Test: [1650/2354]  Time: 0.173 (0.145)  Loss:  0.1000 (0.1552)  Acc@1: 100.0000 (99.1369)  Acc@5: 100.0000 (99.9697)\n",
            "Test: [1700/2354]  Time: 0.087 (0.145)  Loss:  0.0737 (0.1552)  Acc@1: 100.0000 (99.1476)  Acc@5: 100.0000 (99.9706)\n",
            "Test: [1750/2354]  Time: 0.096 (0.145)  Loss:  0.0831 (0.1546)  Acc@1: 100.0000 (99.1719)  Acc@5: 100.0000 (99.9714)\n",
            "Test: [1800/2354]  Time: 0.187 (0.145)  Loss:  0.2539 (0.1535)  Acc@1: 100.0000 (99.1810)  Acc@5: 100.0000 (99.9722)\n",
            "Test: [1850/2354]  Time: 0.184 (0.145)  Loss:  0.1169 (0.1528)  Acc@1: 100.0000 (99.1626)  Acc@5: 100.0000 (99.9730)\n",
            "Test: [1900/2354]  Time: 0.132 (0.145)  Loss:  0.1855 (0.1513)  Acc@1: 100.0000 (99.1846)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1950/2354]  Time: 0.112 (0.145)  Loss:  0.0713 (0.1502)  Acc@1: 100.0000 (99.1927)  Acc@5: 100.0000 (99.9744)\n",
            "Test: [2000/2354]  Time: 0.081 (0.145)  Loss:  0.1378 (0.1500)  Acc@1: 100.0000 (99.1879)  Acc@5: 100.0000 (99.9750)\n",
            "Test: [2050/2354]  Time: 0.182 (0.145)  Loss:  0.3127 (0.1522)  Acc@1: 100.0000 (99.1224)  Acc@5: 100.0000 (99.9634)\n",
            "Test: [2100/2354]  Time: 0.083 (0.145)  Loss:  0.0944 (0.1540)  Acc@1: 100.0000 (99.0600)  Acc@5: 100.0000 (99.9643)\n",
            "Test: [2150/2354]  Time: 0.207 (0.145)  Loss:  0.3049 (0.1552)  Acc@1: 100.0000 (99.0237)  Acc@5: 100.0000 (99.9651)\n",
            "Test: [2200/2354]  Time: 0.177 (0.145)  Loss:  0.4055 (0.1592)  Acc@1: 100.0000 (98.9096)  Acc@5: 100.0000 (99.9659)\n",
            "Test: [2250/2354]  Time: 0.121 (0.145)  Loss:  0.0701 (0.1589)  Acc@1: 100.0000 (98.9116)  Acc@5: 100.0000 (99.9667)\n",
            "Test: [2300/2354]  Time: 0.162 (0.145)  Loss:  0.1259 (0.1583)  Acc@1: 100.0000 (98.9244)  Acc@5: 100.0000 (99.9674)\n",
            "Test: [2350/2354]  Time: 0.076 (0.145)  Loss:  0.0712 (0.1582)  Acc@1: 100.0000 (98.9260)  Acc@5: 100.0000 (99.9681)\n",
            "Test: [2354/2354]  Time: 0.064 (0.145)  Loss:  0.0398 (0.1581)  Acc@1: 100.0000 (98.9277)  Acc@5: 100.0000 (99.9681)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-35.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar', 97.66429557277843)\n",
            "\n",
            "Train: 46 [   0/2354 (  0%)]  Loss: 1.247 (1.25)  Time: 1.322s,    6.05/s  (1.322s,    6.05/s)  LR: 3.894e-05  Data: 0.561 (0.561)\n",
            "Train: 46 [  50/2354 (  2%)]  Loss: 1.911 (1.50)  Time: 0.466s,   17.15/s  (0.507s,   15.78/s)  LR: 3.894e-05  Data: 0.007 (0.019)\n",
            "Train: 46 [ 100/2354 (  4%)]  Loss: 2.121 (1.55)  Time: 0.472s,   16.96/s  (0.488s,   16.38/s)  LR: 3.894e-05  Data: 0.007 (0.014)\n",
            "Train: 46 [ 150/2354 (  6%)]  Loss: 1.028 (1.53)  Time: 0.465s,   17.21/s  (0.489s,   16.36/s)  LR: 3.894e-05  Data: 0.007 (0.012)\n",
            "Train: 46 [ 200/2354 (  8%)]  Loss: 1.429 (1.53)  Time: 0.469s,   17.04/s  (0.484s,   16.52/s)  LR: 3.894e-05  Data: 0.009 (0.011)\n",
            "Train: 46 [ 250/2354 ( 11%)]  Loss: 1.890 (1.52)  Time: 0.470s,   17.02/s  (0.481s,   16.63/s)  LR: 3.894e-05  Data: 0.010 (0.010)\n",
            "Train: 46 [ 300/2354 ( 13%)]  Loss: 1.186 (1.50)  Time: 0.477s,   16.76/s  (0.479s,   16.70/s)  LR: 3.894e-05  Data: 0.007 (0.010)\n",
            "Train: 46 [ 350/2354 ( 15%)]  Loss: 0.9837 (1.54)  Time: 0.464s,   17.24/s  (0.477s,   16.75/s)  LR: 3.894e-05  Data: 0.007 (0.010)\n",
            "Train: 46 [ 400/2354 ( 17%)]  Loss: 2.026 (1.52)  Time: 0.469s,   17.06/s  (0.476s,   16.79/s)  LR: 3.894e-05  Data: 0.007 (0.009)\n",
            "Train: 46 [ 450/2354 ( 19%)]  Loss: 1.077 (1.51)  Time: 0.466s,   17.16/s  (0.478s,   16.75/s)  LR: 3.894e-05  Data: 0.010 (0.009)\n",
            "Train: 46 [ 500/2354 ( 21%)]  Loss: 1.485 (1.52)  Time: 0.478s,   16.75/s  (0.477s,   16.78/s)  LR: 3.894e-05  Data: 0.010 (0.009)\n",
            "Train: 46 [ 550/2354 ( 23%)]  Loss: 1.743 (1.53)  Time: 0.462s,   17.32/s  (0.476s,   16.81/s)  LR: 3.894e-05  Data: 0.007 (0.009)\n",
            "Train: 46 [ 600/2354 ( 25%)]  Loss: 1.545 (1.52)  Time: 0.460s,   17.40/s  (0.475s,   16.83/s)  LR: 3.894e-05  Data: 0.007 (0.009)\n",
            "Train: 46 [ 650/2354 ( 28%)]  Loss: 1.423 (1.51)  Time: 0.470s,   17.02/s  (0.475s,   16.85/s)  LR: 3.894e-05  Data: 0.007 (0.009)\n",
            "Train: 46 [ 700/2354 ( 30%)]  Loss: 1.763 (1.51)  Time: 0.466s,   17.16/s  (0.476s,   16.82/s)  LR: 3.894e-05  Data: 0.009 (0.009)\n",
            "Train: 46 [ 750/2354 ( 32%)]  Loss: 1.554 (1.51)  Time: 0.465s,   17.19/s  (0.475s,   16.84/s)  LR: 3.894e-05  Data: 0.009 (0.009)\n",
            "Train: 46 [ 800/2354 ( 34%)]  Loss: 1.036 (1.51)  Time: 0.464s,   17.25/s  (0.475s,   16.86/s)  LR: 3.894e-05  Data: 0.008 (0.009)\n",
            "Train: 46 [ 850/2354 ( 36%)]  Loss: 1.222 (1.51)  Time: 0.473s,   16.92/s  (0.474s,   16.88/s)  LR: 3.894e-05  Data: 0.007 (0.009)\n",
            "Train: 46 [ 900/2354 ( 38%)]  Loss: 1.990 (1.52)  Time: 0.465s,   17.21/s  (0.474s,   16.89/s)  LR: 3.894e-05  Data: 0.009 (0.009)\n",
            "Train: 46 [ 950/2354 ( 40%)]  Loss: 1.139 (1.52)  Time: 0.466s,   17.16/s  (0.474s,   16.87/s)  LR: 3.894e-05  Data: 0.010 (0.009)\n",
            "Train: 46 [1000/2354 ( 42%)]  Loss: 2.050 (1.52)  Time: 0.480s,   16.67/s  (0.474s,   16.88/s)  LR: 3.894e-05  Data: 0.007 (0.009)\n",
            "Train: 46 [1050/2354 ( 45%)]  Loss: 1.366 (1.52)  Time: 0.465s,   17.20/s  (0.474s,   16.89/s)  LR: 3.894e-05  Data: 0.007 (0.009)\n",
            "Train: 46 [1100/2354 ( 47%)]  Loss: 1.048 (1.52)  Time: 0.477s,   16.77/s  (0.473s,   16.90/s)  LR: 3.894e-05  Data: 0.009 (0.008)\n",
            "Train: 46 [1150/2354 ( 49%)]  Loss: 1.370 (1.52)  Time: 0.470s,   17.01/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1200/2354 ( 51%)]  Loss: 1.276 (1.52)  Time: 0.463s,   17.27/s  (0.474s,   16.88/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1250/2354 ( 53%)]  Loss: 1.002 (1.52)  Time: 0.467s,   17.12/s  (0.474s,   16.89/s)  LR: 3.894e-05  Data: 0.008 (0.008)\n",
            "Train: 46 [1300/2354 ( 55%)]  Loss: 1.956 (1.52)  Time: 0.463s,   17.27/s  (0.473s,   16.90/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1350/2354 ( 57%)]  Loss: 1.950 (1.52)  Time: 0.473s,   16.93/s  (0.473s,   16.90/s)  LR: 3.894e-05  Data: 0.011 (0.008)\n",
            "Train: 46 [1400/2354 ( 59%)]  Loss: 1.787 (1.52)  Time: 0.469s,   17.07/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1450/2354 ( 62%)]  Loss: 0.9727 (1.52)  Time: 0.463s,   17.29/s  (0.474s,   16.89/s)  LR: 3.894e-05  Data: 0.008 (0.008)\n",
            "Train: 46 [1500/2354 ( 64%)]  Loss: 1.544 (1.51)  Time: 0.469s,   17.05/s  (0.473s,   16.90/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1550/2354 ( 66%)]  Loss: 0.9728 (1.52)  Time: 0.464s,   17.24/s  (0.473s,   16.90/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1600/2354 ( 68%)]  Loss: 1.042 (1.52)  Time: 0.464s,   17.24/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1650/2354 ( 70%)]  Loss: 1.011 (1.51)  Time: 0.462s,   17.33/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1700/2354 ( 72%)]  Loss: 0.9968 (1.51)  Time: 0.670s,   11.94/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.021 (0.008)\n",
            "Train: 46 [1750/2354 ( 74%)]  Loss: 1.018 (1.51)  Time: 0.465s,   17.21/s  (0.473s,   16.90/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1800/2354 ( 76%)]  Loss: 1.086 (1.51)  Time: 0.463s,   17.26/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1850/2354 ( 79%)]  Loss: 1.154 (1.51)  Time: 0.466s,   17.15/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.009 (0.008)\n",
            "Train: 46 [1900/2354 ( 81%)]  Loss: 1.461 (1.52)  Time: 0.467s,   17.14/s  (0.473s,   16.92/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [1950/2354 ( 83%)]  Loss: 0.9940 (1.52)  Time: 0.472s,   16.95/s  (0.473s,   16.92/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [2000/2354 ( 85%)]  Loss: 2.600 (1.52)  Time: 0.465s,   17.20/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.010 (0.008)\n",
            "Train: 46 [2050/2354 ( 87%)]  Loss: 1.038 (1.52)  Time: 0.472s,   16.95/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.009 (0.008)\n",
            "Train: 46 [2100/2354 ( 89%)]  Loss: 1.330 (1.52)  Time: 0.465s,   17.20/s  (0.473s,   16.92/s)  LR: 3.894e-05  Data: 0.009 (0.008)\n",
            "Train: 46 [2150/2354 ( 91%)]  Loss: 1.580 (1.52)  Time: 0.474s,   16.86/s  (0.473s,   16.92/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [2200/2354 ( 93%)]  Loss: 2.287 (1.52)  Time: 0.466s,   17.15/s  (0.473s,   16.92/s)  LR: 3.894e-05  Data: 0.009 (0.008)\n",
            "Train: 46 [2250/2354 ( 96%)]  Loss: 1.318 (1.52)  Time: 0.465s,   17.20/s  (0.473s,   16.91/s)  LR: 3.894e-05  Data: 0.007 (0.008)\n",
            "Train: 46 [2300/2354 ( 98%)]  Loss: 2.250 (1.52)  Time: 0.469s,   17.07/s  (0.473s,   16.92/s)  LR: 3.894e-05  Data: 0.010 (0.008)\n",
            "Train: 46 [2350/2354 (100%)]  Loss: 1.046 (1.52)  Time: 0.456s,   17.55/s  (0.473s,   16.92/s)  LR: 3.894e-05  Data: 0.005 (0.008)\n",
            "Train: 46 [2353/2354 (100%)]  Loss: 1.731 (1.52)  Time: 0.456s,   17.54/s  (0.473s,   16.92/s)  LR: 3.894e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.648 (0.648)  Loss:  0.2285 (0.2285)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.109 (0.163)  Loss:  0.0398 (0.1345)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.101 (0.151)  Loss:  0.0442 (0.1290)  Acc@1: 100.0000 (99.5050)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.085 (0.149)  Loss:  0.1538 (0.1663)  Acc@1: 100.0000 (99.1722)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.076 (0.147)  Loss:  0.1228 (0.1741)  Acc@1: 100.0000 (99.1294)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.174 (0.147)  Loss:  0.0717 (0.1617)  Acc@1: 100.0000 (99.3028)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.125 (0.146)  Loss:  0.1855 (0.1579)  Acc@1: 100.0000 (99.4186)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.128 (0.145)  Loss:  0.0772 (0.1658)  Acc@1: 100.0000 (99.3590)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.128 (0.151)  Loss:  0.0815 (0.1646)  Acc@1: 100.0000 (99.3142)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.086 (0.150)  Loss:  0.0984 (0.1617)  Acc@1: 100.0000 (99.3348)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.100 (0.149)  Loss:  0.2859 (0.1625)  Acc@1: 100.0000 (99.2016)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.160 (0.149)  Loss:  0.0883 (0.1622)  Acc@1: 100.0000 (99.1379)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.142 (0.148)  Loss:  0.1259 (0.1582)  Acc@1: 100.0000 (99.2097)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.131 (0.148)  Loss:  0.0849 (0.1560)  Acc@1: 100.0000 (99.2704)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.183 (0.147)  Loss:  0.1190 (0.1556)  Acc@1: 100.0000 (99.3224)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.077 (0.147)  Loss:  0.1426 (0.1555)  Acc@1: 100.0000 (99.3342)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.223 (0.147)  Loss:  0.1257 (0.1574)  Acc@1: 100.0000 (99.2509)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.124 (0.147)  Loss:  0.1550 (0.1558)  Acc@1: 100.0000 (99.2656)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.190 (0.147)  Loss:  0.2053 (0.1545)  Acc@1: 100.0000 (99.3063)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.130 (0.147)  Loss:  0.2250 (0.1547)  Acc@1: 100.0000 (99.3428)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.098 (0.147)  Loss:  0.0719 (0.1540)  Acc@1: 100.0000 (99.3257)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.112 (0.146)  Loss:  0.1772 (0.1553)  Acc@1: 100.0000 (99.3340)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.132 (0.146)  Loss:  0.1246 (0.1541)  Acc@1: 100.0000 (99.3642)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.089 (0.146)  Loss:  0.5654 (0.1543)  Acc@1: 100.0000 (99.3701)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.215 (0.148)  Loss:  0.5352 (0.1564)  Acc@1: 100.0000 (99.3339)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.208 (0.148)  Loss:  0.0793 (0.1546)  Acc@1: 100.0000 (99.3405)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.153 (0.147)  Loss:  0.0461 (0.1541)  Acc@1: 100.0000 (99.3274)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.133 (0.147)  Loss:  0.0637 (0.1533)  Acc@1: 100.0000 (99.3338)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.198 (0.147)  Loss:  0.1426 (0.1527)  Acc@1: 100.0000 (99.3576)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.135 (0.147)  Loss:  0.0984 (0.1538)  Acc@1: 100.0000 (99.3797)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.123 (0.147)  Loss:  0.1400 (0.1523)  Acc@1: 100.0000 (99.4004)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.134 (0.147)  Loss:  0.1824 (0.1545)  Acc@1: 100.0000 (99.3875)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.184 (0.147)  Loss:  0.0662 (0.1563)  Acc@1: 100.0000 (99.3442)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.182 (0.147)  Loss:  0.0675 (0.1569)  Acc@1: 100.0000 (99.3337)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.190 (0.147)  Loss:  0.1207 (0.1563)  Acc@1: 100.0000 (99.3386)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.112 (0.147)  Loss:  0.1619 (0.1566)  Acc@1: 100.0000 (99.3290)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.088 (0.147)  Loss:  0.3762 (0.1581)  Acc@1: 100.0000 (99.3476)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1850/2354]  Time: 0.140 (0.146)  Loss:  0.1049 (0.1581)  Acc@1: 100.0000 (99.3382)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1900/2354]  Time: 0.143 (0.146)  Loss:  0.0611 (0.1569)  Acc@1: 100.0000 (99.3556)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1950/2354]  Time: 0.149 (0.146)  Loss:  0.1340 (0.1581)  Acc@1: 100.0000 (99.3465)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2000/2354]  Time: 0.094 (0.146)  Loss:  0.1068 (0.1573)  Acc@1: 100.0000 (99.3503)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2050/2354]  Time: 0.119 (0.147)  Loss:  0.2094 (0.1595)  Acc@1: 100.0000 (99.2808)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2100/2354]  Time: 0.155 (0.147)  Loss:  0.2318 (0.1639)  Acc@1: 100.0000 (99.1552)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2150/2354]  Time: 0.124 (0.147)  Loss:  0.1276 (0.1646)  Acc@1: 100.0000 (99.1516)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2200/2354]  Time: 0.156 (0.147)  Loss:  0.2350 (0.1639)  Acc@1: 100.0000 (99.1481)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2250/2354]  Time: 0.092 (0.147)  Loss:  0.1031 (0.1629)  Acc@1: 100.0000 (99.1559)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2300/2354]  Time: 0.084 (0.146)  Loss:  0.0630 (0.1630)  Acc@1: 100.0000 (99.1634)  Acc@5: 100.0000 (99.9891)\n",
            "Test: [2350/2354]  Time: 0.076 (0.146)  Loss:  0.0543 (0.1632)  Acc@1: 100.0000 (99.1599)  Acc@5: 100.0000 (99.9894)\n",
            "Test: [2354/2354]  Time: 0.081 (0.146)  Loss:  0.0651 (0.1630)  Acc@1: 100.0000 (99.1613)  Acc@5: 100.0000 (99.9894)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-36.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar', 97.82354814736172)\n",
            "\n",
            "Train: 47 [   0/2354 (  0%)]  Loss: 1.166 (1.17)  Time: 1.259s,    6.36/s  (1.259s,    6.36/s)  LR: 3.706e-05  Data: 0.455 (0.455)\n",
            "Train: 47 [  50/2354 (  2%)]  Loss: 1.247 (1.38)  Time: 0.466s,   17.17/s  (0.507s,   15.78/s)  LR: 3.706e-05  Data: 0.007 (0.017)\n",
            "Train: 47 [ 100/2354 (  4%)]  Loss: 1.352 (1.44)  Time: 0.464s,   17.23/s  (0.489s,   16.37/s)  LR: 3.706e-05  Data: 0.007 (0.012)\n",
            "Train: 47 [ 150/2354 (  6%)]  Loss: 1.915 (1.42)  Time: 0.464s,   17.23/s  (0.488s,   16.39/s)  LR: 3.706e-05  Data: 0.007 (0.011)\n",
            "Train: 47 [ 200/2354 (  8%)]  Loss: 1.088 (1.48)  Time: 0.476s,   16.79/s  (0.483s,   16.56/s)  LR: 3.706e-05  Data: 0.009 (0.010)\n",
            "Train: 47 [ 250/2354 ( 11%)]  Loss: 1.540 (1.47)  Time: 0.467s,   17.14/s  (0.480s,   16.67/s)  LR: 3.706e-05  Data: 0.010 (0.010)\n",
            "Train: 47 [ 300/2354 ( 13%)]  Loss: 1.383 (1.47)  Time: 0.466s,   17.18/s  (0.478s,   16.74/s)  LR: 3.706e-05  Data: 0.009 (0.009)\n",
            "Train: 47 [ 350/2354 ( 15%)]  Loss: 1.432 (1.47)  Time: 0.475s,   16.84/s  (0.476s,   16.79/s)  LR: 3.706e-05  Data: 0.008 (0.009)\n",
            "Train: 47 [ 400/2354 ( 17%)]  Loss: 1.627 (1.48)  Time: 0.585s,   13.67/s  (0.477s,   16.78/s)  LR: 3.706e-05  Data: 0.007 (0.009)\n",
            "Train: 47 [ 450/2354 ( 19%)]  Loss: 1.441 (1.48)  Time: 0.463s,   17.27/s  (0.476s,   16.79/s)  LR: 3.706e-05  Data: 0.007 (0.009)\n",
            "Train: 47 [ 500/2354 ( 21%)]  Loss: 1.087 (1.48)  Time: 0.474s,   16.88/s  (0.476s,   16.82/s)  LR: 3.706e-05  Data: 0.009 (0.009)\n",
            "Train: 47 [ 550/2354 ( 23%)]  Loss: 2.479 (1.48)  Time: 0.470s,   17.03/s  (0.475s,   16.85/s)  LR: 3.706e-05  Data: 0.008 (0.009)\n",
            "Train: 47 [ 600/2354 ( 25%)]  Loss: 3.050 (1.48)  Time: 0.465s,   17.22/s  (0.474s,   16.87/s)  LR: 3.706e-05  Data: 0.007 (0.009)\n",
            "Train: 47 [ 650/2354 ( 28%)]  Loss: 1.054 (1.49)  Time: 0.477s,   16.78/s  (0.474s,   16.89/s)  LR: 3.706e-05  Data: 0.010 (0.009)\n",
            "Train: 47 [ 700/2354 ( 30%)]  Loss: 0.9793 (1.49)  Time: 0.467s,   17.12/s  (0.475s,   16.84/s)  LR: 3.706e-05  Data: 0.011 (0.009)\n",
            "Train: 47 [ 750/2354 ( 32%)]  Loss: 2.143 (1.49)  Time: 0.469s,   17.05/s  (0.475s,   16.86/s)  LR: 3.706e-05  Data: 0.007 (0.009)\n",
            "Train: 47 [ 800/2354 ( 34%)]  Loss: 1.287 (1.48)  Time: 0.464s,   17.23/s  (0.474s,   16.87/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [ 850/2354 ( 36%)]  Loss: 2.454 (1.47)  Time: 0.463s,   17.27/s  (0.474s,   16.88/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [ 900/2354 ( 38%)]  Loss: 2.049 (1.47)  Time: 0.472s,   16.95/s  (0.474s,   16.89/s)  LR: 3.706e-05  Data: 0.009 (0.008)\n",
            "Train: 47 [ 950/2354 ( 40%)]  Loss: 1.853 (1.47)  Time: 0.465s,   17.20/s  (0.474s,   16.87/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1000/2354 ( 42%)]  Loss: 1.102 (1.47)  Time: 0.469s,   17.07/s  (0.474s,   16.88/s)  LR: 3.706e-05  Data: 0.010 (0.008)\n",
            "Train: 47 [1050/2354 ( 45%)]  Loss: 1.034 (1.47)  Time: 0.469s,   17.07/s  (0.474s,   16.89/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1100/2354 ( 47%)]  Loss: 1.123 (1.47)  Time: 0.468s,   17.11/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1150/2354 ( 49%)]  Loss: 1.143 (1.47)  Time: 0.462s,   17.31/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1200/2354 ( 51%)]  Loss: 1.143 (1.46)  Time: 0.463s,   17.30/s  (0.474s,   16.88/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1250/2354 ( 53%)]  Loss: 2.338 (1.47)  Time: 0.474s,   16.89/s  (0.474s,   16.89/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1300/2354 ( 55%)]  Loss: 1.496 (1.46)  Time: 0.477s,   16.77/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.009 (0.008)\n",
            "Train: 47 [1350/2354 ( 57%)]  Loss: 1.666 (1.47)  Time: 0.470s,   17.04/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.009 (0.008)\n",
            "Train: 47 [1400/2354 ( 59%)]  Loss: 1.455 (1.47)  Time: 0.463s,   17.29/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1450/2354 ( 62%)]  Loss: 1.597 (1.47)  Time: 0.468s,   17.10/s  (0.474s,   16.89/s)  LR: 3.706e-05  Data: 0.008 (0.008)\n",
            "Train: 47 [1500/2354 ( 64%)]  Loss: 1.604 (1.47)  Time: 0.471s,   16.98/s  (0.474s,   16.90/s)  LR: 3.706e-05  Data: 0.006 (0.008)\n",
            "Train: 47 [1550/2354 ( 66%)]  Loss: 0.9899 (1.47)  Time: 0.463s,   17.29/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1600/2354 ( 68%)]  Loss: 1.179 (1.47)  Time: 0.467s,   17.13/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1650/2354 ( 70%)]  Loss: 1.330 (1.47)  Time: 0.483s,   16.58/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.006 (0.008)\n",
            "Train: 47 [1700/2354 ( 72%)]  Loss: 1.768 (1.47)  Time: 0.465s,   17.21/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1750/2354 ( 74%)]  Loss: 0.9515 (1.46)  Time: 0.466s,   17.17/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.009 (0.008)\n",
            "Train: 47 [1800/2354 ( 76%)]  Loss: 1.116 (1.46)  Time: 0.475s,   16.83/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.010 (0.008)\n",
            "Train: 47 [1850/2354 ( 79%)]  Loss: 1.085 (1.46)  Time: 0.471s,   16.97/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.008 (0.008)\n",
            "Train: 47 [1900/2354 ( 81%)]  Loss: 0.9530 (1.46)  Time: 0.463s,   17.27/s  (0.473s,   16.92/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [1950/2354 ( 83%)]  Loss: 1.313 (1.47)  Time: 0.471s,   17.00/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.010 (0.008)\n",
            "Train: 47 [2000/2354 ( 85%)]  Loss: 1.492 (1.46)  Time: 0.466s,   17.18/s  (0.473s,   16.90/s)  LR: 3.706e-05  Data: 0.009 (0.008)\n",
            "Train: 47 [2050/2354 ( 87%)]  Loss: 1.046 (1.47)  Time: 0.465s,   17.20/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.010 (0.008)\n",
            "Train: 47 [2100/2354 ( 89%)]  Loss: 2.242 (1.47)  Time: 0.472s,   16.94/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [2150/2354 ( 91%)]  Loss: 1.006 (1.47)  Time: 0.472s,   16.96/s  (0.473s,   16.92/s)  LR: 3.706e-05  Data: 0.008 (0.008)\n",
            "Train: 47 [2200/2354 ( 93%)]  Loss: 1.009 (1.47)  Time: 0.463s,   17.27/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.008 (0.008)\n",
            "Train: 47 [2250/2354 ( 96%)]  Loss: 1.650 (1.47)  Time: 0.463s,   17.26/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.007 (0.008)\n",
            "Train: 47 [2300/2354 ( 98%)]  Loss: 2.054 (1.47)  Time: 0.468s,   17.09/s  (0.473s,   16.91/s)  LR: 3.706e-05  Data: 0.008 (0.008)\n",
            "Train: 47 [2350/2354 (100%)]  Loss: 1.228 (1.47)  Time: 0.459s,   17.44/s  (0.473s,   16.92/s)  LR: 3.706e-05  Data: 0.005 (0.008)\n",
            "Train: 47 [2353/2354 (100%)]  Loss: 1.295 (1.47)  Time: 0.454s,   17.63/s  (0.473s,   16.92/s)  LR: 3.706e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.695 (0.695)  Loss:  0.1716 (0.1716)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.099 (0.153)  Loss:  0.1006 (0.1336)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.168 (0.146)  Loss:  0.0686 (0.1292)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.088 (0.144)  Loss:  0.0793 (0.1563)  Acc@1: 100.0000 (98.3444)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.113 (0.144)  Loss:  0.4629 (0.1572)  Acc@1: 100.0000 (98.7562)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.102 (0.151)  Loss:  0.0732 (0.1471)  Acc@1: 100.0000 (99.0040)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.132 (0.149)  Loss:  0.3696 (0.1491)  Acc@1: 100.0000 (98.9203)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.210 (0.148)  Loss:  0.1097 (0.1643)  Acc@1: 100.0000 (98.8604)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.178 (0.147)  Loss:  0.0731 (0.1658)  Acc@1: 100.0000 (98.9401)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.091 (0.147)  Loss:  0.0894 (0.1604)  Acc@1: 100.0000 (98.9468)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.137 (0.146)  Loss:  0.0518 (0.1563)  Acc@1: 100.0000 (99.0020)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.158 (0.146)  Loss:  0.0489 (0.1521)  Acc@1: 100.0000 (99.0926)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.123 (0.145)  Loss:  0.2773 (0.1479)  Acc@1: 100.0000 (99.1681)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.173 (0.145)  Loss:  0.1236 (0.1453)  Acc@1: 100.0000 (99.2320)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.144 (0.145)  Loss:  0.0646 (0.1424)  Acc@1: 100.0000 (99.2511)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.127 (0.145)  Loss:  0.1017 (0.1420)  Acc@1: 100.0000 (99.3009)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.138 (0.145)  Loss:  0.1373 (0.1429)  Acc@1: 100.0000 (99.3134)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.164 (0.145)  Loss:  0.1125 (0.1422)  Acc@1: 100.0000 (99.3243)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.088 (0.145)  Loss:  0.2544 (0.1422)  Acc@1: 100.0000 (99.3618)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.079 (0.144)  Loss:  0.1750 (0.1417)  Acc@1: 100.0000 (99.3691)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.220 (0.144)  Loss:  0.0671 (0.1417)  Acc@1: 100.0000 (99.4006)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.177 (0.146)  Loss:  0.0951 (0.1415)  Acc@1: 100.0000 (99.4291)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.133 (0.146)  Loss:  0.0770 (0.1418)  Acc@1: 100.0000 (99.4550)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.080 (0.146)  Loss:  0.7100 (0.1460)  Acc@1: 100.0000 (99.4136)  Acc@5: 100.0000 (99.9566)\n",
            "Test: [1200/2354]  Time: 0.141 (0.145)  Loss:  0.3232 (0.1480)  Acc@1: 100.0000 (99.3963)  Acc@5: 100.0000 (99.9376)\n",
            "Test: [1250/2354]  Time: 0.186 (0.145)  Loss:  0.1564 (0.1458)  Acc@1: 100.0000 (99.4205)  Acc@5: 100.0000 (99.9400)\n",
            "Test: [1300/2354]  Time: 0.149 (0.145)  Loss:  0.0881 (0.1470)  Acc@1: 100.0000 (99.3851)  Acc@5: 100.0000 (99.9424)\n",
            "Test: [1350/2354]  Time: 0.080 (0.145)  Loss:  0.1185 (0.1482)  Acc@1: 100.0000 (99.3708)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [1400/2354]  Time: 0.114 (0.145)  Loss:  0.1130 (0.1487)  Acc@1: 100.0000 (99.3754)  Acc@5: 100.0000 (99.9465)\n",
            "Test: [1450/2354]  Time: 0.181 (0.145)  Loss:  0.0720 (0.1474)  Acc@1: 100.0000 (99.3970)  Acc@5: 100.0000 (99.9483)\n",
            "Test: [1500/2354]  Time: 0.150 (0.145)  Loss:  0.2457 (0.1471)  Acc@1: 100.0000 (99.4171)  Acc@5: 100.0000 (99.9500)\n",
            "Test: [1550/2354]  Time: 0.205 (0.145)  Loss:  0.1250 (0.1508)  Acc@1: 100.0000 (99.3553)  Acc@5: 100.0000 (99.9516)\n",
            "Test: [1600/2354]  Time: 0.171 (0.144)  Loss:  0.0403 (0.1513)  Acc@1: 100.0000 (99.2817)  Acc@5: 100.0000 (99.9532)\n",
            "Test: [1650/2354]  Time: 0.152 (0.144)  Loss:  0.1137 (0.1512)  Acc@1: 100.0000 (99.2732)  Acc@5: 100.0000 (99.9394)\n",
            "Test: [1700/2354]  Time: 0.147 (0.144)  Loss:  0.0666 (0.1504)  Acc@1: 100.0000 (99.2945)  Acc@5: 100.0000 (99.9412)\n",
            "Test: [1750/2354]  Time: 0.101 (0.144)  Loss:  0.0967 (0.1520)  Acc@1: 100.0000 (99.2576)  Acc@5: 100.0000 (99.9429)\n",
            "Test: [1800/2354]  Time: 0.170 (0.144)  Loss:  0.2561 (0.1519)  Acc@1: 100.0000 (99.2782)  Acc@5: 100.0000 (99.9445)\n",
            "Test: [1850/2354]  Time: 0.286 (0.144)  Loss:  0.1154 (0.1509)  Acc@1: 100.0000 (99.2842)  Acc@5: 100.0000 (99.9460)\n",
            "Test: [1900/2354]  Time: 0.114 (0.145)  Loss:  0.2189 (0.1510)  Acc@1: 100.0000 (99.2898)  Acc@5: 100.0000 (99.9474)\n",
            "Test: [1950/2354]  Time: 0.135 (0.145)  Loss:  0.0942 (0.1509)  Acc@1: 100.0000 (99.2824)  Acc@5: 100.0000 (99.9487)\n",
            "Test: [2000/2354]  Time: 0.121 (0.145)  Loss:  0.0606 (0.1508)  Acc@1: 100.0000 (99.3003)  Acc@5: 100.0000 (99.9500)\n",
            "Test: [2050/2354]  Time: 0.079 (0.145)  Loss:  0.0994 (0.1530)  Acc@1: 100.0000 (99.2565)  Acc@5: 100.0000 (99.9512)\n",
            "Test: [2100/2354]  Time: 0.119 (0.145)  Loss:  0.1359 (0.1550)  Acc@1: 100.0000 (99.2266)  Acc@5: 100.0000 (99.9524)\n",
            "Test: [2150/2354]  Time: 0.103 (0.144)  Loss:  0.1088 (0.1544)  Acc@1: 100.0000 (99.2445)  Acc@5: 100.0000 (99.9535)\n",
            "Test: [2200/2354]  Time: 0.191 (0.144)  Loss:  0.0841 (0.1547)  Acc@1: 100.0000 (99.2163)  Acc@5: 100.0000 (99.9546)\n",
            "Test: [2250/2354]  Time: 0.118 (0.144)  Loss:  0.0740 (0.1548)  Acc@1: 100.0000 (99.2226)  Acc@5: 100.0000 (99.9556)\n",
            "Test: [2300/2354]  Time: 0.135 (0.144)  Loss:  0.0491 (0.1539)  Acc@1: 100.0000 (99.2286)  Acc@5: 100.0000 (99.9565)\n",
            "Test: [2350/2354]  Time: 0.075 (0.144)  Loss:  0.1475 (0.1530)  Acc@1: 100.0000 (99.2344)  Acc@5: 100.0000 (99.9575)\n",
            "Test: [2354/2354]  Time: 0.067 (0.144)  Loss:  0.0427 (0.1529)  Acc@1: 100.0000 (99.2356)  Acc@5: 100.0000 (99.9575)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-38.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar', 97.86601550058393)\n",
            "\n",
            "Train: 48 [   0/2354 (  0%)]  Loss: 1.178 (1.18)  Time: 1.227s,    6.52/s  (1.227s,    6.52/s)  LR: 3.520e-05  Data: 0.361 (0.361)\n",
            "Train: 48 [  50/2354 (  2%)]  Loss: 1.266 (1.43)  Time: 0.465s,   17.22/s  (0.505s,   15.85/s)  LR: 3.520e-05  Data: 0.007 (0.015)\n",
            "Train: 48 [ 100/2354 (  4%)]  Loss: 2.072 (1.53)  Time: 0.474s,   16.89/s  (0.494s,   16.19/s)  LR: 3.520e-05  Data: 0.007 (0.011)\n",
            "Train: 48 [ 150/2354 (  6%)]  Loss: 1.026 (1.49)  Time: 0.477s,   16.77/s  (0.485s,   16.48/s)  LR: 3.520e-05  Data: 0.010 (0.010)\n",
            "Train: 48 [ 200/2354 (  8%)]  Loss: 1.265 (1.48)  Time: 0.456s,   17.53/s  (0.481s,   16.64/s)  LR: 3.520e-05  Data: 0.007 (0.010)\n",
            "Train: 48 [ 250/2354 ( 11%)]  Loss: 1.033 (1.46)  Time: 0.468s,   17.09/s  (0.478s,   16.73/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 300/2354 ( 13%)]  Loss: 2.981 (1.46)  Time: 0.465s,   17.21/s  (0.476s,   16.81/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 350/2354 ( 15%)]  Loss: 1.034 (1.46)  Time: 0.466s,   17.18/s  (0.477s,   16.76/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 400/2354 ( 17%)]  Loss: 1.604 (1.47)  Time: 0.462s,   17.33/s  (0.476s,   16.81/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 450/2354 ( 19%)]  Loss: 2.133 (1.48)  Time: 0.470s,   17.01/s  (0.475s,   16.85/s)  LR: 3.520e-05  Data: 0.009 (0.009)\n",
            "Train: 48 [ 500/2354 ( 21%)]  Loss: 1.226 (1.47)  Time: 0.462s,   17.30/s  (0.474s,   16.88/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 550/2354 ( 23%)]  Loss: 1.388 (1.47)  Time: 0.468s,   17.08/s  (0.473s,   16.91/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 600/2354 ( 25%)]  Loss: 1.440 (1.47)  Time: 0.466s,   17.18/s  (0.474s,   16.87/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 650/2354 ( 28%)]  Loss: 2.080 (1.47)  Time: 0.464s,   17.22/s  (0.474s,   16.89/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 700/2354 ( 30%)]  Loss: 3.067 (1.47)  Time: 0.470s,   17.03/s  (0.473s,   16.91/s)  LR: 3.520e-05  Data: 0.009 (0.009)\n",
            "Train: 48 [ 750/2354 ( 32%)]  Loss: 0.9786 (1.47)  Time: 0.463s,   17.27/s  (0.473s,   16.92/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 800/2354 ( 34%)]  Loss: 1.111 (1.48)  Time: 0.464s,   17.24/s  (0.472s,   16.93/s)  LR: 3.520e-05  Data: 0.007 (0.009)\n",
            "Train: 48 [ 850/2354 ( 36%)]  Loss: 1.033 (1.47)  Time: 0.472s,   16.95/s  (0.473s,   16.91/s)  LR: 3.520e-05  Data: 0.008 (0.008)\n",
            "Train: 48 [ 900/2354 ( 38%)]  Loss: 3.152 (1.48)  Time: 0.459s,   17.42/s  (0.473s,   16.92/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [ 950/2354 ( 40%)]  Loss: 1.175 (1.47)  Time: 0.488s,   16.39/s  (0.472s,   16.94/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1000/2354 ( 42%)]  Loss: 0.9799 (1.48)  Time: 0.465s,   17.22/s  (0.472s,   16.95/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1050/2354 ( 45%)]  Loss: 1.072 (1.47)  Time: 0.469s,   17.06/s  (0.472s,   16.96/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1100/2354 ( 47%)]  Loss: 2.018 (1.48)  Time: 0.461s,   17.34/s  (0.472s,   16.94/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1150/2354 ( 49%)]  Loss: 1.016 (1.48)  Time: 0.474s,   16.88/s  (0.472s,   16.95/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1200/2354 ( 51%)]  Loss: 1.463 (1.47)  Time: 0.473s,   16.93/s  (0.472s,   16.96/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1250/2354 ( 53%)]  Loss: 2.086 (1.47)  Time: 0.462s,   17.30/s  (0.471s,   16.97/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1300/2354 ( 55%)]  Loss: 0.9871 (1.47)  Time: 0.464s,   17.25/s  (0.471s,   16.97/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1350/2354 ( 57%)]  Loss: 1.506 (1.47)  Time: 0.465s,   17.20/s  (0.472s,   16.96/s)  LR: 3.520e-05  Data: 0.008 (0.008)\n",
            "Train: 48 [1400/2354 ( 59%)]  Loss: 1.606 (1.47)  Time: 0.465s,   17.19/s  (0.472s,   16.96/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1450/2354 ( 62%)]  Loss: 1.666 (1.48)  Time: 0.461s,   17.35/s  (0.471s,   16.97/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1500/2354 ( 64%)]  Loss: 1.013 (1.48)  Time: 0.462s,   17.32/s  (0.471s,   16.98/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1550/2354 ( 66%)]  Loss: 1.136 (1.48)  Time: 0.464s,   17.25/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1600/2354 ( 68%)]  Loss: 0.9776 (1.48)  Time: 0.456s,   17.54/s  (0.471s,   16.97/s)  LR: 3.520e-05  Data: 0.006 (0.008)\n",
            "Train: 48 [1650/2354 ( 70%)]  Loss: 1.003 (1.48)  Time: 0.472s,   16.95/s  (0.471s,   16.98/s)  LR: 3.520e-05  Data: 0.006 (0.008)\n",
            "Train: 48 [1700/2354 ( 72%)]  Loss: 1.028 (1.48)  Time: 0.466s,   17.18/s  (0.471s,   16.98/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1750/2354 ( 74%)]  Loss: 2.446 (1.48)  Time: 0.474s,   16.87/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1800/2354 ( 76%)]  Loss: 1.458 (1.48)  Time: 0.462s,   17.31/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.006 (0.008)\n",
            "Train: 48 [1850/2354 ( 79%)]  Loss: 1.079 (1.49)  Time: 0.466s,   17.16/s  (0.471s,   16.98/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1900/2354 ( 81%)]  Loss: 1.024 (1.49)  Time: 0.464s,   17.23/s  (0.471s,   16.98/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [1950/2354 ( 83%)]  Loss: 1.198 (1.48)  Time: 0.459s,   17.42/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.010 (0.008)\n",
            "Train: 48 [2000/2354 ( 85%)]  Loss: 1.446 (1.48)  Time: 0.480s,   16.66/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [2050/2354 ( 87%)]  Loss: 1.033 (1.48)  Time: 0.463s,   17.27/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [2100/2354 ( 89%)]  Loss: 1.475 (1.48)  Time: 0.468s,   17.08/s  (0.471s,   16.98/s)  LR: 3.520e-05  Data: 0.009 (0.008)\n",
            "Train: 48 [2150/2354 ( 91%)]  Loss: 3.250 (1.48)  Time: 0.462s,   17.31/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.008 (0.008)\n",
            "Train: 48 [2200/2354 ( 93%)]  Loss: 1.064 (1.48)  Time: 0.464s,   17.23/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.008 (0.008)\n",
            "Train: 48 [2250/2354 ( 96%)]  Loss: 1.113 (1.48)  Time: 0.463s,   17.29/s  (0.471s,   17.00/s)  LR: 3.520e-05  Data: 0.007 (0.008)\n",
            "Train: 48 [2300/2354 ( 98%)]  Loss: 2.231 (1.49)  Time: 0.467s,   17.12/s  (0.471s,   17.00/s)  LR: 3.520e-05  Data: 0.008 (0.008)\n",
            "Train: 48 [2350/2354 (100%)]  Loss: 2.186 (1.48)  Time: 0.461s,   17.35/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.005 (0.008)\n",
            "Train: 48 [2353/2354 (100%)]  Loss: 1.160 (1.48)  Time: 0.451s,   17.73/s  (0.471s,   16.99/s)  LR: 3.520e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.643 (0.643)  Loss:  0.0614 (0.0614)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.080 (0.156)  Loss:  0.0612 (0.0938)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.167 (0.149)  Loss:  0.0593 (0.1029)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.116 (0.146)  Loss:  0.0454 (0.1116)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.132 (0.144)  Loss:  0.0895 (0.1133)  Acc@1: 100.0000 (99.8756)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.151 (0.143)  Loss:  0.1140 (0.1108)  Acc@1: 100.0000 (99.9004)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.179 (0.142)  Loss:  0.1154 (0.1187)  Acc@1: 100.0000 (99.8339)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.128 (0.142)  Loss:  0.1143 (0.1325)  Acc@1: 100.0000 (99.4302)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.132 (0.142)  Loss:  0.0767 (0.1327)  Acc@1: 100.0000 (99.4389)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.165 (0.141)  Loss:  0.0689 (0.1286)  Acc@1: 100.0000 (99.4457)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.127 (0.141)  Loss:  0.2136 (0.1274)  Acc@1: 100.0000 (99.5010)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.150 (0.141)  Loss:  0.0481 (0.1259)  Acc@1: 100.0000 (99.5009)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.120 (0.141)  Loss:  0.1106 (0.1237)  Acc@1: 100.0000 (99.5424)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.131 (0.141)  Loss:  0.1173 (0.1207)  Acc@1: 100.0000 (99.5776)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.180 (0.141)  Loss:  0.0551 (0.1178)  Acc@1: 100.0000 (99.5720)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.251 (0.141)  Loss:  0.0817 (0.1173)  Acc@1: 100.0000 (99.5672)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.163 (0.143)  Loss:  0.0873 (0.1189)  Acc@1: 100.0000 (99.5006)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.203 (0.143)  Loss:  0.1099 (0.1190)  Acc@1: 100.0000 (99.5006)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.093 (0.142)  Loss:  0.2532 (0.1177)  Acc@1: 100.0000 (99.5283)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.162 (0.142)  Loss:  0.1263 (0.1182)  Acc@1: 100.0000 (99.5531)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.176 (0.142)  Loss:  0.0697 (0.1169)  Acc@1: 100.0000 (99.5754)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.109 (0.142)  Loss:  0.2219 (0.1152)  Acc@1: 100.0000 (99.5956)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.167 (0.142)  Loss:  0.0851 (0.1158)  Acc@1: 100.0000 (99.6140)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.082 (0.142)  Loss:  0.6499 (0.1167)  Acc@1: 100.0000 (99.6308)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.178 (0.142)  Loss:  0.1115 (0.1172)  Acc@1: 100.0000 (99.6045)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.162 (0.142)  Loss:  0.1034 (0.1158)  Acc@1: 100.0000 (99.6203)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.152 (0.142)  Loss:  0.1785 (0.1163)  Acc@1: 100.0000 (99.5772)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.117 (0.142)  Loss:  0.0692 (0.1173)  Acc@1: 100.0000 (99.5559)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.116 (0.142)  Loss:  0.0902 (0.1180)  Acc@1: 100.0000 (99.5539)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.135 (0.142)  Loss:  0.0834 (0.1190)  Acc@1: 100.0000 (99.5520)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.077 (0.142)  Loss:  0.0747 (0.1174)  Acc@1: 100.0000 (99.5670)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.189 (0.142)  Loss:  0.0634 (0.1196)  Acc@1: 100.0000 (99.5164)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.168 (0.143)  Loss:  0.0739 (0.1206)  Acc@1: 100.0000 (99.4847)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.078 (0.143)  Loss:  0.0577 (0.1228)  Acc@1: 100.0000 (99.4246)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.111 (0.143)  Loss:  0.0625 (0.1229)  Acc@1: 100.0000 (99.4268)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.139 (0.143)  Loss:  0.1047 (0.1238)  Acc@1: 100.0000 (99.4289)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.176 (0.143)  Loss:  0.1606 (0.1229)  Acc@1: 100.0000 (99.4448)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1850/2354]  Time: 0.098 (0.142)  Loss:  0.1293 (0.1231)  Acc@1: 100.0000 (99.4462)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1900/2354]  Time: 0.134 (0.142)  Loss:  0.0461 (0.1230)  Acc@1: 100.0000 (99.4608)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1950/2354]  Time: 0.183 (0.142)  Loss:  0.1175 (0.1228)  Acc@1: 100.0000 (99.4618)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2000/2354]  Time: 0.151 (0.142)  Loss:  0.1187 (0.1223)  Acc@1: 100.0000 (99.4628)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2050/2354]  Time: 0.177 (0.142)  Loss:  0.0912 (0.1236)  Acc@1: 100.0000 (99.4393)  Acc@5: 100.0000 (99.9878)\n",
            "Test: [2100/2354]  Time: 0.118 (0.142)  Loss:  0.1331 (0.1257)  Acc@1: 100.0000 (99.4050)  Acc@5: 100.0000 (99.9881)\n",
            "Test: [2150/2354]  Time: 0.197 (0.142)  Loss:  0.1062 (0.1261)  Acc@1: 100.0000 (99.4189)  Acc@5: 100.0000 (99.9884)\n",
            "Test: [2200/2354]  Time: 0.123 (0.142)  Loss:  0.0567 (0.1272)  Acc@1: 100.0000 (99.4094)  Acc@5: 100.0000 (99.9886)\n",
            "Test: [2250/2354]  Time: 0.096 (0.142)  Loss:  0.0634 (0.1261)  Acc@1: 100.0000 (99.4225)  Acc@5: 100.0000 (99.9889)\n",
            "Test: [2300/2354]  Time: 0.184 (0.142)  Loss:  0.0812 (0.1255)  Acc@1: 100.0000 (99.4242)  Acc@5: 100.0000 (99.9891)\n",
            "Test: [2350/2354]  Time: 0.076 (0.142)  Loss:  0.1284 (0.1252)  Acc@1: 100.0000 (99.4364)  Acc@5: 100.0000 (99.9894)\n",
            "Test: [2354/2354]  Time: 0.065 (0.141)  Loss:  0.0432 (0.1252)  Acc@1: 100.0000 (99.4373)  Acc@5: 100.0000 (99.9894)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-37.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar', 98.12081961991719)\n",
            "\n",
            "Train: 49 [   0/2354 (  0%)]  Loss: 1.170 (1.17)  Time: 1.281s,    6.25/s  (1.281s,    6.25/s)  LR: 3.337e-05  Data: 0.569 (0.569)\n",
            "Train: 49 [  50/2354 (  2%)]  Loss: 1.049 (1.32)  Time: 0.485s,   16.50/s  (0.522s,   15.33/s)  LR: 3.337e-05  Data: 0.009 (0.020)\n",
            "Train: 49 [ 100/2354 (  4%)]  Loss: 1.509 (1.38)  Time: 0.466s,   17.16/s  (0.495s,   16.16/s)  LR: 3.337e-05  Data: 0.007 (0.014)\n",
            "Train: 49 [ 150/2354 (  6%)]  Loss: 2.308 (1.39)  Time: 0.464s,   17.24/s  (0.486s,   16.46/s)  LR: 3.337e-05  Data: 0.007 (0.012)\n",
            "Train: 49 [ 200/2354 (  8%)]  Loss: 0.9961 (1.37)  Time: 0.469s,   17.05/s  (0.482s,   16.61/s)  LR: 3.337e-05  Data: 0.007 (0.011)\n",
            "Train: 49 [ 250/2354 ( 11%)]  Loss: 1.022 (1.40)  Time: 0.485s,   16.49/s  (0.483s,   16.57/s)  LR: 3.337e-05  Data: 0.007 (0.010)\n",
            "Train: 49 [ 300/2354 ( 13%)]  Loss: 1.588 (1.38)  Time: 0.461s,   17.34/s  (0.480s,   16.65/s)  LR: 3.337e-05  Data: 0.007 (0.010)\n",
            "Train: 49 [ 350/2354 ( 15%)]  Loss: 1.648 (1.39)  Time: 0.470s,   17.02/s  (0.479s,   16.71/s)  LR: 3.337e-05  Data: 0.009 (0.010)\n",
            "Train: 49 [ 400/2354 ( 17%)]  Loss: 1.241 (1.41)  Time: 0.467s,   17.13/s  (0.477s,   16.76/s)  LR: 3.337e-05  Data: 0.009 (0.009)\n",
            "Train: 49 [ 450/2354 ( 19%)]  Loss: 1.976 (1.41)  Time: 0.476s,   16.80/s  (0.476s,   16.80/s)  LR: 3.337e-05  Data: 0.006 (0.009)\n",
            "Train: 49 [ 500/2354 ( 21%)]  Loss: 1.954 (1.41)  Time: 0.467s,   17.14/s  (0.477s,   16.77/s)  LR: 3.337e-05  Data: 0.009 (0.009)\n",
            "Train: 49 [ 550/2354 ( 23%)]  Loss: 1.901 (1.42)  Time: 0.463s,   17.27/s  (0.476s,   16.80/s)  LR: 3.337e-05  Data: 0.007 (0.009)\n",
            "Train: 49 [ 600/2354 ( 25%)]  Loss: 1.011 (1.42)  Time: 0.474s,   16.88/s  (0.476s,   16.82/s)  LR: 3.337e-05  Data: 0.007 (0.009)\n",
            "Train: 49 [ 650/2354 ( 28%)]  Loss: 2.303 (1.42)  Time: 0.463s,   17.29/s  (0.475s,   16.84/s)  LR: 3.337e-05  Data: 0.008 (0.009)\n",
            "Train: 49 [ 700/2354 ( 30%)]  Loss: 1.051 (1.43)  Time: 0.465s,   17.19/s  (0.474s,   16.86/s)  LR: 3.337e-05  Data: 0.007 (0.009)\n",
            "Train: 49 [ 750/2354 ( 32%)]  Loss: 1.084 (1.43)  Time: 0.480s,   16.66/s  (0.475s,   16.83/s)  LR: 3.337e-05  Data: 0.007 (0.009)\n",
            "Train: 49 [ 800/2354 ( 34%)]  Loss: 2.341 (1.43)  Time: 0.470s,   17.01/s  (0.475s,   16.85/s)  LR: 3.337e-05  Data: 0.010 (0.009)\n",
            "Train: 49 [ 850/2354 ( 36%)]  Loss: 1.855 (1.43)  Time: 0.462s,   17.32/s  (0.474s,   16.86/s)  LR: 3.337e-05  Data: 0.007 (0.009)\n",
            "Train: 49 [ 900/2354 ( 38%)]  Loss: 1.178 (1.43)  Time: 0.465s,   17.20/s  (0.474s,   16.87/s)  LR: 3.337e-05  Data: 0.009 (0.009)\n",
            "Train: 49 [ 950/2354 ( 40%)]  Loss: 1.700 (1.43)  Time: 0.463s,   17.27/s  (0.474s,   16.88/s)  LR: 3.337e-05  Data: 0.008 (0.009)\n",
            "Train: 49 [1000/2354 ( 42%)]  Loss: 1.265 (1.42)  Time: 0.461s,   17.34/s  (0.475s,   16.86/s)  LR: 3.337e-05  Data: 0.006 (0.009)\n",
            "Train: 49 [1050/2354 ( 45%)]  Loss: 2.196 (1.42)  Time: 0.473s,   16.91/s  (0.474s,   16.87/s)  LR: 3.337e-05  Data: 0.011 (0.009)\n",
            "Train: 49 [1100/2354 ( 47%)]  Loss: 1.276 (1.42)  Time: 0.471s,   16.97/s  (0.474s,   16.88/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1150/2354 ( 49%)]  Loss: 1.027 (1.42)  Time: 0.468s,   17.08/s  (0.474s,   16.89/s)  LR: 3.337e-05  Data: 0.010 (0.008)\n",
            "Train: 49 [1200/2354 ( 51%)]  Loss: 1.086 (1.42)  Time: 0.467s,   17.13/s  (0.473s,   16.90/s)  LR: 3.337e-05  Data: 0.009 (0.008)\n",
            "Train: 49 [1250/2354 ( 53%)]  Loss: 2.380 (1.43)  Time: 0.465s,   17.20/s  (0.474s,   16.89/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1300/2354 ( 55%)]  Loss: 2.127 (1.44)  Time: 0.462s,   17.33/s  (0.474s,   16.89/s)  LR: 3.337e-05  Data: 0.006 (0.008)\n",
            "Train: 49 [1350/2354 ( 57%)]  Loss: 1.557 (1.44)  Time: 0.463s,   17.29/s  (0.473s,   16.90/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1400/2354 ( 59%)]  Loss: 1.483 (1.44)  Time: 0.474s,   16.87/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1450/2354 ( 62%)]  Loss: 1.117 (1.44)  Time: 0.470s,   17.04/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.010 (0.008)\n",
            "Train: 49 [1500/2354 ( 64%)]  Loss: 1.031 (1.44)  Time: 0.467s,   17.12/s  (0.473s,   16.90/s)  LR: 3.337e-05  Data: 0.008 (0.008)\n",
            "Train: 49 [1550/2354 ( 66%)]  Loss: 1.096 (1.44)  Time: 0.465s,   17.20/s  (0.473s,   16.90/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1600/2354 ( 68%)]  Loss: 1.822 (1.44)  Time: 0.464s,   17.23/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.006 (0.008)\n",
            "Train: 49 [1650/2354 ( 70%)]  Loss: 1.257 (1.44)  Time: 0.467s,   17.12/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.008 (0.008)\n",
            "Train: 49 [1700/2354 ( 72%)]  Loss: 1.007 (1.44)  Time: 0.465s,   17.20/s  (0.473s,   16.92/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1750/2354 ( 74%)]  Loss: 1.230 (1.44)  Time: 0.472s,   16.94/s  (0.473s,   16.90/s)  LR: 3.337e-05  Data: 0.013 (0.008)\n",
            "Train: 49 [1800/2354 ( 76%)]  Loss: 1.181 (1.44)  Time: 0.469s,   17.05/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1850/2354 ( 79%)]  Loss: 1.828 (1.44)  Time: 0.469s,   17.05/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1900/2354 ( 81%)]  Loss: 1.017 (1.44)  Time: 0.462s,   17.30/s  (0.473s,   16.92/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [1950/2354 ( 83%)]  Loss: 1.781 (1.44)  Time: 0.465s,   17.20/s  (0.473s,   16.92/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [2000/2354 ( 85%)]  Loss: 1.100 (1.44)  Time: 0.477s,   16.77/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.010 (0.008)\n",
            "Train: 49 [2050/2354 ( 87%)]  Loss: 0.9800 (1.44)  Time: 0.462s,   17.30/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [2100/2354 ( 89%)]  Loss: 2.514 (1.44)  Time: 0.469s,   17.06/s  (0.473s,   16.92/s)  LR: 3.337e-05  Data: 0.010 (0.008)\n",
            "Train: 49 [2150/2354 ( 91%)]  Loss: 2.022 (1.44)  Time: 0.469s,   17.05/s  (0.473s,   16.92/s)  LR: 3.337e-05  Data: 0.009 (0.008)\n",
            "Train: 49 [2200/2354 ( 93%)]  Loss: 1.058 (1.44)  Time: 0.467s,   17.13/s  (0.473s,   16.93/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [2250/2354 ( 96%)]  Loss: 0.9967 (1.44)  Time: 0.463s,   17.29/s  (0.473s,   16.91/s)  LR: 3.337e-05  Data: 0.006 (0.008)\n",
            "Train: 49 [2300/2354 ( 98%)]  Loss: 1.310 (1.44)  Time: 0.468s,   17.10/s  (0.473s,   16.92/s)  LR: 3.337e-05  Data: 0.007 (0.008)\n",
            "Train: 49 [2350/2354 (100%)]  Loss: 1.294 (1.44)  Time: 0.462s,   17.32/s  (0.473s,   16.92/s)  LR: 3.337e-05  Data: 0.006 (0.008)\n",
            "Train: 49 [2353/2354 (100%)]  Loss: 1.845 (1.44)  Time: 0.458s,   17.47/s  (0.473s,   16.92/s)  LR: 3.337e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.624 (0.624)  Loss:  0.0461 (0.0461)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.098 (0.159)  Loss:  0.1870 (0.1134)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.144 (0.150)  Loss:  0.0841 (0.1071)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.204 (0.147)  Loss:  0.0899 (0.1245)  Acc@1: 100.0000 (99.8344)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.127 (0.145)  Loss:  0.1300 (0.1264)  Acc@1: 100.0000 (99.7512)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.181 (0.145)  Loss:  0.1083 (0.1263)  Acc@1: 100.0000 (99.8008)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.149 (0.145)  Loss:  0.1813 (0.1304)  Acc@1: 100.0000 (99.5847)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.268 (0.145)  Loss:  0.0974 (0.1476)  Acc@1: 100.0000 (99.3590)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.163 (0.149)  Loss:  0.1531 (0.1453)  Acc@1: 100.0000 (99.4389)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.092 (0.148)  Loss:  0.0987 (0.1446)  Acc@1: 100.0000 (99.4457)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.102 (0.147)  Loss:  0.1309 (0.1413)  Acc@1: 100.0000 (99.5010)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.079 (0.147)  Loss:  0.0522 (0.1409)  Acc@1: 100.0000 (99.5463)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.107 (0.147)  Loss:  0.1848 (0.1387)  Acc@1: 100.0000 (99.5840)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.083 (0.146)  Loss:  0.1261 (0.1371)  Acc@1: 100.0000 (99.6160)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.104 (0.146)  Loss:  0.0453 (0.1337)  Acc@1: 100.0000 (99.6434)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.101 (0.147)  Loss:  0.1060 (0.1320)  Acc@1: 100.0000 (99.6338)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.213 (0.147)  Loss:  0.1283 (0.1328)  Acc@1: 100.0000 (99.5943)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.220 (0.147)  Loss:  0.1527 (0.1334)  Acc@1: 100.0000 (99.5887)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.184 (0.146)  Loss:  0.2174 (0.1331)  Acc@1: 100.0000 (99.6115)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.162 (0.146)  Loss:  0.1436 (0.1327)  Acc@1: 100.0000 (99.6320)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.191 (0.146)  Loss:  0.0756 (0.1315)  Acc@1: 100.0000 (99.6254)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.094 (0.146)  Loss:  0.1561 (0.1302)  Acc@1: 100.0000 (99.6432)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.117 (0.146)  Loss:  0.0884 (0.1319)  Acc@1: 100.0000 (99.6594)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.312 (0.147)  Loss:  0.4460 (0.1316)  Acc@1: 100.0000 (99.6525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.177 (0.147)  Loss:  0.3940 (0.1319)  Acc@1: 100.0000 (99.6461)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.178 (0.147)  Loss:  0.0791 (0.1310)  Acc@1: 100.0000 (99.6603)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.113 (0.147)  Loss:  0.1919 (0.1331)  Acc@1: 100.0000 (99.6541)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.236 (0.147)  Loss:  0.0566 (0.1329)  Acc@1: 100.0000 (99.6669)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.144 (0.147)  Loss:  0.1037 (0.1329)  Acc@1: 100.0000 (99.6610)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.124 (0.147)  Loss:  0.1379 (0.1330)  Acc@1: 100.0000 (99.6726)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.132 (0.147)  Loss:  0.0873 (0.1330)  Acc@1: 100.0000 (99.6669)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.155 (0.147)  Loss:  0.0927 (0.1355)  Acc@1: 100.0000 (99.6293)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.117 (0.147)  Loss:  0.1249 (0.1379)  Acc@1: 100.0000 (99.6252)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.177 (0.147)  Loss:  0.1017 (0.1392)  Acc@1: 100.0000 (99.6063)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.148 (0.147)  Loss:  0.1013 (0.1395)  Acc@1: 100.0000 (99.6032)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.181 (0.147)  Loss:  0.1230 (0.1411)  Acc@1: 100.0000 (99.5860)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.082 (0.146)  Loss:  0.1196 (0.1404)  Acc@1: 100.0000 (99.5974)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1850/2354]  Time: 0.156 (0.146)  Loss:  0.1230 (0.1405)  Acc@1: 100.0000 (99.5948)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1900/2354]  Time: 0.147 (0.146)  Loss:  0.0845 (0.1391)  Acc@1: 100.0000 (99.6055)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1950/2354]  Time: 0.086 (0.147)  Loss:  0.0828 (0.1379)  Acc@1: 100.0000 (99.6156)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2000/2354]  Time: 0.100 (0.147)  Loss:  0.1466 (0.1380)  Acc@1: 100.0000 (99.6252)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2050/2354]  Time: 0.146 (0.147)  Loss:  0.0665 (0.1396)  Acc@1: 100.0000 (99.5978)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2100/2354]  Time: 0.131 (0.147)  Loss:  0.5464 (0.1433)  Acc@1: 100.0000 (99.5359)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2150/2354]  Time: 0.127 (0.147)  Loss:  0.0801 (0.1435)  Acc@1: 100.0000 (99.5467)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2200/2354]  Time: 0.158 (0.147)  Loss:  0.1296 (0.1452)  Acc@1: 100.0000 (99.5343)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2250/2354]  Time: 0.172 (0.147)  Loss:  0.0490 (0.1451)  Acc@1: 100.0000 (99.5224)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2300/2354]  Time: 0.115 (0.146)  Loss:  0.1015 (0.1444)  Acc@1: 100.0000 (99.5219)  Acc@5: 100.0000 (99.9891)\n",
            "Test: [2350/2354]  Time: 0.075 (0.146)  Loss:  0.0333 (0.1439)  Acc@1: 100.0000 (99.5108)  Acc@5: 100.0000 (99.9894)\n",
            "Test: [2354/2354]  Time: 0.068 (0.146)  Loss:  0.0620 (0.1438)  Acc@1: 100.0000 (99.5116)  Acc@5: 100.0000 (99.9894)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-39.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-49.pth.tar', 99.51162543794457)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar', 98.3650069009449)\n",
            "\n",
            "Train: 50 [   0/2354 (  0%)]  Loss: 2.037 (2.04)  Time: 1.355s,    5.90/s  (1.355s,    5.90/s)  LR: 3.156e-05  Data: 0.585 (0.585)\n",
            "Train: 50 [  50/2354 (  2%)]  Loss: 1.202 (1.36)  Time: 0.477s,   16.76/s  (0.505s,   15.83/s)  LR: 3.156e-05  Data: 0.010 (0.019)\n",
            "Train: 50 [ 100/2354 (  4%)]  Loss: 1.625 (1.40)  Time: 0.468s,   17.08/s  (0.487s,   16.41/s)  LR: 3.156e-05  Data: 0.007 (0.014)\n",
            "Train: 50 [ 150/2354 (  6%)]  Loss: 1.444 (1.40)  Time: 0.468s,   17.10/s  (0.488s,   16.41/s)  LR: 3.156e-05  Data: 0.010 (0.012)\n",
            "Train: 50 [ 200/2354 (  8%)]  Loss: 0.9876 (1.38)  Time: 0.467s,   17.13/s  (0.483s,   16.56/s)  LR: 3.156e-05  Data: 0.007 (0.011)\n",
            "Train: 50 [ 250/2354 ( 11%)]  Loss: 1.090 (1.38)  Time: 0.482s,   16.59/s  (0.481s,   16.63/s)  LR: 3.156e-05  Data: 0.007 (0.010)\n",
            "Train: 50 [ 300/2354 ( 13%)]  Loss: 1.069 (1.36)  Time: 0.478s,   16.72/s  (0.479s,   16.68/s)  LR: 3.156e-05  Data: 0.007 (0.010)\n",
            "Train: 50 [ 350/2354 ( 15%)]  Loss: 1.747 (1.37)  Time: 0.635s,   12.60/s  (0.479s,   16.70/s)  LR: 3.156e-05  Data: 0.016 (0.010)\n",
            "Train: 50 [ 400/2354 ( 17%)]  Loss: 1.067 (1.36)  Time: 0.468s,   17.11/s  (0.480s,   16.68/s)  LR: 3.156e-05  Data: 0.007 (0.010)\n",
            "Train: 50 [ 450/2354 ( 19%)]  Loss: 0.9914 (1.38)  Time: 0.461s,   17.34/s  (0.479s,   16.72/s)  LR: 3.156e-05  Data: 0.007 (0.009)\n",
            "Train: 50 [ 500/2354 ( 21%)]  Loss: 1.030 (1.39)  Time: 0.467s,   17.14/s  (0.478s,   16.74/s)  LR: 3.156e-05  Data: 0.009 (0.009)\n",
            "Train: 50 [ 550/2354 ( 23%)]  Loss: 1.085 (1.40)  Time: 0.463s,   17.29/s  (0.477s,   16.77/s)  LR: 3.156e-05  Data: 0.007 (0.009)\n",
            "Train: 50 [ 600/2354 ( 25%)]  Loss: 1.167 (1.40)  Time: 0.472s,   16.96/s  (0.478s,   16.73/s)  LR: 3.156e-05  Data: 0.007 (0.009)\n",
            "Train: 50 [ 650/2354 ( 28%)]  Loss: 1.838 (1.40)  Time: 0.467s,   17.11/s  (0.478s,   16.75/s)  LR: 3.156e-05  Data: 0.007 (0.009)\n",
            "Train: 50 [ 700/2354 ( 30%)]  Loss: 1.072 (1.41)  Time: 0.470s,   17.04/s  (0.477s,   16.77/s)  LR: 3.156e-05  Data: 0.009 (0.009)\n",
            "Train: 50 [ 750/2354 ( 32%)]  Loss: 1.103 (1.41)  Time: 0.469s,   17.06/s  (0.477s,   16.79/s)  LR: 3.156e-05  Data: 0.010 (0.009)\n",
            "Train: 50 [ 800/2354 ( 34%)]  Loss: 1.322 (1.41)  Time: 0.470s,   17.02/s  (0.476s,   16.80/s)  LR: 3.156e-05  Data: 0.008 (0.009)\n",
            "Train: 50 [ 850/2354 ( 36%)]  Loss: 2.501 (1.41)  Time: 0.464s,   17.25/s  (0.477s,   16.77/s)  LR: 3.156e-05  Data: 0.009 (0.009)\n",
            "Train: 50 [ 900/2354 ( 38%)]  Loss: 2.129 (1.42)  Time: 0.463s,   17.30/s  (0.476s,   16.79/s)  LR: 3.156e-05  Data: 0.007 (0.009)\n",
            "Train: 50 [ 950/2354 ( 40%)]  Loss: 0.9730 (1.41)  Time: 0.476s,   16.82/s  (0.476s,   16.80/s)  LR: 3.156e-05  Data: 0.007 (0.009)\n",
            "Train: 50 [1000/2354 ( 42%)]  Loss: 1.005 (1.41)  Time: 0.469s,   17.06/s  (0.476s,   16.81/s)  LR: 3.156e-05  Data: 0.010 (0.009)\n",
            "Train: 50 [1050/2354 ( 45%)]  Loss: 1.079 (1.41)  Time: 0.482s,   16.61/s  (0.476s,   16.82/s)  LR: 3.156e-05  Data: 0.007 (0.009)\n",
            "Train: 50 [1100/2354 ( 47%)]  Loss: 2.215 (1.42)  Time: 0.470s,   17.03/s  (0.476s,   16.80/s)  LR: 3.156e-05  Data: 0.011 (0.009)\n",
            "Train: 50 [1150/2354 ( 49%)]  Loss: 2.828 (1.42)  Time: 0.467s,   17.13/s  (0.476s,   16.81/s)  LR: 3.156e-05  Data: 0.007 (0.009)\n",
            "Train: 50 [1200/2354 ( 51%)]  Loss: 3.110 (1.42)  Time: 0.470s,   17.02/s  (0.476s,   16.82/s)  LR: 3.156e-05  Data: 0.009 (0.009)\n",
            "Train: 50 [1250/2354 ( 53%)]  Loss: 1.295 (1.42)  Time: 0.476s,   16.82/s  (0.475s,   16.83/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [1300/2354 ( 55%)]  Loss: 2.171 (1.42)  Time: 0.471s,   16.97/s  (0.475s,   16.84/s)  LR: 3.156e-05  Data: 0.010 (0.008)\n",
            "Train: 50 [1350/2354 ( 57%)]  Loss: 1.775 (1.42)  Time: 0.468s,   17.10/s  (0.475s,   16.82/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [1400/2354 ( 59%)]  Loss: 1.095 (1.42)  Time: 0.473s,   16.91/s  (0.475s,   16.83/s)  LR: 3.156e-05  Data: 0.010 (0.008)\n",
            "Train: 50 [1450/2354 ( 62%)]  Loss: 2.376 (1.42)  Time: 0.476s,   16.80/s  (0.475s,   16.84/s)  LR: 3.156e-05  Data: 0.006 (0.008)\n",
            "Train: 50 [1500/2354 ( 64%)]  Loss: 1.003 (1.42)  Time: 0.463s,   17.28/s  (0.475s,   16.84/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [1550/2354 ( 66%)]  Loss: 1.411 (1.42)  Time: 0.465s,   17.21/s  (0.475s,   16.85/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [1600/2354 ( 68%)]  Loss: 2.474 (1.42)  Time: 0.469s,   17.06/s  (0.475s,   16.83/s)  LR: 3.156e-05  Data: 0.009 (0.008)\n",
            "Train: 50 [1650/2354 ( 70%)]  Loss: 0.9981 (1.42)  Time: 0.474s,   16.87/s  (0.475s,   16.84/s)  LR: 3.156e-05  Data: 0.010 (0.008)\n",
            "Train: 50 [1700/2354 ( 72%)]  Loss: 0.9695 (1.42)  Time: 0.466s,   17.19/s  (0.475s,   16.84/s)  LR: 3.156e-05  Data: 0.008 (0.008)\n",
            "Train: 50 [1750/2354 ( 74%)]  Loss: 1.722 (1.42)  Time: 0.468s,   17.11/s  (0.475s,   16.85/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [1800/2354 ( 76%)]  Loss: 1.018 (1.42)  Time: 0.465s,   17.20/s  (0.475s,   16.86/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [1850/2354 ( 79%)]  Loss: 1.597 (1.42)  Time: 0.473s,   16.93/s  (0.475s,   16.85/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [1900/2354 ( 81%)]  Loss: 1.129 (1.42)  Time: 0.464s,   17.23/s  (0.475s,   16.86/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [1950/2354 ( 83%)]  Loss: 1.675 (1.42)  Time: 0.465s,   17.20/s  (0.474s,   16.86/s)  LR: 3.156e-05  Data: 0.008 (0.008)\n",
            "Train: 50 [2000/2354 ( 85%)]  Loss: 1.815 (1.42)  Time: 0.469s,   17.05/s  (0.474s,   16.87/s)  LR: 3.156e-05  Data: 0.007 (0.008)\n",
            "Train: 50 [2050/2354 ( 87%)]  Loss: 1.530 (1.42)  Time: 0.481s,   16.62/s  (0.474s,   16.87/s)  LR: 3.156e-05  Data: 0.010 (0.008)\n",
            "Train: 50 [2100/2354 ( 89%)]  Loss: 1.029 (1.42)  Time: 0.468s,   17.09/s  (0.474s,   16.86/s)  LR: 3.156e-05  Data: 0.008 (0.008)\n",
            "Train: 50 [2150/2354 ( 91%)]  Loss: 2.076 (1.42)  Time: 0.472s,   16.97/s  (0.474s,   16.87/s)  LR: 3.156e-05  Data: 0.008 (0.008)\n",
            "Train: 50 [2200/2354 ( 93%)]  Loss: 1.594 (1.42)  Time: 0.464s,   17.25/s  (0.474s,   16.87/s)  LR: 3.156e-05  Data: 0.008 (0.008)\n",
            "Train: 50 [2250/2354 ( 96%)]  Loss: 1.727 (1.42)  Time: 0.478s,   16.74/s  (0.474s,   16.87/s)  LR: 3.156e-05  Data: 0.010 (0.008)\n",
            "Train: 50 [2300/2354 ( 98%)]  Loss: 1.342 (1.42)  Time: 0.466s,   17.18/s  (0.474s,   16.88/s)  LR: 3.156e-05  Data: 0.008 (0.008)\n",
            "Train: 50 [2350/2354 (100%)]  Loss: 1.572 (1.42)  Time: 0.462s,   17.31/s  (0.474s,   16.87/s)  LR: 3.156e-05  Data: 0.006 (0.008)\n",
            "Train: 50 [2353/2354 (100%)]  Loss: 1.031 (1.42)  Time: 0.463s,   17.26/s  (0.474s,   16.87/s)  LR: 3.156e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.630 (0.630)  Loss:  0.1566 (0.1566)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.139 (0.156)  Loss:  0.1119 (0.1325)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.150 (0.149)  Loss:  0.1193 (0.1152)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.190 (0.147)  Loss:  0.0898 (0.1215)  Acc@1: 100.0000 (99.8344)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.176 (0.147)  Loss:  0.1843 (0.1236)  Acc@1: 100.0000 (99.6269)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.182 (0.146)  Loss:  0.0673 (0.1267)  Acc@1: 100.0000 (99.7012)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.169 (0.146)  Loss:  0.2827 (0.1251)  Acc@1: 100.0000 (99.6678)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.171 (0.146)  Loss:  0.0576 (0.1389)  Acc@1: 100.0000 (99.3590)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.081 (0.145)  Loss:  0.2284 (0.1387)  Acc@1: 100.0000 (99.3766)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.113 (0.146)  Loss:  0.0810 (0.1362)  Acc@1: 100.0000 (99.3348)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.170 (0.145)  Loss:  0.0635 (0.1337)  Acc@1: 100.0000 (99.4012)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.138 (0.146)  Loss:  0.0579 (0.1308)  Acc@1: 100.0000 (99.4555)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.134 (0.145)  Loss:  0.0784 (0.1276)  Acc@1: 100.0000 (99.5008)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.077 (0.148)  Loss:  0.0947 (0.1243)  Acc@1: 100.0000 (99.5392)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.134 (0.148)  Loss:  0.0586 (0.1211)  Acc@1: 100.0000 (99.5720)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.080 (0.148)  Loss:  0.1376 (0.1205)  Acc@1: 100.0000 (99.6005)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.174 (0.147)  Loss:  0.0844 (0.1195)  Acc@1: 100.0000 (99.6255)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.105 (0.147)  Loss:  0.0800 (0.1184)  Acc@1: 100.0000 (99.6181)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.166 (0.147)  Loss:  0.1053 (0.1182)  Acc@1: 100.0000 (99.6393)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.111 (0.147)  Loss:  0.1440 (0.1179)  Acc@1: 100.0000 (99.6583)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.112 (0.146)  Loss:  0.0559 (0.1177)  Acc@1: 100.0000 (99.6753)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.103 (0.146)  Loss:  0.1085 (0.1158)  Acc@1: 100.0000 (99.6908)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.089 (0.146)  Loss:  0.0480 (0.1150)  Acc@1: 100.0000 (99.6821)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.183 (0.146)  Loss:  0.4561 (0.1159)  Acc@1: 100.0000 (99.6742)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.151 (0.146)  Loss:  0.2561 (0.1166)  Acc@1: 100.0000 (99.6461)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.122 (0.145)  Loss:  0.1730 (0.1158)  Acc@1: 100.0000 (99.6603)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.084 (0.145)  Loss:  0.0914 (0.1172)  Acc@1: 100.0000 (99.6733)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.114 (0.145)  Loss:  0.0682 (0.1172)  Acc@1: 100.0000 (99.6854)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.138 (0.145)  Loss:  0.1399 (0.1188)  Acc@1: 100.0000 (99.6788)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.079 (0.146)  Loss:  0.0896 (0.1184)  Acc@1: 100.0000 (99.6899)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.094 (0.146)  Loss:  0.0869 (0.1178)  Acc@1: 100.0000 (99.6835)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.197 (0.146)  Loss:  0.0820 (0.1178)  Acc@1: 100.0000 (99.6454)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.112 (0.146)  Loss:  0.0959 (0.1192)  Acc@1: 100.0000 (99.6096)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.178 (0.146)  Loss:  0.0613 (0.1202)  Acc@1: 100.0000 (99.6063)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.131 (0.146)  Loss:  0.0887 (0.1210)  Acc@1: 100.0000 (99.6032)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.201 (0.146)  Loss:  0.0707 (0.1208)  Acc@1: 100.0000 (99.6002)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.089 (0.146)  Loss:  0.1837 (0.1203)  Acc@1: 100.0000 (99.6113)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1850/2354]  Time: 0.166 (0.146)  Loss:  0.0455 (0.1201)  Acc@1: 100.0000 (99.5948)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1900/2354]  Time: 0.121 (0.145)  Loss:  0.1178 (0.1196)  Acc@1: 100.0000 (99.6055)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1950/2354]  Time: 0.114 (0.145)  Loss:  0.1146 (0.1208)  Acc@1: 100.0000 (99.5900)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2000/2354]  Time: 0.167 (0.145)  Loss:  0.1256 (0.1201)  Acc@1: 100.0000 (99.6002)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2050/2354]  Time: 0.133 (0.145)  Loss:  0.0447 (0.1218)  Acc@1: 100.0000 (99.5490)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2100/2354]  Time: 0.089 (0.145)  Loss:  0.0873 (0.1224)  Acc@1: 100.0000 (99.5478)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2150/2354]  Time: 0.092 (0.145)  Loss:  0.2937 (0.1232)  Acc@1: 100.0000 (99.5583)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2200/2354]  Time: 0.129 (0.145)  Loss:  0.0766 (0.1244)  Acc@1: 100.0000 (99.5457)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2250/2354]  Time: 0.164 (0.146)  Loss:  0.0646 (0.1241)  Acc@1: 100.0000 (99.5335)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2300/2354]  Time: 0.165 (0.146)  Loss:  0.0825 (0.1236)  Acc@1: 100.0000 (99.5328)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2350/2354]  Time: 0.075 (0.146)  Loss:  0.1164 (0.1231)  Acc@1: 100.0000 (99.5427)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2354/2354]  Time: 0.070 (0.146)  Loss:  0.0381 (0.1231)  Acc@1: 100.0000 (99.5435)  Acc@5: 100.0000 (100.0000)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-40.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-50.pth.tar', 99.54347595286124)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-49.pth.tar', 99.51162543794457)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar', 98.69412888841703)\n",
            "\n",
            "Train: 51 [   0/2354 (  0%)]  Loss: 1.044 (1.04)  Time: 1.349s,    5.93/s  (1.349s,    5.93/s)  LR: 2.978e-05  Data: 0.609 (0.609)\n",
            "Train: 51 [  50/2354 (  2%)]  Loss: 1.771 (1.44)  Time: 0.466s,   17.18/s  (0.504s,   15.87/s)  LR: 2.978e-05  Data: 0.007 (0.020)\n",
            "Train: 51 [ 100/2354 (  4%)]  Loss: 1.863 (1.42)  Time: 0.470s,   17.04/s  (0.487s,   16.43/s)  LR: 2.978e-05  Data: 0.009 (0.014)\n",
            "Train: 51 [ 150/2354 (  6%)]  Loss: 1.456 (1.47)  Time: 0.469s,   17.05/s  (0.481s,   16.63/s)  LR: 2.978e-05  Data: 0.007 (0.012)\n",
            "Train: 51 [ 200/2354 (  8%)]  Loss: 1.185 (1.47)  Time: 0.538s,   14.88/s  (0.479s,   16.72/s)  LR: 2.978e-05  Data: 0.009 (0.011)\n",
            "Train: 51 [ 250/2354 ( 11%)]  Loss: 1.425 (1.46)  Time: 0.473s,   16.90/s  (0.480s,   16.66/s)  LR: 2.978e-05  Data: 0.009 (0.010)\n",
            "Train: 51 [ 300/2354 ( 13%)]  Loss: 1.156 (1.47)  Time: 0.468s,   17.08/s  (0.479s,   16.71/s)  LR: 2.978e-05  Data: 0.007 (0.010)\n",
            "Train: 51 [ 350/2354 ( 15%)]  Loss: 1.692 (1.45)  Time: 0.469s,   17.05/s  (0.478s,   16.74/s)  LR: 2.978e-05  Data: 0.007 (0.010)\n",
            "Train: 51 [ 400/2354 ( 17%)]  Loss: 1.053 (1.44)  Time: 0.490s,   16.32/s  (0.477s,   16.75/s)  LR: 2.978e-05  Data: 0.010 (0.010)\n",
            "Train: 51 [ 450/2354 ( 19%)]  Loss: 2.547 (1.43)  Time: 0.690s,   11.59/s  (0.479s,   16.71/s)  LR: 2.978e-05  Data: 0.013 (0.009)\n",
            "Train: 51 [ 500/2354 ( 21%)]  Loss: 1.260 (1.43)  Time: 0.472s,   16.94/s  (0.479s,   16.71/s)  LR: 2.978e-05  Data: 0.010 (0.009)\n",
            "Train: 51 [ 550/2354 ( 23%)]  Loss: 0.9798 (1.42)  Time: 0.477s,   16.78/s  (0.478s,   16.73/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [ 600/2354 ( 25%)]  Loss: 1.632 (1.43)  Time: 0.483s,   16.55/s  (0.478s,   16.75/s)  LR: 2.978e-05  Data: 0.008 (0.009)\n",
            "Train: 51 [ 650/2354 ( 28%)]  Loss: 2.096 (1.44)  Time: 0.468s,   17.09/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [ 700/2354 ( 30%)]  Loss: 1.404 (1.44)  Time: 0.469s,   17.07/s  (0.478s,   16.72/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [ 750/2354 ( 32%)]  Loss: 3.280 (1.44)  Time: 0.474s,   16.86/s  (0.478s,   16.73/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [ 800/2354 ( 34%)]  Loss: 1.208 (1.43)  Time: 0.470s,   17.03/s  (0.478s,   16.74/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [ 850/2354 ( 36%)]  Loss: 1.556 (1.44)  Time: 0.470s,   17.01/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.010 (0.009)\n",
            "Train: 51 [ 900/2354 ( 38%)]  Loss: 1.110 (1.43)  Time: 0.470s,   17.02/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.009 (0.009)\n",
            "Train: 51 [ 950/2354 ( 40%)]  Loss: 1.040 (1.43)  Time: 0.475s,   16.83/s  (0.478s,   16.74/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [1000/2354 ( 42%)]  Loss: 0.9488 (1.43)  Time: 0.469s,   17.04/s  (0.478s,   16.75/s)  LR: 2.978e-05  Data: 0.010 (0.009)\n",
            "Train: 51 [1050/2354 ( 45%)]  Loss: 2.667 (1.43)  Time: 0.464s,   17.25/s  (0.477s,   16.75/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [1100/2354 ( 47%)]  Loss: 1.107 (1.43)  Time: 0.474s,   16.88/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.009 (0.009)\n",
            "Train: 51 [1150/2354 ( 49%)]  Loss: 1.863 (1.44)  Time: 0.472s,   16.96/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [1200/2354 ( 51%)]  Loss: 3.481 (1.44)  Time: 0.475s,   16.84/s  (0.478s,   16.75/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [1250/2354 ( 53%)]  Loss: 1.055 (1.43)  Time: 0.469s,   17.08/s  (0.477s,   16.75/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [1300/2354 ( 55%)]  Loss: 1.791 (1.44)  Time: 0.476s,   16.81/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.007 (0.009)\n",
            "Train: 51 [1350/2354 ( 57%)]  Loss: 1.006 (1.43)  Time: 0.465s,   17.21/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [1400/2354 ( 59%)]  Loss: 1.328 (1.43)  Time: 0.466s,   17.15/s  (0.477s,   16.78/s)  LR: 2.978e-05  Data: 0.010 (0.008)\n",
            "Train: 51 [1450/2354 ( 62%)]  Loss: 1.200 (1.43)  Time: 0.471s,   16.97/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [1500/2354 ( 64%)]  Loss: 1.059 (1.43)  Time: 0.481s,   16.62/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.014 (0.008)\n",
            "Train: 51 [1550/2354 ( 66%)]  Loss: 1.022 (1.42)  Time: 0.471s,   16.98/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [1600/2354 ( 68%)]  Loss: 1.909 (1.42)  Time: 0.470s,   17.02/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [1650/2354 ( 70%)]  Loss: 2.319 (1.42)  Time: 0.474s,   16.89/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [1700/2354 ( 72%)]  Loss: 1.048 (1.43)  Time: 0.467s,   17.14/s  (0.478s,   16.75/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [1750/2354 ( 74%)]  Loss: 0.9607 (1.43)  Time: 0.471s,   16.97/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.010 (0.008)\n",
            "Train: 51 [1800/2354 ( 76%)]  Loss: 1.442 (1.43)  Time: 0.471s,   16.99/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [1850/2354 ( 79%)]  Loss: 0.9613 (1.43)  Time: 0.479s,   16.72/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.009 (0.008)\n",
            "Train: 51 [1900/2354 ( 81%)]  Loss: 0.9987 (1.42)  Time: 0.470s,   17.01/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [1950/2354 ( 83%)]  Loss: 0.9886 (1.43)  Time: 0.470s,   17.02/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [2000/2354 ( 85%)]  Loss: 1.071 (1.42)  Time: 0.471s,   16.99/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.010 (0.008)\n",
            "Train: 51 [2050/2354 ( 87%)]  Loss: 1.574 (1.43)  Time: 0.469s,   17.04/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.008 (0.008)\n",
            "Train: 51 [2100/2354 ( 89%)]  Loss: 1.019 (1.43)  Time: 0.471s,   16.99/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.009 (0.008)\n",
            "Train: 51 [2150/2354 ( 91%)]  Loss: 0.9635 (1.43)  Time: 0.470s,   17.01/s  (0.477s,   16.78/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [2200/2354 ( 93%)]  Loss: 2.431 (1.43)  Time: 0.473s,   16.92/s  (0.477s,   16.76/s)  LR: 2.978e-05  Data: 0.011 (0.008)\n",
            "Train: 51 [2250/2354 ( 96%)]  Loss: 1.397 (1.43)  Time: 0.468s,   17.11/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.007 (0.008)\n",
            "Train: 51 [2300/2354 ( 98%)]  Loss: 1.074 (1.43)  Time: 0.469s,   17.05/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.010 (0.008)\n",
            "Train: 51 [2350/2354 (100%)]  Loss: 1.263 (1.43)  Time: 0.466s,   17.18/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.006 (0.008)\n",
            "Train: 51 [2353/2354 (100%)]  Loss: 1.176 (1.43)  Time: 0.454s,   17.62/s  (0.477s,   16.77/s)  LR: 2.978e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.664 (0.664)  Loss:  0.4727 (0.4727)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.115 (0.164)  Loss:  0.1049 (0.1354)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.111 (0.157)  Loss:  0.1353 (0.1197)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.130 (0.154)  Loss:  0.1953 (0.1465)  Acc@1: 100.0000 (99.6689)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.111 (0.161)  Loss:  0.1423 (0.1444)  Acc@1: 100.0000 (99.5025)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.148 (0.159)  Loss:  0.0945 (0.1402)  Acc@1: 100.0000 (99.6016)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.166 (0.157)  Loss:  0.5244 (0.1437)  Acc@1: 100.0000 (99.5847)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.166 (0.156)  Loss:  0.0836 (0.1628)  Acc@1: 100.0000 (99.4302)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.109 (0.154)  Loss:  0.0883 (0.1617)  Acc@1: 100.0000 (99.4389)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.136 (0.153)  Loss:  0.1437 (0.1596)  Acc@1: 100.0000 (99.4457)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.194 (0.153)  Loss:  0.0532 (0.1587)  Acc@1: 100.0000 (99.4012)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.091 (0.153)  Loss:  0.1139 (0.1546)  Acc@1: 100.0000 (99.4102)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.170 (0.153)  Loss:  0.2218 (0.1529)  Acc@1: 100.0000 (99.4592)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.211 (0.152)  Loss:  0.1427 (0.1524)  Acc@1: 100.0000 (99.5008)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.186 (0.152)  Loss:  0.1060 (0.1509)  Acc@1: 100.0000 (99.5007)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.174 (0.152)  Loss:  0.1851 (0.1497)  Acc@1: 100.0000 (99.5340)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.157 (0.151)  Loss:  0.1816 (0.1512)  Acc@1: 100.0000 (99.5630)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.165 (0.151)  Loss:  0.1223 (0.1501)  Acc@1: 100.0000 (99.5593)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.118 (0.151)  Loss:  0.1599 (0.1484)  Acc@1: 100.0000 (99.5560)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.328 (0.153)  Loss:  0.1582 (0.1472)  Acc@1: 100.0000 (99.5794)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.088 (0.153)  Loss:  0.0596 (0.1449)  Acc@1: 100.0000 (99.5754)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.157 (0.153)  Loss:  0.0859 (0.1425)  Acc@1: 100.0000 (99.5956)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.148 (0.153)  Loss:  0.0851 (0.1436)  Acc@1: 100.0000 (99.5913)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.136 (0.153)  Loss:  0.6729 (0.1435)  Acc@1: 100.0000 (99.6090)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.198 (0.152)  Loss:  0.4062 (0.1443)  Acc@1: 100.0000 (99.5629)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.202 (0.152)  Loss:  0.1340 (0.1428)  Acc@1: 100.0000 (99.5803)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.188 (0.152)  Loss:  0.1001 (0.1440)  Acc@1: 100.0000 (99.5772)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.100 (0.152)  Loss:  0.1071 (0.1428)  Acc@1: 100.0000 (99.5929)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.176 (0.152)  Loss:  0.0925 (0.1439)  Acc@1: 100.0000 (99.5717)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.129 (0.151)  Loss:  0.0875 (0.1431)  Acc@1: 100.0000 (99.5865)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.192 (0.151)  Loss:  0.1139 (0.1426)  Acc@1: 100.0000 (99.5836)  Acc@5: 100.0000 (99.9833)\n",
            "Test: [1550/2354]  Time: 0.115 (0.151)  Loss:  0.0864 (0.1432)  Acc@1: 100.0000 (99.5809)  Acc@5: 100.0000 (99.9839)\n",
            "Test: [1600/2354]  Time: 0.136 (0.151)  Loss:  0.1273 (0.1455)  Acc@1: 100.0000 (99.5784)  Acc@5: 100.0000 (99.9844)\n",
            "Test: [1650/2354]  Time: 0.122 (0.151)  Loss:  0.1202 (0.1462)  Acc@1: 100.0000 (99.5760)  Acc@5: 100.0000 (99.9849)\n",
            "Test: [1700/2354]  Time: 0.143 (0.151)  Loss:  0.0968 (0.1451)  Acc@1: 100.0000 (99.5885)  Acc@5: 100.0000 (99.9853)\n",
            "Test: [1750/2354]  Time: 0.195 (0.152)  Loss:  0.1100 (0.1457)  Acc@1: 100.0000 (99.5860)  Acc@5: 100.0000 (99.9857)\n",
            "Test: [1800/2354]  Time: 0.156 (0.152)  Loss:  0.2090 (0.1462)  Acc@1: 100.0000 (99.5836)  Acc@5: 100.0000 (99.9722)\n",
            "Test: [1850/2354]  Time: 0.204 (0.152)  Loss:  0.1097 (0.1461)  Acc@1: 100.0000 (99.5813)  Acc@5: 100.0000 (99.9730)\n",
            "Test: [1900/2354]  Time: 0.179 (0.152)  Loss:  0.1373 (0.1451)  Acc@1: 100.0000 (99.5923)  Acc@5: 100.0000 (99.9737)\n",
            "Test: [1950/2354]  Time: 0.116 (0.152)  Loss:  0.1058 (0.1447)  Acc@1: 100.0000 (99.6028)  Acc@5: 100.0000 (99.9744)\n",
            "Test: [2000/2354]  Time: 0.120 (0.152)  Loss:  0.1818 (0.1445)  Acc@1: 100.0000 (99.6127)  Acc@5: 100.0000 (99.9750)\n",
            "Test: [2050/2354]  Time: 0.085 (0.152)  Loss:  0.0413 (0.1451)  Acc@1: 100.0000 (99.6099)  Acc@5: 100.0000 (99.9756)\n",
            "Test: [2100/2354]  Time: 0.145 (0.152)  Loss:  0.6104 (0.1464)  Acc@1: 75.0000 (99.6073)  Acc@5: 100.0000 (99.9762)\n",
            "Test: [2150/2354]  Time: 0.130 (0.152)  Loss:  0.1935 (0.1487)  Acc@1: 100.0000 (99.5816)  Acc@5: 100.0000 (99.9768)\n",
            "Test: [2200/2354]  Time: 0.147 (0.152)  Loss:  0.1879 (0.1511)  Acc@1: 100.0000 (99.5570)  Acc@5: 100.0000 (99.9773)\n",
            "Test: [2250/2354]  Time: 0.104 (0.152)  Loss:  0.0771 (0.1505)  Acc@1: 100.0000 (99.5446)  Acc@5: 100.0000 (99.9778)\n",
            "Test: [2300/2354]  Time: 0.177 (0.152)  Loss:  0.0916 (0.1508)  Acc@1: 100.0000 (99.5328)  Acc@5: 100.0000 (99.9674)\n",
            "Test: [2350/2354]  Time: 0.074 (0.151)  Loss:  0.0670 (0.1513)  Acc@1: 100.0000 (99.5215)  Acc@5: 100.0000 (99.9681)\n",
            "Test: [2354/2354]  Time: 0.067 (0.151)  Loss:  0.0421 (0.1512)  Acc@1: 100.0000 (99.5222)  Acc@5: 100.0000 (99.9681)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-41.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-50.pth.tar', 99.54347595286124)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-51.pth.tar', 99.52224227625014)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-49.pth.tar', 99.51162543794457)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar', 98.74721307994479)\n",
            "\n",
            "Train: 52 [   0/2354 (  0%)]  Loss: 1.243 (1.24)  Time: 1.494s,    5.35/s  (1.494s,    5.35/s)  LR: 2.803e-05  Data: 0.678 (0.678)\n",
            "Train: 52 [  50/2354 (  2%)]  Loss: 1.165 (1.46)  Time: 0.472s,   16.96/s  (0.538s,   14.87/s)  LR: 2.803e-05  Data: 0.007 (0.021)\n",
            "Train: 52 [ 100/2354 (  4%)]  Loss: 1.875 (1.47)  Time: 0.475s,   16.84/s  (0.508s,   15.75/s)  LR: 2.803e-05  Data: 0.007 (0.015)\n",
            "Train: 52 [ 150/2354 (  6%)]  Loss: 1.710 (1.45)  Time: 0.480s,   16.68/s  (0.498s,   16.07/s)  LR: 2.803e-05  Data: 0.009 (0.012)\n",
            "Train: 52 [ 200/2354 (  8%)]  Loss: 0.9664 (1.44)  Time: 0.469s,   17.05/s  (0.492s,   16.24/s)  LR: 2.803e-05  Data: 0.007 (0.011)\n",
            "Train: 52 [ 250/2354 ( 11%)]  Loss: 1.794 (1.42)  Time: 0.470s,   17.02/s  (0.489s,   16.35/s)  LR: 2.803e-05  Data: 0.009 (0.011)\n",
            "Train: 52 [ 300/2354 ( 13%)]  Loss: 1.990 (1.40)  Time: 0.473s,   16.91/s  (0.490s,   16.32/s)  LR: 2.803e-05  Data: 0.007 (0.010)\n",
            "Train: 52 [ 350/2354 ( 15%)]  Loss: 3.867 (1.39)  Time: 0.473s,   16.91/s  (0.488s,   16.40/s)  LR: 2.803e-05  Data: 0.007 (0.010)\n",
            "Train: 52 [ 400/2354 ( 17%)]  Loss: 1.122 (1.39)  Time: 0.468s,   17.10/s  (0.486s,   16.45/s)  LR: 2.803e-05  Data: 0.007 (0.010)\n",
            "Train: 52 [ 450/2354 ( 19%)]  Loss: 1.611 (1.40)  Time: 0.472s,   16.96/s  (0.485s,   16.50/s)  LR: 2.803e-05  Data: 0.007 (0.010)\n",
            "Train: 52 [ 500/2354 ( 21%)]  Loss: 1.694 (1.39)  Time: 0.469s,   17.07/s  (0.484s,   16.54/s)  LR: 2.803e-05  Data: 0.008 (0.009)\n",
            "Train: 52 [ 550/2354 ( 23%)]  Loss: 1.312 (1.38)  Time: 0.479s,   16.70/s  (0.485s,   16.51/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [ 600/2354 ( 25%)]  Loss: 0.9617 (1.39)  Time: 0.470s,   17.03/s  (0.484s,   16.54/s)  LR: 2.803e-05  Data: 0.012 (0.009)\n",
            "Train: 52 [ 650/2354 ( 28%)]  Loss: 3.421 (1.39)  Time: 0.474s,   16.89/s  (0.483s,   16.58/s)  LR: 2.803e-05  Data: 0.010 (0.009)\n",
            "Train: 52 [ 700/2354 ( 30%)]  Loss: 2.391 (1.40)  Time: 0.480s,   16.67/s  (0.482s,   16.60/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [ 750/2354 ( 32%)]  Loss: 1.626 (1.39)  Time: 0.470s,   17.03/s  (0.481s,   16.62/s)  LR: 2.803e-05  Data: 0.008 (0.009)\n",
            "Train: 52 [ 800/2354 ( 34%)]  Loss: 1.100 (1.39)  Time: 0.471s,   16.98/s  (0.482s,   16.59/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [ 850/2354 ( 36%)]  Loss: 1.190 (1.39)  Time: 0.466s,   17.16/s  (0.481s,   16.62/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [ 900/2354 ( 38%)]  Loss: 1.206 (1.38)  Time: 0.477s,   16.78/s  (0.481s,   16.64/s)  LR: 2.803e-05  Data: 0.010 (0.009)\n",
            "Train: 52 [ 950/2354 ( 40%)]  Loss: 1.625 (1.39)  Time: 0.465s,   17.20/s  (0.480s,   16.65/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1000/2354 ( 42%)]  Loss: 2.008 (1.38)  Time: 0.473s,   16.91/s  (0.480s,   16.67/s)  LR: 2.803e-05  Data: 0.009 (0.009)\n",
            "Train: 52 [1050/2354 ( 45%)]  Loss: 1.061 (1.38)  Time: 0.468s,   17.10/s  (0.481s,   16.65/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1100/2354 ( 47%)]  Loss: 1.087 (1.38)  Time: 0.463s,   17.28/s  (0.480s,   16.66/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1150/2354 ( 49%)]  Loss: 0.9982 (1.38)  Time: 0.484s,   16.54/s  (0.480s,   16.67/s)  LR: 2.803e-05  Data: 0.010 (0.009)\n",
            "Train: 52 [1200/2354 ( 51%)]  Loss: 2.430 (1.39)  Time: 0.463s,   17.29/s  (0.479s,   16.69/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1250/2354 ( 53%)]  Loss: 1.456 (1.39)  Time: 0.469s,   17.07/s  (0.479s,   16.70/s)  LR: 2.803e-05  Data: 0.010 (0.009)\n",
            "Train: 52 [1300/2354 ( 55%)]  Loss: 1.430 (1.39)  Time: 0.465s,   17.20/s  (0.479s,   16.69/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1350/2354 ( 57%)]  Loss: 1.347 (1.40)  Time: 0.471s,   16.99/s  (0.479s,   16.70/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1400/2354 ( 59%)]  Loss: 1.222 (1.41)  Time: 0.481s,   16.63/s  (0.479s,   16.71/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1450/2354 ( 62%)]  Loss: 1.032 (1.41)  Time: 0.467s,   17.12/s  (0.478s,   16.72/s)  LR: 2.803e-05  Data: 0.010 (0.009)\n",
            "Train: 52 [1500/2354 ( 64%)]  Loss: 1.070 (1.41)  Time: 0.466s,   17.17/s  (0.478s,   16.73/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1550/2354 ( 66%)]  Loss: 1.048 (1.41)  Time: 0.472s,   16.95/s  (0.478s,   16.72/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1600/2354 ( 68%)]  Loss: 1.020 (1.40)  Time: 0.469s,   17.05/s  (0.478s,   16.73/s)  LR: 2.803e-05  Data: 0.009 (0.009)\n",
            "Train: 52 [1650/2354 ( 70%)]  Loss: 2.135 (1.40)  Time: 0.473s,   16.91/s  (0.478s,   16.74/s)  LR: 2.803e-05  Data: 0.007 (0.009)\n",
            "Train: 52 [1700/2354 ( 72%)]  Loss: 1.326 (1.40)  Time: 0.473s,   16.93/s  (0.478s,   16.75/s)  LR: 2.803e-05  Data: 0.007 (0.008)\n",
            "Train: 52 [1750/2354 ( 74%)]  Loss: 1.123 (1.40)  Time: 0.466s,   17.17/s  (0.477s,   16.75/s)  LR: 2.803e-05  Data: 0.007 (0.008)\n",
            "Train: 52 [1800/2354 ( 76%)]  Loss: 1.097 (1.40)  Time: 0.470s,   17.02/s  (0.478s,   16.74/s)  LR: 2.803e-05  Data: 0.009 (0.008)\n",
            "Train: 52 [1850/2354 ( 79%)]  Loss: 1.091 (1.40)  Time: 0.468s,   17.10/s  (0.478s,   16.75/s)  LR: 2.803e-05  Data: 0.007 (0.008)\n",
            "Train: 52 [1900/2354 ( 81%)]  Loss: 0.9755 (1.41)  Time: 0.471s,   17.00/s  (0.477s,   16.76/s)  LR: 2.803e-05  Data: 0.007 (0.008)\n",
            "Train: 52 [1950/2354 ( 83%)]  Loss: 0.9691 (1.41)  Time: 0.469s,   17.07/s  (0.477s,   16.76/s)  LR: 2.803e-05  Data: 0.008 (0.008)\n",
            "Train: 52 [2000/2354 ( 85%)]  Loss: 1.543 (1.41)  Time: 0.461s,   17.37/s  (0.477s,   16.77/s)  LR: 2.803e-05  Data: 0.007 (0.008)\n",
            "Train: 52 [2050/2354 ( 87%)]  Loss: 1.383 (1.41)  Time: 0.469s,   17.06/s  (0.477s,   16.76/s)  LR: 2.803e-05  Data: 0.008 (0.008)\n",
            "Train: 52 [2100/2354 ( 89%)]  Loss: 2.045 (1.41)  Time: 0.480s,   16.68/s  (0.477s,   16.77/s)  LR: 2.803e-05  Data: 0.007 (0.008)\n",
            "Train: 52 [2150/2354 ( 91%)]  Loss: 0.9996 (1.41)  Time: 0.462s,   17.30/s  (0.477s,   16.77/s)  LR: 2.803e-05  Data: 0.006 (0.008)\n",
            "Train: 52 [2200/2354 ( 93%)]  Loss: 1.542 (1.41)  Time: 0.472s,   16.94/s  (0.477s,   16.78/s)  LR: 2.803e-05  Data: 0.007 (0.008)\n",
            "Train: 52 [2250/2354 ( 96%)]  Loss: 1.486 (1.41)  Time: 0.464s,   17.26/s  (0.477s,   16.78/s)  LR: 2.803e-05  Data: 0.007 (0.008)\n",
            "Train: 52 [2300/2354 ( 98%)]  Loss: 1.418 (1.41)  Time: 0.469s,   17.06/s  (0.477s,   16.77/s)  LR: 2.803e-05  Data: 0.010 (0.008)\n",
            "Train: 52 [2350/2354 (100%)]  Loss: 1.024 (1.41)  Time: 0.466s,   17.17/s  (0.477s,   16.78/s)  LR: 2.803e-05  Data: 0.006 (0.008)\n",
            "Train: 52 [2353/2354 (100%)]  Loss: 0.9587 (1.42)  Time: 0.459s,   17.42/s  (0.477s,   16.78/s)  LR: 2.803e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.603 (0.603)  Loss:  0.1771 (0.1771)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.163 (0.161)  Loss:  0.0673 (0.1211)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.133 (0.152)  Loss:  0.0704 (0.1139)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.212 (0.150)  Loss:  0.0926 (0.1193)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.180 (0.148)  Loss:  0.1455 (0.1255)  Acc@1: 100.0000 (99.7512)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.100 (0.148)  Loss:  0.1200 (0.1282)  Acc@1: 100.0000 (99.8008)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.217 (0.148)  Loss:  0.2952 (0.1309)  Acc@1: 100.0000 (99.7508)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.095 (0.147)  Loss:  0.0577 (0.1488)  Acc@1: 100.0000 (99.7863)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.117 (0.148)  Loss:  0.1252 (0.1496)  Acc@1: 100.0000 (99.8130)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.233 (0.147)  Loss:  0.1450 (0.1481)  Acc@1: 100.0000 (99.7783)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.180 (0.148)  Loss:  0.0841 (0.1475)  Acc@1: 100.0000 (99.8004)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.183 (0.148)  Loss:  0.1018 (0.1471)  Acc@1: 100.0000 (99.8185)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.221 (0.151)  Loss:  0.1276 (0.1432)  Acc@1: 100.0000 (99.8336)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.151 (0.151)  Loss:  0.1312 (0.1418)  Acc@1: 100.0000 (99.8464)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.177 (0.151)  Loss:  0.0643 (0.1401)  Acc@1: 100.0000 (99.8217)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.169 (0.151)  Loss:  0.1913 (0.1394)  Acc@1: 100.0000 (99.8003)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.140 (0.151)  Loss:  0.1113 (0.1400)  Acc@1: 100.0000 (99.7815)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.126 (0.150)  Loss:  0.1562 (0.1396)  Acc@1: 100.0000 (99.7944)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.157 (0.150)  Loss:  0.2037 (0.1408)  Acc@1: 100.0000 (99.8058)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.140 (0.150)  Loss:  0.1531 (0.1400)  Acc@1: 100.0000 (99.8160)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.096 (0.150)  Loss:  0.0971 (0.1408)  Acc@1: 100.0000 (99.8252)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.106 (0.150)  Loss:  0.0773 (0.1392)  Acc@1: 100.0000 (99.8335)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.168 (0.149)  Loss:  0.0855 (0.1394)  Acc@1: 100.0000 (99.8183)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.146 (0.149)  Loss:  0.7505 (0.1399)  Acc@1: 100.0000 (99.8262)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.085 (0.149)  Loss:  0.2491 (0.1418)  Acc@1: 100.0000 (99.7710)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.141 (0.149)  Loss:  0.1395 (0.1406)  Acc@1: 100.0000 (99.7802)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.157 (0.149)  Loss:  0.1104 (0.1409)  Acc@1: 100.0000 (99.7694)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.155 (0.149)  Loss:  0.0906 (0.1402)  Acc@1: 100.0000 (99.7779)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.105 (0.150)  Loss:  0.1212 (0.1402)  Acc@1: 100.0000 (99.7680)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.092 (0.150)  Loss:  0.1078 (0.1408)  Acc@1: 100.0000 (99.7760)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.173 (0.150)  Loss:  0.1109 (0.1402)  Acc@1: 100.0000 (99.7668)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.180 (0.150)  Loss:  0.0835 (0.1415)  Acc@1: 100.0000 (99.7743)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.128 (0.150)  Loss:  0.0968 (0.1420)  Acc@1: 100.0000 (99.7502)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.167 (0.150)  Loss:  0.0765 (0.1413)  Acc@1: 100.0000 (99.7426)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.187 (0.150)  Loss:  0.1388 (0.1407)  Acc@1: 100.0000 (99.7354)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.216 (0.150)  Loss:  0.1448 (0.1406)  Acc@1: 100.0000 (99.7287)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.090 (0.150)  Loss:  0.1298 (0.1405)  Acc@1: 100.0000 (99.7224)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1850/2354]  Time: 0.176 (0.150)  Loss:  0.0600 (0.1405)  Acc@1: 100.0000 (99.7299)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1900/2354]  Time: 0.173 (0.150)  Loss:  0.1595 (0.1396)  Acc@1: 100.0000 (99.7370)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1950/2354]  Time: 0.135 (0.150)  Loss:  0.0743 (0.1396)  Acc@1: 100.0000 (99.7309)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2000/2354]  Time: 0.155 (0.150)  Loss:  0.1475 (0.1392)  Acc@1: 100.0000 (99.7251)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2050/2354]  Time: 0.132 (0.150)  Loss:  0.0746 (0.1401)  Acc@1: 100.0000 (99.7075)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2100/2354]  Time: 0.158 (0.150)  Loss:  0.2390 (0.1415)  Acc@1: 100.0000 (99.7144)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2150/2354]  Time: 0.098 (0.150)  Loss:  0.2551 (0.1413)  Acc@1: 100.0000 (99.7211)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2200/2354]  Time: 0.204 (0.150)  Loss:  0.1975 (0.1422)  Acc@1: 100.0000 (99.7160)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2250/2354]  Time: 0.201 (0.150)  Loss:  0.0958 (0.1413)  Acc@1: 100.0000 (99.7223)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2300/2354]  Time: 0.117 (0.150)  Loss:  0.0681 (0.1417)  Acc@1: 100.0000 (99.7175)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2350/2354]  Time: 0.075 (0.150)  Loss:  0.1030 (0.1412)  Acc@1: 100.0000 (99.7235)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2354/2354]  Time: 0.068 (0.150)  Loss:  0.0551 (0.1411)  Acc@1: 100.0000 (99.7240)  Acc@5: 100.0000 (100.0000)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-42.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-52.pth.tar', 99.72396220405564)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-50.pth.tar', 99.54347595286124)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-51.pth.tar', 99.52224227625014)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-49.pth.tar', 99.51162543794457)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar', 98.87461513961142)\n",
            "\n",
            "Train: 53 [   0/2354 (  0%)]  Loss: 1.021 (1.02)  Time: 1.363s,    5.87/s  (1.363s,    5.87/s)  LR: 2.631e-05  Data: 0.608 (0.608)\n",
            "Train: 53 [  50/2354 (  2%)]  Loss: 1.951 (1.41)  Time: 0.471s,   16.98/s  (0.506s,   15.82/s)  LR: 2.631e-05  Data: 0.007 (0.019)\n",
            "Train: 53 [ 100/2354 (  4%)]  Loss: 1.078 (1.37)  Time: 0.464s,   17.25/s  (0.489s,   16.37/s)  LR: 2.631e-05  Data: 0.007 (0.014)\n",
            "Train: 53 [ 150/2354 (  6%)]  Loss: 0.9782 (1.34)  Time: 0.463s,   17.28/s  (0.483s,   16.56/s)  LR: 2.631e-05  Data: 0.007 (0.012)\n",
            "Train: 53 [ 200/2354 (  8%)]  Loss: 1.016 (1.32)  Time: 0.478s,   16.75/s  (0.485s,   16.48/s)  LR: 2.631e-05  Data: 0.007 (0.011)\n",
            "Train: 53 [ 250/2354 ( 11%)]  Loss: 1.048 (1.32)  Time: 0.469s,   17.07/s  (0.482s,   16.58/s)  LR: 2.631e-05  Data: 0.008 (0.010)\n",
            "Train: 53 [ 300/2354 ( 13%)]  Loss: 0.9764 (1.33)  Time: 0.463s,   17.28/s  (0.480s,   16.66/s)  LR: 2.631e-05  Data: 0.007 (0.010)\n",
            "Train: 53 [ 350/2354 ( 15%)]  Loss: 1.288 (1.34)  Time: 0.484s,   16.54/s  (0.479s,   16.71/s)  LR: 2.631e-05  Data: 0.007 (0.010)\n",
            "Train: 53 [ 400/2354 ( 17%)]  Loss: 1.025 (1.34)  Time: 0.472s,   16.94/s  (0.478s,   16.74/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [ 450/2354 ( 19%)]  Loss: 1.036 (1.34)  Time: 0.467s,   17.15/s  (0.479s,   16.69/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [ 500/2354 ( 21%)]  Loss: 1.130 (1.35)  Time: 0.468s,   17.08/s  (0.479s,   16.71/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [ 550/2354 ( 23%)]  Loss: 1.061 (1.37)  Time: 0.469s,   17.05/s  (0.478s,   16.73/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [ 600/2354 ( 25%)]  Loss: 0.9540 (1.37)  Time: 0.472s,   16.94/s  (0.478s,   16.74/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [ 650/2354 ( 28%)]  Loss: 1.118 (1.37)  Time: 0.466s,   17.16/s  (0.477s,   16.75/s)  LR: 2.631e-05  Data: 0.009 (0.009)\n",
            "Train: 53 [ 700/2354 ( 30%)]  Loss: 1.426 (1.38)  Time: 0.481s,   16.65/s  (0.479s,   16.71/s)  LR: 2.631e-05  Data: 0.014 (0.009)\n",
            "Train: 53 [ 750/2354 ( 32%)]  Loss: 1.168 (1.38)  Time: 0.470s,   17.00/s  (0.478s,   16.72/s)  LR: 2.631e-05  Data: 0.008 (0.009)\n",
            "Train: 53 [ 800/2354 ( 34%)]  Loss: 1.221 (1.38)  Time: 0.463s,   17.30/s  (0.478s,   16.74/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [ 850/2354 ( 36%)]  Loss: 0.9842 (1.38)  Time: 0.472s,   16.94/s  (0.478s,   16.75/s)  LR: 2.631e-05  Data: 0.010 (0.009)\n",
            "Train: 53 [ 900/2354 ( 38%)]  Loss: 0.9753 (1.38)  Time: 0.472s,   16.96/s  (0.477s,   16.76/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [ 950/2354 ( 40%)]  Loss: 1.280 (1.39)  Time: 0.473s,   16.91/s  (0.478s,   16.72/s)  LR: 2.631e-05  Data: 0.008 (0.009)\n",
            "Train: 53 [1000/2354 ( 42%)]  Loss: 1.328 (1.39)  Time: 0.464s,   17.23/s  (0.478s,   16.73/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [1050/2354 ( 45%)]  Loss: 2.135 (1.39)  Time: 0.479s,   16.71/s  (0.478s,   16.74/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [1100/2354 ( 47%)]  Loss: 1.103 (1.39)  Time: 0.485s,   16.51/s  (0.478s,   16.75/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [1150/2354 ( 49%)]  Loss: 2.125 (1.39)  Time: 0.473s,   16.90/s  (0.477s,   16.76/s)  LR: 2.631e-05  Data: 0.007 (0.009)\n",
            "Train: 53 [1200/2354 ( 51%)]  Loss: 1.159 (1.40)  Time: 0.593s,   13.50/s  (0.478s,   16.75/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1250/2354 ( 53%)]  Loss: 1.043 (1.39)  Time: 0.469s,   17.05/s  (0.478s,   16.74/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1300/2354 ( 55%)]  Loss: 1.498 (1.39)  Time: 0.471s,   16.97/s  (0.478s,   16.75/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1350/2354 ( 57%)]  Loss: 1.027 (1.39)  Time: 0.468s,   17.11/s  (0.477s,   16.76/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1400/2354 ( 59%)]  Loss: 1.629 (1.40)  Time: 0.471s,   16.98/s  (0.477s,   16.77/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1450/2354 ( 62%)]  Loss: 1.539 (1.40)  Time: 0.475s,   16.83/s  (0.477s,   16.77/s)  LR: 2.631e-05  Data: 0.010 (0.008)\n",
            "Train: 53 [1500/2354 ( 64%)]  Loss: 1.058 (1.40)  Time: 0.480s,   16.66/s  (0.477s,   16.76/s)  LR: 2.631e-05  Data: 0.008 (0.008)\n",
            "Train: 53 [1550/2354 ( 66%)]  Loss: 3.061 (1.40)  Time: 0.468s,   17.11/s  (0.477s,   16.76/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1600/2354 ( 68%)]  Loss: 1.153 (1.40)  Time: 0.466s,   17.16/s  (0.477s,   16.77/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1650/2354 ( 70%)]  Loss: 0.9702 (1.40)  Time: 0.472s,   16.95/s  (0.477s,   16.78/s)  LR: 2.631e-05  Data: 0.008 (0.008)\n",
            "Train: 53 [1700/2354 ( 72%)]  Loss: 1.316 (1.40)  Time: 0.469s,   17.07/s  (0.477s,   16.78/s)  LR: 2.631e-05  Data: 0.012 (0.008)\n",
            "Train: 53 [1750/2354 ( 74%)]  Loss: 1.026 (1.40)  Time: 0.468s,   17.09/s  (0.477s,   16.77/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1800/2354 ( 76%)]  Loss: 2.192 (1.40)  Time: 0.468s,   17.08/s  (0.477s,   16.77/s)  LR: 2.631e-05  Data: 0.008 (0.008)\n",
            "Train: 53 [1850/2354 ( 79%)]  Loss: 1.303 (1.40)  Time: 0.466s,   17.18/s  (0.477s,   16.78/s)  LR: 2.631e-05  Data: 0.010 (0.008)\n",
            "Train: 53 [1900/2354 ( 81%)]  Loss: 1.229 (1.40)  Time: 0.473s,   16.90/s  (0.477s,   16.78/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [1950/2354 ( 83%)]  Loss: 1.110 (1.40)  Time: 0.468s,   17.08/s  (0.476s,   16.79/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [2000/2354 ( 85%)]  Loss: 1.541 (1.40)  Time: 0.472s,   16.95/s  (0.477s,   16.78/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [2050/2354 ( 87%)]  Loss: 1.010 (1.40)  Time: 0.467s,   17.13/s  (0.477s,   16.78/s)  LR: 2.631e-05  Data: 0.008 (0.008)\n",
            "Train: 53 [2100/2354 ( 89%)]  Loss: 1.156 (1.40)  Time: 0.475s,   16.83/s  (0.477s,   16.79/s)  LR: 2.631e-05  Data: 0.009 (0.008)\n",
            "Train: 53 [2150/2354 ( 91%)]  Loss: 1.078 (1.40)  Time: 0.468s,   17.09/s  (0.476s,   16.79/s)  LR: 2.631e-05  Data: 0.007 (0.008)\n",
            "Train: 53 [2200/2354 ( 93%)]  Loss: 1.329 (1.40)  Time: 0.478s,   16.73/s  (0.476s,   16.80/s)  LR: 2.631e-05  Data: 0.009 (0.008)\n",
            "Train: 53 [2250/2354 ( 96%)]  Loss: 1.059 (1.41)  Time: 0.467s,   17.11/s  (0.477s,   16.78/s)  LR: 2.631e-05  Data: 0.010 (0.008)\n",
            "Train: 53 [2300/2354 ( 98%)]  Loss: 1.983 (1.40)  Time: 0.468s,   17.11/s  (0.477s,   16.79/s)  LR: 2.631e-05  Data: 0.009 (0.008)\n",
            "Train: 53 [2350/2354 (100%)]  Loss: 1.322 (1.41)  Time: 0.464s,   17.24/s  (0.476s,   16.79/s)  LR: 2.631e-05  Data: 0.006 (0.008)\n",
            "Train: 53 [2353/2354 (100%)]  Loss: 1.084 (1.41)  Time: 0.469s,   17.04/s  (0.476s,   16.79/s)  LR: 2.631e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.620 (0.620)  Loss:  0.1505 (0.1505)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.102 (0.159)  Loss:  0.1300 (0.1391)  Acc@1: 100.0000 (98.5294)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.186 (0.154)  Loss:  0.1121 (0.1275)  Acc@1: 100.0000 (99.2574)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.100 (0.151)  Loss:  0.0707 (0.1310)  Acc@1: 100.0000 (99.3377)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.090 (0.149)  Loss:  0.2576 (0.1342)  Acc@1: 100.0000 (99.3781)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.112 (0.148)  Loss:  0.1083 (0.1289)  Acc@1: 100.0000 (99.5020)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.160 (0.147)  Loss:  0.2483 (0.1283)  Acc@1: 100.0000 (99.5847)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.090 (0.146)  Loss:  0.0712 (0.1403)  Acc@1: 100.0000 (99.5014)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.162 (0.147)  Loss:  0.0695 (0.1376)  Acc@1: 100.0000 (99.5012)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.102 (0.151)  Loss:  0.1339 (0.1366)  Acc@1: 100.0000 (99.5011)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.180 (0.150)  Loss:  0.0728 (0.1364)  Acc@1: 100.0000 (99.5509)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.173 (0.150)  Loss:  0.1080 (0.1352)  Acc@1: 100.0000 (99.5917)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.120 (0.149)  Loss:  0.0762 (0.1337)  Acc@1: 100.0000 (99.6256)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.146 (0.149)  Loss:  0.1065 (0.1314)  Acc@1: 100.0000 (99.6544)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.230 (0.149)  Loss:  0.0955 (0.1307)  Acc@1: 100.0000 (99.6434)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.182 (0.148)  Loss:  0.1215 (0.1298)  Acc@1: 100.0000 (99.6671)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.144 (0.148)  Loss:  0.1242 (0.1314)  Acc@1: 100.0000 (99.6255)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.092 (0.148)  Loss:  0.1434 (0.1325)  Acc@1: 100.0000 (99.6475)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.128 (0.148)  Loss:  0.2321 (0.1312)  Acc@1: 100.0000 (99.6670)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.140 (0.148)  Loss:  0.1377 (0.1304)  Acc@1: 100.0000 (99.6845)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.138 (0.147)  Loss:  0.1261 (0.1287)  Acc@1: 100.0000 (99.7003)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.087 (0.147)  Loss:  0.1678 (0.1275)  Acc@1: 100.0000 (99.7146)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.117 (0.147)  Loss:  0.1035 (0.1285)  Acc@1: 100.0000 (99.7048)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.169 (0.147)  Loss:  0.2893 (0.1285)  Acc@1: 100.0000 (99.7176)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.174 (0.147)  Loss:  0.3379 (0.1301)  Acc@1: 100.0000 (99.6878)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.152 (0.147)  Loss:  0.1091 (0.1290)  Acc@1: 100.0000 (99.7002)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.086 (0.148)  Loss:  0.0778 (0.1296)  Acc@1: 100.0000 (99.6925)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.134 (0.148)  Loss:  0.0840 (0.1298)  Acc@1: 100.0000 (99.7039)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.171 (0.148)  Loss:  0.1152 (0.1298)  Acc@1: 100.0000 (99.6966)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.186 (0.148)  Loss:  0.0803 (0.1296)  Acc@1: 100.0000 (99.7071)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.187 (0.148)  Loss:  0.1333 (0.1300)  Acc@1: 100.0000 (99.7169)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.172 (0.148)  Loss:  0.0814 (0.1318)  Acc@1: 100.0000 (99.7260)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.138 (0.148)  Loss:  0.0811 (0.1323)  Acc@1: 100.0000 (99.7189)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.183 (0.148)  Loss:  0.0763 (0.1333)  Acc@1: 100.0000 (99.7123)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.167 (0.148)  Loss:  0.0743 (0.1329)  Acc@1: 100.0000 (99.7208)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.118 (0.147)  Loss:  0.1287 (0.1339)  Acc@1: 100.0000 (99.6859)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.086 (0.147)  Loss:  0.1929 (0.1348)  Acc@1: 100.0000 (99.6807)  Acc@5: 100.0000 (99.9861)\n",
            "Test: [1850/2354]  Time: 0.167 (0.147)  Loss:  0.0677 (0.1356)  Acc@1: 100.0000 (99.6759)  Acc@5: 100.0000 (99.9865)\n",
            "Test: [1900/2354]  Time: 0.204 (0.147)  Loss:  0.2610 (0.1349)  Acc@1: 100.0000 (99.6844)  Acc@5: 100.0000 (99.9868)\n",
            "Test: [1950/2354]  Time: 0.131 (0.147)  Loss:  0.0697 (0.1346)  Acc@1: 100.0000 (99.6797)  Acc@5: 100.0000 (99.9872)\n",
            "Test: [2000/2354]  Time: 0.192 (0.147)  Loss:  0.1460 (0.1345)  Acc@1: 100.0000 (99.6752)  Acc@5: 100.0000 (99.9875)\n",
            "Test: [2050/2354]  Time: 0.127 (0.147)  Loss:  0.1038 (0.1356)  Acc@1: 100.0000 (99.6343)  Acc@5: 100.0000 (99.9878)\n",
            "Test: [2100/2354]  Time: 0.244 (0.148)  Loss:  0.1984 (0.1372)  Acc@1: 100.0000 (99.6311)  Acc@5: 100.0000 (99.9881)\n",
            "Test: [2150/2354]  Time: 0.157 (0.148)  Loss:  0.2905 (0.1371)  Acc@1: 100.0000 (99.6397)  Acc@5: 100.0000 (99.9884)\n",
            "Test: [2200/2354]  Time: 0.127 (0.148)  Loss:  0.0974 (0.1378)  Acc@1: 100.0000 (99.6365)  Acc@5: 100.0000 (99.9886)\n",
            "Test: [2250/2354]  Time: 0.119 (0.148)  Loss:  0.0812 (0.1373)  Acc@1: 100.0000 (99.6335)  Acc@5: 100.0000 (99.9889)\n",
            "Test: [2300/2354]  Time: 0.184 (0.148)  Loss:  0.0882 (0.1370)  Acc@1: 100.0000 (99.6306)  Acc@5: 100.0000 (99.9891)\n",
            "Test: [2350/2354]  Time: 0.075 (0.147)  Loss:  0.1015 (0.1365)  Acc@1: 100.0000 (99.6385)  Acc@5: 100.0000 (99.9894)\n",
            "Test: [2354/2354]  Time: 0.065 (0.147)  Loss:  0.0859 (0.1365)  Acc@1: 100.0000 (99.6390)  Acc@5: 100.0000 (99.9894)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-43.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-52.pth.tar', 99.72396220405564)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-53.pth.tar', 99.63902749761121)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-50.pth.tar', 99.54347595286124)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-51.pth.tar', 99.52224227625014)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-49.pth.tar', 99.51162543794457)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar', 98.92769933113918)\n",
            "\n",
            "Train: 54 [   0/2354 (  0%)]  Loss: 1.048 (1.05)  Time: 1.201s,    6.66/s  (1.201s,    6.66/s)  LR: 2.464e-05  Data: 0.510 (0.510)\n",
            "Train: 54 [  50/2354 (  2%)]  Loss: 1.597 (1.45)  Time: 0.463s,   17.29/s  (0.504s,   15.86/s)  LR: 2.464e-05  Data: 0.007 (0.018)\n",
            "Train: 54 [ 100/2354 (  4%)]  Loss: 1.444 (1.48)  Time: 0.464s,   17.23/s  (0.487s,   16.42/s)  LR: 2.464e-05  Data: 0.006 (0.013)\n",
            "Train: 54 [ 150/2354 (  6%)]  Loss: 1.498 (1.42)  Time: 0.474s,   16.86/s  (0.481s,   16.62/s)  LR: 2.464e-05  Data: 0.008 (0.011)\n",
            "Train: 54 [ 200/2354 (  8%)]  Loss: 1.982 (1.40)  Time: 0.471s,   16.99/s  (0.484s,   16.53/s)  LR: 2.464e-05  Data: 0.007 (0.011)\n",
            "Train: 54 [ 250/2354 ( 11%)]  Loss: 1.849 (1.42)  Time: 0.473s,   16.91/s  (0.482s,   16.60/s)  LR: 2.464e-05  Data: 0.008 (0.010)\n",
            "Train: 54 [ 300/2354 ( 13%)]  Loss: 2.270 (1.41)  Time: 0.471s,   16.98/s  (0.480s,   16.65/s)  LR: 2.464e-05  Data: 0.009 (0.010)\n",
            "Train: 54 [ 350/2354 ( 15%)]  Loss: 1.037 (1.39)  Time: 0.484s,   16.52/s  (0.479s,   16.69/s)  LR: 2.464e-05  Data: 0.007 (0.010)\n",
            "Train: 54 [ 400/2354 ( 17%)]  Loss: 1.793 (1.38)  Time: 0.468s,   17.08/s  (0.478s,   16.72/s)  LR: 2.464e-05  Data: 0.010 (0.009)\n",
            "Train: 54 [ 450/2354 ( 19%)]  Loss: 1.064 (1.39)  Time: 0.475s,   16.83/s  (0.481s,   16.65/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [ 500/2354 ( 21%)]  Loss: 1.298 (1.38)  Time: 0.475s,   16.86/s  (0.480s,   16.68/s)  LR: 2.464e-05  Data: 0.010 (0.009)\n",
            "Train: 54 [ 550/2354 ( 23%)]  Loss: 1.690 (1.38)  Time: 0.468s,   17.09/s  (0.479s,   16.71/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [ 600/2354 ( 25%)]  Loss: 1.183 (1.39)  Time: 0.471s,   16.98/s  (0.478s,   16.72/s)  LR: 2.464e-05  Data: 0.008 (0.009)\n",
            "Train: 54 [ 650/2354 ( 28%)]  Loss: 1.935 (1.39)  Time: 0.474s,   16.88/s  (0.478s,   16.74/s)  LR: 2.464e-05  Data: 0.009 (0.009)\n",
            "Train: 54 [ 700/2354 ( 30%)]  Loss: 1.168 (1.38)  Time: 0.476s,   16.80/s  (0.479s,   16.70/s)  LR: 2.464e-05  Data: 0.010 (0.009)\n",
            "Train: 54 [ 750/2354 ( 32%)]  Loss: 0.9694 (1.39)  Time: 0.464s,   17.24/s  (0.479s,   16.72/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [ 800/2354 ( 34%)]  Loss: 2.351 (1.39)  Time: 0.466s,   17.16/s  (0.478s,   16.73/s)  LR: 2.464e-05  Data: 0.010 (0.009)\n",
            "Train: 54 [ 850/2354 ( 36%)]  Loss: 1.052 (1.39)  Time: 0.481s,   16.62/s  (0.478s,   16.75/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [ 900/2354 ( 38%)]  Loss: 1.229 (1.39)  Time: 0.464s,   17.24/s  (0.477s,   16.77/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [ 950/2354 ( 40%)]  Loss: 1.164 (1.39)  Time: 0.468s,   17.11/s  (0.477s,   16.78/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [1000/2354 ( 42%)]  Loss: 2.084 (1.39)  Time: 0.466s,   17.15/s  (0.477s,   16.76/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [1050/2354 ( 45%)]  Loss: 1.162 (1.39)  Time: 0.475s,   16.85/s  (0.477s,   16.78/s)  LR: 2.464e-05  Data: 0.009 (0.009)\n",
            "Train: 54 [1100/2354 ( 47%)]  Loss: 1.365 (1.38)  Time: 0.467s,   17.15/s  (0.476s,   16.80/s)  LR: 2.464e-05  Data: 0.010 (0.009)\n",
            "Train: 54 [1150/2354 ( 49%)]  Loss: 0.9570 (1.38)  Time: 0.466s,   17.16/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [1200/2354 ( 51%)]  Loss: 1.022 (1.38)  Time: 0.472s,   16.96/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.009 (0.009)\n",
            "Train: 54 [1250/2354 ( 53%)]  Loss: 0.9539 (1.39)  Time: 0.468s,   17.09/s  (0.476s,   16.79/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [1300/2354 ( 55%)]  Loss: 1.639 (1.39)  Time: 0.471s,   17.00/s  (0.476s,   16.80/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [1350/2354 ( 57%)]  Loss: 1.100 (1.38)  Time: 0.473s,   16.93/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [1400/2354 ( 59%)]  Loss: 1.468 (1.38)  Time: 0.472s,   16.96/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.011 (0.009)\n",
            "Train: 54 [1450/2354 ( 62%)]  Loss: 1.638 (1.38)  Time: 0.467s,   17.15/s  (0.476s,   16.82/s)  LR: 2.464e-05  Data: 0.011 (0.009)\n",
            "Train: 54 [1500/2354 ( 64%)]  Loss: 1.056 (1.38)  Time: 0.465s,   17.22/s  (0.476s,   16.80/s)  LR: 2.464e-05  Data: 0.007 (0.009)\n",
            "Train: 54 [1550/2354 ( 66%)]  Loss: 1.094 (1.38)  Time: 0.476s,   16.82/s  (0.476s,   16.80/s)  LR: 2.464e-05  Data: 0.010 (0.009)\n",
            "Train: 54 [1600/2354 ( 68%)]  Loss: 3.804 (1.39)  Time: 0.472s,   16.93/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.010 (0.009)\n",
            "Train: 54 [1650/2354 ( 70%)]  Loss: 1.106 (1.38)  Time: 0.470s,   17.02/s  (0.476s,   16.82/s)  LR: 2.464e-05  Data: 0.009 (0.008)\n",
            "Train: 54 [1700/2354 ( 72%)]  Loss: 1.845 (1.39)  Time: 0.482s,   16.60/s  (0.476s,   16.82/s)  LR: 2.464e-05  Data: 0.008 (0.008)\n",
            "Train: 54 [1750/2354 ( 74%)]  Loss: 0.9659 (1.38)  Time: 0.468s,   17.08/s  (0.476s,   16.80/s)  LR: 2.464e-05  Data: 0.007 (0.008)\n",
            "Train: 54 [1800/2354 ( 76%)]  Loss: 1.007 (1.38)  Time: 0.461s,   17.35/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.007 (0.008)\n",
            "Train: 54 [1850/2354 ( 79%)]  Loss: 0.9676 (1.38)  Time: 0.467s,   17.13/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.007 (0.008)\n",
            "Train: 54 [1900/2354 ( 81%)]  Loss: 1.797 (1.38)  Time: 0.482s,   16.60/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.010 (0.008)\n",
            "Train: 54 [1950/2354 ( 83%)]  Loss: 1.961 (1.38)  Time: 0.469s,   17.06/s  (0.476s,   16.82/s)  LR: 2.464e-05  Data: 0.010 (0.008)\n",
            "Train: 54 [2000/2354 ( 85%)]  Loss: 1.078 (1.38)  Time: 0.478s,   16.73/s  (0.476s,   16.82/s)  LR: 2.464e-05  Data: 0.010 (0.008)\n",
            "Train: 54 [2050/2354 ( 87%)]  Loss: 1.018 (1.38)  Time: 0.480s,   16.65/s  (0.476s,   16.80/s)  LR: 2.464e-05  Data: 0.009 (0.008)\n",
            "Train: 54 [2100/2354 ( 89%)]  Loss: 0.9847 (1.39)  Time: 0.471s,   16.97/s  (0.476s,   16.80/s)  LR: 2.464e-05  Data: 0.007 (0.008)\n",
            "Train: 54 [2150/2354 ( 91%)]  Loss: 1.210 (1.39)  Time: 0.461s,   17.35/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.007 (0.008)\n",
            "Train: 54 [2200/2354 ( 93%)]  Loss: 2.570 (1.39)  Time: 0.474s,   16.87/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.007 (0.008)\n",
            "Train: 54 [2250/2354 ( 96%)]  Loss: 1.618 (1.39)  Time: 0.477s,   16.76/s  (0.476s,   16.82/s)  LR: 2.464e-05  Data: 0.007 (0.008)\n",
            "Train: 54 [2300/2354 ( 98%)]  Loss: 2.252 (1.39)  Time: 0.468s,   17.11/s  (0.476s,   16.80/s)  LR: 2.464e-05  Data: 0.007 (0.008)\n",
            "Train: 54 [2350/2354 (100%)]  Loss: 0.9914 (1.39)  Time: 0.463s,   17.29/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.006 (0.008)\n",
            "Train: 54 [2353/2354 (100%)]  Loss: 2.317 (1.39)  Time: 0.455s,   17.59/s  (0.476s,   16.81/s)  LR: 2.464e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.702 (0.702)  Loss:  0.0960 (0.0960)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.094 (0.160)  Loss:  0.1034 (0.1128)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.121 (0.153)  Loss:  0.0814 (0.1063)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.170 (0.152)  Loss:  0.0649 (0.1139)  Acc@1: 100.0000 (99.6689)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.180 (0.150)  Loss:  0.1085 (0.1130)  Acc@1: 100.0000 (99.6269)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.177 (0.149)  Loss:  0.0638 (0.1137)  Acc@1: 100.0000 (99.7012)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.167 (0.150)  Loss:  0.2015 (0.1164)  Acc@1: 100.0000 (99.7508)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.121 (0.149)  Loss:  0.2213 (0.1248)  Acc@1: 100.0000 (99.5726)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.214 (0.149)  Loss:  0.0877 (0.1294)  Acc@1: 100.0000 (99.5636)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.148 (0.148)  Loss:  0.1174 (0.1290)  Acc@1: 100.0000 (99.5565)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.082 (0.148)  Loss:  0.1653 (0.1317)  Acc@1: 100.0000 (99.6008)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.108 (0.148)  Loss:  0.1212 (0.1304)  Acc@1: 100.0000 (99.6370)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.117 (0.151)  Loss:  0.0910 (0.1286)  Acc@1: 100.0000 (99.6672)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.083 (0.150)  Loss:  0.1041 (0.1277)  Acc@1: 100.0000 (99.6928)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.168 (0.150)  Loss:  0.0912 (0.1268)  Acc@1: 100.0000 (99.7147)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.104 (0.150)  Loss:  0.0598 (0.1251)  Acc@1: 100.0000 (99.7004)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.166 (0.150)  Loss:  0.0961 (0.1257)  Acc@1: 100.0000 (99.6879)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.130 (0.149)  Loss:  0.1356 (0.1258)  Acc@1: 100.0000 (99.7062)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.172 (0.149)  Loss:  0.1036 (0.1243)  Acc@1: 100.0000 (99.7225)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.141 (0.149)  Loss:  0.1653 (0.1241)  Acc@1: 100.0000 (99.7371)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.083 (0.149)  Loss:  0.0578 (0.1239)  Acc@1: 100.0000 (99.7502)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.200 (0.149)  Loss:  0.0906 (0.1237)  Acc@1: 100.0000 (99.7621)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.128 (0.149)  Loss:  0.1093 (0.1236)  Acc@1: 100.0000 (99.7729)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.156 (0.149)  Loss:  0.3914 (0.1232)  Acc@1: 100.0000 (99.7828)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.207 (0.148)  Loss:  0.2289 (0.1239)  Acc@1: 100.0000 (99.7710)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.135 (0.148)  Loss:  0.1161 (0.1235)  Acc@1: 100.0000 (99.7802)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.224 (0.148)  Loss:  0.0660 (0.1234)  Acc@1: 100.0000 (99.7886)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.119 (0.148)  Loss:  0.0629 (0.1238)  Acc@1: 100.0000 (99.7779)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.098 (0.148)  Loss:  0.1083 (0.1240)  Acc@1: 100.0000 (99.7859)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.147 (0.149)  Loss:  0.1160 (0.1246)  Acc@1: 100.0000 (99.7932)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.121 (0.149)  Loss:  0.1473 (0.1238)  Acc@1: 100.0000 (99.8001)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.163 (0.149)  Loss:  0.1320 (0.1247)  Acc@1: 100.0000 (99.7905)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.123 (0.149)  Loss:  0.1345 (0.1262)  Acc@1: 100.0000 (99.7502)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.098 (0.149)  Loss:  0.0804 (0.1267)  Acc@1: 100.0000 (99.7426)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.186 (0.149)  Loss:  0.0759 (0.1266)  Acc@1: 100.0000 (99.7354)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.132 (0.149)  Loss:  0.1290 (0.1265)  Acc@1: 100.0000 (99.7430)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.210 (0.149)  Loss:  0.1465 (0.1273)  Acc@1: 100.0000 (99.7363)  Acc@5: 100.0000 (99.9861)\n",
            "Test: [1850/2354]  Time: 0.211 (0.149)  Loss:  0.0753 (0.1270)  Acc@1: 100.0000 (99.7434)  Acc@5: 100.0000 (99.9865)\n",
            "Test: [1900/2354]  Time: 0.206 (0.149)  Loss:  0.2013 (0.1260)  Acc@1: 100.0000 (99.7501)  Acc@5: 100.0000 (99.9868)\n",
            "Test: [1950/2354]  Time: 0.163 (0.149)  Loss:  0.0856 (0.1261)  Acc@1: 100.0000 (99.7565)  Acc@5: 100.0000 (99.9872)\n",
            "Test: [2000/2354]  Time: 0.141 (0.149)  Loss:  0.1125 (0.1258)  Acc@1: 100.0000 (99.7501)  Acc@5: 100.0000 (99.9875)\n",
            "Test: [2050/2354]  Time: 0.205 (0.149)  Loss:  0.0666 (0.1271)  Acc@1: 100.0000 (99.7196)  Acc@5: 100.0000 (99.9878)\n",
            "Test: [2100/2354]  Time: 0.159 (0.149)  Loss:  0.2852 (0.1276)  Acc@1: 100.0000 (99.7263)  Acc@5: 100.0000 (99.9881)\n",
            "Test: [2150/2354]  Time: 0.154 (0.149)  Loss:  0.2834 (0.1279)  Acc@1: 100.0000 (99.7327)  Acc@5: 100.0000 (99.9884)\n",
            "Test: [2200/2354]  Time: 0.151 (0.148)  Loss:  0.1257 (0.1285)  Acc@1: 100.0000 (99.7274)  Acc@5: 100.0000 (99.9886)\n",
            "Test: [2250/2354]  Time: 0.171 (0.148)  Loss:  0.0606 (0.1280)  Acc@1: 100.0000 (99.7223)  Acc@5: 100.0000 (99.9889)\n",
            "Test: [2300/2354]  Time: 0.201 (0.149)  Loss:  0.0942 (0.1275)  Acc@1: 100.0000 (99.7284)  Acc@5: 100.0000 (99.9891)\n",
            "Test: [2350/2354]  Time: 0.074 (0.149)  Loss:  0.0679 (0.1272)  Acc@1: 100.0000 (99.7342)  Acc@5: 100.0000 (99.9894)\n",
            "Test: [2354/2354]  Time: 0.065 (0.149)  Loss:  0.0399 (0.1271)  Acc@1: 100.0000 (99.7346)  Acc@5: 100.0000 (99.9894)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-45.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-54.pth.tar', 99.73457904236119)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-52.pth.tar', 99.72396220405564)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-53.pth.tar', 99.63902749761121)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-50.pth.tar', 99.54347595286124)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-51.pth.tar', 99.52224227625014)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-49.pth.tar', 99.51162543794457)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar', 98.92769933113918)\n",
            "\n",
            "Train: 55 [   0/2354 (  0%)]  Loss: 1.283 (1.28)  Time: 1.331s,    6.01/s  (1.331s,    6.01/s)  LR: 2.300e-05  Data: 0.568 (0.568)\n",
            "Train: 55 [  50/2354 (  2%)]  Loss: 1.144 (1.43)  Time: 0.479s,   16.71/s  (0.503s,   15.90/s)  LR: 2.300e-05  Data: 0.007 (0.019)\n",
            "Train: 55 [ 100/2354 (  4%)]  Loss: 1.281 (1.35)  Time: 0.467s,   17.14/s  (0.486s,   16.45/s)  LR: 2.300e-05  Data: 0.010 (0.013)\n",
            "Train: 55 [ 150/2354 (  6%)]  Loss: 1.768 (1.31)  Time: 0.464s,   17.23/s  (0.481s,   16.65/s)  LR: 2.300e-05  Data: 0.008 (0.012)\n",
            "Train: 55 [ 200/2354 (  8%)]  Loss: 1.321 (1.35)  Time: 0.472s,   16.93/s  (0.478s,   16.75/s)  LR: 2.300e-05  Data: 0.010 (0.011)\n",
            "Train: 55 [ 250/2354 ( 11%)]  Loss: 1.258 (1.35)  Time: 0.468s,   17.09/s  (0.480s,   16.68/s)  LR: 2.300e-05  Data: 0.011 (0.010)\n",
            "Train: 55 [ 300/2354 ( 13%)]  Loss: 1.022 (1.35)  Time: 0.471s,   16.97/s  (0.478s,   16.74/s)  LR: 2.300e-05  Data: 0.007 (0.010)\n",
            "Train: 55 [ 350/2354 ( 15%)]  Loss: 1.076 (1.36)  Time: 0.467s,   17.12/s  (0.477s,   16.79/s)  LR: 2.300e-05  Data: 0.009 (0.010)\n",
            "Train: 55 [ 400/2354 ( 17%)]  Loss: 1.420 (1.36)  Time: 0.470s,   17.03/s  (0.476s,   16.82/s)  LR: 2.300e-05  Data: 0.008 (0.009)\n",
            "Train: 55 [ 450/2354 ( 19%)]  Loss: 0.9907 (1.35)  Time: 0.483s,   16.56/s  (0.475s,   16.85/s)  LR: 2.300e-05  Data: 0.008 (0.009)\n",
            "Train: 55 [ 500/2354 ( 21%)]  Loss: 1.507 (1.35)  Time: 0.531s,   15.06/s  (0.475s,   16.84/s)  LR: 2.300e-05  Data: 0.007 (0.009)\n",
            "Train: 55 [ 550/2354 ( 23%)]  Loss: 2.081 (1.36)  Time: 0.467s,   17.12/s  (0.475s,   16.83/s)  LR: 2.300e-05  Data: 0.007 (0.009)\n",
            "Train: 55 [ 600/2354 ( 25%)]  Loss: 1.542 (1.36)  Time: 0.463s,   17.29/s  (0.475s,   16.86/s)  LR: 2.300e-05  Data: 0.006 (0.009)\n",
            "Train: 55 [ 650/2354 ( 28%)]  Loss: 1.224 (1.36)  Time: 0.461s,   17.36/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.009 (0.009)\n",
            "Train: 55 [ 700/2354 ( 30%)]  Loss: 1.195 (1.36)  Time: 0.469s,   17.07/s  (0.474s,   16.89/s)  LR: 2.300e-05  Data: 0.009 (0.009)\n",
            "Train: 55 [ 750/2354 ( 32%)]  Loss: 2.109 (1.36)  Time: 0.469s,   17.06/s  (0.474s,   16.89/s)  LR: 2.300e-05  Data: 0.007 (0.009)\n",
            "Train: 55 [ 800/2354 ( 34%)]  Loss: 2.115 (1.37)  Time: 0.463s,   17.26/s  (0.475s,   16.86/s)  LR: 2.300e-05  Data: 0.007 (0.009)\n",
            "Train: 55 [ 850/2354 ( 36%)]  Loss: 1.072 (1.36)  Time: 0.469s,   17.07/s  (0.474s,   16.86/s)  LR: 2.300e-05  Data: 0.010 (0.009)\n",
            "Train: 55 [ 900/2354 ( 38%)]  Loss: 2.338 (1.36)  Time: 0.484s,   16.55/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.010 (0.009)\n",
            "Train: 55 [ 950/2354 ( 40%)]  Loss: 0.9720 (1.37)  Time: 0.466s,   17.18/s  (0.474s,   16.88/s)  LR: 2.300e-05  Data: 0.007 (0.009)\n",
            "Train: 55 [1000/2354 ( 42%)]  Loss: 1.085 (1.37)  Time: 0.462s,   17.33/s  (0.474s,   16.89/s)  LR: 2.300e-05  Data: 0.006 (0.009)\n",
            "Train: 55 [1050/2354 ( 45%)]  Loss: 0.9997 (1.37)  Time: 0.480s,   16.67/s  (0.474s,   16.86/s)  LR: 2.300e-05  Data: 0.007 (0.009)\n",
            "Train: 55 [1100/2354 ( 47%)]  Loss: 1.072 (1.37)  Time: 0.479s,   16.72/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.010 (0.009)\n",
            "Train: 55 [1150/2354 ( 49%)]  Loss: 1.069 (1.36)  Time: 0.477s,   16.78/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.010 (0.009)\n",
            "Train: 55 [1200/2354 ( 51%)]  Loss: 1.057 (1.37)  Time: 0.477s,   16.77/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.010 (0.009)\n",
            "Train: 55 [1250/2354 ( 53%)]  Loss: 1.086 (1.36)  Time: 0.470s,   17.02/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.010 (0.009)\n",
            "Train: 55 [1300/2354 ( 55%)]  Loss: 1.234 (1.36)  Time: 0.477s,   16.77/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.008 (0.009)\n",
            "Train: 55 [1350/2354 ( 57%)]  Loss: 2.003 (1.36)  Time: 0.463s,   17.28/s  (0.475s,   16.84/s)  LR: 2.300e-05  Data: 0.008 (0.009)\n",
            "Train: 55 [1400/2354 ( 59%)]  Loss: 1.787 (1.36)  Time: 0.466s,   17.15/s  (0.475s,   16.84/s)  LR: 2.300e-05  Data: 0.007 (0.009)\n",
            "Train: 55 [1450/2354 ( 62%)]  Loss: 1.765 (1.37)  Time: 0.486s,   16.45/s  (0.475s,   16.84/s)  LR: 2.300e-05  Data: 0.009 (0.009)\n",
            "Train: 55 [1500/2354 ( 64%)]  Loss: 1.486 (1.36)  Time: 0.467s,   17.11/s  (0.475s,   16.85/s)  LR: 2.300e-05  Data: 0.009 (0.009)\n",
            "Train: 55 [1550/2354 ( 66%)]  Loss: 1.249 (1.36)  Time: 0.468s,   17.09/s  (0.475s,   16.86/s)  LR: 2.300e-05  Data: 0.009 (0.008)\n",
            "Train: 55 [1600/2354 ( 68%)]  Loss: 1.762 (1.37)  Time: 0.466s,   17.15/s  (0.475s,   16.84/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [1650/2354 ( 70%)]  Loss: 1.006 (1.37)  Time: 0.472s,   16.96/s  (0.475s,   16.85/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [1700/2354 ( 72%)]  Loss: 2.444 (1.37)  Time: 0.461s,   17.34/s  (0.475s,   16.86/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [1750/2354 ( 74%)]  Loss: 1.488 (1.37)  Time: 0.465s,   17.21/s  (0.474s,   16.86/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [1800/2354 ( 76%)]  Loss: 0.9738 (1.37)  Time: 0.470s,   17.02/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.008 (0.008)\n",
            "Train: 55 [1850/2354 ( 79%)]  Loss: 1.704 (1.37)  Time: 0.576s,   13.90/s  (0.475s,   16.86/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [1900/2354 ( 81%)]  Loss: 1.017 (1.37)  Time: 0.467s,   17.15/s  (0.474s,   16.86/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [1950/2354 ( 83%)]  Loss: 2.084 (1.37)  Time: 0.473s,   16.90/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [2000/2354 ( 85%)]  Loss: 1.674 (1.37)  Time: 0.463s,   17.27/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [2050/2354 ( 87%)]  Loss: 1.130 (1.38)  Time: 0.463s,   17.28/s  (0.474s,   16.88/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [2100/2354 ( 89%)]  Loss: 1.007 (1.38)  Time: 0.462s,   17.30/s  (0.474s,   16.88/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [2150/2354 ( 91%)]  Loss: 1.726 (1.38)  Time: 0.470s,   17.03/s  (0.474s,   16.87/s)  LR: 2.300e-05  Data: 0.010 (0.008)\n",
            "Train: 55 [2200/2354 ( 93%)]  Loss: 1.887 (1.38)  Time: 0.469s,   17.06/s  (0.474s,   16.88/s)  LR: 2.300e-05  Data: 0.011 (0.008)\n",
            "Train: 55 [2250/2354 ( 96%)]  Loss: 1.348 (1.38)  Time: 0.466s,   17.17/s  (0.474s,   16.88/s)  LR: 2.300e-05  Data: 0.008 (0.008)\n",
            "Train: 55 [2300/2354 ( 98%)]  Loss: 1.501 (1.38)  Time: 0.469s,   17.07/s  (0.474s,   16.89/s)  LR: 2.300e-05  Data: 0.007 (0.008)\n",
            "Train: 55 [2350/2354 (100%)]  Loss: 1.720 (1.38)  Time: 0.470s,   17.00/s  (0.474s,   16.89/s)  LR: 2.300e-05  Data: 0.006 (0.008)\n",
            "Train: 55 [2353/2354 (100%)]  Loss: 1.253 (1.38)  Time: 0.456s,   17.56/s  (0.474s,   16.89/s)  LR: 2.300e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.648 (0.648)  Loss:  0.0922 (0.0922)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.166 (0.158)  Loss:  0.1129 (0.1348)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.144 (0.148)  Loss:  0.0931 (0.1231)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.129 (0.159)  Loss:  0.0853 (0.1252)  Acc@1: 100.0000 (99.6689)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.176 (0.156)  Loss:  0.1213 (0.1243)  Acc@1: 100.0000 (99.5025)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.187 (0.153)  Loss:  0.1051 (0.1218)  Acc@1: 100.0000 (99.6016)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.165 (0.151)  Loss:  0.3547 (0.1198)  Acc@1: 100.0000 (99.6678)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.098 (0.150)  Loss:  0.0310 (0.1285)  Acc@1: 100.0000 (99.6439)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.164 (0.149)  Loss:  0.0854 (0.1254)  Acc@1: 100.0000 (99.6883)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.143 (0.148)  Loss:  0.1368 (0.1243)  Acc@1: 100.0000 (99.6674)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.140 (0.148)  Loss:  0.0661 (0.1266)  Acc@1: 100.0000 (99.7006)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.191 (0.148)  Loss:  0.0869 (0.1254)  Acc@1: 100.0000 (99.7278)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.101 (0.148)  Loss:  0.1294 (0.1241)  Acc@1: 100.0000 (99.7504)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.192 (0.148)  Loss:  0.1214 (0.1235)  Acc@1: 100.0000 (99.7696)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.099 (0.147)  Loss:  0.0687 (0.1224)  Acc@1: 100.0000 (99.7860)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.181 (0.147)  Loss:  0.1584 (0.1219)  Acc@1: 100.0000 (99.8003)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.169 (0.147)  Loss:  0.1035 (0.1230)  Acc@1: 100.0000 (99.8127)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.097 (0.147)  Loss:  0.1222 (0.1238)  Acc@1: 100.0000 (99.7944)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.183 (0.146)  Loss:  0.1754 (0.1227)  Acc@1: 100.0000 (99.8058)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.168 (0.146)  Loss:  0.1532 (0.1226)  Acc@1: 100.0000 (99.8160)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.255 (0.147)  Loss:  0.0476 (0.1213)  Acc@1: 100.0000 (99.8252)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.127 (0.148)  Loss:  0.1689 (0.1200)  Acc@1: 100.0000 (99.8335)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.179 (0.147)  Loss:  0.0983 (0.1208)  Acc@1: 100.0000 (99.8183)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.202 (0.147)  Loss:  0.4639 (0.1214)  Acc@1: 100.0000 (99.8262)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.099 (0.147)  Loss:  0.2573 (0.1223)  Acc@1: 100.0000 (99.7918)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.134 (0.147)  Loss:  0.1357 (0.1221)  Acc@1: 100.0000 (99.8002)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.136 (0.147)  Loss:  0.0677 (0.1222)  Acc@1: 100.0000 (99.8078)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.182 (0.147)  Loss:  0.0840 (0.1230)  Acc@1: 100.0000 (99.7964)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.184 (0.147)  Loss:  0.1063 (0.1234)  Acc@1: 100.0000 (99.8037)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.082 (0.146)  Loss:  0.0992 (0.1231)  Acc@1: 100.0000 (99.8105)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.113 (0.146)  Loss:  0.2195 (0.1225)  Acc@1: 100.0000 (99.8168)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.127 (0.146)  Loss:  0.1144 (0.1233)  Acc@1: 100.0000 (99.8227)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.181 (0.146)  Loss:  0.1143 (0.1249)  Acc@1: 100.0000 (99.7814)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.145 (0.146)  Loss:  0.0938 (0.1254)  Acc@1: 100.0000 (99.7880)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.163 (0.146)  Loss:  0.1068 (0.1255)  Acc@1: 100.0000 (99.7942)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.119 (0.146)  Loss:  0.0833 (0.1254)  Acc@1: 100.0000 (99.8001)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.108 (0.146)  Loss:  0.1401 (0.1256)  Acc@1: 100.0000 (99.8057)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1850/2354]  Time: 0.188 (0.146)  Loss:  0.1613 (0.1261)  Acc@1: 100.0000 (99.7974)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1900/2354]  Time: 0.122 (0.147)  Loss:  0.1200 (0.1254)  Acc@1: 100.0000 (99.8027)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1950/2354]  Time: 0.095 (0.147)  Loss:  0.0724 (0.1257)  Acc@1: 100.0000 (99.8078)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2000/2354]  Time: 0.132 (0.147)  Loss:  0.1309 (0.1257)  Acc@1: 100.0000 (99.8001)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2050/2354]  Time: 0.140 (0.147)  Loss:  0.0605 (0.1266)  Acc@1: 100.0000 (99.7928)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2100/2354]  Time: 0.126 (0.147)  Loss:  0.1838 (0.1272)  Acc@1: 100.0000 (99.7977)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2150/2354]  Time: 0.163 (0.147)  Loss:  0.2156 (0.1268)  Acc@1: 100.0000 (99.8024)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2200/2354]  Time: 0.091 (0.147)  Loss:  0.0652 (0.1273)  Acc@1: 100.0000 (99.7955)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2250/2354]  Time: 0.089 (0.147)  Loss:  0.0793 (0.1271)  Acc@1: 100.0000 (99.7890)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2300/2354]  Time: 0.116 (0.147)  Loss:  0.0996 (0.1270)  Acc@1: 100.0000 (99.7936)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2350/2354]  Time: 0.075 (0.147)  Loss:  0.1044 (0.1271)  Acc@1: 100.0000 (99.7980)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2354/2354]  Time: 0.064 (0.146)  Loss:  0.0646 (0.1270)  Acc@1: 100.0000 (99.7983)  Acc@5: 100.0000 (100.0000)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-44.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-55.pth.tar', 99.7982800721945)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-54.pth.tar', 99.73457904236119)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-52.pth.tar', 99.72396220405564)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-53.pth.tar', 99.63902749761121)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-50.pth.tar', 99.54347595286124)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-51.pth.tar', 99.52224227625014)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-49.pth.tar', 99.51162543794457)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar', 99.16126977386135)\n",
            "\n",
            "Train: 56 [   0/2354 (  0%)]  Loss: 2.627 (2.63)  Time: 1.419s,    5.64/s  (1.419s,    5.64/s)  LR: 2.140e-05  Data: 0.737 (0.737)\n",
            "Train: 56 [  50/2354 (  2%)]  Loss: 1.364 (1.42)  Time: 0.475s,   16.84/s  (0.509s,   15.73/s)  LR: 2.140e-05  Data: 0.007 (0.022)\n",
            "Train: 56 [ 100/2354 (  4%)]  Loss: 0.9469 (1.47)  Time: 0.462s,   17.32/s  (0.489s,   16.35/s)  LR: 2.140e-05  Data: 0.007 (0.015)\n",
            "Train: 56 [ 150/2354 (  6%)]  Loss: 1.213 (1.41)  Time: 0.473s,   16.92/s  (0.489s,   16.36/s)  LR: 2.140e-05  Data: 0.007 (0.013)\n",
            "Train: 56 [ 200/2354 (  8%)]  Loss: 0.9819 (1.41)  Time: 0.464s,   17.23/s  (0.484s,   16.54/s)  LR: 2.140e-05  Data: 0.007 (0.012)\n",
            "Train: 56 [ 250/2354 ( 11%)]  Loss: 1.092 (1.37)  Time: 0.465s,   17.21/s  (0.480s,   16.65/s)  LR: 2.140e-05  Data: 0.007 (0.011)\n",
            "Train: 56 [ 300/2354 ( 13%)]  Loss: 1.135 (1.37)  Time: 0.464s,   17.23/s  (0.478s,   16.73/s)  LR: 2.140e-05  Data: 0.007 (0.010)\n",
            "Train: 56 [ 350/2354 ( 15%)]  Loss: 1.085 (1.36)  Time: 0.465s,   17.19/s  (0.477s,   16.78/s)  LR: 2.140e-05  Data: 0.007 (0.010)\n",
            "Train: 56 [ 400/2354 ( 17%)]  Loss: 1.637 (1.37)  Time: 0.484s,   16.54/s  (0.478s,   16.75/s)  LR: 2.140e-05  Data: 0.007 (0.010)\n",
            "Train: 56 [ 450/2354 ( 19%)]  Loss: 1.530 (1.37)  Time: 0.468s,   17.08/s  (0.477s,   16.79/s)  LR: 2.140e-05  Data: 0.010 (0.010)\n",
            "Train: 56 [ 500/2354 ( 21%)]  Loss: 0.9879 (1.36)  Time: 0.463s,   17.28/s  (0.475s,   16.82/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [ 550/2354 ( 23%)]  Loss: 1.021 (1.37)  Time: 0.464s,   17.24/s  (0.475s,   16.85/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [ 600/2354 ( 25%)]  Loss: 1.372 (1.37)  Time: 0.467s,   17.15/s  (0.474s,   16.86/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [ 650/2354 ( 28%)]  Loss: 1.696 (1.37)  Time: 0.476s,   16.80/s  (0.474s,   16.88/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [ 700/2354 ( 30%)]  Loss: 1.296 (1.36)  Time: 0.467s,   17.13/s  (0.475s,   16.84/s)  LR: 2.140e-05  Data: 0.009 (0.009)\n",
            "Train: 56 [ 750/2354 ( 32%)]  Loss: 1.024 (1.36)  Time: 0.461s,   17.34/s  (0.475s,   16.86/s)  LR: 2.140e-05  Data: 0.006 (0.009)\n",
            "Train: 56 [ 800/2354 ( 34%)]  Loss: 1.401 (1.36)  Time: 0.462s,   17.31/s  (0.474s,   16.87/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [ 850/2354 ( 36%)]  Loss: 2.048 (1.36)  Time: 0.482s,   16.58/s  (0.474s,   16.89/s)  LR: 2.140e-05  Data: 0.009 (0.009)\n",
            "Train: 56 [ 900/2354 ( 38%)]  Loss: 1.068 (1.36)  Time: 0.468s,   17.09/s  (0.473s,   16.90/s)  LR: 2.140e-05  Data: 0.008 (0.009)\n",
            "Train: 56 [ 950/2354 ( 40%)]  Loss: 0.9551 (1.35)  Time: 0.467s,   17.13/s  (0.474s,   16.87/s)  LR: 2.140e-05  Data: 0.010 (0.009)\n",
            "Train: 56 [1000/2354 ( 42%)]  Loss: 1.545 (1.35)  Time: 0.470s,   17.04/s  (0.474s,   16.88/s)  LR: 2.140e-05  Data: 0.010 (0.009)\n",
            "Train: 56 [1050/2354 ( 45%)]  Loss: 1.020 (1.35)  Time: 0.477s,   16.78/s  (0.474s,   16.89/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [1100/2354 ( 47%)]  Loss: 1.007 (1.35)  Time: 0.465s,   17.20/s  (0.473s,   16.90/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [1150/2354 ( 49%)]  Loss: 1.686 (1.35)  Time: 0.467s,   17.14/s  (0.473s,   16.91/s)  LR: 2.140e-05  Data: 0.010 (0.009)\n",
            "Train: 56 [1200/2354 ( 51%)]  Loss: 1.045 (1.35)  Time: 0.464s,   17.24/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [1250/2354 ( 53%)]  Loss: 1.215 (1.35)  Time: 0.468s,   17.08/s  (0.474s,   16.89/s)  LR: 2.140e-05  Data: 0.010 (0.009)\n",
            "Train: 56 [1300/2354 ( 55%)]  Loss: 0.9732 (1.35)  Time: 0.467s,   17.15/s  (0.474s,   16.89/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [1350/2354 ( 57%)]  Loss: 1.520 (1.35)  Time: 0.467s,   17.14/s  (0.473s,   16.90/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [1400/2354 ( 59%)]  Loss: 1.188 (1.35)  Time: 0.466s,   17.17/s  (0.473s,   16.91/s)  LR: 2.140e-05  Data: 0.007 (0.009)\n",
            "Train: 56 [1450/2354 ( 62%)]  Loss: 1.050 (1.34)  Time: 0.475s,   16.85/s  (0.473s,   16.91/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [1500/2354 ( 64%)]  Loss: 0.9897 (1.35)  Time: 0.464s,   17.24/s  (0.473s,   16.90/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [1550/2354 ( 66%)]  Loss: 1.259 (1.35)  Time: 0.464s,   17.26/s  (0.473s,   16.90/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [1600/2354 ( 68%)]  Loss: 1.362 (1.35)  Time: 0.478s,   16.74/s  (0.473s,   16.91/s)  LR: 2.140e-05  Data: 0.009 (0.008)\n",
            "Train: 56 [1650/2354 ( 70%)]  Loss: 0.9758 (1.35)  Time: 0.464s,   17.25/s  (0.473s,   16.91/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [1700/2354 ( 72%)]  Loss: 1.887 (1.35)  Time: 0.469s,   17.05/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.010 (0.008)\n",
            "Train: 56 [1750/2354 ( 74%)]  Loss: 2.115 (1.35)  Time: 0.473s,   16.93/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.009 (0.008)\n",
            "Train: 56 [1800/2354 ( 76%)]  Loss: 1.078 (1.35)  Time: 0.466s,   17.17/s  (0.473s,   16.91/s)  LR: 2.140e-05  Data: 0.008 (0.008)\n",
            "Train: 56 [1850/2354 ( 79%)]  Loss: 1.067 (1.35)  Time: 0.470s,   17.02/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [1900/2354 ( 81%)]  Loss: 0.9963 (1.35)  Time: 0.465s,   17.22/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [1950/2354 ( 83%)]  Loss: 1.049 (1.35)  Time: 0.481s,   16.65/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.009 (0.008)\n",
            "Train: 56 [2000/2354 ( 85%)]  Loss: 1.082 (1.35)  Time: 0.465s,   17.20/s  (0.473s,   16.93/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [2050/2354 ( 87%)]  Loss: 1.002 (1.35)  Time: 0.465s,   17.20/s  (0.473s,   16.91/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [2100/2354 ( 89%)]  Loss: 1.191 (1.35)  Time: 0.473s,   16.90/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [2150/2354 ( 91%)]  Loss: 1.926 (1.35)  Time: 0.462s,   17.32/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [2200/2354 ( 93%)]  Loss: 0.9811 (1.35)  Time: 0.461s,   17.34/s  (0.473s,   16.93/s)  LR: 2.140e-05  Data: 0.007 (0.008)\n",
            "Train: 56 [2250/2354 ( 96%)]  Loss: 1.096 (1.35)  Time: 0.467s,   17.12/s  (0.473s,   16.93/s)  LR: 2.140e-05  Data: 0.010 (0.008)\n",
            "Train: 56 [2300/2354 ( 98%)]  Loss: 1.739 (1.35)  Time: 0.468s,   17.09/s  (0.472s,   16.93/s)  LR: 2.140e-05  Data: 0.010 (0.008)\n",
            "Train: 56 [2350/2354 (100%)]  Loss: 1.107 (1.35)  Time: 0.462s,   17.31/s  (0.473s,   16.92/s)  LR: 2.140e-05  Data: 0.005 (0.008)\n",
            "Train: 56 [2353/2354 (100%)]  Loss: 1.965 (1.35)  Time: 0.456s,   17.56/s  (0.473s,   16.93/s)  LR: 2.140e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.682 (0.682)  Loss:  0.1066 (0.1066)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.159 (0.162)  Loss:  0.0981 (0.1177)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.178 (0.153)  Loss:  0.0866 (0.1126)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.166 (0.150)  Loss:  0.0893 (0.1271)  Acc@1: 100.0000 (99.8344)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.124 (0.149)  Loss:  0.1353 (0.1198)  Acc@1: 100.0000 (99.8756)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.163 (0.148)  Loss:  0.1997 (0.1189)  Acc@1: 100.0000 (99.9004)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.192 (0.147)  Loss:  0.2388 (0.1253)  Acc@1: 100.0000 (99.9169)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.165 (0.147)  Loss:  0.0884 (0.1336)  Acc@1: 100.0000 (99.9288)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.114 (0.146)  Loss:  0.0931 (0.1301)  Acc@1: 100.0000 (99.9377)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.130 (0.146)  Loss:  0.0847 (0.1284)  Acc@1: 100.0000 (99.8891)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.182 (0.146)  Loss:  0.1279 (0.1285)  Acc@1: 100.0000 (99.9002)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.193 (0.146)  Loss:  0.0411 (0.1272)  Acc@1: 100.0000 (99.9093)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.127 (0.146)  Loss:  0.1147 (0.1255)  Acc@1: 100.0000 (99.9168)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.136 (0.145)  Loss:  0.1187 (0.1240)  Acc@1: 100.0000 (99.9232)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.110 (0.145)  Loss:  0.0785 (0.1230)  Acc@1: 100.0000 (99.9287)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.157 (0.145)  Loss:  0.1338 (0.1225)  Acc@1: 100.0000 (99.9001)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.172 (0.148)  Loss:  0.1595 (0.1232)  Acc@1: 100.0000 (99.8439)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.176 (0.147)  Loss:  0.0927 (0.1222)  Acc@1: 100.0000 (99.8531)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.082 (0.147)  Loss:  0.2029 (0.1207)  Acc@1: 100.0000 (99.8613)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.138 (0.147)  Loss:  0.1874 (0.1219)  Acc@1: 100.0000 (99.8686)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.083 (0.147)  Loss:  0.1167 (0.1214)  Acc@1: 100.0000 (99.8751)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.128 (0.146)  Loss:  0.2072 (0.1205)  Acc@1: 100.0000 (99.8811)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.118 (0.146)  Loss:  0.0784 (0.1207)  Acc@1: 100.0000 (99.8865)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.078 (0.146)  Loss:  0.5659 (0.1215)  Acc@1: 100.0000 (99.8914)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.157 (0.146)  Loss:  0.1823 (0.1224)  Acc@1: 100.0000 (99.8751)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.129 (0.146)  Loss:  0.0652 (0.1213)  Acc@1: 100.0000 (99.8801)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.150 (0.146)  Loss:  0.0622 (0.1211)  Acc@1: 100.0000 (99.8847)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.202 (0.145)  Loss:  0.0995 (0.1208)  Acc@1: 100.0000 (99.8890)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.088 (0.145)  Loss:  0.1840 (0.1210)  Acc@1: 100.0000 (99.8929)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.159 (0.145)  Loss:  0.0884 (0.1214)  Acc@1: 100.0000 (99.8966)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.198 (0.145)  Loss:  0.1140 (0.1207)  Acc@1: 100.0000 (99.9001)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.169 (0.145)  Loss:  0.1157 (0.1222)  Acc@1: 100.0000 (99.9033)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.174 (0.145)  Loss:  0.0919 (0.1223)  Acc@1: 100.0000 (99.9063)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.214 (0.145)  Loss:  0.1124 (0.1233)  Acc@1: 100.0000 (99.9091)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.079 (0.146)  Loss:  0.0775 (0.1221)  Acc@1: 100.0000 (99.9118)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.190 (0.146)  Loss:  0.0435 (0.1216)  Acc@1: 100.0000 (99.9143)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.152 (0.146)  Loss:  0.1058 (0.1215)  Acc@1: 100.0000 (99.9167)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1850/2354]  Time: 0.133 (0.146)  Loss:  0.0707 (0.1220)  Acc@1: 100.0000 (99.9055)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1900/2354]  Time: 0.180 (0.145)  Loss:  0.1455 (0.1213)  Acc@1: 100.0000 (99.9079)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1950/2354]  Time: 0.106 (0.145)  Loss:  0.0720 (0.1219)  Acc@1: 100.0000 (99.8975)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2000/2354]  Time: 0.123 (0.145)  Loss:  0.1306 (0.1221)  Acc@1: 100.0000 (99.8876)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2050/2354]  Time: 0.152 (0.145)  Loss:  0.1392 (0.1230)  Acc@1: 100.0000 (99.8903)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2100/2354]  Time: 0.192 (0.145)  Loss:  0.3025 (0.1244)  Acc@1: 100.0000 (99.8929)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2150/2354]  Time: 0.187 (0.145)  Loss:  0.3589 (0.1259)  Acc@1: 100.0000 (99.8954)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2200/2354]  Time: 0.143 (0.145)  Loss:  0.1326 (0.1271)  Acc@1: 100.0000 (99.8864)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2250/2354]  Time: 0.161 (0.145)  Loss:  0.0829 (0.1271)  Acc@1: 100.0000 (99.8778)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2300/2354]  Time: 0.134 (0.145)  Loss:  0.0967 (0.1271)  Acc@1: 100.0000 (99.8696)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2350/2354]  Time: 0.075 (0.145)  Loss:  0.1062 (0.1269)  Acc@1: 100.0000 (99.8724)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2354/2354]  Time: 0.073 (0.144)  Loss:  0.0442 (0.1268)  Acc@1: 100.0000 (99.8726)  Acc@5: 100.0000 (100.0000)\n",
            "ERROR: Exception '[Errno 2] No such file or directory: 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-46.pth.tar'' while deleting checkpoint\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-56.pth.tar', 99.87259794033336)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-55.pth.tar', 99.7982800721945)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-54.pth.tar', 99.73457904236119)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-52.pth.tar', 99.72396220405564)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-53.pth.tar', 99.63902749761121)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-50.pth.tar', 99.54347595286124)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-51.pth.tar', 99.52224227625014)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-49.pth.tar', 99.51162543794457)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-48.pth.tar', 99.43730756980571)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/checkpoint-47.pth.tar', 99.23558764200021)\n",
            "\n",
            "Train: 57 [   0/2354 (  0%)]  Loss: 1.033 (1.03)  Time: 1.253s,    6.39/s  (1.253s,    6.39/s)  LR: 1.985e-05  Data: 0.407 (0.407)\n",
            "Train: 57 [  50/2354 (  2%)]  Loss: 1.023 (1.27)  Time: 0.469s,   17.04/s  (0.503s,   15.90/s)  LR: 1.985e-05  Data: 0.010 (0.016)\n",
            "Train: 57 [ 100/2354 (  4%)]  Loss: 0.9613 (1.35)  Time: 0.465s,   17.20/s  (0.495s,   16.18/s)  LR: 1.985e-05  Data: 0.007 (0.012)\n",
            "Train: 57 [ 150/2354 (  6%)]  Loss: 1.086 (1.33)  Time: 0.466s,   17.16/s  (0.486s,   16.45/s)  LR: 1.985e-05  Data: 0.008 (0.011)\n",
            "Train: 57 [ 200/2354 (  8%)]  Loss: 1.059 (1.33)  Time: 0.465s,   17.22/s  (0.482s,   16.60/s)  LR: 1.985e-05  Data: 0.007 (0.010)\n",
            "Train: 57 [ 250/2354 ( 11%)]  Loss: 1.183 (1.33)  Time: 0.465s,   17.19/s  (0.479s,   16.70/s)  LR: 1.985e-05  Data: 0.007 (0.010)\n",
            "Train: 57 [ 300/2354 ( 13%)]  Loss: 0.9830 (1.37)  Time: 0.464s,   17.24/s  (0.477s,   16.77/s)  LR: 1.985e-05  Data: 0.008 (0.009)\n",
            "Train: 57 [ 350/2354 ( 15%)]  Loss: 2.244 (1.36)  Time: 0.466s,   17.15/s  (0.478s,   16.73/s)  LR: 1.985e-05  Data: 0.010 (0.009)\n",
            "Train: 57 [ 400/2354 ( 17%)]  Loss: 1.003 (1.37)  Time: 0.468s,   17.08/s  (0.477s,   16.78/s)  LR: 1.985e-05  Data: 0.007 (0.009)\n",
            "Train: 57 [ 450/2354 ( 19%)]  Loss: 1.789 (1.37)  Time: 0.470s,   17.01/s  (0.476s,   16.81/s)  LR: 1.985e-05  Data: 0.010 (0.009)\n",
            "Train: 57 [ 500/2354 ( 21%)]  Loss: 1.348 (1.37)  Time: 0.471s,   16.97/s  (0.475s,   16.84/s)  LR: 1.985e-05  Data: 0.010 (0.009)\n",
            "Train: 57 [ 550/2354 ( 23%)]  Loss: 1.865 (1.38)  Time: 0.476s,   16.81/s  (0.474s,   16.87/s)  LR: 1.985e-05  Data: 0.007 (0.009)\n",
            "Train: 57 [ 600/2354 ( 25%)]  Loss: 0.9455 (1.38)  Time: 0.465s,   17.20/s  (0.474s,   16.89/s)  LR: 1.985e-05  Data: 0.007 (0.009)\n",
            "Train: 57 [ 650/2354 ( 28%)]  Loss: 1.266 (1.37)  Time: 0.468s,   17.08/s  (0.475s,   16.86/s)  LR: 1.985e-05  Data: 0.009 (0.009)\n",
            "Train: 57 [ 700/2354 ( 30%)]  Loss: 1.289 (1.37)  Time: 0.463s,   17.27/s  (0.474s,   16.88/s)  LR: 1.985e-05  Data: 0.007 (0.009)\n",
            "Train: 57 [ 750/2354 ( 32%)]  Loss: 2.110 (1.37)  Time: 0.476s,   16.80/s  (0.474s,   16.89/s)  LR: 1.985e-05  Data: 0.007 (0.009)\n",
            "Train: 57 [ 800/2354 ( 34%)]  Loss: 0.9519 (1.37)  Time: 0.463s,   17.26/s  (0.473s,   16.90/s)  LR: 1.985e-05  Data: 0.008 (0.009)\n",
            "Train: 57 [ 850/2354 ( 36%)]  Loss: 1.678 (1.37)  Time: 0.465s,   17.20/s  (0.473s,   16.91/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [ 900/2354 ( 38%)]  Loss: 2.111 (1.36)  Time: 0.466s,   17.15/s  (0.474s,   16.88/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [ 950/2354 ( 40%)]  Loss: 1.006 (1.36)  Time: 0.468s,   17.09/s  (0.474s,   16.89/s)  LR: 1.985e-05  Data: 0.010 (0.008)\n",
            "Train: 57 [1000/2354 ( 42%)]  Loss: 2.017 (1.36)  Time: 0.483s,   16.57/s  (0.473s,   16.90/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1050/2354 ( 45%)]  Loss: 2.015 (1.36)  Time: 0.472s,   16.94/s  (0.473s,   16.91/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1100/2354 ( 47%)]  Loss: 2.049 (1.36)  Time: 0.464s,   17.23/s  (0.473s,   16.92/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1150/2354 ( 49%)]  Loss: 0.9746 (1.36)  Time: 0.462s,   17.33/s  (0.473s,   16.93/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1200/2354 ( 51%)]  Loss: 0.9859 (1.35)  Time: 0.476s,   16.82/s  (0.473s,   16.91/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1250/2354 ( 53%)]  Loss: 1.931 (1.36)  Time: 0.466s,   17.18/s  (0.473s,   16.92/s)  LR: 1.985e-05  Data: 0.010 (0.008)\n",
            "Train: 57 [1300/2354 ( 55%)]  Loss: 0.9889 (1.35)  Time: 0.470s,   17.01/s  (0.473s,   16.93/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1350/2354 ( 57%)]  Loss: 2.000 (1.35)  Time: 0.467s,   17.14/s  (0.472s,   16.93/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1400/2354 ( 59%)]  Loss: 0.9674 (1.35)  Time: 0.465s,   17.20/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.010 (0.008)\n",
            "Train: 57 [1450/2354 ( 62%)]  Loss: 1.602 (1.35)  Time: 0.466s,   17.18/s  (0.473s,   16.92/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1500/2354 ( 64%)]  Loss: 1.038 (1.35)  Time: 0.471s,   17.00/s  (0.473s,   16.93/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [1550/2354 ( 66%)]  Loss: 1.630 (1.35)  Time: 0.469s,   17.07/s  (0.473s,   16.93/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [1600/2354 ( 68%)]  Loss: 1.334 (1.35)  Time: 0.466s,   17.18/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [1650/2354 ( 70%)]  Loss: 1.205 (1.35)  Time: 0.469s,   17.07/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.010 (0.008)\n",
            "Train: 57 [1700/2354 ( 72%)]  Loss: 2.233 (1.35)  Time: 0.467s,   17.14/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1750/2354 ( 74%)]  Loss: 1.177 (1.35)  Time: 0.463s,   17.30/s  (0.473s,   16.93/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1800/2354 ( 76%)]  Loss: 0.9846 (1.35)  Time: 0.475s,   16.85/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1850/2354 ( 79%)]  Loss: 1.193 (1.35)  Time: 0.472s,   16.96/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1900/2354 ( 81%)]  Loss: 0.9915 (1.35)  Time: 0.467s,   17.11/s  (0.472s,   16.95/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1950/2354 ( 83%)]  Loss: 1.003 (1.35)  Time: 0.468s,   17.11/s  (0.472s,   16.95/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [2000/2354 ( 85%)]  Loss: 1.191 (1.35)  Time: 0.464s,   17.25/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [2050/2354 ( 87%)]  Loss: 1.880 (1.35)  Time: 0.464s,   17.24/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [2100/2354 ( 89%)]  Loss: 1.005 (1.35)  Time: 0.466s,   17.16/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [2150/2354 ( 91%)]  Loss: 2.062 (1.35)  Time: 0.464s,   17.25/s  (0.472s,   16.95/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [2200/2354 ( 93%)]  Loss: 2.007 (1.35)  Time: 0.480s,   16.66/s  (0.472s,   16.95/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [2250/2354 ( 96%)]  Loss: 1.825 (1.36)  Time: 0.479s,   16.72/s  (0.472s,   16.95/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [2300/2354 ( 98%)]  Loss: 1.367 (1.36)  Time: 0.461s,   17.37/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [2350/2354 (100%)]  Loss: 0.9937 (1.36)  Time: 0.462s,   17.32/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.005 (0.008)\n",
            "Train: 57 [2353/2354 (100%)]  Loss: 1.675 (1.36)  Time: 0.453s,   17.66/s  (0.472s,   16.94/s)  LR: 1.985e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.651 (0.651)  Loss:  0.0912 (0.0912)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.171 (0.160)  Loss:  0.0739 (0.1416)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.137 (0.153)  Loss:  0.0863 (0.1334)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n"
          ]
        }
      ],
      "source": [
        "! python -u -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 --node_rank=0 ./pytorch-image-models/train.py orchidaceae_train --model sequencer2d_l --opt adabelief --lr 0.0001 --epochs 80 --aa v0r-mstd0.5 --aug-splits 2 --jsd-loss --decay-epochs 3 --cooldown-epochs 0 --weight-decay 1e-4 --sched cosine -b 4 --input-size 3 600 600 --num-classes=300 --vflip 0.5 --hflip 0.5 --amp --pretrained --output drive/MyDrive/UNC/H2022/output/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhBwjDtON9GP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24ce5eed-5c21-413e-c0ba-a16a0b2b9aea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Training with a single process on 1 GPUs.\n",
            "Loading pretrained weights from url (https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_l.pth)\n",
            "Downloading: \"https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_l.pth\" to /root/.cache/torch/hub/checkpoints/sequencer2d_l.pth\n",
            "Model sequencer2d_l created, param count:54028716\n",
            "Data processing configuration for current model + dataset:\n",
            "\tinput_size: (3, 600, 600)\n",
            "\tinterpolation: bicubic\n",
            "\tmean: (0.485, 0.456, 0.406)\n",
            "\tstd: (0.229, 0.224, 0.225)\n",
            "\tcrop_pct: 0.875\n",
            "Using native Torch AMP. Training in mixed precision.\n",
            "Restoring model state from checkpoint...\n",
            "Restoring optimizer state from checkpoint...\n",
            "Restoring AMP loss scaler state from checkpoint...\n",
            "Loaded checkpoint 'drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/last.pth.tar' (epoch 56)\n",
            "Scheduled epochs: 80\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Train: 57 [   0/2354 (  0%)]  Loss: 3.452 (3.45)  Time: 7.065s,    1.13/s  (7.065s,    1.13/s)  LR: 1.985e-05  Data: 0.927 (0.927)\n",
            "Train: 57 [  50/2354 (  2%)]  Loss: 2.123 (1.38)  Time: 0.466s,   17.18/s  (0.600s,   13.33/s)  LR: 1.985e-05  Data: 0.008 (0.025)\n",
            "Train: 57 [ 100/2354 (  4%)]  Loss: 1.495 (1.39)  Time: 0.464s,   17.24/s  (0.536s,   14.92/s)  LR: 1.985e-05  Data: 0.006 (0.016)\n",
            "Train: 57 [ 150/2354 (  6%)]  Loss: 1.206 (1.37)  Time: 0.472s,   16.95/s  (0.522s,   15.34/s)  LR: 1.985e-05  Data: 0.006 (0.013)\n",
            "Train: 57 [ 200/2354 (  8%)]  Loss: 0.9620 (1.35)  Time: 0.472s,   16.95/s  (0.509s,   15.73/s)  LR: 1.985e-05  Data: 0.008 (0.012)\n",
            "Train: 57 [ 250/2354 ( 11%)]  Loss: 1.168 (1.35)  Time: 0.464s,   17.23/s  (0.501s,   15.97/s)  LR: 1.985e-05  Data: 0.007 (0.011)\n",
            "Train: 57 [ 300/2354 ( 13%)]  Loss: 0.9611 (1.36)  Time: 0.467s,   17.12/s  (0.496s,   16.14/s)  LR: 1.985e-05  Data: 0.008 (0.011)\n",
            "Train: 57 [ 350/2354 ( 15%)]  Loss: 1.358 (1.39)  Time: 0.465s,   17.19/s  (0.492s,   16.26/s)  LR: 1.985e-05  Data: 0.006 (0.010)\n",
            "Train: 57 [ 400/2354 ( 17%)]  Loss: 1.245 (1.38)  Time: 0.475s,   16.84/s  (0.492s,   16.27/s)  LR: 1.985e-05  Data: 0.010 (0.010)\n",
            "Train: 57 [ 450/2354 ( 19%)]  Loss: 1.163 (1.37)  Time: 0.465s,   17.22/s  (0.489s,   16.35/s)  LR: 1.985e-05  Data: 0.009 (0.010)\n",
            "Train: 57 [ 500/2354 ( 21%)]  Loss: 1.652 (1.37)  Time: 0.468s,   17.11/s  (0.487s,   16.42/s)  LR: 1.985e-05  Data: 0.010 (0.009)\n",
            "Train: 57 [ 550/2354 ( 23%)]  Loss: 1.620 (1.37)  Time: 0.468s,   17.10/s  (0.485s,   16.48/s)  LR: 1.985e-05  Data: 0.006 (0.009)\n",
            "Train: 57 [ 600/2354 ( 25%)]  Loss: 1.023 (1.36)  Time: 0.462s,   17.31/s  (0.484s,   16.53/s)  LR: 1.985e-05  Data: 0.006 (0.009)\n",
            "Train: 57 [ 650/2354 ( 28%)]  Loss: 1.326 (1.36)  Time: 0.563s,   14.21/s  (0.485s,   16.51/s)  LR: 1.985e-05  Data: 0.018 (0.009)\n",
            "Train: 57 [ 700/2354 ( 30%)]  Loss: 1.110 (1.36)  Time: 0.463s,   17.27/s  (0.483s,   16.55/s)  LR: 1.985e-05  Data: 0.006 (0.009)\n",
            "Train: 57 [ 750/2354 ( 32%)]  Loss: 1.015 (1.35)  Time: 0.463s,   17.27/s  (0.482s,   16.58/s)  LR: 1.985e-05  Data: 0.006 (0.009)\n",
            "Train: 57 [ 800/2354 ( 34%)]  Loss: 0.9956 (1.35)  Time: 0.463s,   17.27/s  (0.482s,   16.61/s)  LR: 1.985e-05  Data: 0.006 (0.009)\n",
            "Train: 57 [ 850/2354 ( 36%)]  Loss: 1.199 (1.35)  Time: 0.475s,   16.84/s  (0.481s,   16.63/s)  LR: 1.985e-05  Data: 0.006 (0.009)\n",
            "Train: 57 [ 900/2354 ( 38%)]  Loss: 1.291 (1.35)  Time: 0.522s,   15.33/s  (0.480s,   16.65/s)  LR: 1.985e-05  Data: 0.010 (0.009)\n",
            "Train: 57 [ 950/2354 ( 40%)]  Loss: 1.613 (1.35)  Time: 0.472s,   16.95/s  (0.481s,   16.65/s)  LR: 1.985e-05  Data: 0.008 (0.009)\n",
            "Train: 57 [1000/2354 ( 42%)]  Loss: 0.9821 (1.35)  Time: 0.465s,   17.21/s  (0.480s,   16.67/s)  LR: 1.985e-05  Data: 0.006 (0.009)\n",
            "Train: 57 [1050/2354 ( 45%)]  Loss: 0.9935 (1.35)  Time: 0.463s,   17.26/s  (0.480s,   16.68/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1100/2354 ( 47%)]  Loss: 1.875 (1.35)  Time: 0.468s,   17.09/s  (0.479s,   16.70/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [1150/2354 ( 49%)]  Loss: 1.066 (1.35)  Time: 0.467s,   17.12/s  (0.479s,   16.72/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1200/2354 ( 51%)]  Loss: 1.169 (1.36)  Time: 0.470s,   17.00/s  (0.479s,   16.71/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1250/2354 ( 53%)]  Loss: 2.519 (1.36)  Time: 0.470s,   17.03/s  (0.478s,   16.72/s)  LR: 1.985e-05  Data: 0.008 (0.008)\n",
            "Train: 57 [1300/2354 ( 55%)]  Loss: 1.567 (1.36)  Time: 0.470s,   17.01/s  (0.478s,   16.74/s)  LR: 1.985e-05  Data: 0.010 (0.008)\n",
            "Train: 57 [1350/2354 ( 57%)]  Loss: 0.9712 (1.36)  Time: 0.471s,   16.99/s  (0.478s,   16.75/s)  LR: 1.985e-05  Data: 0.008 (0.008)\n",
            "Train: 57 [1400/2354 ( 59%)]  Loss: 0.9787 (1.36)  Time: 0.465s,   17.19/s  (0.477s,   16.76/s)  LR: 1.985e-05  Data: 0.008 (0.008)\n",
            "Train: 57 [1450/2354 ( 62%)]  Loss: 1.040 (1.36)  Time: 0.468s,   17.09/s  (0.478s,   16.75/s)  LR: 1.985e-05  Data: 0.010 (0.008)\n",
            "Train: 57 [1500/2354 ( 64%)]  Loss: 1.071 (1.36)  Time: 0.465s,   17.21/s  (0.477s,   16.76/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1550/2354 ( 66%)]  Loss: 1.912 (1.36)  Time: 0.467s,   17.13/s  (0.477s,   16.77/s)  LR: 1.985e-05  Data: 0.011 (0.008)\n",
            "Train: 57 [1600/2354 ( 68%)]  Loss: 1.351 (1.36)  Time: 0.467s,   17.15/s  (0.477s,   16.77/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1650/2354 ( 70%)]  Loss: 1.533 (1.36)  Time: 0.476s,   16.80/s  (0.477s,   16.78/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1700/2354 ( 72%)]  Loss: 0.9909 (1.36)  Time: 0.468s,   17.08/s  (0.477s,   16.77/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [1750/2354 ( 74%)]  Loss: 1.039 (1.36)  Time: 0.476s,   16.79/s  (0.477s,   16.78/s)  LR: 1.985e-05  Data: 0.011 (0.008)\n",
            "Train: 57 [1800/2354 ( 76%)]  Loss: 1.531 (1.37)  Time: 0.465s,   17.20/s  (0.477s,   16.79/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [1850/2354 ( 79%)]  Loss: 1.498 (1.37)  Time: 0.471s,   16.98/s  (0.476s,   16.79/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [1900/2354 ( 81%)]  Loss: 0.9533 (1.37)  Time: 0.466s,   17.17/s  (0.476s,   16.80/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [1950/2354 ( 83%)]  Loss: 1.693 (1.36)  Time: 0.473s,   16.92/s  (0.477s,   16.79/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [2000/2354 ( 85%)]  Loss: 1.126 (1.36)  Time: 0.467s,   17.15/s  (0.476s,   16.79/s)  LR: 1.985e-05  Data: 0.007 (0.008)\n",
            "Train: 57 [2050/2354 ( 87%)]  Loss: 0.9694 (1.36)  Time: 0.470s,   17.03/s  (0.476s,   16.80/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [2100/2354 ( 89%)]  Loss: 1.142 (1.36)  Time: 0.466s,   17.15/s  (0.476s,   16.80/s)  LR: 1.985e-05  Data: 0.008 (0.008)\n",
            "Train: 57 [2150/2354 ( 91%)]  Loss: 1.182 (1.35)  Time: 0.468s,   17.09/s  (0.476s,   16.81/s)  LR: 1.985e-05  Data: 0.008 (0.008)\n",
            "Train: 57 [2200/2354 ( 93%)]  Loss: 1.255 (1.36)  Time: 0.466s,   17.17/s  (0.476s,   16.80/s)  LR: 1.985e-05  Data: 0.011 (0.008)\n",
            "Train: 57 [2250/2354 ( 96%)]  Loss: 2.704 (1.36)  Time: 0.465s,   17.22/s  (0.476s,   16.80/s)  LR: 1.985e-05  Data: 0.006 (0.008)\n",
            "Train: 57 [2300/2354 ( 98%)]  Loss: 1.074 (1.36)  Time: 0.471s,   16.99/s  (0.476s,   16.81/s)  LR: 1.985e-05  Data: 0.009 (0.008)\n",
            "Train: 57 [2350/2354 (100%)]  Loss: 1.021 (1.36)  Time: 0.460s,   17.40/s  (0.476s,   16.82/s)  LR: 1.985e-05  Data: 0.005 (0.008)\n",
            "Train: 57 [2353/2354 (100%)]  Loss: 1.030 (1.36)  Time: 0.455s,   17.57/s  (0.476s,   16.82/s)  LR: 1.985e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 1.118 (1.118)  Loss:  0.1763 (0.1763)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.118 (0.160)  Loss:  0.1250 (0.1214)  Acc@1: 100.0000 (99.5098)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.114 (0.151)  Loss:  0.1052 (0.1283)  Acc@1: 100.0000 (99.7525)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.158 (0.147)  Loss:  0.1907 (0.1353)  Acc@1: 100.0000 (99.8344)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.104 (0.145)  Loss:  0.1699 (0.1351)  Acc@1: 100.0000 (99.6269)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.147 (0.153)  Loss:  0.0874 (0.1313)  Acc@1: 100.0000 (99.7012)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.085 (0.150)  Loss:  0.1974 (0.1268)  Acc@1: 100.0000 (99.7508)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.104 (0.149)  Loss:  0.0981 (0.1324)  Acc@1: 100.0000 (99.6439)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 400/2354]  Time: 0.194 (0.148)  Loss:  0.1636 (0.1335)  Acc@1: 100.0000 (99.6883)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 450/2354]  Time: 0.146 (0.148)  Loss:  0.0938 (0.1346)  Acc@1: 100.0000 (99.7228)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 500/2354]  Time: 0.120 (0.147)  Loss:  0.1006 (0.1340)  Acc@1: 100.0000 (99.7505)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 550/2354]  Time: 0.155 (0.147)  Loss:  0.0772 (0.1311)  Acc@1: 100.0000 (99.7731)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 600/2354]  Time: 0.189 (0.147)  Loss:  0.1464 (0.1300)  Acc@1: 100.0000 (99.7920)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 650/2354]  Time: 0.076 (0.146)  Loss:  0.1229 (0.1299)  Acc@1: 100.0000 (99.8080)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 700/2354]  Time: 0.166 (0.146)  Loss:  0.0922 (0.1282)  Acc@1: 100.0000 (99.8217)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 750/2354]  Time: 0.095 (0.145)  Loss:  0.1333 (0.1286)  Acc@1: 100.0000 (99.8336)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 800/2354]  Time: 0.152 (0.145)  Loss:  0.1153 (0.1285)  Acc@1: 100.0000 (99.8127)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 850/2354]  Time: 0.206 (0.145)  Loss:  0.1038 (0.1278)  Acc@1: 100.0000 (99.8237)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 900/2354]  Time: 0.101 (0.145)  Loss:  0.2146 (0.1268)  Acc@1: 100.0000 (99.8335)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 950/2354]  Time: 0.126 (0.145)  Loss:  0.1250 (0.1272)  Acc@1: 100.0000 (99.8423)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1000/2354]  Time: 0.163 (0.144)  Loss:  0.1157 (0.1260)  Acc@1: 100.0000 (99.8501)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1050/2354]  Time: 0.263 (0.145)  Loss:  0.0767 (0.1259)  Acc@1: 100.0000 (99.8573)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1100/2354]  Time: 0.178 (0.146)  Loss:  0.1495 (0.1250)  Acc@1: 100.0000 (99.8638)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1150/2354]  Time: 0.161 (0.146)  Loss:  0.1399 (0.1254)  Acc@1: 100.0000 (99.8480)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1200/2354]  Time: 0.161 (0.146)  Loss:  0.2369 (0.1258)  Acc@1: 100.0000 (99.8335)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1250/2354]  Time: 0.113 (0.146)  Loss:  0.1171 (0.1251)  Acc@1: 100.0000 (99.8401)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1300/2354]  Time: 0.177 (0.146)  Loss:  0.0784 (0.1251)  Acc@1: 100.0000 (99.8463)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1350/2354]  Time: 0.105 (0.146)  Loss:  0.0998 (0.1254)  Acc@1: 100.0000 (99.8520)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1400/2354]  Time: 0.181 (0.145)  Loss:  0.1049 (0.1256)  Acc@1: 100.0000 (99.8394)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1450/2354]  Time: 0.140 (0.145)  Loss:  0.1058 (0.1259)  Acc@1: 100.0000 (99.8449)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1500/2354]  Time: 0.090 (0.145)  Loss:  0.1746 (0.1253)  Acc@1: 100.0000 (99.8501)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1550/2354]  Time: 0.155 (0.145)  Loss:  0.1417 (0.1261)  Acc@1: 100.0000 (99.8549)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1600/2354]  Time: 0.175 (0.145)  Loss:  0.1663 (0.1280)  Acc@1: 100.0000 (99.8438)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1650/2354]  Time: 0.167 (0.145)  Loss:  0.1019 (0.1281)  Acc@1: 100.0000 (99.8183)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1700/2354]  Time: 0.114 (0.145)  Loss:  0.0792 (0.1277)  Acc@1: 100.0000 (99.8236)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1750/2354]  Time: 0.114 (0.145)  Loss:  0.0481 (0.1274)  Acc@1: 100.0000 (99.8287)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1800/2354]  Time: 0.171 (0.145)  Loss:  0.1247 (0.1272)  Acc@1: 100.0000 (99.8334)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1850/2354]  Time: 0.163 (0.145)  Loss:  0.1161 (0.1269)  Acc@1: 100.0000 (99.8244)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1900/2354]  Time: 0.149 (0.146)  Loss:  0.0952 (0.1264)  Acc@1: 100.0000 (99.8290)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [1950/2354]  Time: 0.242 (0.146)  Loss:  0.0703 (0.1261)  Acc@1: 100.0000 (99.8334)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2000/2354]  Time: 0.174 (0.146)  Loss:  0.1046 (0.1259)  Acc@1: 100.0000 (99.8376)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2050/2354]  Time: 0.090 (0.146)  Loss:  0.0702 (0.1261)  Acc@1: 100.0000 (99.8294)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2100/2354]  Time: 0.156 (0.146)  Loss:  0.1290 (0.1267)  Acc@1: 100.0000 (99.8215)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2150/2354]  Time: 0.175 (0.146)  Loss:  0.1488 (0.1260)  Acc@1: 100.0000 (99.8257)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2200/2354]  Time: 0.119 (0.146)  Loss:  0.1204 (0.1265)  Acc@1: 100.0000 (99.7955)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2250/2354]  Time: 0.166 (0.146)  Loss:  0.1259 (0.1265)  Acc@1: 100.0000 (99.7779)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2300/2354]  Time: 0.114 (0.146)  Loss:  0.1418 (0.1264)  Acc@1: 100.0000 (99.7827)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2350/2354]  Time: 0.075 (0.145)  Loss:  0.0812 (0.1263)  Acc@1: 100.0000 (99.7873)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [2354/2354]  Time: 0.214 (0.145)  Loss:  0.0501 (0.1261)  Acc@1: 100.0000 (99.7877)  Acc@5: 100.0000 (100.0000)\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220722-163041-sequencer2d_l-600/checkpoint-57.pth.tar', 99.78766323388895)\n",
            "\n",
            "Train: 58 [   0/2354 (  0%)]  Loss: 1.226 (1.23)  Time: 1.310s,    6.11/s  (1.310s,    6.11/s)  LR: 1.835e-05  Data: 0.480 (0.480)\n",
            "Train: 58 [  50/2354 (  2%)]  Loss: 1.286 (1.35)  Time: 0.472s,   16.94/s  (0.504s,   15.88/s)  LR: 1.835e-05  Data: 0.009 (0.017)\n",
            "Train: 58 [ 100/2354 (  4%)]  Loss: 1.931 (1.38)  Time: 0.473s,   16.92/s  (0.500s,   16.01/s)  LR: 1.835e-05  Data: 0.007 (0.013)\n",
            "Train: 58 [ 150/2354 (  6%)]  Loss: 0.9453 (1.41)  Time: 0.465s,   17.21/s  (0.490s,   16.33/s)  LR: 1.835e-05  Data: 0.007 (0.011)\n",
            "Train: 58 [ 200/2354 (  8%)]  Loss: 1.029 (1.39)  Time: 0.470s,   17.01/s  (0.485s,   16.48/s)  LR: 1.835e-05  Data: 0.009 (0.010)\n",
            "Train: 58 [ 250/2354 ( 11%)]  Loss: 1.460 (1.37)  Time: 0.474s,   16.87/s  (0.483s,   16.58/s)  LR: 1.835e-05  Data: 0.011 (0.010)\n",
            "Train: 58 [ 300/2354 ( 13%)]  Loss: 2.169 (1.37)  Time: 0.468s,   17.08/s  (0.481s,   16.64/s)  LR: 1.835e-05  Data: 0.007 (0.010)\n",
            "Train: 58 [ 350/2354 ( 15%)]  Loss: 0.9814 (1.37)  Time: 0.470s,   17.03/s  (0.483s,   16.57/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [ 400/2354 ( 17%)]  Loss: 0.9931 (1.36)  Time: 0.484s,   16.52/s  (0.482s,   16.61/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [ 450/2354 ( 19%)]  Loss: 2.208 (1.35)  Time: 0.470s,   17.04/s  (0.481s,   16.64/s)  LR: 1.835e-05  Data: 0.008 (0.009)\n",
            "Train: 58 [ 500/2354 ( 21%)]  Loss: 1.121 (1.34)  Time: 0.469s,   17.04/s  (0.480s,   16.67/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [ 550/2354 ( 23%)]  Loss: 0.9575 (1.34)  Time: 0.468s,   17.11/s  (0.479s,   16.69/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [ 600/2354 ( 25%)]  Loss: 2.331 (1.34)  Time: 0.470s,   17.02/s  (0.481s,   16.64/s)  LR: 1.835e-05  Data: 0.008 (0.009)\n",
            "Train: 58 [ 650/2354 ( 28%)]  Loss: 2.578 (1.34)  Time: 0.467s,   17.12/s  (0.480s,   16.67/s)  LR: 1.835e-05  Data: 0.009 (0.009)\n",
            "Train: 58 [ 700/2354 ( 30%)]  Loss: 1.317 (1.34)  Time: 0.471s,   17.00/s  (0.479s,   16.68/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [ 750/2354 ( 32%)]  Loss: 1.304 (1.34)  Time: 0.481s,   16.64/s  (0.479s,   16.70/s)  LR: 1.835e-05  Data: 0.021 (0.009)\n",
            "Train: 58 [ 800/2354 ( 34%)]  Loss: 1.158 (1.34)  Time: 0.477s,   16.77/s  (0.478s,   16.72/s)  LR: 1.835e-05  Data: 0.006 (0.009)\n",
            "Train: 58 [ 850/2354 ( 36%)]  Loss: 1.917 (1.33)  Time: 0.465s,   17.20/s  (0.479s,   16.69/s)  LR: 1.835e-05  Data: 0.006 (0.009)\n",
            "Train: 58 [ 900/2354 ( 38%)]  Loss: 1.787 (1.33)  Time: 0.468s,   17.10/s  (0.479s,   16.71/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [ 950/2354 ( 40%)]  Loss: 1.208 (1.33)  Time: 0.462s,   17.31/s  (0.478s,   16.72/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [1000/2354 ( 42%)]  Loss: 1.069 (1.33)  Time: 0.486s,   16.46/s  (0.478s,   16.74/s)  LR: 1.835e-05  Data: 0.009 (0.009)\n",
            "Train: 58 [1050/2354 ( 45%)]  Loss: 1.028 (1.33)  Time: 0.472s,   16.94/s  (0.478s,   16.75/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [1100/2354 ( 47%)]  Loss: 2.167 (1.34)  Time: 0.471s,   16.98/s  (0.478s,   16.73/s)  LR: 1.835e-05  Data: 0.008 (0.009)\n",
            "Train: 58 [1150/2354 ( 49%)]  Loss: 1.086 (1.34)  Time: 0.487s,   16.43/s  (0.478s,   16.74/s)  LR: 1.835e-05  Data: 0.010 (0.009)\n",
            "Train: 58 [1200/2354 ( 51%)]  Loss: 1.862 (1.34)  Time: 0.468s,   17.08/s  (0.478s,   16.75/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [1250/2354 ( 53%)]  Loss: 1.698 (1.34)  Time: 0.480s,   16.66/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.007 (0.009)\n",
            "Train: 58 [1300/2354 ( 55%)]  Loss: 1.460 (1.34)  Time: 0.464s,   17.25/s  (0.477s,   16.77/s)  LR: 1.835e-05  Data: 0.007 (0.008)\n",
            "Train: 58 [1350/2354 ( 57%)]  Loss: 1.496 (1.34)  Time: 0.474s,   16.87/s  (0.478s,   16.75/s)  LR: 1.835e-05  Data: 0.010 (0.008)\n",
            "Train: 58 [1400/2354 ( 59%)]  Loss: 1.550 (1.34)  Time: 0.474s,   16.88/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.009 (0.008)\n",
            "Train: 58 [1450/2354 ( 62%)]  Loss: 0.9727 (1.35)  Time: 0.472s,   16.96/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.008 (0.008)\n",
            "Train: 58 [1500/2354 ( 64%)]  Loss: 1.032 (1.35)  Time: 0.476s,   16.82/s  (0.477s,   16.77/s)  LR: 1.835e-05  Data: 0.007 (0.008)\n",
            "Train: 58 [1550/2354 ( 66%)]  Loss: 1.467 (1.35)  Time: 0.467s,   17.13/s  (0.477s,   16.78/s)  LR: 1.835e-05  Data: 0.009 (0.008)\n",
            "Train: 58 [1600/2354 ( 68%)]  Loss: 0.9766 (1.35)  Time: 0.473s,   16.92/s  (0.478s,   16.75/s)  LR: 1.835e-05  Data: 0.007 (0.008)\n",
            "Train: 58 [1650/2354 ( 70%)]  Loss: 1.176 (1.35)  Time: 0.478s,   16.73/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.010 (0.008)\n",
            "Train: 58 [1700/2354 ( 72%)]  Loss: 1.696 (1.35)  Time: 0.467s,   17.14/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.007 (0.008)\n",
            "Train: 58 [1750/2354 ( 74%)]  Loss: 1.109 (1.35)  Time: 0.472s,   16.94/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.008 (0.008)\n",
            "Train: 58 [1800/2354 ( 76%)]  Loss: 0.9758 (1.35)  Time: 0.473s,   16.93/s  (0.477s,   16.77/s)  LR: 1.835e-05  Data: 0.008 (0.008)\n",
            "Train: 58 [1850/2354 ( 79%)]  Loss: 0.9625 (1.35)  Time: 0.472s,   16.94/s  (0.478s,   16.75/s)  LR: 1.835e-05  Data: 0.007 (0.008)\n",
            "Train: 58 [1900/2354 ( 81%)]  Loss: 0.9557 (1.35)  Time: 0.466s,   17.18/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.007 (0.008)\n",
            "Train: 58 [1950/2354 ( 83%)]  Loss: 2.261 (1.35)  Time: 0.471s,   17.00/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.007 (0.008)\n",
            "Train: 58 [2000/2354 ( 85%)]  Loss: 1.562 (1.35)  Time: 0.472s,   16.95/s  (0.477s,   16.77/s)  LR: 1.835e-05  Data: 0.008 (0.008)\n",
            "Train: 58 [2050/2354 ( 87%)]  Loss: 1.374 (1.34)  Time: 0.624s,   12.81/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.013 (0.008)\n",
            "Train: 58 [2100/2354 ( 89%)]  Loss: 1.014 (1.35)  Time: 0.474s,   16.86/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.011 (0.008)\n",
            "Train: 58 [2150/2354 ( 91%)]  Loss: 1.770 (1.34)  Time: 0.485s,   16.48/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.007 (0.008)\n",
            "Train: 58 [2200/2354 ( 93%)]  Loss: 2.141 (1.35)  Time: 0.482s,   16.59/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.008 (0.008)\n",
            "Train: 58 [2250/2354 ( 96%)]  Loss: 2.748 (1.34)  Time: 0.479s,   16.70/s  (0.477s,   16.77/s)  LR: 1.835e-05  Data: 0.009 (0.008)\n",
            "Train: 58 [2300/2354 ( 98%)]  Loss: 1.464 (1.34)  Time: 0.470s,   17.03/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.009 (0.008)\n",
            "Train: 58 [2350/2354 (100%)]  Loss: 1.179 (1.34)  Time: 0.461s,   17.36/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.006 (0.008)\n",
            "Train: 58 [2353/2354 (100%)]  Loss: 1.624 (1.34)  Time: 0.458s,   17.45/s  (0.477s,   16.76/s)  LR: 1.835e-05  Data: 0.000 (0.008)\n",
            "Test: [   0/2354]  Time: 0.657 (0.657)  Loss:  0.1508 (0.1508)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/2354]  Time: 0.158 (0.160)  Loss:  0.0970 (0.1246)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 100/2354]  Time: 0.156 (0.151)  Loss:  0.0771 (0.1191)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 150/2354]  Time: 0.077 (0.149)  Loss:  0.0770 (0.1250)  Acc@1: 100.0000 (100.0000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 200/2354]  Time: 0.167 (0.147)  Loss:  0.1639 (0.1259)  Acc@1: 100.0000 (99.8756)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 250/2354]  Time: 0.148 (0.147)  Loss:  0.0890 (0.1198)  Acc@1: 100.0000 (99.9004)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 300/2354]  Time: 0.176 (0.147)  Loss:  0.2499 (0.1217)  Acc@1: 100.0000 (99.9169)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [ 350/2354]  Time: 0.169 (0.147)  Loss:  0.0854 (0.1272)  Acc@1: 100.0000 (99.9288)  Acc@5: 100.0000 (100.0000)\n"
          ]
        }
      ],
      "source": [
        "! python -u -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 --node_rank=0 ./pytorch-image-models/train.py orchidaceae_train --model sequencer2d_l --opt adabelief --lr 0.0001 --epochs 80 --aa v0r-mstd0.5 --aug-splits 2 --jsd-loss --decay-epochs 3 --cooldown-epochs 0 --weight-decay 1e-4 --sched cosine -b 4 --input-size 3 600 600 --num-classes=300 --vflip 0.5 --hflip 0.5 --amp --pretrained --output drive/MyDrive/UNC/H2022/output/ --resume drive/MyDrive/UNC/H2022/output/20220721-160046-sequencer2d_l-600/last.pth.tar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "mMHrwfTNvpQI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "[Summer] GPU-Sequencer2D",
      "provenance": [],
      "mount_file_id": "1lhmCcyiAhsKUJKf_Uzlw5ARR7lkYrMg2",
      "authorship_tag": "ABX9TyMOZ/Il6IpgM9QY01FYi9dR",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}