{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakilaledesma/Atomized_NN_Experiments/blob/main/augmentation_differences/TResNet_600_AugMix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RBv2CGN3gJv",
        "outputId": "7277fbc4-179c-4469-f5ca-9120d3034274"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 126 ms, sys: 25.3 ms, total: 151 ms\n",
            "Wall time: 20.2 s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "! unzip -q drive/MyDrive/UNC/H2022/orchidaceae_train.zip -d /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXOHMDgapMby",
        "outputId": "63d85eb7-f821-454d-a9af-6df33cf3466c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-image-models'...\n",
            "remote: Enumerating objects: 10677, done.\u001b[K\n",
            "remote: Counting objects: 100% (208/208), done.\u001b[K\n",
            "remote: Compressing objects: 100% (125/125), done.\u001b[K\n",
            "remote: Total 10677 (delta 100), reused 152 (delta 78), pack-reused 10469\u001b[K\n",
            "Receiving objects: 100% (10677/10677), 20.34 MiB | 18.57 MiB/s, done.\n",
            "Resolving deltas: 100% (7813/7813), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/rwightman/pytorch-image-models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZkKqSVJeDQt",
        "outputId": "67a9f2f2-ed96-4164-b899-df03ac569c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/mapillary/inplace_abn.git@v1.0.12\n",
            "  Cloning https://github.com/mapillary/inplace_abn.git (to revision v1.0.12) to /tmp/pip-req-build-g4rilgq1\n",
            "  Running command git clone -q https://github.com/mapillary/inplace_abn.git /tmp/pip-req-build-g4rilgq1\n",
            "  Running command git checkout -q 24fc791e6d4796a1639e7a5dce6fa67377e51a3e\n",
            "Building wheels for collected packages: inplace-abn\n",
            "  Building wheel for inplace-abn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for inplace-abn: filename=inplace_abn-1.0.12-cp37-cp37m-linux_x86_64.whl size=2279341 sha256=cbf3e9ff4d029ad0b46b025778d0a1ed8f1ab39d8c1b91d11fe8a741265d871f\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qr6wcf7k/wheels/df/ad/aa/7ec1eff8c9b56fb3fab10471e91c80bdf3b52036bf47727bae\n",
            "Successfully built inplace-abn\n",
            "Installing collected packages: inplace-abn\n",
            "Successfully installed inplace-abn-1.0.12\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/mapillary/inplace_abn.git@v1.0.12"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slckThLBilky"
      },
      "outputs": [],
      "source": [
        "import fileinput\n",
        "import sys\n",
        "\n",
        "def replacement(file, previousw, nextw):\n",
        "   for line in fileinput.input(file, inplace=1):\n",
        "       line = line.replace(previousw, nextw)\n",
        "       sys.stdout.write(line)\n",
        "\n",
        "file = \"/content/pytorch-image-models/timm/utils/checkpoint_saver.py\"\n",
        "replacement(file, \"if os.path.exists(last_save_path):\", \"# if os.path.exists(last_save_path):\")\n",
        "replacement(file, \"os.unlink(last_save_path)  # required for Windows support.\", \"# os.unlink(last_save_path)  # required for Windows support.\")\n",
        "replacement(file, \"os.link(last_save_path, save_path)\", \"# os.link(last_save_path, save_path)\")\n",
        "replacement(file, \"os.unlink(best_save_path)\", \"# os.unlink(best_save_path)\")\n",
        "replacement(file, \"os.link(last_save_path, best_save_path)\", \"# os.link(last_save_path, best_save_path)\")\n",
        "replacement(file, \"if os.path.exists(best_save_path):\", \"# if os.path.exists(best_save_path):\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kIBgHy6pSFD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65ad5992-29d9-45ee-8771-9f6aa51a5ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Training with a single process on 1 GPUs.\n",
            "Loading pretrained weights from url (https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-tresnet/tresnet_m_448-bc359d10.pth)\n",
            "Model tresnet_m_448 created, param count:29954732\n",
            "Data processing configuration for current model + dataset:\n",
            "\tinput_size: (3, 600, 600)\n",
            "\tinterpolation: bilinear\n",
            "\tmean: (0, 0, 0)\n",
            "\tstd: (1, 1, 1)\n",
            "\tcrop_pct: 0.875\n",
            "Using native Torch AMP. Training in mixed precision.\n",
            "Scheduled epochs: 80\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Train: 0 [   0/588 (  0%)]  Loss: 5.780 (5.78)  Time: 32.235s,    1.99/s  (32.235s,    1.99/s)  LR: 1.000e-04  Data: 18.939 (18.939)\n",
            "Train: 0 [  50/588 (  9%)]  Loss: 5.809 (5.69)  Time: 1.114s,   57.44/s  (4.807s,   13.31/s)  LR: 1.000e-04  Data: 0.080 (3.575)\n",
            "Train: 0 [ 100/588 ( 17%)]  Loss: 5.419 (5.63)  Time: 1.109s,   57.70/s  (4.776s,   13.40/s)  LR: 1.000e-04  Data: 0.109 (3.668)\n",
            "Train: 0 [ 150/588 ( 26%)]  Loss: 5.639 (5.56)  Time: 1.102s,   58.07/s  (4.633s,   13.81/s)  LR: 1.000e-04  Data: 0.076 (3.571)\n",
            "Train: 0 [ 200/588 ( 34%)]  Loss: 5.468 (5.47)  Time: 0.999s,   64.05/s  (4.634s,   13.81/s)  LR: 1.000e-04  Data: 0.098 (3.591)\n",
            "Train: 0 [ 250/588 ( 43%)]  Loss: 4.779 (5.38)  Time: 1.094s,   58.48/s  (4.581s,   13.97/s)  LR: 1.000e-04  Data: 0.088 (3.551)\n",
            "Train: 0 [ 300/588 ( 51%)]  Loss: 5.125 (5.29)  Time: 1.046s,   61.18/s  (4.576s,   13.99/s)  LR: 1.000e-04  Data: 0.080 (3.556)\n",
            "Train: 0 [ 350/588 ( 60%)]  Loss: 4.830 (5.21)  Time: 1.107s,   57.82/s  (4.545s,   14.08/s)  LR: 1.000e-04  Data: 0.100 (3.532)\n",
            "Train: 0 [ 400/588 ( 68%)]  Loss: 4.602 (5.12)  Time: 1.051s,   60.88/s  (4.552s,   14.06/s)  LR: 1.000e-04  Data: 0.061 (3.544)\n",
            "Train: 0 [ 450/588 ( 77%)]  Loss: 3.966 (5.04)  Time: 1.162s,   55.06/s  (4.526s,   14.14/s)  LR: 1.000e-04  Data: 0.093 (3.521)\n",
            "Train: 0 [ 500/588 ( 85%)]  Loss: 4.149 (4.96)  Time: 1.061s,   60.30/s  (4.535s,   14.11/s)  LR: 1.000e-04  Data: 0.072 (3.532)\n",
            "Train: 0 [ 550/588 ( 94%)]  Loss: 4.331 (4.89)  Time: 1.043s,   61.37/s  (4.519s,   14.16/s)  LR: 1.000e-04  Data: 0.085 (3.516)\n",
            "Train: 0 [ 587/588 (100%)]  Loss: 4.359 (4.84)  Time: 0.651s,   98.24/s  (4.501s,   14.22/s)  LR: 1.000e-04  Data: 0.000 (3.501)\n",
            "Test: [   0/588]  Time: 2.447 (2.447)  Loss:  4.1289 (4.1289)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 37.5000 (37.5000)\n",
            "Test: [  50/588]  Time: 0.094 (0.359)  Loss:  4.8750 (3.0126)  Acc@1:  0.0000 (33.4559)  Acc@5: 12.5000 (67.1569)\n",
            "Test: [ 100/588]  Time: 0.093 (0.352)  Loss:  2.7188 (3.0010)  Acc@1: 18.7500 (33.8490)  Acc@5: 87.5000 (65.6559)\n",
            "Test: [ 150/588]  Time: 0.093 (0.341)  Loss:  2.8184 (2.9323)  Acc@1: 37.5000 (36.5894)  Acc@5: 81.2500 (67.5497)\n",
            "Test: [ 200/588]  Time: 0.108 (0.351)  Loss:  1.9736 (2.8609)  Acc@1: 50.0000 (38.2774)  Acc@5: 93.7500 (69.2786)\n",
            "Test: [ 250/588]  Time: 0.106 (0.346)  Loss:  3.0273 (2.8158)  Acc@1: 25.0000 (40.7869)  Acc@5: 68.7500 (71.0906)\n",
            "Test: [ 300/588]  Time: 0.117 (0.345)  Loss:  0.9775 (2.7905)  Acc@1: 87.5000 (42.4003)  Acc@5: 93.7500 (71.4286)\n",
            "Test: [ 350/588]  Time: 0.090 (0.341)  Loss:  3.1504 (2.7869)  Acc@1:  6.2500 (41.3462)  Acc@5: 56.2500 (71.2785)\n",
            "Test: [ 400/588]  Time: 0.176 (0.341)  Loss:  2.1289 (2.8087)  Acc@1: 75.0000 (39.8223)  Acc@5: 93.7500 (70.8541)\n",
            "Test: [ 450/588]  Time: 0.114 (0.340)  Loss:  1.7344 (2.7858)  Acc@1: 87.5000 (40.0637)  Acc@5: 87.5000 (71.0920)\n",
            "Test: [ 500/588]  Time: 0.076 (0.339)  Loss:  1.4932 (2.7841)  Acc@1: 81.2500 (40.1946)  Acc@5: 93.7500 (71.2824)\n",
            "Test: [ 550/588]  Time: 0.115 (0.343)  Loss:  4.6445 (2.7781)  Acc@1:  0.0000 (39.7686)  Acc@5: 12.5000 (71.1434)\n",
            "Test: [ 588/588]  Time: 0.599 (0.341)  Loss:  4.0156 (2.8223)  Acc@1:  0.0000 (39.1974)  Acc@5: 18.1818 (70.0074)\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-0.pth.tar', 39.197367024100224)\n",
            "\n",
            "Train: 1 [   0/588 (  0%)]  Loss: 4.121 (4.12)  Time: 19.502s,    3.28/s  (19.502s,    3.28/s)  LR: 4.000e-04  Data: 18.479 (18.479)\n",
            "Train: 1 [  50/588 (  9%)]  Loss: 4.774 (4.48)  Time: 7.366s,    8.69/s  (4.795s,   13.35/s)  LR: 4.000e-04  Data: 6.218 (3.796)\n",
            "Train: 1 [ 100/588 ( 17%)]  Loss: 4.181 (4.48)  Time: 1.092s,   58.62/s  (4.685s,   13.66/s)  LR: 4.000e-04  Data: 0.105 (3.693)\n",
            "Train: 1 [ 150/588 ( 26%)]  Loss: 4.549 (4.46)  Time: 5.803s,   11.03/s  (4.621s,   13.85/s)  LR: 4.000e-04  Data: 4.821 (3.630)\n",
            "Train: 1 [ 200/588 ( 34%)]  Loss: 4.205 (4.40)  Time: 1.043s,   61.33/s  (4.621s,   13.85/s)  LR: 4.000e-04  Data: 0.097 (3.632)\n",
            "Train: 1 [ 250/588 ( 43%)]  Loss: 4.187 (4.37)  Time: 1.059s,   60.46/s  (4.607s,   13.89/s)  LR: 4.000e-04  Data: 0.082 (3.620)\n",
            "Train: 1 [ 300/588 ( 51%)]  Loss: 4.661 (4.34)  Time: 1.655s,   38.68/s  (4.589s,   13.95/s)  LR: 4.000e-04  Data: 0.669 (3.601)\n",
            "Train: 1 [ 350/588 ( 60%)]  Loss: 3.833 (4.30)  Time: 1.069s,   59.89/s  (4.571s,   14.00/s)  LR: 4.000e-04  Data: 0.068 (3.585)\n",
            "Train: 1 [ 400/588 ( 68%)]  Loss: 4.068 (4.26)  Time: 3.041s,   21.05/s  (4.566s,   14.02/s)  LR: 4.000e-04  Data: 2.070 (3.578)\n",
            "Train: 1 [ 450/588 ( 77%)]  Loss: 4.035 (4.23)  Time: 1.042s,   61.42/s  (4.571s,   14.00/s)  LR: 4.000e-04  Data: 0.094 (3.584)\n",
            "Train: 1 [ 500/588 ( 85%)]  Loss: 3.973 (4.20)  Time: 1.029s,   62.19/s  (4.559s,   14.04/s)  LR: 4.000e-04  Data: 0.065 (3.573)\n",
            "Train: 1 [ 550/588 ( 94%)]  Loss: 3.957 (4.17)  Time: 1.101s,   58.11/s  (4.558s,   14.04/s)  LR: 4.000e-04  Data: 0.103 (3.571)\n",
            "Train: 1 [ 587/588 (100%)]  Loss: 3.401 (4.14)  Time: 0.647s,   98.84/s  (4.531s,   14.12/s)  LR: 4.000e-04  Data: 0.000 (3.546)\n",
            "Test: [   0/588]  Time: 1.431 (1.431)  Loss:  4.4805 (4.4805)  Acc@1:  0.0000 ( 0.0000)  Acc@5: 18.7500 (18.7500)\n",
            "Test: [  50/588]  Time: 0.092 (0.350)  Loss:  5.1055 (2.7680)  Acc@1:  0.0000 (31.9853)  Acc@5:  6.2500 (67.2794)\n",
            "Test: [ 100/588]  Time: 0.086 (0.346)  Loss:  2.1387 (2.6097)  Acc@1: 43.7500 (37.5000)  Acc@5: 93.7500 (72.0916)\n",
            "Test: [ 150/588]  Time: 0.090 (0.340)  Loss:  2.5391 (2.4654)  Acc@1: 37.5000 (43.1291)  Acc@5: 75.0000 (75.3725)\n",
            "Test: [ 200/588]  Time: 0.096 (0.340)  Loss:  1.4951 (2.4318)  Acc@1: 75.0000 (44.5585)  Acc@5: 93.7500 (75.2799)\n",
            "Test: [ 250/588]  Time: 0.119 (0.337)  Loss:  3.5195 (2.3453)  Acc@1:  6.2500 (46.4890)  Acc@5: 43.7500 (77.0667)\n",
            "Test: [ 300/588]  Time: 0.227 (0.343)  Loss:  1.9502 (2.3295)  Acc@1: 68.7500 (46.9477)  Acc@5: 87.5000 (77.1595)\n",
            "Test: [ 350/588]  Time: 0.089 (0.341)  Loss:  1.6914 (2.3623)  Acc@1: 68.7500 (46.7415)  Acc@5: 93.7500 (76.5135)\n",
            "Test: [ 400/588]  Time: 0.092 (0.340)  Loss:  1.5947 (2.3786)  Acc@1: 68.7500 (45.9009)  Acc@5: 100.0000 (76.7145)\n",
            "Test: [ 450/588]  Time: 0.109 (0.340)  Loss:  2.9941 (2.3947)  Acc@1: 50.0000 (44.7894)  Acc@5: 87.5000 (76.4135)\n",
            "Test: [ 500/588]  Time: 0.083 (0.340)  Loss:  1.3057 (2.3975)  Acc@1: 81.2500 (45.4341)  Acc@5: 93.7500 (76.3972)\n",
            "Test: [ 550/588]  Time: 0.084 (0.338)  Loss:  4.4180 (2.3860)  Acc@1: 18.7500 (45.1565)  Acc@5: 31.2500 (76.4973)\n",
            "Test: [ 588/588]  Time: 0.043 (0.336)  Loss:  3.2188 (2.4287)  Acc@1:  0.0000 (44.3253)  Acc@5: 54.5455 (75.4645)\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-1.pth.tar', 44.32529992568213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-0.pth.tar', 39.197367024100224)\n",
            "\n",
            "Train: 2 [   0/588 (  0%)]  Loss: 3.487 (3.49)  Time: 19.495s,    3.28/s  (19.495s,    3.28/s)  LR: 7.000e-04  Data: 18.498 (18.498)\n",
            "Train: 2 [  50/588 (  9%)]  Loss: 4.055 (4.00)  Time: 1.031s,   62.09/s  (4.747s,   13.48/s)  LR: 7.000e-04  Data: 0.092 (3.749)\n",
            "Train: 2 [ 100/588 ( 17%)]  Loss: 3.819 (3.99)  Time: 1.082s,   59.12/s  (4.703s,   13.61/s)  LR: 7.000e-04  Data: 0.105 (3.703)\n",
            "Train: 2 [ 150/588 ( 26%)]  Loss: 4.144 (3.98)  Time: 4.926s,   12.99/s  (4.590s,   13.94/s)  LR: 7.000e-04  Data: 3.967 (3.594)\n",
            "Train: 2 [ 200/588 ( 34%)]  Loss: 4.264 (3.97)  Time: 1.026s,   62.36/s  (4.579s,   13.98/s)  LR: 7.000e-04  Data: 0.104 (3.585)\n",
            "Train: 2 [ 250/588 ( 43%)]  Loss: 3.701 (3.96)  Time: 5.751s,   11.13/s  (4.558s,   14.04/s)  LR: 7.000e-04  Data: 4.825 (3.561)\n",
            "Train: 2 [ 300/588 ( 51%)]  Loss: 3.551 (3.94)  Time: 1.027s,   62.30/s  (4.547s,   14.07/s)  LR: 7.000e-04  Data: 0.073 (3.553)\n",
            "Train: 2 [ 350/588 ( 60%)]  Loss: 3.435 (3.92)  Time: 9.089s,    7.04/s  (4.547s,   14.07/s)  LR: 7.000e-04  Data: 8.079 (3.555)\n",
            "Train: 2 [ 400/588 ( 68%)]  Loss: 3.562 (3.90)  Time: 1.117s,   57.31/s  (4.538s,   14.10/s)  LR: 7.000e-04  Data: 0.105 (3.546)\n",
            "Train: 2 [ 450/588 ( 77%)]  Loss: 3.146 (3.88)  Time: 14.169s,    4.52/s  (4.544s,   14.08/s)  LR: 7.000e-04  Data: 13.215 (3.551)\n",
            "Train: 2 [ 500/588 ( 85%)]  Loss: 3.889 (3.86)  Time: 1.035s,   61.85/s  (4.534s,   14.11/s)  LR: 7.000e-04  Data: 0.076 (3.542)\n",
            "Train: 2 [ 550/588 ( 94%)]  Loss: 3.310 (3.85)  Time: 6.247s,   10.25/s  (4.535s,   14.11/s)  LR: 7.000e-04  Data: 5.272 (3.542)\n",
            "Train: 2 [ 587/588 (100%)]  Loss: 4.179 (3.83)  Time: 0.646s,   99.14/s  (4.503s,   14.21/s)  LR: 7.000e-04  Data: 0.000 (3.513)\n",
            "Test: [   0/588]  Time: 1.453 (1.453)  Loss:  2.6367 (2.6367)  Acc@1: 50.0000 (50.0000)  Acc@5: 62.5000 (62.5000)\n",
            "Test: [  50/588]  Time: 0.099 (0.347)  Loss:  3.5977 (2.4516)  Acc@1: 12.5000 (47.0588)  Acc@5: 31.2500 (73.7745)\n",
            "Test: [ 100/588]  Time: 0.078 (0.345)  Loss:  2.9004 (2.5131)  Acc@1:  0.0000 (44.3069)  Acc@5: 81.2500 (74.6287)\n",
            "Test: [ 150/588]  Time: 0.108 (0.351)  Loss:  1.8223 (2.2722)  Acc@1: 62.5000 (49.5033)  Acc@5: 100.0000 (78.8079)\n",
            "Test: [ 200/588]  Time: 0.098 (0.350)  Loss:  0.9121 (2.2033)  Acc@1: 93.7500 (51.1816)  Acc@5: 93.7500 (79.7886)\n",
            "Test: [ 250/588]  Time: 0.110 (0.345)  Loss:  1.7637 (2.1561)  Acc@1: 68.7500 (50.6723)  Acc@5: 93.7500 (81.4492)\n",
            "Test: [ 300/588]  Time: 0.533 (0.343)  Loss:  1.9072 (2.1746)  Acc@1: 62.5000 (50.8306)  Acc@5: 81.2500 (80.7517)\n",
            "Test: [ 350/588]  Time: 0.101 (0.342)  Loss:  1.0420 (2.1623)  Acc@1: 81.2500 (51.4601)  Acc@5: 100.0000 (80.9473)\n",
            "Test: [ 400/588]  Time: 0.094 (0.340)  Loss:  1.6074 (2.2042)  Acc@1: 75.0000 (49.9221)  Acc@5: 87.5000 (79.6758)\n",
            "Test: [ 450/588]  Time: 0.087 (0.340)  Loss:  2.1426 (2.2383)  Acc@1: 75.0000 (48.8775)  Acc@5: 87.5000 (79.0604)\n",
            "Test: [ 500/588]  Time: 0.083 (0.343)  Loss:  1.5420 (2.2243)  Acc@1: 68.7500 (49.2889)  Acc@5: 93.7500 (79.3164)\n",
            "Test: [ 550/588]  Time: 0.105 (0.342)  Loss:  4.1250 (2.2504)  Acc@1:  0.0000 (48.6388)  Acc@5: 18.7500 (78.9927)\n",
            "Test: [ 588/588]  Time: 0.043 (0.339)  Loss:  3.4688 (2.2611)  Acc@1:  9.0909 (48.7207)  Acc@5: 63.6364 (78.7132)\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-2.pth.tar', 48.72067098407966)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-1.pth.tar', 44.32529992568213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-0.pth.tar', 39.197367024100224)\n",
            "\n",
            "Train: 3 [   0/588 (  0%)]  Loss: 3.308 (3.31)  Time: 19.812s,    3.23/s  (19.812s,    3.23/s)  LR: 9.965e-04  Data: 18.777 (18.777)\n",
            "Train: 3 [  50/588 (  9%)]  Loss: 3.375 (3.73)  Time: 1.074s,   59.60/s  (4.649s,   13.77/s)  LR: 9.965e-04  Data: 0.088 (3.652)\n",
            "Train: 3 [ 100/588 ( 17%)]  Loss: 3.747 (3.75)  Time: 1.073s,   59.66/s  (4.662s,   13.73/s)  LR: 9.965e-04  Data: 0.086 (3.663)\n",
            "Train: 3 [ 150/588 ( 26%)]  Loss: 3.360 (3.75)  Time: 1.070s,   59.81/s  (4.551s,   14.06/s)  LR: 9.965e-04  Data: 0.073 (3.555)\n",
            "Train: 3 [ 200/588 ( 34%)]  Loss: 3.257 (3.71)  Time: 1.056s,   60.61/s  (4.563s,   14.03/s)  LR: 9.965e-04  Data: 0.112 (3.567)\n",
            "Train: 3 [ 250/588 ( 43%)]  Loss: 3.832 (3.70)  Time: 1.054s,   60.73/s  (4.560s,   14.04/s)  LR: 9.965e-04  Data: 0.077 (3.562)\n",
            "Train: 3 [ 300/588 ( 51%)]  Loss: 3.976 (3.69)  Time: 4.362s,   14.67/s  (4.575s,   13.99/s)  LR: 9.965e-04  Data: 3.362 (3.579)\n",
            "Train: 3 [ 350/588 ( 60%)]  Loss: 3.365 (3.70)  Time: 1.086s,   58.94/s  (4.567s,   14.01/s)  LR: 9.965e-04  Data: 0.109 (3.572)\n",
            "Train: 3 [ 400/588 ( 68%)]  Loss: 3.455 (3.69)  Time: 2.852s,   22.44/s  (4.550s,   14.07/s)  LR: 9.965e-04  Data: 1.850 (3.557)\n",
            "Train: 3 [ 450/588 ( 77%)]  Loss: 3.726 (3.68)  Time: 1.078s,   59.38/s  (4.530s,   14.13/s)  LR: 9.965e-04  Data: 0.108 (3.536)\n",
            "Train: 3 [ 500/588 ( 85%)]  Loss: 3.316 (3.66)  Time: 7.405s,    8.64/s  (4.539s,   14.10/s)  LR: 9.965e-04  Data: 6.331 (3.544)\n",
            "Train: 3 [ 550/588 ( 94%)]  Loss: 3.470 (3.65)  Time: 1.042s,   61.45/s  (4.516s,   14.17/s)  LR: 9.965e-04  Data: 0.068 (3.522)\n",
            "Train: 3 [ 587/588 (100%)]  Loss: 2.959 (3.65)  Time: 0.646s,   99.04/s  (4.495s,   14.24/s)  LR: 9.965e-04  Data: 0.000 (3.503)\n",
            "Test: [   0/588]  Time: 1.471 (1.471)  Loss:  2.8398 (2.8398)  Acc@1: 43.7500 (43.7500)  Acc@5: 56.2500 (56.2500)\n",
            "Test: [  50/588]  Time: 0.085 (0.349)  Loss:  4.3555 (2.1622)  Acc@1:  0.0000 (55.1471)  Acc@5:  0.0000 (81.8627)\n",
            "Test: [ 100/588]  Time: 0.106 (0.363)  Loss:  1.4902 (2.2320)  Acc@1: 75.0000 (51.4233)  Acc@5: 87.5000 (79.8267)\n",
            "Test: [ 150/588]  Time: 0.109 (0.350)  Loss:  2.7188 (2.2306)  Acc@1: 50.0000 (52.3179)  Acc@5: 81.2500 (80.4636)\n",
            "Test: [ 200/588]  Time: 0.105 (0.346)  Loss:  0.9810 (2.1606)  Acc@1: 93.7500 (53.1405)  Acc@5: 93.7500 (81.6853)\n",
            "Test: [ 250/588]  Time: 0.126 (0.345)  Loss:  2.5078 (2.1504)  Acc@1: 12.5000 (52.9631)  Acc@5: 93.7500 (82.8934)\n",
            "Test: [ 300/588]  Time: 0.082 (0.341)  Loss:  1.6885 (2.1160)  Acc@1: 68.7500 (54.2151)  Acc@5: 81.2500 (83.7209)\n",
            "Test: [ 350/588]  Time: 0.105 (0.342)  Loss:  1.7012 (2.0838)  Acc@1: 75.0000 (54.8611)  Acc@5: 100.0000 (84.3127)\n",
            "Test: [ 400/588]  Time: 0.105 (0.340)  Loss:  1.5410 (2.0851)  Acc@1: 68.7500 (54.3641)  Acc@5: 100.0000 (84.3516)\n",
            "Test: [ 450/588]  Time: 0.084 (0.343)  Loss:  1.0400 (2.0692)  Acc@1: 93.7500 (55.0028)  Acc@5: 100.0000 (84.6591)\n",
            "Test: [ 500/588]  Time: 0.111 (0.342)  Loss:  1.3457 (2.0616)  Acc@1: 81.2500 (55.0025)  Acc@5: 93.7500 (84.8428)\n",
            "Test: [ 550/588]  Time: 0.099 (0.341)  Loss:  3.4551 (2.0597)  Acc@1: 18.7500 (54.6506)  Acc@5: 43.7500 (84.9819)\n",
            "Test: [ 588/588]  Time: 0.043 (0.338)  Loss:  2.6621 (2.0748)  Acc@1: 36.3636 (54.2096)  Acc@5: 90.9091 (84.7011)\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-3.pth.tar', 54.20957638774661)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-2.pth.tar', 48.72067098407966)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-1.pth.tar', 44.32529992568213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-0.pth.tar', 39.197367024100224)\n",
            "\n",
            "Train: 4 [   0/588 (  0%)]  Loss: 3.102 (3.10)  Time: 18.898s,    3.39/s  (18.898s,    3.39/s)  LR: 9.939e-04  Data: 17.908 (17.908)\n",
            "Train: 4 [  50/588 (  9%)]  Loss: 2.884 (3.37)  Time: 4.725s,   13.55/s  (4.687s,   13.65/s)  LR: 9.939e-04  Data: 3.760 (3.705)\n",
            "Train: 4 [ 100/588 ( 17%)]  Loss: 3.782 (3.35)  Time: 2.669s,   23.98/s  (4.599s,   13.92/s)  LR: 9.939e-04  Data: 1.667 (3.611)\n",
            "Train: 4 [ 150/588 ( 26%)]  Loss: 3.007 (3.33)  Time: 1.079s,   59.32/s  (4.546s,   14.08/s)  LR: 9.939e-04  Data: 0.080 (3.556)\n",
            "Train: 4 [ 200/588 ( 34%)]  Loss: 2.934 (3.34)  Time: 8.301s,    7.71/s  (4.574s,   13.99/s)  LR: 9.939e-04  Data: 7.227 (3.586)\n",
            "Train: 4 [ 250/588 ( 43%)]  Loss: 3.577 (3.34)  Time: 1.403s,   45.63/s  (4.522s,   14.15/s)  LR: 9.939e-04  Data: 0.154 (3.532)\n",
            "Train: 4 [ 300/588 ( 51%)]  Loss: 2.824 (3.34)  Time: 3.225s,   19.84/s  (4.531s,   14.12/s)  LR: 9.939e-04  Data: 2.207 (3.539)\n",
            "Train: 4 [ 350/588 ( 60%)]  Loss: 3.480 (3.34)  Time: 1.102s,   58.07/s  (4.522s,   14.15/s)  LR: 9.939e-04  Data: 0.089 (3.531)\n",
            "Train: 4 [ 400/588 ( 68%)]  Loss: 3.517 (3.33)  Time: 2.515s,   25.45/s  (4.497s,   14.23/s)  LR: 9.939e-04  Data: 1.542 (3.508)\n",
            "Train: 4 [ 450/588 ( 77%)]  Loss: 3.586 (3.32)  Time: 1.101s,   58.13/s  (4.509s,   14.19/s)  LR: 9.939e-04  Data: 0.099 (3.519)\n",
            "Train: 4 [ 500/588 ( 85%)]  Loss: 2.913 (3.32)  Time: 1.082s,   59.16/s  (4.490s,   14.25/s)  LR: 9.939e-04  Data: 0.077 (3.498)\n",
            "Train: 4 [ 550/588 ( 94%)]  Loss: 2.992 (3.32)  Time: 1.096s,   58.40/s  (4.502s,   14.22/s)  LR: 9.939e-04  Data: 0.103 (3.508)\n",
            "Train: 4 [ 587/588 (100%)]  Loss: 3.063 (3.31)  Time: 0.646s,   99.09/s  (4.475s,   14.30/s)  LR: 9.939e-04  Data: 0.000 (3.485)\n",
            "Test: [   0/588]  Time: 1.469 (1.469)  Loss:  1.4258 (1.4258)  Acc@1: 75.0000 (75.0000)  Acc@5: 93.7500 (93.7500)\n",
            "Test: [  50/588]  Time: 0.114 (0.388)  Loss:  3.4258 (1.9880)  Acc@1:  6.2500 (57.3529)  Acc@5: 56.2500 (86.8873)\n",
            "Test: [ 100/588]  Time: 0.087 (0.357)  Loss:  1.7344 (2.1712)  Acc@1: 62.5000 (49.5668)  Acc@5: 87.5000 (82.2401)\n",
            "Test: [ 150/588]  Time: 0.106 (0.353)  Loss:  2.8379 (2.0001)  Acc@1: 43.7500 (54.4702)  Acc@5: 87.5000 (84.5199)\n",
            "Test: [ 200/588]  Time: 0.103 (0.346)  Loss:  1.5039 (1.9511)  Acc@1: 75.0000 (55.8147)  Acc@5: 93.7500 (85.2301)\n",
            "Test: [ 250/588]  Time: 0.096 (0.346)  Loss:  1.6748 (1.8597)  Acc@1: 75.0000 (57.9930)  Acc@5: 93.7500 (86.6036)\n",
            "Test: [ 300/588]  Time: 0.072 (0.343)  Loss:  0.5952 (1.7995)  Acc@1: 93.7500 (59.6553)  Acc@5: 100.0000 (87.2508)\n",
            "Test: [ 350/588]  Time: 0.110 (0.347)  Loss:  1.1387 (1.7843)  Acc@1: 68.7500 (59.7222)  Acc@5: 100.0000 (87.3932)\n",
            "Test: [ 400/588]  Time: 0.121 (0.344)  Loss:  0.3884 (1.7580)  Acc@1: 100.0000 (60.1309)  Acc@5: 100.0000 (87.9052)\n",
            "Test: [ 450/588]  Time: 0.083 (0.344)  Loss:  1.3975 (1.7397)  Acc@1: 75.0000 (60.1857)  Acc@5: 93.7500 (88.1652)\n",
            "Test: [ 500/588]  Time: 0.099 (0.342)  Loss:  0.9233 (1.7256)  Acc@1: 87.5000 (60.9656)  Acc@5: 93.7500 (88.1362)\n",
            "Test: [ 550/588]  Time: 0.103 (0.341)  Loss:  2.5820 (1.7488)  Acc@1: 25.0000 (60.0386)  Acc@5: 87.5000 (88.0331)\n",
            "Test: [ 588/588]  Time: 0.043 (0.338)  Loss:  2.4258 (1.7458)  Acc@1: 36.3636 (60.1550)  Acc@5: 100.0000 (88.0136)\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-4.pth.tar', 60.15500583885607)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-3.pth.tar', 54.20957638774661)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-2.pth.tar', 48.72067098407966)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-1.pth.tar', 44.32529992568213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-0.pth.tar', 39.197367024100224)\n",
            "\n",
            "Train: 5 [   0/588 (  0%)]  Loss: 2.766 (2.77)  Time: 21.195s,    3.02/s  (21.195s,    3.02/s)  LR: 9.904e-04  Data: 20.226 (20.226)\n",
            "Train: 5 [  50/588 (  9%)]  Loss: 2.804 (3.05)  Time: 1.003s,   63.82/s  (4.684s,   13.66/s)  LR: 9.904e-04  Data: 0.106 (3.696)\n",
            "Train: 5 [ 100/588 ( 17%)]  Loss: 2.435 (3.11)  Time: 0.985s,   64.95/s  (4.638s,   13.80/s)  LR: 9.904e-04  Data: 0.081 (3.647)\n",
            "Train: 5 [ 150/588 ( 26%)]  Loss: 3.110 (3.11)  Time: 1.089s,   58.79/s  (4.535s,   14.11/s)  LR: 9.904e-04  Data: 0.074 (3.546)\n",
            "Train: 5 [ 200/588 ( 34%)]  Loss: 3.190 (3.13)  Time: 1.104s,   57.99/s  (4.547s,   14.08/s)  LR: 9.904e-04  Data: 0.091 (3.558)\n",
            "Train: 5 [ 250/588 ( 43%)]  Loss: 2.930 (3.13)  Time: 12.157s,    5.26/s  (4.552s,   14.06/s)  LR: 9.904e-04  Data: 11.120 (3.562)\n",
            "Train: 5 [ 300/588 ( 51%)]  Loss: 3.393 (3.12)  Time: 1.080s,   59.28/s  (4.540s,   14.10/s)  LR: 9.904e-04  Data: 0.111 (3.551)\n",
            "Train: 5 [ 350/588 ( 60%)]  Loss: 2.558 (3.11)  Time: 14.126s,    4.53/s  (4.540s,   14.10/s)  LR: 9.904e-04  Data: 13.141 (3.552)\n",
            "Train: 5 [ 400/588 ( 68%)]  Loss: 3.066 (3.12)  Time: 1.070s,   59.82/s  (4.513s,   14.18/s)  LR: 9.904e-04  Data: 0.086 (3.525)\n",
            "Train: 5 [ 450/588 ( 77%)]  Loss: 2.641 (3.12)  Time: 12.113s,    5.28/s  (4.516s,   14.17/s)  LR: 9.904e-04  Data: 11.164 (3.526)\n",
            "Train: 5 [ 500/588 ( 85%)]  Loss: 2.991 (3.12)  Time: 1.110s,   57.65/s  (4.513s,   14.18/s)  LR: 9.904e-04  Data: 0.101 (3.523)\n",
            "Train: 5 [ 550/588 ( 94%)]  Loss: 3.357 (3.12)  Time: 11.955s,    5.35/s  (4.515s,   14.17/s)  LR: 9.904e-04  Data: 10.964 (3.527)\n",
            "Train: 5 [ 587/588 (100%)]  Loss: 3.012 (3.12)  Time: 0.647s,   98.91/s  (4.483s,   14.28/s)  LR: 9.904e-04  Data: 0.000 (3.498)\n",
            "Test: [   0/588]  Time: 1.465 (1.465)  Loss:  1.3486 (1.3486)  Acc@1: 62.5000 (62.5000)  Acc@5: 100.0000 (100.0000)\n",
            "Test: [  50/588]  Time: 0.107 (0.346)  Loss:  2.8281 (1.4156)  Acc@1: 31.2500 (68.7500)  Acc@5: 68.7500 (92.8922)\n",
            "Test: [ 100/588]  Time: 0.656 (0.360)  Loss:  1.0820 (1.4796)  Acc@1: 81.2500 (68.6262)  Acc@5: 93.7500 (92.3886)\n",
            "Test: [ 150/588]  Time: 0.088 (0.351)  Loss:  1.4775 (1.3841)  Acc@1: 68.7500 (70.5298)  Acc@5: 87.5000 (93.2533)\n",
            "Test: [ 200/588]  Time: 0.599 (0.345)  Loss:  1.5029 (1.3707)  Acc@1: 75.0000 (71.5485)  Acc@5: 93.7500 (93.0659)\n",
            "Test: [ 250/588]  Time: 0.113 (0.342)  Loss:  1.9111 (1.3236)  Acc@1: 68.7500 (73.6056)  Acc@5: 93.7500 (93.7251)\n",
            "Test: [ 300/588]  Time: 0.232 (0.340)  Loss:  0.7251 (1.3077)  Acc@1: 87.5000 (74.4186)  Acc@5: 93.7500 (93.6462)\n",
            "Test: [ 350/588]  Time: 0.107 (0.340)  Loss:  0.5791 (1.2910)  Acc@1: 100.0000 (74.7863)  Acc@5: 100.0000 (93.5719)\n",
            "Test: [ 400/588]  Time: 0.151 (0.343)  Loss:  0.5537 (1.3056)  Acc@1: 100.0000 (73.4414)  Acc@5: 100.0000 (93.6565)\n",
            "Test: [ 450/588]  Time: 0.114 (0.342)  Loss:  1.4131 (1.3199)  Acc@1: 68.7500 (72.4224)  Acc@5: 93.7500 (93.3897)\n",
            "Test: [ 500/588]  Time: 0.115 (0.340)  Loss:  0.6719 (1.3173)  Acc@1: 93.7500 (72.9167)  Acc@5: 100.0000 (93.4506)\n",
            "Test: [ 550/588]  Time: 0.118 (0.340)  Loss:  1.4443 (1.3199)  Acc@1: 75.0000 (72.3457)  Acc@5: 93.7500 (93.3417)\n",
            "Test: [ 588/588]  Time: 0.043 (0.337)  Loss:  0.9536 (1.3167)  Acc@1: 81.8182 (72.4281)  Acc@5: 100.0000 (93.3432)\n",
            "Current checkpoints:\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-5.pth.tar', 72.42807092290988)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-4.pth.tar', 60.15500583885607)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-3.pth.tar', 54.20957638774661)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-2.pth.tar', 48.72067098407966)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-1.pth.tar', 44.32529992568213)\n",
            " ('drive/MyDrive/UNC/H2022/output/20220721-164211-tresnet_m_448-600/checkpoint-0.pth.tar', 39.197367024100224)\n",
            "\n",
            "Train: 6 [   0/588 (  0%)]  Loss: 2.638 (2.64)  Time: 19.331s,    3.31/s  (19.331s,    3.31/s)  LR: 9.862e-04  Data: 18.298 (18.298)\n",
            "Train: 6 [  50/588 (  9%)]  Loss: 2.942 (2.91)  Time: 1.084s,   59.03/s  (4.701s,   13.61/s)  LR: 9.862e-04  Data: 0.107 (3.714)\n",
            "Train: 6 [ 100/588 ( 17%)]  Loss: 2.553 (2.92)  Time: 7.218s,    8.87/s  (4.660s,   13.74/s)  LR: 9.862e-04  Data: 6.263 (3.677)\n",
            "Train: 6 [ 150/588 ( 26%)]  Loss: 2.305 (2.91)  Time: 1.070s,   59.82/s  (4.550s,   14.06/s)  LR: 9.862e-04  Data: 0.114 (3.564)\n",
            "Train: 6 [ 200/588 ( 34%)]  Loss: 2.631 (2.92)  Time: 5.042s,   12.69/s  (4.565s,   14.02/s)  LR: 9.862e-04  Data: 4.044 (3.579)\n",
            "Train: 6 [ 250/588 ( 43%)]  Loss: 3.225 (2.94)  Time: 1.055s,   60.65/s  (4.519s,   14.16/s)  LR: 9.862e-04  Data: 0.076 (3.534)\n",
            "Train: 6 [ 300/588 ( 51%)]  Loss: 3.097 (2.94)  Time: 1.074s,   59.62/s  (4.545s,   14.08/s)  LR: 9.862e-04  Data: 0.103 (3.561)\n",
            "Train: 6 [ 350/588 ( 60%)]  Loss: 2.155 (2.95)  Time: 5.848s,   10.94/s  (4.521s,   14.16/s)  LR: 9.862e-04  Data: 4.864 (3.536)\n"
          ]
        }
      ],
      "source": [
        "! python -u -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 --node_rank=0 ./pytorch-image-models/train.py orchidaceae_train --model tresnet_m_448 --opt adabelief --lr 0.001 --epochs 80 --aa augmix-m5-w4-mstd0.5 --aug-splits 4 --jsd-loss --decay-epochs 3 --cooldown-epochs 0 --weight-decay 1e-4 --sched cosine -b 16 --input-size 3 600 600 --num-classes=300 --vflip 0.5 --hflip 0.5 --amp --pretrained --output drive/MyDrive/UNC/H2022/output/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhBwjDtON9GP"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "[Summer] GPU-TResNet 600-AugMix",
      "provenance": [],
      "mount_file_id": "1Xivofk1gxkaYI_okV2fDVJdbxnrkDNRo",
      "authorship_tag": "ABX9TyOupk/lDAHnphSdusSE810j",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}